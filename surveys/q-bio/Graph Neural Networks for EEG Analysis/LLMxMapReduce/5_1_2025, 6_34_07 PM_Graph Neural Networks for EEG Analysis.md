# 5/1/2025, 6:34:07 PM_Graph Neural Networks for EEG Analysis  

# 0. Graph Neural Networks for EEG Analysis  

# 1. Introduction  

Electroencephalography (EEG) is a non-invasive neurophysiological technique that measures the electrical activity of the brain via electrodes placed on the scalp. The analysis of EEG signals provides crucial insights into brain function and has garnered significant attention across diverse fields, including clinical diagnosis, neuroscience research, and Brain-Computer Interfaces (BCIs) [12,17,22,32,35]. EEG signals offer advantages such as high temporal resolution, non-invasiveness, and relative affordability [9,22].​  

Despite its broad utility, EEG analysis presents substantial challenges. Traditional signal processing and statistical methods often struggle to adequately capture the intrinsic complexity and non-linearity inherent in EEG signals [31,32]. Furthermore, EEG data is characterized by non-stationarity, high dimensionality, and significant inter-subject variability [24,42]. Conventional approaches frequently overlook the spatial distribution and relationships between EEG electrodes and signals [37], relying on laborious manual feature extraction [6,22] or simplified models that fail to exploit the rich correlational structure within the data. These limitations hinder accurate and reliable interpretations for downstream tasks like disease diagnosis or affective state estimation [28].  

Recently, Graph Neural Networks (GNNs) have emerged as a powerful class of deep learning models specifically designed to process data structured as graphs [18,19,21,29,33]. Unlike traditional neural networks limited to regular grid structures, GNNs excel at capturing complex relationships and dependencies by leveraging the inherent connections between data points represented as nodes and edges [18,19]. The core idea behind GNNs is to iteratively aggregate information from neighboring nodes to update node representations, effectively learning patterns across the graph structure [18].​  

The application of GNNs is particularly well-suited for EEG analysis due to the intrinsic graph structure of EEG data. EEG electrodes placed on the scalp can be naturally represented as nodes in a graph, while the functional or structural connectivity between these electrodes or underlying brain regions can be modeled as edges. This representation allows GNNs to explicitly capture both local and global inter-channel relationships and spatial information [7,8,37].​  

![](images/0740cfb21f7ff830d2a54d8607f709d21bc7c59368b653e36871662afac4fd9f.jpg)  

The motivation for employing GNNs in EEG analysis stems directly from the need to overcome the aforementioned limitations of traditional methods and improve performance across various tasks. Researchers are driven to utilize GNNs to effectively model the topological structure of EEG channels and capture functional relationships [7,8], thereby achieving higher accuracy in tasks such as emotion recognition [7,8] and brain network analysis [4,11]. GNN-based frameworks aim to unleash the full potential of brain network analysis by adapting model architectures to specific network characteristics [4] and enhancing feature extraction and pattern recognition capabilities for complex EEG data [42]. Furthermore, GNNs, including variants like Graph-Generative Neural Networks (GGNs), are explored to characterize dynamic brain functional connectivity, which is crucial for detecting transient neurological events like epileptic seizures [2].  

Despite the promise, applying GNNs to EEG data presents its own set of challenges. Key issues include data scarcity, which limits the ability to train complex deep learning models effectively [9,14]; the critical need to simultaneously capture both spatial dependencies (connectivity) and temporal dynamics inherent in EEG signals [1,5,17]; significant inter-subject variability that hampers the generalization of trained models [8]; and challenges posed by noisy labels and data heterogeneity [8,20]. Low spatiotemporal resolution in scalp EEG also remains a challenge, particularly for analyzing dynamic connectivity [2].  

This survey provides a comprehensive review of recent advancements in applying GNNs for EEG analysis. It aims to synthesize existing research, categorize different GNN architectures and methodologies used for various EEG tasks, and discuss how these approaches address the unique challenges of EEG data. The survey is structured as follows: Section 2 provides background on EEG signal processing and traditional analysis methods. Section 3 introduces the fundamentals of Graph Neural Networks relevant to EEG. Section 4 reviews existing GNN-based methods categorized by their architectural approaches. Section 5 discusses the applications of GNNs in specific EEG analysis tasks, such as emotion recognition, motor imagery, seizure detection, and neurological disorder diagnosis [17]. Section 6 delves into the challenges specific to applying GNNs in this domain and potential future research directions [1,2,9,17,23]. Finally, Section 7 concludes the survey.  

# 2. Fundamentals of EEG and Graph Neural Networks  

This section provides a foundational understanding of Electroencephalography (EEG) and Graph Neural Networks (GNNs), the two core components that form the basis of this survey. Establishing the principles of both techniques is essential for comprehending how GNNs are applied to analyze complex EEG data, which inherently possesses relational structures conducive to graph-based modeling.​  

Electroencephalography (EEG) is a well-established, non-invasive technique for measuring the brain's electrical activity. It captures voltage fluctuations resulting from neuronal currents via electrodes placed on the scalp [9,32]. Known for its high temporal resolution, EEG is valuable for studying dynamic brain processes, although it has comparatively lower spatial resolution [9,23]. EEG signals are typically low-amplitude and span various frequency bands—delta, theta, alpha, beta, and gamma—each associated with distinct brain states and functions [37,43]. Standard electrode placement systems, such as the 10-20 system, ensure consistency [6]. However, raw EEG data is susceptible to various artifacts (e.g., eye movements, muscle activity) and exhibits non-stationarity and significant inter-subject variability, necessitating rigorous preprocessing steps like filtering, artifact removal, re-referencing, and segmentation [23,32,43]. Following preprocessing, feature extraction is performed to derive informative representations, including time-domain, frequency-domain (e.g., Power Spectral Density, Differential Entropy), time-frequency (e.g., using wavelet transform), and, crucial for graph-based methods, connectivity features (e.g., coherence, phase-locking value) [1,2,4,17,28,31,37,43]. These connectivity measures quantify the functional or statistical relationships between different brain regions or electrodes, forming a natural basis for graph representation [1,2].​  

Graph Neural Networks (GNNs) are a class of deep learning models designed to process data structured as graphs, diverging from traditional models that assume a Euclidean data structure [7,21,29]. This makes them inherently suitable for analyzing relational data, such as interactions within brain networks [1,7]. At their core, GNNs operate through iterative message passing and aggregation mechanisms, where nodes exchange and combine information from their neighbors to update their feature representations [4,11,18,25,33]. The mathematical formulation often involves updating node states based on previous states and the graph structure, typically represented by the adjacency matrix, as shown by a general form:  

$$
h ^ { ( l + 1 ) } = \sigma \big ( h ^ { ( l ) } , A \big )
$$  

where $\boldsymbol { h } ^ { ( l ) }$ is the node's hidden state at layer $l$ , and $\sigma$ is a learnable nonlinear function [18]. Various GNN architectures exist, including Graph Convolutional Networks (GCNs) that adapt convolution for graphs [1,4,5,7,29], Graph Attention Networks (GATs) that use attention mechanisms to weigh neighbor importance [4,18,19], Graph Isomorphism Networks (GINs) designed for strong discriminative power [25], and Dynamic Graph Convolutional Neural Networks (DGCNNs) that incorporate temporal dependencies [2,5,29]. A common layer update rule for GCNs is:​  

$$
H ^ { ( l + 1 ) } = \sigma \Bigl ( \widetilde { D } ^ { - \frac { 1 } { 2 } } \widetilde { A } \widetilde { D } ^ { - \frac { 1 } { 2 } } H ^ { ( l ) } W ^ { ( l ) } \Bigr )
$$  

where $\boldsymbol { H } ^ { ( l ) }$ is the node feature matrix, ${ \tilde { A } } = A + I$ , $\widetilde { D }$ is the degree matrix of $\tilde { A }$ , and $W ^ { ( l ) }$ is the weight matrix [5]. GATs utilize attention to compute weighted sums of neighbor features:​  

$$
F ^ { ( 1 ) } ( i ) = \sigma \left( \sum _ { v _ { j } \in V ( i ) } \hat { C } ( i , j ) T ^ { ( 1 ) } F ^ { ( 0 ) } ( j ) \right)
$$  

where $F ^ { ( 0 ) } ( i )$ is the initial feature, $\boldsymbol { T } ^ { ( 1 ) }$ is a transformation matrix, $\hat { C } ( i , j )$ is the normalized importance coefficient, and $V ( i )$ is the neighbor set [4]. The strength of GNNs lies in their ability to learn node and graph representations that capture complex structural and relational information, offering a powerful approach for understanding intricate connections in data [19,33].​  

The integration of EEG and GNNs presents a powerful framework for analyzing brain activity. EEG data, representing the coordinated activity across multiple brain regions or recording sites, can be naturally modeled as a graph. Here, electrodes or predefined brain areas serve as nodes, while the edges can represent various types of relationships, predominantly functional connectivity derived from signal analysis [1,2,4]. Node features can be the time series data from each channel or extracted features. GNNs are then employed to process these brain graphs, enabling the models to leverage the spatial structure of electrodes and the functional interactions between regions. This graph-based approach allows for a more holistic analysis of brain networks, potentially capturing complex spatio-temporal patterns and inter-dependencies that are critical for understanding brain states and disorders but challenging for models that treat channels independently or assume grid-like structures. Different GNN architectures can capture these relationships in varied ways, from spatially localized convolutions (GCNs) to flexible attention-weighted aggregations (GATs) or dynamic interactions (DGCNNs). This framework provides a theoretically grounded method to analyze the relational complexities inherent in EEG data. However, challenges remain in optimally constructing meaningful graphs from noisy and dynamic EEG signals and in interpreting the resulting GNN models in a neurophysiological context. Understanding these fundamentals sets the stage for exploring specific GNN applications and architectures tailored for diverse EEG analysis tasks.  

# 2.1 Electroencephalography (EEG)  

Electroencephalography (EEG) is a non-invasive neurophysiological technique that measures the electrical activity of the brain. This activity primarily consists of voltage fluctuations generated by ionic currents within the neurons, which are recorded by electrodes placed on the scalp [9,32]. The resulting signal represents the summation of postsynaptic potentials from large populations of synchronously active cortical neurons [9]. EEG is widely utilized for studying brain bioelectrical function and degeneration due to its non-invasive nature, high temporal resolution, accessibility, and relatively low cost [1]. Compared to other neuroimaging techniques, EEG offers excellent temporal resolution, allowing for the capture of rapid brain dynamics, although its spatial resolution is relatively poor [9,23]. EEG signals are low-frequency bioelectrical signals, typically ranging from $5 { \mathrm { - } } 1 0 0 \mu \nu ,$ necessitating amplification for display and processing [6,43]. Common EEG acquisition devices include systems from Neurosky, Emotiv, Neuroelectrics, and Biosemi, which vary in technical specifications [9].  

Standard electrode placement systems, such as the 10–20 system, are commonly employed to ensure consistent electrode positioning across subjects [6]. EEG signals exhibit distinct patterns characterized by different frequency bands: delta (0–3 Hz), theta $( 4 - 7 \ H z )$ , alpha $( 8 - 1 2 \mathsf { H z } )$ , beta $( 1 3 - 2 9 \mathsf { H z } )$ , and gamma $( 3 0 - 5 0 H z )$ [37,43]. These frequency bands are associated with various cognitive states and neurological conditions [43]. For instance, during sensorimotor-related activities, $8 { - } 1 2 \ H z$ $\mu$ rhythms and $1 8 \substack { - 2 6 \mathsf { H z } \beta }$ rhythms are recorded in the sensorimotor cortex, and their changes (Event-Related Synchronization – ERS and Event-Related Desynchronization – ERD) are related to motor imagery [43]. Control over the amplitude of $\mu / \beta$ rhythms in specific brain regions forms the basis for certain Brain-Computer Interfaces (BCIs) [43].  

EEG data is susceptible to various artifacts, which are non-brain electrical signals that can contaminate the recording [23,43]. Common artifacts include eye movements (electrooculogram – EOG), muscle movements (electromyogram – EMG), and power line interference (e.g., $5 0 \mathsf { H z }$ or $6 0 \mathsf { H z }$ noise) [22,23,43]. Preprocessing is an essential step in EEG analysis to remove these noise components and artifacts and enhance the signal-to-noise ratio [32,43]. Essential preprocessing techniques include filtering, artifact removal, re-referencing, and data segmentation [43]. Filtering is widely used to remove noise in specific frequency ranges. For example, a band-pass filter of $4 { - } 4 5 \mathsf { H z }$ has been applied to remove EOG artifacts and other noise [22,28]. Other artifact removal methods include spatial filters like Common Average Reference (CAR) for eye movements and myoelectric interference [43], Savitzky-Golay filter, and Multi-Scale Principal Component Analysis (MSPCA) [31]. Preprocessing workflows often leverage libraries such as MNE in Python [32] or toolboxes like Fieldtrip [4].​  

EEG data presents significant challenges for analysis, notably its non-stationarity, meaning its statistical properties change over time, and high inter-subject variability [6,9,23]. These characteristics complicate the development of robust analysis models [9]. To address non-stationarity and facilitate analysis, EEG signals are often windowed and segmented [6]. Data segmentation involves dividing the continuous EEG recording into shorter, manageable epochs or segments [28]. The choice of segment length and overlap can significantly affect subsequent feature extraction and analysis, influencing the temporal resolution of the features and the total number of samples available [28]. For example, in emotion recognition studies, 60- second emotion-related EEG signals have been divided into 15 non-overlapping segments of 4 seconds each [28], while other studies utilize 3-second windows with 2.5-second overlap [37].  

<html><body><table><tr><td>Feature Type</td><td>Description</td><td>Examples / Use Case</td></tr><tr><td>Time-domain</td><td>Directly from raw signal or linear combinations of samples.</td><td>Amplitude,Variance, Event- Related Potentials (ERPs)</td></tr><tr><td>Frequency-domain</td><td>Characterize spectral power distribution over frequency bands.</td><td>Power Spectral Density (PSD), Differential Entropy</td></tr><tr><td>Time-frequency</td><td>Capture spectral content changes over time,address non-stationarity.</td><td>Wavelet Transform, EMD, DTCWT</td></tr><tr><td>Connectivity</td><td>Quantify functional interaction or statistical dependencies between channels.</td><td>Coherence, Phase-Locking Value (PLV), IPC</td></tr></table></body></html>  

Following preprocessing, feature extraction aims to reduce data dimensionality and derive informative representations relevant to the task [43]. Common EEG feature types include time-domain, frequency-domain, time-frequency, and connectivity features [17,43].  

• Time-domain features are derived directly from the raw signal or linear combinations of time samples, such as amplitude and variance [17]. These are particularly useful for analyzing event-related potentials (ERPs), which are timelocked responses to specific stimuli [17].  

• Frequency-domain features characterize the spectral power distribution of the signal. Widely used techniques include Fast Fourier Transform (FFT), wavelet decomposition, Principal Component Analysis (PCA), and multi-taper power spectral analysis [17,43]. Power Spectral Density (PSD) is a fundamental frequency-domain feature representing how the power of the signal is distributed over frequency bands [37]. Differential Entropy is another frequency-domain feature related to the logarithm of power spectral density under certain assumptions [37].  

• Time-frequency features capture how the spectral content of the signal changes over time, addressing the nonstationary nature of EEG. Methods like wavelet transform decompose the signal into different frequency components at different time scales [43]. For instance, the Db4 wavelet has been used to decompose signals into five levels corresponding to different frequency bands [28]. Other decomposition methods include Empirical Mode Decomposition (EMD) and Dual-Tree Complex Wavelet Transform (DTCWT) [31]. Time-frequency features can also be visualized as images for input into deep learning models like CNNs [17].  

• Connectivity features quantify the functional interaction or statistical dependencies between different brain regions [1,2]. These features are crucial for studying intrinsic brain networks and information flow [1,2]. Common connectivity measures include coherence and phase-locking value [4]. Coherence, a frequency-domain measure, indicates the consistency of amplitude and phase differences between two signals. The imaginary part of the coherency spectrum can be used to mitigate the effects of volume conduction [4]. Calculating coherence between sources parcellated according to anatomical atlases, such as the Desikan-Killiany cortical atlas, allows for the study of interactions between specific brain regions [4]. These connectivity patterns can be used to construct brain functional connectivity graphs [2].​  

In summary, EEG provides a versatile, non-invasive window into brain activity, crucial for understanding both normal cognitive function and pathological states. However, its inherent challenges, coupled with the complexity of extracting relevant information from noisy and non-stationary signals, underscore the need for sophisticated processing and analysis techniques.  

# 2.2 Graph Neural Networks (GNNs)  

Graph Neural Networks (GNNs) represent a class of deep learning models specifically designed to process data structured as graphs [7,21,29]. This capability is particularly relevant for domains like EEG analysis, where relationships between electrodes or brain regions can be naturally represented as a graph, diverging from the Euclidean structure assumed by traditional convolutional neural networks (CNNs) [1,7]. GNNs leverage graph theory principles, where data points are modeled as nodes and their connections as edges [7]. The history of GNNs dates back to the early 2000s, with foundational work exploring their application to various graph types [29].​  

A core concept in GNNs is graph representation learning, which aims to convert graph instances, such as brain networks derived from EEG signals, into vector representations that encapsulate their structural and feature information [4,11,21]. This is typically achieved through an iterative process involving message passing and aggregation [11,18,33]. In message passing, nodes exchange information with their neighbors along the edges of the graph [18]. The aggregation step then combines the information received from neighboring nodes with the node's own current representation to update its feature vector for the next layer [4,25]. The number of GNN layers determines the extent of this iterative aggregation, allowing nodes to incorporate information from increasingly distant neighbors [4].  

Mathematically, GNNs can be broadly represented by an iterative function that updates node states based on their previous state and the graph structure, often involving the adjacency matrix A. A common formulation is  

$$
h ^ { ( l + 1 ) } = \sigma \big ( h ^ { ( l ) } , A \big )
$$  

where $\backslash ( \mathsf { h } ^ { \wedge } \{ ( \mathsf { l } ) \} \backslash )$ is the node's hidden state at layer $\mathsf { \backslash } ( \mathsf { I } \backslash )$ , and $\backslash ( \textsf { f } \backslash )$ is a learnable nonlinear function [18]. More fundamentally, a GNN can be seen as learning a function  

$$
\tau ( G , n ) \in \mathbb { R } ^ { m }
$$  

that maps a graph $\mathsf { \backslash } ( \mathsf { G } \backslash )$ and one of its nodes $\mathsf { \backslash } ( \mathsf { n } \backslash )$ into an $\left\backslash ( \mathsf { m } \right\backslash )$ -dimensional Euclidean space, enabling the network to learn node representations based on their graph context [21].  

<html><body><table><tr><td>Architecture Type</td><td>Core Mechanism</td><td>EEG Relevance / Example Application</td></tr><tr><td>Graph Convolutional Networks (GCNs)</td><td>Adapt convolution for graphs,aggregate neighbor features via defined operation (often matrix multiply with Adj).</td><td>Processing non-Euclidean EEG (channels as nodes); Emotion Recognition [7,8, 37]</td></tr><tr><td>Graph Attention Networks (GATs)</td><td>Use attention to weigh importance of neighboring nodes during aggregation.</td><td>More flexible aggregation, capture non-uniform dependencies [11]</td></tr><tr><td>Graph Isomorphism Networks (GINs)</td><td>Powerful discriminators of graph structure via neighborhood aggregation + MLP.</td><td>Potential for discriminating brain network states [25]</td></tr><tr><td>Dynamic Graph CNNs (DGCNNs)</td><td>Incorporate dynamic graph structures and temporal dependencies.</td><td>Motor Imagery Classification [5]; Emotion Recognition (adaptive graph) [7]</td></tr></table></body></html>  

Various GNN architectures have been developed, each employing distinct methods for message passing and aggregation [18,29,33]. Prominent examples include Graph Convolutional Networks (GCNs), Graph Attention Networks (GATs), GraphSAGE, and Graph Isomorphism Networks (GINs) [18,19,33]. Other architectures like Graph Generative Networks (GGNs) and Dynamic Graph Convolutional Neural Networks (DGCNNs) also exist [2,5,29].  

Graph Convolutional Networks (GCNs) adapt the concept of convolution from grids to graphs [29]. They are particularly suitable for processing non-Euclidean data like EEG signals, treating each channel as a node and cross-channel interactions as edges [1,7]. GCNs aggregate information using a defined graph convolution operation. One common mathematical formulation for the layer-wise propagation rule in GCNs is:​  

$$
F ^ { ( l + 1 ) } = \sigma \Bigl ( \hat { A } F ^ { ( l ) } T ^ { ( l ) } \Bigr )
$$  

where $\backslash ( \backslash \mathsf { h a t } \{ \mathsf { A } \} \backslash )$ is the symmetrically normalized adjacency matrix, $\backslash ( \mathsf { F } ^ { \wedge } \{ ( \mathsf { I } ) \} \backslash )$ is the feature matrix at layer $\backslash ( \mid \backslash ) , \backslash ( \top \wedge \{ ( \lfloor ) \} \backslash )$ is a trainable weight matrix, and $\mathsf { \backslash } ( \mathsf { \backslash s i g m a \backslash } )$ is a non-linear activation function [4]. Another variant used for processing EEG signals is represented as:​  

$$
H ^ { ( l + 1 ) } = \sigma \Bigl ( \widetilde { D } ^ { - \frac { 1 } { 2 } } \widetilde { A } \widetilde { D } ^ { - \frac { 1 } { 2 } } H ^ { ( l ) } W ^ { ( l ) } \Bigr )
$$  

where $\backslash ( \mathsf { H } ^ { \wedge } \{ ( \mathsf { I } ) \} \backslash )$ is the node feature matrix, \( \widetilde $\{ A \} = A + 1 \backslash \backslash$ (the adjacency matrix $\mathsf { \backslash } ( \mathsf { A } \backslash )$ plus the identity matrix \( \)), \( \widetilde{D} \) is the degree matrix of \( \widetilde{A} \), and $\backslash ( \mathsf { W } ^ { \wedge } \{ ( \mathsf { I } ) \} \backslash )$ is the weight matrix [5].  

Graph Attention Networks (GATs) enhance the aggregation process by incorporating an attention mechanism [18,19]. Unlike GCNs which use a fixed convolution kernel for all neighbors, GATs compute attention scores to weigh the importance of different neighbors during aggregation [19]. This allows GATs to learn more flexible and adaptive aggregation schemes [19]. The attention scores are computed using attention heads, and the results are typically averaged or concatenated [19]. The node feature aggregation in GATs can be formulated as:​  

$$
F ^ { ( 1 ) } ( i ) = \sigma \left( \sum _ { v _ { j } \in V ( i ) } \hat { C } ( i , j ) T ^ { ( 1 ) } F ^ { ( 0 ) } ( j ) \right)
$$  

where $\backslash ( \mathsf { F } ^ { \wedge } \{ ( 0 ) \} ( \mathsf { i } ) \backslash )$ is the initial feature of node $\backslash ( \vee _ { - } \mathfrak { i } \vee ) , \backslash ( \top \wedge \{ ( 1 ) \} \backslash )$ is a shared transformation matrix, $\backslash ( \backslash \mathsf { h a t } \{ \mathsf { C } \} ( \mathsf { i } , \mathsf { j } ) \backslash )$ is the normalized importance coefficient of neighbor $\backslash ( \vee _ { - } { \ j } \backslash )$ to node $\backslash ( \vee _ { - } \dot { \iota } \vee )$ , and $\backslash ( \vee ( \mathfrak { j } ) \vee )$ is the neighbor set of $\backslash ( \vee _ { - } \mathfrak { i } \backslash )$ [4]. This mechanism allows GATs to capture richer information by letting each head focus on different features or patterns [19].  

Graph Isomorphism Networks (GINs) are designed to be powerful discriminators of graph structures, theoretically achieving the maximum discriminative power among GNNs that rely on neighborhood aggregation [25]. The update rule for GINs involves aggregating neighbor features and applying a Multi-Layer Perceptron (MLP):​  

$$
h _ { v } ^ { ( k ) } = M L P ^ { ( k ) } \left( \left( 1 + \epsilon ^ { ( k ) } \right) \cdot h _ { v } ^ { ( k - 1 ) } + \sum _ { u \in N ( v ) } h _ { u } ^ { ( k - 1 ) } \right)
$$  

where $\backslash ( \mathsf { h \_ v } \mathsf { \iota } _ { \mathsf { i } } ( \mathsf { k } ) \mathsf { \xi } \backslash )$ is the feature of node $\mathsf { \backslash } ( \mathsf { v } \backslash )$ at layer $\backslash ( \boldsymbol { \mathsf { k } } \backslash ) , \backslash ( \boldsymbol { \mathsf { N } } ( \boldsymbol { \mathsf { v } } ) \backslash )$ is the neighbor set, and $\backslash ( \mathsf { \backslash e p s i l o n ^ { \wedge } \{ ( k ) \} } \backslash )$ is a learnable parameter or a fixed scalar [25]. Graph-level representations can then be obtained using a readout function on the node embeddings [25].  

Dynamic Graph Convolutional Neural Networks (DGCNNs), as applied in some EEG studies, treat each node as part of a dynamic graph structure, incorporating temporal dependencies. The feature representation for a node in DGCNNs can involve combining neighbor information and temporal information [5]:  

$$
h _ { i } = \sigma \Bigg ( \sum _ { j \in N ( i ) } w _ { e } \left( e _ { i j } \right) x _ { j } + \sum _ { k \in T ( i ) } w _ { t } \left( t _ { i , k } \right) x _ { k } \Bigg )
$$  

where $\backslash ( \mathsf { h \_ i } \backslash )$ is the feature of node $\backslash ( \mathfrak { i } \backslash ) , \backslash ( \mathsf { N } ( \mathfrak { i } ) \backslash )$ denotes the set of neighboring nodes, $\backslash ( \mathsf { T } ( \mathfrak { i } ) \backslash )$ represents related time steps, $\backslash ( \times \_ j \backslash )$ and $\backslash ( \mathsf { x \_ k } \backslash )$ are the features of the neighbor nodes and time steps respectively, \( e_{ij} \) and \( t_{i,k} \) represent dependencies, and $\backslash ( \boldsymbol { \mathsf { w _ { - } e } } \backslash )$ and $\mathsf { \backslash } ( \mathsf { w \_ t } \backslash )$ are learnable weights [5].  

The primary advantage of GNNs lies in their ability to directly process and learn from graph-structured data, which is crucial for analyzing relational data where traditional models struggle [33]. Different GNN architectures offer distinct mechanisms for capturing relationships; GCNs provide a spectral-based or spatial-based convolution, while GATs offer the flexibility of attention-weighted aggregation [19]. In general, GNNs enable a deeper understanding of objective relationships within the data structure [19]. Their ability to handle various graph types (acyclic, cyclic, directed, undirected) further contributes to their versatility [21,29]. While powerful for complex graph data with spatiotemporal interactions, limitations can include scalability issues for very large graphs and potential difficulties in capturing long-range dependencies depending on the architecture and number of layers [1].  

# 3. Graph Construction Methods for EEG Data  

Graph construction is a critical initial step in applying Graph Neural Networks (GNNs) to Electroencephalography (EEG) data, as it transforms complex time-series signals into a structured representation suitable for graph-based learning. The choice of graph construction method significantly influences the GNN’s ability to capture relevant information from the brain activity [17,25].  

Nodes in EEG graphs typically represent different aspects of the neural data. The most common approach is to use individual EEG channels as nodes [1,5,8]. However, nodes can also represent brain regions defined by atlases, specific time points within a signal segment, distinct frequency bands, or independent components derived from signal processing [17].  

Edges between nodes are defined to represent relationships or connections. A prevalent method for edge construction is based on functional connectivity (FC), which quantifies the statistical dependencies between EEG channels. Various FC measures are employed, including Pearson Correlation Coefficient [1,37], Phase Locking Value (PLV) [1,5,37], Phase Lag Index (PLI) [1,37], Magnitude Squared Coherence (MSC) [1], Imaginary Part of Coherence (IPC) [1], and Wavelet Coherence (WC) [1]. These measures yield connectivity matrices, where each element represents the strength of the relationship between two channels [1,37]. For instance, PLV measures the degree of phase synchronization, ranging from 0 to 1 [5].  

These connectivity matrices are then often transformed into adjacency matrices, for example, by applying thresholds or using methods like k-Nearest Neighbors (KNN) to select reliable neighbors based on an initial weighted matrix derived from FC measures or feature embeddings [4]. While correlation and partial correlation are noted for BOLD data [11], similar principles apply to EEG FC analysis.  

Another approach involves using structural connectivity, which refers to the physical connections between brain regions based on anatomical data, often derived from Diffusion Tensor Imaging (DTI) or anatomical atlases [17,25]. While conceptually valuable, the integration of structural connectivity directly into EEG graph construction is less common compared to FC, primarily due to the indirect mapping between EEG electrode signals and underlying brain structures.  

Spatial proximity is a straightforward method for defining edges, based on the physical locations of EEG electrodes on the scalp. Edges can be defined between channels that are physically close. For example, an adjacency matrix can be initialized based on the inverse of the physical distance between channels, potentially with a calibration constant to control sparsity [8]. This physically inspired structure can be combined with additional connections based on known brain asymmetry, such as linking contralateral electrode pairs to incorporate global inter-channel relationships [8]. While simpler, spatial proximity graphs may not fully capture the functional interactions between channels [7].​  

Methods also exist to transform the EEG time series directly into a graph structure without relying solely on traditional FC measures. Examples include Visibility Graphs, such as the Natural Visibility Graph (NVG) and Horizontal Visibility Graph (HVG), where each time point becomes a node and edges are drawn based on visibility criteria determined by the signal amplitude at different time points [24,25]. The NVG connects points $( t _ { a } , y _ { a } )$ and $( t _ { b } , y _ { b } )$ if no intermediate point $( t _ { c } , y _ { c } )$ , with $t _ { a } < t _ { c } < t _ { b }$ , obstructs the view, i.e.,  

$$
y _ { c } < y _ { b } + ( y _ { a } - y _ { b } ) \frac { t _ { b } - t _ { c } } { t _ { c } - t _ { a } } .
$$  

The HVG simplifies this by requiring that the intermediate points lie below the horizontal line connecting the two points, i.e., $y _ { a } , y _ { b } > y _ { c }$ ​ for all $t _ { c }$ ​ such that $t _ { a } < t _ { c } < t _ { b }$ ​,  

[25]. Another approach, the Quantile Graph (QG), partitions the time series into quantiles, using each quantile as a node, and edges represent the transition frequency between quantiles over time [25]. Complex network analysis methods, including multilayer visibility graphs or networks based on features like wavelet entropy, can also be adapted from other time series applications to construct graphs from EEG data [24].​  

More advanced methods aim to learn the graph structure directly from the data. Instead of relying on fixed predefined structures (like spatial proximity) or pre-calculated FC matrices, these methods dynamically update or learn the adjacency matrix during the training process [7,9]. This allows the model to discover the most relevant relationships between channels or nodes for the specific task, potentially capturing more intrinsic functional connectivity [7]. Methods include using learnable adjacency matrices optimized via backpropagation [7,8] or probabilistic graph generation guided by task performance [2]. This contrasts with traditional GCNNs that use static, predefined graphs based on factors like electrode positions [7].  

<html><body><table><tr><td>Method</td><td>Node Definition</td><td>Edge Definition</td><td>Pros (EEG Relevance)</td><td>Cons (EEG Relevance)</td></tr><tr><td></td><td></td><td></td><td></td><td></td></tr></table></body></html>  

<html><body><table><tr><td>Functional Connectivity (FC)</td><td>Channels/Regio</td><td>Statistical dependencies (Corr, PLV, Coherence, etc.)</td><td>Captures brain functional interactions related to task</td><td>Sensitive to noise, choice of measure/thresh old [1]</td></tr><tr><td>Structural Connectivity</td><td>Brain Regions</td><td>Physical connections (from MRI/DTI)</td><td>Biologically grounded</td><td>Indirect mapping to EEG electrodes [17,</td></tr><tr><td>Proximity</td><td>EEG Channels</td><td>Physical distance on scalp</td><td>Simple,uses electrode layout</td><td>Oversimplifies complex functional networks [8,7]</td></tr><tr><td>Graph</td><td>Points/Quantile</td><td>(NVG/HVG) or Transition Freq (QG)</td><td>Transforms temporal dynamics to structure [24,</td><td>information from multi- channel EEG</td></tr><tr><td></td><td>Channels/Nodes</td><td>learned via optimization</td><td>relevant relationships [2,</td><td>interpretable defined graphs</td></tr></table></body></html>  

Comparing these methods, FC-based graphs excel at capturing statistical dependencies and functional interactions between brain regions or channels, which are directly related to brain states and cognitive processes [1]. However, the choice of FC measure, thresholding, and dynamic aspects of connectivity can significantly impact the resulting graph [1]. Spatial proximity graphs are simple but may oversimplify the complex functional network of the brain [8]. Time-series-to-graph methods like NVG/HVG transform the temporal dynamics into structural properties but may lose the spatial information inherent in multi-channel EEG. Learned graph structures offer flexibility and the potential to discover optimal task-specific connectivity patterns [2,7], addressing the limitation that physical electrode positions do not necessarily reflect functional relationships [9]. However, learned graphs can be less interpretable than biologically motivated or FC-based graphs.  

The impact of different graph construction methods on GNN performance in EEG analysis is substantial [8,17,25]. Graphs that effectively capture the underlying neural connectivity patterns relevant to the specific task (e.g., emotion recognition, disease diagnosis) tend to yield better performance. For example, learned adjacency matrices capturing functional relationships have been shown to improve emotion classification accuracy compared to spatially predefined graphs [7,9]. The choice often depends on the research question and the specific characteristics of the EEG data being analyzed. Adaptive or learned methods, particularly those capturing dynamic connectivity, show promise in better modeling the complex and time-varying nature of brain activity [1,2].​  

# 4. GNN Architectures for EEG Analysis  

Analyzing electroencephalography (EEG) data presents unique challenges due to its complex nature, encompassing intricate spatial relationships between electrodes or brain regions and dynamic temporal patterns. Graph Neural Networks (GNNs) are particularly well-suited for addressing these challenges by naturally modeling data structured as graphs, where EEG channels or brain regions can be represented as nodes and their connections (physical proximity, functional connectivity, etc.) as edges [11,29]. This section provides an overview of the different categories of GNN architectures applied to EEG analysis, detailing their core principles, common approaches, and specific examples, while also highlighting their respective strengths and limitations.​  

![](images/1a9fec535b750ea1803737f17abe795dfbcccd3b0387483c9d38f5782a831851.jpg)  

The landscape of GNN architectures for EEG analysis can be broadly categorized based on how they process graph information and incorporate the temporal dimension. The primary distinction often lies between spatial-based and spectralbased approaches to graph convolution [29]. Spatial-based GNNs operate directly on the graph structure, aggregating information from a node's local neighborhood [29]. This category includes prominent architectures like Graph Convolutional Networks (GCNs) and Graph Attention Networks (GATs) [11,39]. GCNs, for instance, learn representations by aggregating neighbor features often using forms of matrix multiplication involving the graph adjacency matrix, such as $\boldsymbol { F } ^ { ( l + 1 ) } = \sigma ( \hat { A } \boldsymbol { F } ^ { ( l ) } \boldsymbol { T } ^ { ( l ) } ) ,$ ​  

where $\hat { A }$ is a normalized adjacency matrix, $F ^ { ( l ) }$ represents the features at layer $l$ , $\boldsymbol { T } ^ { ( l ) }$ denotes the weights, and $\sigma$ is the activation function [4]. GATs enhance this by employing attention mechanisms to weigh the importance of different neighbors [11]. These spatial methods excel at capturing local spatial dependencies and structural patterns within EEG channels or brain networks [11]. Examples include applying GCNs or related spatial models for emotion recognition and neurological diagnosis based on EEG and connectivity data [1,7,8,37]. However, purely spatial models inherently lack the ability to process the temporal dynamics of EEG signals [7].  

In contrast, spectral-based GNNs define graph convolution in the spectral domain using the eigendecomposition of the graph Laplacian, drawing an analogy to the Fourier transform in classical signal processing [29]. This approach transforms graph signals into the frequency domain, where convolution is performed as multiplication [29]. While theoretically grounded in graph spectral theory, detailed applications and evaluations specific to EEG using solely spectral methods were not extensively covered in the provided digests, limiting a comprehensive discussion of their unique advantages or disadvantages in this domain based on the available information.  

Recognizing the critical temporal dimension of EEG, Spatio-Temporal GNNs integrate spatial graph processing with temporal modeling techniques. This is crucial for capturing how brain activity and inter-region dependencies evolve over time [5]. Common temporal components include Recurrent Neural Networks (RNNs), Long Short-Term Memory networks (LSTMs), or Temporal Convolutional Networks (TCNs), the latter being favored for efficiency and large receptive fields [5]. Spatio-temporal architectures combine these elements, such as integrating Dynamic GCNNs with TCNs for motor imagery classification or using ST-GCN blocks for neurological diagnosis [1,5]. Models like Graph-Generative Networks (GGNs) are also employed to model dynamic functional connectivity, capturing transient changes in brain networks over time [2]. These models offer enhanced capabilities for tasks sensitive to the dynamic interplay of brain regions, but often come with increased complexity and computational demands.​  

Beyond dedicated spatio-temporal designs, Hybrid GNN Architectures further combine GNNs with other powerful neural network paradigms like Convolutional Neural Networks (CNNs), RNNs, and attention-based Transformers [24]. This hybridization aims to leverage complementary strengths – GNNs for graph structure and relationships, CNNs for grid-like spatial or spectral patterns, RNNs/LSTMs for temporal sequences, and Transformers for global dependencies [2,24]. Examples include integrating graph-based methods with CNNs for disorder detection or emotion recognition [24], or combining convolutional feature extraction with Transformers, as seen in the ERTNet framework which uses spatial/temporal convolutions and attention to model relationships [22]. These hybrid models can yield richer feature representations and potentially higher performance but are complex to design, computationally intensive, and prone to overfitting [22,24]. They differ from non-GNN hybrids (like 3DCNN-BLSTM [26]) by explicitly incorporating graph convolution to process inter-channel relationships based on defined connections.​  

Finally, the field explores Other GNN Architectures and related models beyond the standard GCNs and GATs [29]. This includes models like Graph Isomorphism Networks (GINs), noted for their strength in distinguishing graph structures through an aggregation function like  

$$
h _ { v } ^ { ( k ) } = M L P ^ { ( k ) } \Bigl ( ( 1 + \epsilon ^ { ( k ) } ) \cdot h _ { v } ^ { ( k - 1 ) } + \sum _ { u \in N ( v ) } h _ { u } ^ { ( k - 1 ) } \Bigr )
$$  

[25]. Other paradigms like Graph Autoencoders (GAEs) enable unsupervised learning of node representations, and Graph Recurrent Networks (GRNs) are designed for processing sequences of graphs, highly relevant for dynamic EEG [29]. Additionally, alternative network architectures adapted for brain network analysis, such as Transformer encoders in models like BrainMass [14], or integrating connectivity features with Capsule Networks as in SACC-CapsNet [13], represent diverse approaches to capture complex relationships in EEG data, even if they deviate from standard GNN formulations.​  

In essence, the variety of GNN architectures and hybrid approaches for EEG analysis reflects the ongoing effort to effectively model the multifaceted spatial, spectral, and temporal characteristics of brain activity. While spatial GNNs provide a foundation for processing graph structures, spatio-temporal and hybrid models address the dynamic and complex nature of EEG data by integrating temporal processing and leveraging complementary network strengths. Exploring alternative GNN paradigms and graph-aware architectures further expands the toolkit for extracting informative representations from EEG, although challenges related to computational cost, interpretability, and handling data variability remain prevalent across these advanced models.​  

# 4.1 Spatial-based GNNs  

Spatial-based Graph Neural Networks (GNNs) are particularly well-suited for analyzing Electroencephalography (EEG) data due to their ability to process information structured as graphs, which aligns with the inherent non-Euclidean nature of brain connectivity and electrode placement [11]. These models operate directly on graphs where EEG channels or brain regions are represented as nodes, and the connections (e.g., physical proximity, functional connectivity) between them are edges. By leveraging spatial graph convolutions, these methods can effectively capture local dependencies and relationships between neighboring EEG channels, which is crucial for understanding brain activity patterns [29].  

The application of spatial GNNs in EEG analysis often involves adapting core GNN architectures like Graph Convolutional Networks (GCNs). In GCNs, the convolutional operation aggregates features from a node's neighbors by defining how information is passed and transformed across the graph structure. The aggregation process can be formulated as learning a function that combines the features of a central node and its neighbors, often involving matrix multiplication with an adjacency matrix representing the graph structure. For instance, the BN-GNN framework utilizes GCNs where the aggregation step for the feature matrix F at layer $( \left. + \right. )$ is described by the formula:  

$$
\boldsymbol { F } ^ { ( l + 1 ) } = \sigma ( \hat { A } \boldsymbol { F } ^ { ( l ) } \boldsymbol { T } ^ { ( l ) } )
$$  

Here, $\hat { A }$ is the symmetrically normalized adjacency matrix, $F ^ { ( l ) }$ is the feature matrix from the l-th layer, $\boldsymbol { T } ^ { ( l ) }$ is a trainable weight matrix, and $\sigma$ is an activation function [4]. Key considerations in designing spatial graph convolution layers include selecting central nodes, determining the receptive field (i.e., the number of neighbors considered), and defining aggregation functions [29]. Subsequent layers often involve applying non-linear activation functions to the aggregated features, such as the ReLU function used in the DGCNN model [7]. Pooling layers are also employed in spatial GNNs as modifications to downsample the graph or nodes, reducing dimensionality and computational complexity while preserving important features [11].​  

Graph Attention Networks (GATs) offer an alternative spatial approach by employing attention mechanisms to assign varying importance weights to different neighboring nodes (EEG channels) during the aggregation process [11,39]. This allows the model to dynamically learn which channels are more relevant for a particular task, potentially capturing complex, non-uniform spatial dependencies. The Attention-Diffusion-Bilinear Neural Network (ADB-NN), considered a spatial-based GNN, incorporates attention alongside diffusion and a bilinear layer to model interactions and propagate information across brain regions [39]. While not explicitly detailed in the provided digests concerning EEG, GraphSAGE represents another type of spatial GNN that aggregates information from a sampled set of neighbors, offering efficiency for large graphs.​  

These spatial GNN architectures have been successfully applied to various EEG analysis tasks [11]. For example, the ST-GCN model—which includes a spatial graph convolution layer—has been utilized for the diagnosis of Alzheimer's Disease (AD) based on EEG and brain functional connectivity, demonstrating the capability of spatial methods to process neurophysiological signals [1]. The RGNN model, a spatial-based GNN that employs graph convolution on a learned adjacency matrix, was applied to EEG-based emotion recognition [8]. Similarly, the DGCNN model, comprising graph filtering and convolutional layers operating on EEG features extracted from frequency bands, was used for emotion recognition [7]. Even standard Convolutional Neural Networks (CNNs) can be viewed as a form of spatial-based approach when applied to EEG, as their convolution operations capture spatial relationships between electrodes and their inter  

electrode connectivity [37]. Architectures like CNN-2, CNN-5, and CNN-10—with varying numbers of convolutional and pooling layers—have been explored for EEG emotion recognition [37].  

The primary advantages of spatial GNNs for EEG analysis stem from their inherent design to handle non-Euclidean data structures, enabling them to naturally model the irregular arrangement of EEG electrodes or complex brain networks better than grid-based methods. They excel at capturing local dependencies and spatial patterns by aggregating information from neighboring channels. However, limitations exist. Purely spatial GNNs might struggle with the dynamic and temporal aspects of EEG signals, often requiring integration with temporal processing modules. Furthermore, like other machine learning models, they can be susceptible to issues such as inter-subject variability and noise in EEG data [7]. Approaches to overcome these limitations include incorporating temporal convolutional layers, as seen in the ST-GCN [1], using regularization techniques like Node Domain Adversarial Training and Emotion-aware Distribution Learning as implemented in RGNN to enhance robustness against variability and noisy labels [8], or employing dynamic graph structures that evolve over time. The trade-off in integrating temporal modules or regularization is an increase in model complexity and computational cost versus improved performance and robustness, necessitating careful model selection and tuning based on the specific EEG task and available data.​  

# 4.2 Spectral-based GNNs  

Graph Convolutional Networks (GCNs) extend the concept of convolution to graph-structured data. Fundamentally, GCNs perform convolution operations through two primary approaches: transformation in the node space (i.e., spatial methods) and convolution defined in the spectral domain (i.e., spectral methods) [29].  

The spectral approach to graph convolution was pioneered by Bruna et al., who generalized Convolutional Neural Networks to graphs by proposing models based on spectral decomposition [29]. In this method, graph convolution is defined using the eigendecomposition of the graph Laplacian matrix, which is conceptually analogous to applying the Fourier transform on graphs. A signal on the nodes of a graph is transformed into the spectral domain by projecting it onto the eigenvectors of the graph Laplacian. Convolution is then carried out as a multiplication in this spectral domain, similar to the convolution theorem in classical signal processing.  

Although the theoretical framework involves concepts such as the graph Fourier transform and the convolution theorem on graphs, the provided materials do not offer detailed explanations of these mathematical foundations or their specific applications for designing spectral filters to extract relevant features from EEG data. Furthermore, the available sources do not discuss the advantages, disadvantages, limitations, or potential improvements related to employing spectral-based GNNs for EEG analysis. Consequently, a comprehensive analysis based solely on the provided information is not feasible.  

# 4.3 Spatio-Temporal GNNs  

Analyzing electroencephalogram (EEG) signals necessitates accounting for their inherent temporal dynamics, as brain activity evolves continuously over time. While graph neural networks (GNNs) excel at modeling the complex spatial relationships between different brain regions or EEG channels, incorporating the temporal dimension is crucial for a comprehensive understanding of brain function and state. Traditional neural network architectures like Recurrent Neural Networks (RNNs) and Long Short-Term Memory networks (LSTMs) have been widely applied in EEG analysis to model temporal dependencies, leveraging their ability to process sequential data. More recently, Temporal Convolutional Networks (TCNs) have gained prominence due to their effectiveness in capturing long-range dependencies, larger receptive fields compared to standard CNNs, and suitability for parallel processing, making them efficient for handling lengthy EEG time series.​  

![](images/a5bfcacdee21334192471a568b3f089e3d3da92223b1e6dd387a83c783654edc.jpg)  

To simultaneously capture both the spatial dependencies among EEG channels and the temporal evolution of the signals, various approaches combine GNNs with temporal modeling techniques such as RNNs, LSTMs, or TCNs. This integration allows models to learn spatio-temporal representations from EEG data, which are often more discriminative for various analysis tasks.​  

One such approach involves the use of Dynamic Graph Convolutional Neural Networks (DGCNNs) integrated with TCNs for processing motor imagery EEG signals [5]. In this architecture, the DGCNN component is specifically designed to capture the spatial relationships between EEG channels, while a TCN is employed to model the temporal dynamics [5]. The proposed model preprocesses the original EEG signal by filtering it into multiple sub-bands using convolutional filters, with each subband subsequently processed by a dedicated DGCNN [5]. The outputs from these parallel DGCNN streams are then concatenated and fed into a TCN for further feature extraction [5]. The TCN, composed of multiple layers utilizing temporal, causal, and dilated convolutions, is responsible for extracting relevant temporal features from the concatenated spatial representations [5]. Finally, the extracted spatio-temporal features are passed through a fully connected layer for the classification task [5]. This architecture leverages the strengths of DGCNNs in potentially adapting the graph structure based on data and TCNs in efficiently processing long temporal sequences.  

Another method proposes a spatio-temporal GNN architecture, specifically an ST-GCN, which utilizes spatial graph convolution layers to capture channel relationships and temporal convolutional layers to model signal dynamics [1]. This design incorporates ST-Conv blocks aimed at exploring spatio-temporal dependencies in a coherent and integrated manner, allowing the network to jointly learn features across both dimensions [1].​  

Furthermore, dynamic functional connectivity analysis benefits significantly from spatio-temporal modeling. A GraphGenerative Neural Network (GGN) has been proposed to model the dynamic brain functional connectivity, effectively capturing both spatial and temporal information from EEG signals [2]. This GGN aims to overcome limitations of traditional methods by generating brain functional connectivity graphs that reflect the transient characteristics of brain activity over time [2]. By learning spatio-temporal features, the GGN can generate high-resolution dynamic functional connectivity graphs, facilitating the detection of functional connectivity transitions, for instance, during different stages of epileptic seizures [2].​  

These spatio-temporal GNN approaches demonstrate the critical role of explicitly modeling both spatial and temporal dimensions in EEG analysis tasks. The advantage lies in their ability to capture the intricate interplay between brain regions as it evolves over time, potentially leading to more accurate and robust models for various applications, including motor imagery classification, neurological disorder diagnosis, and dynamic functional connectivity analysis. While the specific performance metrics across different tasks are not uniformly detailed in the provided digests, the methodologies highlight a general trend towards integrating advanced temporal models like TCNs or developing specialized spatio-temporal convolutional blocks and dynamic graph structures to enhance the analysis capabilities of GNNs for complex, time-varying EEG data. A limitation often encountered in such complex models is increased computational cost and the challenge of interpreting the learned spatio-temporal features.  

# 4.4 Hybrid GNN Architectures  

Hybrid Graph Neural Networks (GNNs) represent a significant direction in EEG analysis by integrating GNNs with other neural network architectures—such as Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), and attention mechanisms like Transformers. The primary rationale for employing hybrid architectures is to overcome the limitations of using a single model type and to leverage the complementary strengths of different network components to capture the multifaceted nature of EEG data [24]. While GNNs excel at modeling relationships and dependencies between EEG channels based on graph structures (which represent brain connectivity or electrode proximity), they may not optimally capture temporal dynamics or fine-grained spatial features. By combining GNNs with CNNs, RNNs, or attention mechanisms, these hybrid models aim to achieve a more comprehensive representation of EEG signals by integrating information across spatial, spectral, temporal, and connectivity domains. This synergistic approach is expected to enhance performance in various EEG-based classification and regression tasks, such as emotion recognition and the detection of neurological disorders [24].​  

Several specific hybrid architectures have been proposed for EEG analysis. One common approach is the integration of graph-based methods with convolutional networks. For instance, a complex network–based graph convolutional network has been employed in conjunction with CNNs for detecting major depressive disorder [24]. Similarly, the Core-BrainNetwork–Based Multilayer Convolutional Neural Network architecture combines graph-based representations derived from brain networks with convolutional layers to capture both spatial and spectral features relevant for emotion recognition [24]. These architectures explicitly leverage the power of graph convolution to model inter-electrode relationships alongside the ability of CNNs to process spatial or spectral patterns.​  

Another form of hybridization involves enhancing existing network types with GNN concepts for improved spatiotemporal feature extraction. The GGN model, for example, is designed to augment the feature extraction capabilities of various networks—including CNNs, GNNs, and Transformers—by improving their ability to capture spatiotemporal dependencies [2]. Beyond CNNs, integrating GNNs with attention mechanisms has also shown promise. The ERTNet framework is a notable example, comprising a feature extraction module utilizing spatio-temporal convolution techniques similar to EEGNet, coupled with a Transformer module [22]. In this framework, the feature extraction module employs a sequence of convolutional layers (including 1D, spatial, and separable convolutions), batch normalization, pooling, and dropout to extract initial spatiotemporal features, which are then processed by the Transformer to model long-range dependencies through attention [22]. The combination of convolutional feature extraction and Transformer-based attention enables ERTNet to capture both local patterns and global interactions within the EEG data [22].  

The primary advantage of hybrid GNN architectures lies in their capacity for richer feature representation by combining diverse modeling strengths. By integrating GNNs, these models can incorporate graph-structured connectivity information alongside the capabilities of CNNs for grid-like spatial processing, RNNs/LSTMs for temporal sequences, or Transformers for global dependencies. This comprehensive approach can lead to improved performance in tasks that are sensitive to complex spatiotemporal dynamics and inter-channel relationships [2,24]. However, these architectures are typically more complex to design and computationally more expensive to train than simpler models. The integration strategy among different network components requires careful consideration, and the increased number of parameters can heighten the risk of overfitting, necessitating regularization techniques such as dropout [22].​  

When comparing hybrid GNNs to other non-GNN hybrid models used in EEG analysis—such as the 3DCNN-BLSTM architecture [26]—a key difference is the explicit use of graph structures. The 3DCNN-BLSTM model combines a 3D-CNN to extract spatial features (by viewing EEG data as a 3D volume with channels construed spatially over time) and a BLSTM to capture temporal dependencies [26]. In contrast, hybrid GNN architectures leverage graph convolution to model the relationships between electrodes (nodes) based on their defined connections, thereby providing a direct mechanism to incorporate brain connectivity information into the spatial processing—an approach that is distinct from the grid-based spatial processing of 3DCNNs. Both types of hybrid models aim to capture spatiotemporal information, but they differ fundamentally in their representation and processing of the spatial dimension.​  

# 4.5 Other GNN Architectures  

While Graph Convolutional Networks (GCNs) and Graph Attention Networks (GATs) are widely adopted in applying Graph Neural Networks (GNNs) to EEG analysis, researchers have also explored other GNN architectures and related models. These alternative approaches often leverage different mechanisms for message passing, graph representation learning, or  

integrate graph structures with distinct neural network paradigms to address specific challenges in analyzing complex EEG data.  

One such architecture explored in related bio-signal analysis is the Graph Isomorphism Network (GIN) [25]. GIN is a powerful message-passing GNN that is theoretically proven to be as powerful as the Weisfeiler-Lehman test in distinguishing nonisomorphic graphs. Its aggregation function is defined as:​  

$$
h _ { v } ^ { ( k ) } = M L P ^ { ( k ) } \Bigl ( ( 1 + \epsilon ^ { ( k ) } ) \cdot h _ { v } ^ { ( k - 1 ) } + \sum _ { u \in N ( v ) } h _ { u } ^ { ( k - 1 ) } \Bigr )
$$  

where $h _ { v } ^ { ( k ) }$ ​ is the feature vector of node $\ v { v }$ at layer $k$ , $N ( v )$ is the set of neighbors of $v$ , and $M L P ^ { ( k ) }$ is a multilayer perceptron. For graph classification tasks, a readout function aggregates node features to obtain a graph-level representation [25].  

While the provided digest specifically details GIN's application to ECG data classification [25], its strength in capturing subtle graph structural differences makes it a promising candidate for EEG analysis, particularly for tasks involving the discrimination of distinct brain network states or topological changes.​  

Beyond specific layer types like GIN, other GNN paradigms offer diverse functionalities. Graph Autoencoders (GAEs), based on the autoencoder framework, learn graph node information in a semi-supervised or unsupervised manner [29]. This is particularly valuable for EEG analysis where labeled data might be scarce, allowing for the unsupervised extraction of meaningful node (e.g., electrode or ROI) representations or network structures. Graph Generative Networks (GGNs) are designed to generate graph data by recombining nodes and edges, potentially useful for data augmentation in EEG studies or modeling the generative processes of brain connectivity [29]. Graph Recurrent Networks (GRNs) convert graph data into sequences and use recurrent structures like Bidirectional RNNs or LSTMs [29]. GRNs are well-suited for handling temporal sequences of graphs, which is highly relevant for EEG time-series data where brain networks evolve dynamically over time. Compared to static or spatially focused GCNs/GATs, GRNs explicitly model temporal dependencies on graph structures.​  

Another notable approach applied to brain network analysis, though utilizing a Transformer encoder rather than traditional GNN layers, is the BrainMass model [14]. This model operates on Regions of Interest (ROIs), which can be conceptualized as nodes in a functional brain network. It employs self-supervised strategies like Masked Region Modeling (MRM) and Latent Representation Alignment (LRA) [14]. MRM predicts masked ROI features, aiding in learning internal network dependencies, while LRA aligns representations from different segments of the same signal [14]. This Transformer-based approach, applied to brain network components, represents an alternative to GNNs for capturing relationships and dependencies within the network, leveraging global attention mechanisms inherent in Transformers rather than local neighborhood aggregation.  

Furthermore, architectures that combine graph-like feature representations with non-standard neural network types have been proposed. The Self-Attentive Channel-Connectivity Capsule Network (SACC-CapsNet) [13] processes EEG signals by first refining them using temporal-channel attention and then transforming them into a channel covariance matrix to capture inter-channel relations, which can be viewed as a graph-like representation of connectivity [13]. This connectivity matrix is then analyzed by a Capsule Neural Network, which learns hierarchical relationships between connectivity features [13]. This method distinguishes itself by focusing specifically on connectivity features derived from the data and processing them using a Capsule Network, an architecture different from standard convolutional or graph layers, potentially offering advantages in capturing part–whole relationships within brain connectivity patterns.​  

In summary, while GCNs and GATs are prevalent, the field is exploring diverse GNN paradigms such as GINs, GAEs, GGNs, and GRNs, each offering unique computational strengths for specific aspects of EEG data (structural discrimination, unsupervised learning, generation, temporal dynamics) [25,29]. Additionally, models like BrainMass employ Transformer architectures on brain networks [14], and SACC-CapsNet integrates graph-like connectivity features with Capsule Networks [13], representing efforts to leverage alternative neural network architectures and feature representations for comprehensive EEG analysis. Detailed empirical comparisons of these varied architectures on a wide range of EEG tasks remain an active area of research.​  

# 5. Applications of GNNs in EEG Analysis  

![](images/532c3d633c0ff57c49200f13773420ff00759dd87351069cee9dc918e106f444.jpg)  

Graph Neural Networks (GNNs) are increasingly being applied to a diverse range of electroencephalography (EEG) analysis tasks, leveraging their inherent capability to model data represented as graphs. This aligns naturally with multi-channel EEG signals, where electrodes or brain regions can serve as nodes, and their functional or structural relationships can be represented as edges [1,9,11,17]. By explicitly modeling these complex inter-channel relationships and the network topology of brain activity, GNNs offer a powerful approach for capturing distributed patterns often missed by methods that analyze channels independently or rely solely on local convolutional operations.​  

One of the most significant application areas for GNNs in EEG analysis is emotion recognition [17]. Emotional experiences manifest as complex, spatially distributed brain activity, and GNNs are well-suited to model the intricate relationships between brain regions during emotional states [9]. Various GNN architectures, such as Dynamic Graph Convolutional Neural Networks (DGCNNs) and Regularized Graph Neural Networks (RGNNs), have been applied, utilizing features like Power Spectral Density (PSD) and constructing graphs based on static topological layouts or dynamic functional connectivity [7,8]. The interpretability of GNN models can provide insights into the neurophysiological underpinnings of emotion, suggesting the importance of specific brain regions like the frontal, parietal, and occipital lobes [8].​  

Brain-Computer Interfaces (BCIs) represent another prominent domain where GNNs are making significant contributions, particularly in motor imagery (MI) classification [3,24]. Accurate decoding of imagined movements from EEG is crucial for BCI applications like exoskeleton control [17]. GNNs can model the complex spatial and functional connectivity patterns underlying MI, potentially improving decoding accuracy compared to traditional methods like Common Spatial Pattern (CSP) by integrating spectral, spatial, and temporal features [5].​  

In clinical neuroscience, GNNs are being explored for automated seizure detection and prediction from EEG signals [17]. Manual analysis is time-consuming and subjective, highlighting the need for robust automated systems [6]. GNNs can leverage the relational structure of multi-channel EEG to identify patterns indicative of different seizure types. A GraphGuided Network (GGN) model, for instance, has demonstrated high accuracy in detecting multiple seizure types on a clinical dataset [2]. Such systems hold substantial clinical potential for assisting neurologists in diagnosis and management [2].  

The diagnosis and prediction of various neurological and mental disorders also benefit from GNN applications in EEG analysis [11,20]. Conditions such as Alzheimer's disease (AD), schizophrenia, depression, and autism spectrum disorder (ASD) are associated with alterations in brain network connectivity [1,34]. By representing the brain as a graph, GNNs, including Spatio-temporal Graph Convolutional Networks (ST-GCNs), can analyze functional connectivity patterns derived from EEG to identify disease-specific biomarkers and improve diagnostic accuracy [1,2].  

Decoding cognitive states, such as mental workload, attention, memory, and fatigue, from EEG is another area where GNNs show promise [17]. These states involve distributed brain activity, and GNNs are suitable for modeling the underlying network dynamics. While not always explicitly GNNs, related network-based analyses and deep learning approaches demonstrate the utility of capturing complex patterns for tasks like driver fatigue detection [3,13,24].​  

Sleep stage classification is a critical task for diagnosing sleep disorders, and GNNs offer a means to automate this process [17]. Hybrid models, such as Graph-Temporal fused CNNs, have been explored to integrate both spatial (graph-based) and temporal information from EEG for automated sleep scoring [3,24].​  

Beyond these key areas, GNNs are applicable to other domains including neuromodulation, neural rehabilitation, neurofeedback, and EEG-based biometrics [12,34]. The ability of GNNs to process complex graph structures also suggests potential in areas like motor imagery recognition [3] and potentially analyzing the effects of drugs on brain activity by modeling changes in functional connectivity, although specific GNN applications in drug effect analysis using EEG are not extensively detailed in the provided digests [29].​  

Despite the advancements and diverse applications, several cross-cutting challenges persist. These include the inherent non-stationarity and significant inter-subject variability of EEG signals, which necessitate robust and adaptive GNN architectures [7,8,17]. Acquiring large, diverse, and well-annotated datasets remains a challenge across various  

applications, impacting model generalization and the ability to detect rare events like seizures or subtle pre-ictal patterns [17]. Furthermore, enhancing the interpretability of GNN models is crucial for gaining clinical trust and understanding the neurophysiological basis of findings [2,8]. Finally, deploying GNNs in real-time applications like BCIs requires addressing computational efficiency [16]. Future research is focused on developing novel GNN architectures tailored to EEG dynamics, creating robust methods for handling data variability and non-stationarity, improving model interpretability, and developing larger and more ecologically valid datasets.​  

# 5.1 Emotion Recognition  

EEG-based emotion recognition constitutes a significant application area within the broader field of deep learning for EEG analysis, positioned as the second largest area following motor imagery task classification [17]. The application of Graph Neural Networks (GNNs) in this domain is motivated by their capacity to effectively model the complex and spatially distributed nature of brain activity and the intricate relationships between different brain regions during emotional experiences [9,24]. By representing EEG features within graph structures, GNNs can learn essential associations between nodes (EEG channels or brain regions) [9]. Commonly used benchmark datasets for developing and evaluating EEG-based emotion recognition models include DEAP, SEED, AMIGOS, SEED-IV, and DREAMER [7,8,17,22,26,37].  

Various GNN-based and graph-inspired methodologies have been developed for EEG emotion recognition, characterized by diverse approaches to preprocessing, graph construction, feature extraction, and network architectures. Some methods leverage brain network analysis principles within deep learning frameworks, such as a Brain Network Analysis-Based Double Way Deep Neural Network [3,24] and a Core-Brain-Network-Based Multilayer Convolutional Neural Network [24]. Specific GNN models include the Dynamic Graph Convolutional Neural Network (DGCNN), applied to datasets like SEED and DREAMER [7]. The DGCNN approach can utilize features such as Power Spectral Density (PSD) and dynamically updates the adjacency matrix, allowing the model to capture transient changes in functional connectivity [7,9]. Another approach, the Regularized Graph Neural Network (RGNN), has been evaluated on SEED and SEED-IV datasets [8]. The RGNN constructs a biologically-inspired adjacency matrix that represents the static topological layout of EEG channels, incorporating regularizers like Node Domain Adversarial Training (NodeDAT) and Emotion-aware Distribution Learning (EmotionDL) within its custom architecture [8]. Furthermore, studies have explored integrating brain connectivity explicitly into other deep learning architectures, such as using PLV connectivity matrices and considering spatial electrode arrangements (e.g., dist2) with CNN models on the DEAP dataset, demonstrating the benefit of modeling non-symmetric brain activity patterns [37]. Preprocessing steps commonly involve standard procedures like downsampling, filtering, and artifact removal, while feature extraction can range from traditional time-frequency methods like wavelet analysis [28] to feeding raw or processed data directly into the network.​  

Performance metrics reported across these studies primarily include classification accuracy and AUC [7,8,15,22,26,28,37]. Comparisons often involve state-of-the-art methods, including both GNNs and other deep learning or traditional machine learning approaches [7,8,15,22,26,28]. While direct quantitative comparison is challenging due to variations in datasets, preprocessing, classification tasks (binary, three-class, four-class), and experimental protocols (subject-dependent vs. subject-independent), some studies report very high accuracies. For instance, a hybrid 3DCNN-BLSTM model achieved accuracies up to $9 3 . 5 6 \%$ for arousal and $9 3 . 2 1 \%$ for valence (two-class) on DEAP, and $9 8 . 9 0 \%$ for three-class on SEED [26]. A CNN model incorporating PLV connectivity and spatial layout achieved $9 9 . 7 2 \%$ accuracy for binary valence on DEAP [37]. Among non-GNN methods, MKL-SVM achieved $9 2 . 2 5 \%$ accuracy on SEED (random split) [15], and an RF classifier with LPP feature reduction on gamma band features reached $8 2 . 0 \% \pm 7 . 1 \%$ on DEAP [28]. The ERTNet (CNN-Transformer) model reported $7 4 . 2 3 \% \pm 2 . 5 9 \%$ accuracy on DEAP and $6 7 . 1 7 \% \pm 1 . 7 0 \%$ on SEED- $\cdot \vee$ [22]. GNNs offer the potential to explicitly model inter-channel relationships, which is a key aspect of brain connectivity and spatial information in EEG signals [9,37].  

The interpretability of these models provides insights into the neurophysiological basis of emotion. RGNN-based analysis suggests that the frontal, parietal, and occipital regions are particularly informative for emotion recognition [8]. Complementary findings from non-GNN models like ERTNet indicate that high-frequency bands (beta and gamma) and midfrequency bands (alpha) are relevant, with high-frequency contributions concentrated in temporal and prefrontal regions [22]. Another study using MKL-SVM also found higher frequency band information to be more correlated with emotional state [15]. These results collectively highlight the importance of specific frequency bands and their distribution across the scalp, which is inherently addressed when GNNs model spatial and connectivity patterns.  

Despite the advancements, challenges persist in GNN-based emotion recognition, notably addressing dataset bias and subject variability. While studies conducting subject-dependent and subject-independent experiments [7,8] provide valuable insights into generalization capabilities, achieving robust performance across a wide range of individuals remains difficult. Future directions involve developing more advanced and adaptive graph construction techniques that can capture individual brain network characteristics and dynamic emotional changes. Exploring novel GNN architectures that seamlessly integrate temporal, spatial, and connectivity features is also crucial. Furthermore, the field would benefit from the creation of larger, more diverse, and ecologically valid datasets to reduce bias and improve the models' ability to generalize to real-world scenarios. Continued focus on model interpretability will also be vital for uncovering deeper insights into the neural mechanisms underlying emotional processing.  

# 5.2 Brain-Computer Interfaces (BCIs)  

Brain-Computer Interfaces (BCIs) represent a rapidly evolving field aimed at establishing direct communication pathways between the brain and external devices. EEG signals are a primary modality for non-invasive BCIs due to their portability and relatively low cost [6]. Effectively analyzing EEG signals is crucial for BCI performance, and Graph Neural Networks (GNNs) have emerged as a promising technique by effectively modeling the complex relationships and functional connectivity between different EEG channels [17,42]. The application of machine learning, including GNNs, is actively explored to solve practical problems in BCI systems [12].​  

A significant application area for GNNs in BCIs is motor imagery (MI) classification [3,24]. Motor imagery tasks, which involve imagining movements without physical execution, are commonly used for applications like exoskeleton control [17]. These tasks are typically categorized into visual motor imagery (VMI) and kinesthetic motor imagery (KMI) [17]. Deep learning architectures, including GNNs, have demonstrated potential for improving classification accuracy in MI applications [17]. For instance, Dynamic Graph Convolutional Neural Networks (DGCNNs) combined with Temporal Convolutional Networks (TCNs) have been proposed to enhance the decoding accuracy of motor imagery tasks by processing EEG data to classify intended movements like left and right-hand movements [5]. Another approach utilizes Siamese Neural Networks for MI classification, transforming the multi-class problem into binary classification tasks handled by the network on preprocessed EEG signals [41]. Beyond GNNs specifically, other deep learning methods like ABiLSTM-CNN models are designed to capture both spatial and temporal features from MI EEG signals, highlighting the importance of extracting comprehensive representations for accurate classification [10]. The BCI field also encompasses other applications such as multi-modal emotion BCI [22,34], VEP-based and SSVEP-based BCIs [3,34], and decoding various mental states [30].  

GNNs offer several advantages in BCI applications. By modeling the topological structure and functional connectivity of brain activity captured by EEG, GNNs can potentially capture more complex and spatially distributed patterns compared to methods that treat channels independently or rely on simpler linear spatial filters. This capability contributes to improved decoding accuracy and potentially enhanced robustness against noise or variations in electrode placement [5,22]. Compared to traditional BCI methods, such as those based on Common Spatial Pattern (CSP) which primarily relies on spatial filtering for feature extraction in MI-BCI [43], GNNs can integrate spectral, spatial, and temporal features within a unified framework, potentially leading to more sophisticated pattern recognition. However, traditional BCI methods still face challenges in usability, training duration, and information transfer rate [6].​  

Despite the advantages, several challenges remain in deploying GNNs for BCI. EEG signals are inherently non-stationary, and developing GNN architectures capable of effectively handling these temporal dynamics and adapting to changes in brain activity over time is crucial [17]. Furthermore, EEG patterns can vary significantly between individuals, necessitating the development of GNN models that can adapt to individual users without extensive calibration data [17,30]. Implementing GNNs in real-time BCI systems introduces challenges related to computational complexity, requiring efficient network architectures and optimized algorithms for online inference and potentially online training [16]. Future research directions include exploring novel GNN architectures tailored for the unique characteristics of EEG data, developing robust methods for handling data non-stationarity and inter-subject variability, and optimizing computational efficiency for real-time BCI applications. Research into neuromorphic computing also offers insights into developing low-cost, adaptive systems for brain-machine interfaces [16]. Addressing these challenges is key to realizing the full potential of GNNs in enhancing BCI performance and usability [6].  

# 5.3 Seizure Detection and Prediction  

Automated detection, classification, and prediction of epileptic seizures from electroencephalography (EEG) signals represent a critical area of research aimed at overcoming the limitations of manual analysis, which is time-consuming and subjective [6]. Machine learning and deep learning techniques have been widely explored for this purpose, including recent applications of Graph Neural Networks (GNNs) [2,17,31].  

While traditional machine learning methods such as Support Vector Machine (SVM), k-Nearest Neighbor (k-NN), and Linear Discriminant Analysis (LDA) have demonstrated high classification accuracy, achieving up to $1 0 0 \%$ on databases like CHBMIT for distinguishing ictal (seizure) and interictal (free seizure) states [31], these methods often rely on hand-crafted features and do not explicitly model the complex functional or structural connectivity of the brain.  

GNNs, by contrast, are inherently suited to leverage the relational structure present in multi-channel EEG data, which can be represented as a graph where nodes correspond to electrodes and edges represent statistical dependencies or spatial proximity. Research has explored deep learning approaches utilizing multi-frequency multilayer brain networks for EEGbased epilepsy detection, implicitly suggesting the use of graph representations [24]. More explicitly, a Graph-Guided Network (GGN) model has been developed specifically for detecting various types of epileptic seizures using EEG data [2]. This GGN model was evaluated on a clinical dataset comprising 3047 epileptic seizure cases, demonstrating notable performance with over $9 0 \%$ accuracy in detecting seven distinct seizure types [2]. Comparisons against other models, including traditional machine learning (SVM) and deep learning architectures (CNN, generic GNN, Transformer), indicated that the GGN model achieved superior accuracy and ROC-AUC scores on this clinical dataset [2]. This highlights the potential of specialized GNN architectures to capture intricate patterns related to different seizure manifestations.​  

In the related task of seizure prediction, LSTM networks have also shown high predictive accuracy on the CHB-MIT scalp EEG database [36], underscoring the broader utility of deep learning for anticipating seizure onset. While the provided digests primarily focus on detection and classification, the application of graph representations within prediction models is a natural extension.  

The clinical applications of accurate, automated seizure detection systems are substantial. They can provide a machine learning framework to assist neurologists in the precise identification of various seizure types, potentially speeding up diagnosis and improving patient management [2,6]. Furthermore, reliable real-time detection could inform clinical interventions, such as closed-loop control systems involving transcranial electrical stimulation for epilepsy management [16].​  

Despite the promising results, challenges persist in the application of GNNs for seizure detection and prediction. While not explicitly detailed in the provided digests concerning GNNs, common challenges in this field include the need for large amounts of high-quality labeled data, which can be difficult and expensive to obtain, and the inherent difficulty in detecting rare seizure events or subtle pre-ictal patterns. The variability in EEG signals across patients and different seizure types also poses a significant hurdle.  

Investigating the interpretability of GNNs in seizure detection is crucial for clinical trust and adoption. While the GGN study provides a framework intended for use by brain experts [2], the mechanisms by which GNNs identify the specific EEG patterns indicative of seizure activity are not explicitly elaborated upon in the provided digests. Future research needs to focus on methods to visualize and understand the graph features and nodes that contribute most significantly to the model's decision-making process, thereby potentially revealing novel neurophysiological markers of seizure onset and propagation.​  

# 5.4 Brain Disease Diagnosis and Prediction (Neurological/Mental Disorders)  

Graph Neural Networks (GNNs) have demonstrated effectiveness in the diagnosis and prediction of brain diseases using Electroencephalography (EEG) data [4,11,20]. The application spans a range of neurological and mental disorders, including Alzheimer's disease, epilepsy, schizophrenia, depression, autism spectrum disorder (ASD), and sleep disorders [2,3,11,12,20,24,31,34,36].​  

A key aspect of applying GNNs in this domain is the representation of brain activity as graphs, where nodes typically represent EEG electrodes or brain regions, and edges represent functional or structural connectivity [1,11]. Various input features derived from EEG signals are utilized. Common approaches include using functional connectivity measures, such as correlation or partial correlation matrices, which capture the statistical interdependencies between different brain areas [1,11]. For instance, studies have employed correlation and partial correlation matrices as input features for GNN models in the diagnosis of ASD [11]. Another approach leverages functional connectivity derived from EEG to represent the intricate interactions within the brain network [1].​  

Different GNN architectures are employed based on the nature of the EEG data and the specific task. Spatio-temporal Graph Convolutional Networks (ST-GCNs) are utilized to capture both the spatial (connectivity) and temporal dynamics of EEG signals, as demonstrated in the diagnosis of Alzheimer's disease [1]. Other studies explore novel complex network-based GCNs and combinations of multilayer brain networks with deep convolutional neural networks for conditions like major depressive disorder (MDD) [3,24]. These architectural choices reflect efforts to effectively model the complex, dynamic interactions inherent in brain activity.​  

GNNs enhance the accuracy of disease diagnosis and prediction by effectively analyzing the complex patterns within brain networks, thereby facilitating the identification of relevant biomarkers [4,11]. By modeling the relationships and interactions between brain regions, GNNs can detect subtle alterations in functional connectivity and network topology that are indicative of pathological states. For instance, applying an ST-GCN model using functional connectivity derived from EEG achieved a classification accuracy of $9 2 . 3 \%$ in distinguishing AD patients from healthy controls [1]. Furthermore, methods like GGN have been proposed to accurately discover functional connectivity from limited observation windows, offering a valuable tool for analyzing brain connectivity in various neurological disorders, including AD and schizophrenia, and potentially identifying biomarkers [2].​  

Applying GNNs to different mental disorders presents specific challenges and opportunities. Mental disorders, such as depression, often involve complex and sometimes overlapping pathological mechanisms [34,39]. The heterogeneity within diagnostic categories and the influence of various factors, including potential issues like over-diagnosis in depression [34], necessitate robust and nuanced analytical methods. GNNs offer an opportunity to explore the network-level dysfunctions associated with these disorders, potentially revealing specific connectivity patterns or biomarkers that distinguish subtypes or severity levels. However, challenges include acquiring sufficiently large and well-characterized datasets for various mental disorders and developing GNN models capable of capturing the intricate and often dynamic nature of mental health conditions.​  

Alzheimer's disease (AD) is a prominent area of application for GNNs in EEG analysis [1,17,20]. GNNs, particularly ST-GCNs processing functional connectivity, are used to identify EEG biomarkers associated with AD progression [1]. This approach aims to differentiate AD patients from healthy individuals and potentially classify different stages of AD severity, such as preclinical, prodromal, mild, moderate, and severe AD, which is a key focus in current research [17]. By capturing the alterations in brain network topology and dynamics, GNNs contribute to improving the accuracy of AD diagnosis based on non-invasive EEG data [1].  

Common datasets utilized in GNN-based brain disease diagnosis include publicly available repositories like ABIDE (for ASD) and various clinical EEG datasets collected for specific conditions like AD [1,11]. Evaluation metrics commonly employed to assess model performance include accuracy (acc), Area Under the Curve (auc), and F1-score, depending on the specific classification task [1,11].  

GNNs contribute to detecting disease-related EEG patterns by overcoming inherent challenges of bioelectrical signals, such as strong noise, randomness, nonlinearity, and significant inter-individual variability [35]. By modeling the brain as a graph, GNNs can learn complex dependencies and global network properties that may not be apparent from analyzing individual EEG channels or simple statistical features. This ability to capture structural and functional relationships within the brain network allows GNNs to identify sophisticated disease-related patterns, thereby improving diagnostic accuracy and aiding in automatic diagnosis, which is crucial for developing smart healthcare systems [35]. The potential of GNNs to identify these complex biomarkers from EEG data holds promise for the early detection of brain diseases, potentially enabling interventions at earlier, more treatable stages.  

# 5.5 Cognitive State Decoding (including Cognitive Load, Attention, Memory)  

Decoding cognitive states such as mental workload, attention, and memory from electroencephalogram (EEG) signals represents a critical application area for advanced analytical techniques [17,34]. Mental workload, defined as the mental effort expended during task performance [17], is one specific cognitive state frequently targeted for analysis. Beyond workload, researchers also investigate attention mechanisms, memory processes, and states like driver fatigue using EEG [3,34]. Effectively analyzing EEG for these purposes often necessitates modeling the complex interactions and functional connectivity among different brain regions.  

Graph Neural Networks (GNNs) hold significant potential in this domain due to their inherent ability to model data with underlying graph structures, which aligns well with the representation of brain activity as a network where electrodes or brain regions are nodes and their statistical dependencies or functional connections are edges [17]. By capturing both local node features (e.g., spectral power at an electrode) and the relational structure (e.g., coherence between regions), GNNs can potentially provide richer insights into the distributed nature of cognitive processes compared to methods that analyze channels independently or rely solely on temporal or spatial convolution without explicitly modeling connectivity.  

Various approaches have been explored to decode cognitive states from EEG, some of which utilize network-based analysis or deep learning architectures relevant to the application context where GNNs could be employed. For instance, complex network analysis has been applied to experimental EEG signals specifically for decoding brain cognitive states [24]. Within this approach, specific techniques like complex network-based broad learning systems, novel multiplex limited penetrable horizontal visibility graphs, and relative wavelet entropy complex networks have been utilized for tasks such as detecting driver fatigue from EEG signals [3]. These methods demonstrate the utility of representing EEG data as networks to extract features indicative of cognitive states.​  

In the realm of deep learning, approaches beyond traditional GNNs have also shown promise. Bashivan et al., as noted in a review on GNNs for EEG analysis, employed a deep recurrent-convolutional neural network (RCNN) for predicting mental workload [17]. By converting preprocessed EEG into topologically-preserved multi-spectral images, this RCNN achieved an $8 . 9 \%$ improvement in classification accuracy over contemporary state-of-the-art methods [17]. Other general deep learning methods have also been explored for brain state recognition [34]. While these examples may not explicitly use GNN architectures, they highlight the application area and the effectiveness of deep learning in extracting relevant patterns from complex EEG data, setting the stage for GNN applications that can leverage both deep feature extraction and graph-based connectivity modeling.​  

The potential applications of GNNs in cognitive state monitoring are substantial, ranging from real-time assessment of operator workload in demanding tasks to fatigue detection for safety-critical professions [3,17,34]. Furthermore, accurate cognitive state decoding is crucial for the development of advanced brain-computer interfaces (BCIs) that can adapt to a user's cognitive state or provide feedback based on detected attention or workload levels [34]. By modeling the functional connectivity dynamics underlying cognitive processes, GNNs could contribute to more robust and user-adaptive BCIs.  

Despite the promising outlook, applying GNNs to cognitive state analysis from EEG faces several challenges and limitations. A fundamental requirement is access to high-quality EEG data, which is often susceptible to noise artifacts and requires rigorous preprocessing. Furthermore, establishing standardized training procedures and appropriate evaluation metrics for GNN models in this context remains an active area of research. The difficulty of validating GNN models stems from the complex, inter-subject variability in EEG signals and brain network structures, as well as the need for ground truth labels for cognitive states, which can be subjective or require demanding experimental protocols. Future work needs to address these data quality and validation challenges to fully realize the potential of GNNs for decoding intricate cognitive states from EEG.  

# 5.6 Sleep Stage Classification  

The application of Graph Neural Networks (GNNs) in the analysis of electroencephalogram (EEG) data extends to the crucial task of sleep stage classification [17]. Automating sleep scoring is a critical area of research with potential clinical applications, offering the prospect of more efficient and objective diagnosis of sleep disorders [17]. Various methodologies have been explored for automated sleep analysis, including deep learning approaches. For instance, DeepSleepNet, a network not based on GNNs but employing 1D Convolutional Neural Networks (CNNs) combined with bidirectional Long Short-Term Memory (LSTM) modules, has been applied to raw single-channel EEG data and demonstrated substantial agreement with human expert scoring, reporting a kappa value of 0.80 [17].​  

Within the domain of GNN-based approaches for sleep stage detection from EEG signals, one notable architecture that has been utilized is the Graph-Temporal fused dual-input Convolutional Neural Network [3,24]. This method integrates both graph-based and temporal processing streams, leveraging CNNs to extract features that capture spatial relationships (potentially through graph processing) and temporal dynamics within the EEG signals. While the specific details regarding the preprocessing steps, graph construction methodology, and performance metrics like accuracy or kappa for this particular GNN-based model are not provided in the digests, its application highlights the exploration of hybrid graphtemporal models in this field [3,24].​  

Compared to non-GNN methods like DeepSleepNet which primarily rely on temporal and local spatial features from single or multi-channel EEG using standard convolutional and recurrent layers [17], GNN-based approaches inherently offer the capability to explicitly model the functional or structural connectivity between different EEG channels as a graph. This  

allows for the direct incorporation of inter-channel relationships, which can be crucial for understanding brain states like sleep stages.  

The potential clinical applications of robust GNN-based sleep stage classification systems are significant [17]. Automated systems could alleviate the labor-intensive process of manual sleep scoring, providing consistent and timely analysis. Furthermore, accurate automated scoring using GNNs could facilitate the diagnosis and monitoring of various sleep disorders by identifying aberrant patterns in sleep architecture [17]. Future research using GNNs in this area would benefit from detailed comparisons of different graph construction strategies (e.g., based on functional connectivity, spatial proximity), diverse GNN architectures (e.g., GCN, GAT, complex graph-temporal models), and rigorous performance evaluation against state-of-the-art non-GNN and other GNN models using standard datasets and metrics.  

# 5.7 Human-Robot Interaction (HRI)  

Enhancing human-robot interaction (HRI) necessitates the accurate estimation of a user's affective state, which can significantly influence the robot's responsiveness and adaptability during social engagement [27].  

Electroencephalography (EEG) has emerged as a valuable modality for capturing user affective responses in HRI scenarios [27].​  

Research in this area focuses on understanding how variables—such as robot personality—impact user emotions measure by EEG signals [27].  

Affective states are commonly represented using models like valence–arousal, and classification techniques such as Support Vector Machines (SVM), Decision Trees, and Deep Neural Networks (DNNs) are employed for their estimation [27]  

For instance, studies have demonstrated that a robot exhibiting a positive attitude can contribute to reducing negative emotional states, specifically stress, in users during interaction [27].  

While this work highlights the importance of EEG-based emotion recognition in HRI, the methodologies described utilize traditional machine learning and deep learning approaches without incorporating Graph Neural Networks for the analysis of EEG data [27].​  

Consequently, based on the provided digest for this section, the specific application or demonstrated benefits of Graph Neural Networks for enhancing emotion recognition and affective state estimation in HRI using EEG are not presented.  

# 5.8 Other Applications  

Beyond widely explored areas such as emotion recognition and disease diagnosis, graph neural networks (GNNs) are finding application in a variety of other emerging domains within electroencephalography (EEG) analysis. These applications underscore the versatility of GNNs in leveraging the complex connectivity inherent in brain activity. Relevant fields include neuromodulation technology, brain-computer interfaces (BCI), brain function assessment, diagnosis of brain diseases, motor function evaluation post‐stroke, neural rehabilitation engineering, neurofeedback, and EEG‐based biometrics [12,34]. Similarly, analogous applications of GNNs in related bio‐signal processing, such as electrocardiogram (ECG) signal classification, further illustrate the potential for graph‐based methods to model complex physiological data [25]. General applications of GNNs in diverse fields like image recognition, natural language processing, and recommendation systems, utilizing architectures such as Graph Attention Networks (GATs), suggest their adaptability to capturing intricate relationships within EEG data [19].  

A prominent emerging application is the detection of driving fatigue using EEG data. This is a critical area for traffic safety, where variations in brain states need to be accurately identified. Studies in this domain compare various machine learning approaches, including deep learning models like Channel‐wise CNN (CCNN) and Residual CNN (CNN‐R), with traditional methods to differentiate between alert and drowsy states [17]. Hajinoroozi et al. found that a CCNN architecture demonstrated superior performance compared to regular CNN, DNN, LDA, and SVM models in estimating driver drowsiness in a simulated environment [17]. Furthermore, Hong et al. observed that a CNN‐R model achieved faster convergence and lower loss volatility for estimating driver mental workload compared to a CNN without residual connections [17]. Within graph‐based approaches for fatigue detection, the SACC-CapsNet model has been applied to EEG data [13]. This model utilizes a temporal-channel attention module to enhance the significance of critical brain regions [13]. Analysis using the channel covariance matrix within the SACC-CapsNet framework indicated that the frontal pole region is particularly informative for driving fatigue detection, followed by the parietal and central regions [13]. The reconstructed channel  

covariance matrix was found to preserve valuable information about these key areas [13]. Other graph-based or complex network methods have also been employed, including a relative wavelet entropy complex network for improved fatiguedriving classification and an adaptive optimal-Kernel time-frequency representation-based complex network method for characterizing fatigued behavior using SSVEP-based BCI systems [24].  

Another potential application area for GNNs in EEG analysis is assessing the impact of drugs on brain activity. While the provided digests highlight the general application of GNNs in the field of drug medicine [29], specific examples demonstrating the use of GNNs for analyzing drug effects directly from EEG data are not detailed in the available materials. However, given the capability of GNNs to model complex interactions within networks, they hold promise for analyzing how pharmacological substances alter the functional connectivity and activity patterns of the brain as captured by EEG.  

Other domains such as motor imagery recognition, where brain signals corresponding to imagined movements are classified, represent fertile ground for GNN applications given the network nature of motor control processes in the brain [3,40]. The capability of GNNs to process complex graph structures makes them well-suited for capturing the intricate functional or structural relationships between EEG channels during such cognitive tasks.  

In summary, GNNs are expanding their reach into diverse EEG application areas, particularly demonstrating effectiveness in tasks like driving fatigue detection by identifying key brain regions and utilizing complex network analyses. While specific examples in fields like drug effect analysis using EEG are less documented in the provided digests, the general applicability of GNNs in related areas suggests significant potential for future research.​  

# 6. Challenges and Future Directions  

The application of Graph Neural Networks (GNNs) to Electroencephalography (EEG) analysis holds significant promise for advancing our understanding of brain function and improving diagnostic and therapeutic tools. However, realizing this potential necessitates addressing several fundamental challenges, stemming from both the inherent limitations of GNN architectures and the unique characteristics of EEG data. Current GNN models often face issues related to computational complexity, particularly with large datasets or sophisticated mechanisms like attention [18,19,21]. A critical hurdle, especially for clinical deployment, is the limited interpretability of GNN predictions [18], making it difficult to understand the basis for a model's decision. Furthermore, GNN performance is highly sensitive to the specific method used for constructing the graph representation of EEG channels or brain regions [18,21], raising concerns about model robustness and generalizability across different graph definitions. The over-smoothing phenomenon in deep GNNs, where node representations become indistinguishable, also restricts their ability to capture complex hierarchical patterns [4,18]. Early GNN variants also struggled with handling the dynamic and variable nature of graph structures [29].  

Beyond GNN-specific issues, challenges arise from the nature of EEG data itself. EEG signals are non-stationary, non-linear, and susceptible to noise and artifacts [6,17,23,43]. Non-invasive EEG suffers from low spatial resolution and high intersubject variability [23,43]. Data heterogeneity across recording setups and paradigms is common [20]. A pervasive challenge is the limited availability of large, labeled EEG datasets, which hinders the training of data-hungry deep learning models like Dynamic Graph Convolutional Neural Networks (DGCNN) and significantly impacts generalization, especially in crosssubject scenarios [1,7,14,22,37]. The difficulty in aligning deep learning models with the inherent temporal dynamics of EEG also poses a significant challenge [23], as does the lag in real-time data acquisition and interpretation for online BrainComputer Interfaces (BCI) [43].​  

Addressing these challenges necessitates exploring several interconnected future directions. Overcoming GNN limitations requires developing more efficient architectures and optimizing training processes, for instance, through dynamic graph methods that adapt to time-varying data [5,21] or leveraging Deep Reinforcement Learning (DRL) to automatically configure optimal model structures [4]. Channel selection and neuromorphic computing are also promising for efficiency and realtime processing [6,16].​  

Enhancing interpretability is paramount. Future work needs to focus on integrating Explainable AI (XAI) techniques specifically adapted for GNNs in EEG, including methods for visualizing learned parameters, analyzing attention mechanisms, and interpreting derived functional connectivity patterns [1,2,8,10,13,17,37]. Developing standardized evaluation frameworks and metrics for assessing explanation quality is also crucial [18,22].  

Effectively capturing the temporal dynamics of EEG is another key direction. This involves integrating GNNs with dedicated temporal models like LSTMs or TCNs [5,10], developing Spatio-Temporal GNNs (ST-GNNs) [1], or employing dynamic graph models that capture evolving brain connectivity [2]. Brain-inspired algorithms and neuromorphic approaches are also inherently suited for temporal processing [16,23].  

Multi-modal data fusion represents a powerful avenue for obtaining a more comprehensive view of brain activity [17,23,28,30,34]. Future research needs to explore novel methods for representing heterogeneous multi-modal data within a unified structure compatible with GNNs, potentially utilizing concepts like multi-layer complex networks [25].  

Integrating brain-inspired algorithms, such as Spiking Neural Networks (SNNs), and leveraging Deep Reinforcement Learning (DRL) offer paths towards more biologically plausible, efficient, and optimized GNN architectures for EEG analysis [3,4,16,19,23,36,42]. However, challenges remain in formulating effective DRL reward functions and exploration strategies [4].​  

Finally, advancing the field critically depends on establishing standardized benchmarking and evaluation protocols. Addressing reproducibility issues through widespread data and code sharing, guided by principles like FAIR neuroscience and BIDS, is essential [17]. Developing standard benchmarks that represent the diversity of real-world EEG tasks [11,20] and consistently reporting a comprehensive set of evaluation metrics (e.g., Accuracy, Precision, Recall, F1-score, AUC) are vital steps for rigorous comparison and progress tracking [1,2,4,5,7,8,10,31]. Future research must carefully consider the tradeoffs among model complexity, data requirements, computational efficiency, and performance when designing GNN-based solutions for EEG analysis.  

# 6.1 Overcoming Limitations of Current GNN Models  

Applying Graph Neural Networks (GNNs) to Electroencephalography (EEG) analysis presents several challenges, stemming from both the inherent limitations of GNN architectures and the unique characteristics of EEG data. A primary limitation of GNN models includes their computational complexity, particularly when processing large graphs or employing complex attention mechanisms, which can make them computationally expensive [18,19,21]. The interpretability of GNN predictions is often poor [18], which poses a significant obstacle in clinical applications requiring transparency and understanding of the model's decision-making process. Furthermore, GNN performance is highly sensitive to the graph construction method employed [18,21], raising questions about the robustness and generalizability of models across different graph definitions. The "over-smoothing" problem, where node representations become increasingly similar with greater network depth, limits the expressive power and generalization capability of deep GNNs [4,18]. Early GNNs, often based on Recurrent Neural Networks (RNNs), struggled to effectively handle complex and variable graph structures [29].​  

Beyond GNN-specific issues, the application to EEG data introduces challenges related to data characteristics and availability. EEG signals are inherently non-stationary, non-linear, and non-Gaussian [6]. Signals acquired via non-invasive scalp electrodes exhibit low spatial resolution, instability, large individual differences, and are highly susceptible to interference, making accurate information extraction difficult [23,43]. A major hurdle is data heterogeneity, arising from variations in recording equipment, experimental paradigms, and subject populations [20]. Limited sample size is a pervasive issue in EEG studies [1,7,14,22,37], posing difficulties for training data-intensive deep neural networks like Dynamic Graph Convolutional Neural Networks (DGCNN) [7] and significantly impacting model generalizability, particularly in cross-subject validation scenarios [1,22]. When using hybrid methods combining deep learning with traditional techniques, there is a risk that the model may inadvertently learn from artifacts if their removal or minimization is not explicitly addressed [17]. The lag in developing methods for accurate real-time acquisition and interpretation of EEG data also restricts the transition from offline to online Brain-Computer Interface (BCI) applications [43]. Furthermore, aligning the structural characteristics of deep learning models with the temporal dynamics of EEG signals remains a challenge [23].​  

Various approaches have been explored to mitigate these limitations and challenges. To address model efficiency and architecture inflexibility, the development of more efficient GNN architectures is crucial [21]. Dynamic graph convolution, which adapts to time-series data characteristics by updating edge weights via backpropagation, offers improved feature extraction for EEG [5]. Deep Reinforcement Learning (DRL) has been utilized to automatically determine the optimal number of GNN layers, overcoming the limitation of fixed-layer architectures that may not be suitable for all brain networks [4]. Channel selection algorithms can reduce computational complexity when handling high-density EEG data [6]. Neuromorphic computing is proposed as a potential solution for developing ultra-low energy and adaptive BMI systems [16].  

Enhancing interpretability, despite the inherent challenges of GNNs [18], is vital. Incorporating explainability techniques is necessary. Ensemble learning or integrating domain-specific knowledge into feature extraction could potentially improve model precision and interpretability [22].  

To improve robustness to graph construction sensitivity [18,21] and account for the specific spatial and functional characteristics of the brain, utilizing robust graph construction methods is essential. Models like Graph Generative Networks (GGN) employ probabilistic graph generation and attention mechanisms to better capture dynamic spatial information and brain functional connections over time [2]. Incorporating brain connectivity features and explicitly considering the spatial arrangement of electrodes can enhance performance, such as in emotion recognition [37]. Integrating other heterogeneous physiological signals can lead to more robust and accurate multi-modal emotion recognition [28].  

Addressing limited data samples and data heterogeneity is critical. Techniques like k-fold cross-validation [37], data augmentation, transfer learning, and semi-supervised learning are standard approaches (as mentioned in the description). Large-scale self-supervised learning (SSL) represents a promising avenue for tackling limited data and insufficient supervision, aiming to improve generalizability and adaptability of brain network analysis models [14]. Pre-trained multitask models are suggested for achieving scalable and generalizable performance across diverse datasets and task variations [20]. Regularization techniques, such as Node Domain Adversarial Training (NodeDAT), can enhance robustness to intersubject EEG variations, while Emotion-aware Distribution Learning (EmotionDL) improves robustness to noisy labels [8]. The development of user- or environment-adaptive BCIs also contributes to handling data variability [30].​  

Mitigating over-smoothing in deep GNNs can be partially addressed using strategies like skip connections [4]. Furthermore, optimizing model architectures and training processes is crucial. This includes optimizing loss functions [41], utilizing AutoML tools like NNI for hyperparameter tuning [11], employing regularization techniques such as Dropout and l1 regularization to prevent overfitting and enhance generalization [10], applying supervised learning algorithms for model parameter estimation [21], and developing improved training techniques, particularly for hybrid models [23].​  

Analyzing the trade-offs between these approaches is important. For example, developing more complex, adaptive architectures (e.g., dynamic graphs or DRL-guided layers) may improve performance and flexibility but often increases computational cost. Utilizing large-scale SSL requires significant computational resources for pre-training but can yield models with superior generalizability on downstream tasks with limited data. Transfer learning can accelerate training and improve performance on small datasets but is dependent on the availability of relevant pre-trained models and the similarity between source and target domains. Incorporating multi-modal data increases robustness but adds complexity to data acquisition, preprocessing, and model design. Regularization techniques like NodeDAT or EmotionDL improve robustness to specific data variations but require careful implementation and tuning. While skip connections help mitigate over-smoothing, they modify the standard GNN message passing and may not fully resolve the issue in all cases. The balance between model complexity, data requirements, computational efficiency, and performance remains a key consideration in designing GNNs for EEG analysis.  

# 6.2 Enhancing Interpretability (Explainable AI for GNNs in EEG)  

The increasing complexity of deep learning models, including Graph Neural Networks (GNNs), necessitates the development of Explainable Artificial Intelligence (XAI) techniques to enhance their transparency and interpretability, particularly in sensitive domains like EEG analysis [17]. Interpretability is of paramount importance not only for fostering trust in GNNbased EEG analysis systems but also for gaining novel insights into the underlying neural mechanisms associated with various cognitive or emotional states and pathological conditions [1,17,22]. The need for lucidity is especially critical in clinical settings, where interpretability can be as crucial as accuracy for system reliability [22].​  

Applying XAI to GNNs for EEG involves developing methods to understand how these models arrive at their predictions. Techniques can broadly be categorized into instance-level explanations, which identify crucial input features for a specific prediction, and model-level explanations, which offer general insights into the overall behavior of the GNN [18]. Various methods have been explored to improve the interpretability of deep learning models in EEG research, many of which are applicable or have been adapted for GNNs and related architectures.  

One common approach involves visualizing learned model parameters. This includes visualizing weights, such as projecting learned weights onto a scalp map to understand spatial filter characteristics [17]. Similarly, visualizing the weights of initial convolutional layers can reveal insights into the type of features being extracted from different connectivity or spectral representations [37]. Activation analysis provides another avenue, often involving averaging the output of activation functions to infer spatial and temporal filtering properties learned by the network [17].  

Attention mechanisms are frequently integrated into models to explicitly highlight important features or regions. By assigning different weights to inputs or intermediate representations, attention allows the model to focus on the most informative components [10]. For instance, a temporal-channel attention module was used to enhance the significance of critical brain regions for detecting driving fatigue, identifying the frontal pole as most informative, followed by parietal and central regions [13].  

Furthermore, analyzing learned graph structures or derived connectivity matrices can provide crucial insights into interchannel relationships and the roles of different brain regions. Visualization of the channel covariance matrix learned by a model has revealed specific regions critical for tasks like fatigue detection [13]. Studies have also identified important brain regions (e.g., frontal, parietal, occipital) and specific inter-channel relationships (e.g., between hemispheres or specific channel pairs like FP1-AF3) contributing significantly to tasks such as emotion recognition [8]. In the context of neurological disorders, visualizing derived functional connectivity graphs, such as wavelet coherence adjacency matrices, can provide evidence of abnormal connectivity patterns associated with conditions like Alzheimer's disease or identify key regions and patterns related to epileptic seizures, thereby enhancing the transparency of the model's decision-making process [1,2].  

These visualization and analysis techniques serve to make the decision-making process of GNNs more understandable, allowing researchers and clinicians to link model outputs to specific neural activity patterns and brain regions. This facilitates a deeper understanding of the neural basis of the studied phenomena and builds confidence in the model's predictions. However, despite these advancements, challenges remain. There is a notable lack of standardized datasets and metrics specifically designed for evaluating the quality and utility of explanations generated by GNN models for EEG [18]. Moreover, even models designed with interpretability in mind may still present explanations that are not entirely lucid, indicating a need for continued research to fortify the interpretability of these sophisticated models [22]. Future work should focus on developing rigorous evaluation frameworks and more intuitively understandable explanation methods to fully leverage XAI for both advancing brain science and deploying trustworthy EEG analysis systems.​  

# 6.3 Incorporating Temporal Dynamics  

Given that electroencephalography (EEG) signals represent dynamic brain activity evolving over time, the effective analysis of this data necessitates methodologies capable of capturing its inherent temporal dependencies [6]. While Graph Neural Networks (GNNs) are primarily designed to model spatial relationships between EEG channels (nodes in a graph), integrating temporal dynamics into GNN frameworks is crucial for a comprehensive understanding of brain function and state transitions. This integration is typically achieved through the use of recurrent GNNs, spatio-temporal GNNs, or by combining GNNs with other temporal processing techniques.​  

One approach involves employing temporal models alongside GNNs to process the feature sequences extracted from the graph structure. For instance, bi-directional Long Short-Term Memory (BiLSTM) networks combined with attention mechanisms have been utilized to extract temporal features and capture sequence information between adjacent channels, addressing limitations of unidirectional methods [10]. Similarly, Temporal Convolutional Networks (TCNs) can be applied after spatial processing by a dynamic GCNN to capture temporal features within the EEG signals, enabling the model to learn both spatial relationships and temporal dependencies [5]. Attention mechanisms specifically designed to focus on critical temporal information have also been employed for tasks like driving fatigue detection [13].​  

A more integrated approach involves spatio-temporal graph neural networks (ST-GNNs), which are specifically designed to simultaneously model both spatial and temporal dimensions of the data. These models typically combine spatial graph convolution layers—which capture the relationships between different EEG channels based on structural or functional connectivity—with temporal convolution layers or recurrent units, which process the time series data associated with each channel or node [1]. This allows ST-GCNs to consider both the functional connectivity patterns and the dynamic characteristics of the corresponding EEG channels over time. Examples include the use of ST-GCNs for Alzheimer’s disease diagnosis, demonstrating the capability to leverage both connectivity information and temporal dynamics [1].​  

Furthermore, the use of dynamic graphs within GNN frameworks allows for explicitly modeling changes in connectivity over time. This involves constructing graphs for small time windows and analyzing how the graph structure or node features evolve. This approach is particularly effective for tasks involving the detection of transitions in brain activity, such as identifying functional connectivity changes during different stages of epileptic seizures [2]. By capturing these highresolution dynamic functional connectivity graphs, dynamic GNN models enable a more accurate analysis of time-varying brain states [2].  

Alternative paradigms, such as brain-inspired algorithms and neuromorphic computing, also inherently emphasize temporal dynamics. These approaches are often better suited for processing time-dependent spiking activity and learning sequences compared to traditional methods [23]. By directly interacting with neuronal spike trains, neuromorphic models can capture the precise timing and spike order between neurons—information often lost in converting spike trains to continuous values—potentially enhancing the accuracy and stability of brain–machine interfaces [16]. Considering the nonlinear and non-stationary nature of EEG signals is paramount, and techniques like time–frequency analysis or segmentation are vital for effective temporal feature extraction [6,12].  

In summary, effectively modeling EEG signals with GNNs necessitates explicit mechanisms for handling their temporal dimension. Approaches ranging from combining GNNs with established temporal networks like BiLSTM and TCNs to employing dedicated ST-GNN architectures and dynamic graph models enable the capture of complex spatio-temporal dynamics inherent in brain activity. These methods offer significant advantages in analyzing time–varying phenomena and state transitions, which are crucial for a wide array of EEG–based applications.​  

# 6.4 Multi-Modal Data Fusion  

The analysis of electroencephalogram (EEG) signals can be significantly enhanced by integrating data from other modalities, such as functional magnetic resonance imaging (fMRI), magnetoencephalography (MEG), or other physiological signals [17,23]. This multi-modal approach holds substantial potential to improve the accuracy and robustness of analyses by providing a more comprehensive view of brain activity and physiological states [28]. The exploration of novel methodologies for multi-modal brain-computer interfaces (BCI) underscores the growing interest in this area [30].  

Multi-modal data fusion is increasingly recognized as a vital direction in neuroimaging analysis, extending its application to diverse fields such as emotion recognition, brain state identification, and the detection of brain diseases like epilepsy [28,34]. The combination of neuroimaging modalities, including multi-modal magnetic resonance, alongside deep learning techniques, is being actively explored for tasks such as brain state recognition and disease diagnosis [34].​  

Integrating multiple modalities allows for the construction of richer, more comprehensive brain networks that capture interdependencies not evident in single-modality data. However, multi-modal data integration presents inherent challenges, notably data alignment across different temporal and spatial resolutions and effective feature fusion. Representing such diverse data within a unified structure suitable for graph neural networks (GNNs) is a key challenge. One promising direction for addressing feature fusion and network construction involves exploring multi-layer complex networks [25]. This approach allows different variables or data types, such as EEG and other signals (e.g., ECG or spatial features), to be represented on separate layers within the same complex network structure. Classifying these multi-layer networks using GNNs is a potential avenue for leveraging the power of GNNs in a multi-modal context [25]. While specific examples of successful studies applying GNNs to fused multi-modal EEG data with detailed outcome analysis are emerging, the general potential and foundational techniques for representing multi-modal data in a GNN-compatible format, such as multi-layer networks, are being recognized as crucial future research directions [25].​  

# 6.5 Integration with Brain-Inspired Algorithms / Deep Reinforcement Learning  

Advancements in artificial intelligence research increasingly explore synergies between traditional machine learning paradigms and principles derived from neuroscience. For Graph Neural Networks (GNNs) applied to EEG analysis, this involves the integration of brain-inspired algorithms and Deep Reinforcement Learning (DRL) to potentially enhance performance, efficiency, and biological plausibility [42].  

One avenue is the integration of brain-inspired algorithms, such as Spiking Neural Networks (SNNs), Hierarchical Temporal Memory (HTM), and Hebbian learning, with foundation models to create hybrid architectures for EEG signal analysis [23]. This approach aims to combine the scalability and generalizability inherent in large foundation models with the temporal specificity and biological plausibility characteristic of brain-inspired methods [23]. Specific proposals include incorporating SNNs or HTM during the training and adaptation phases of foundation models to improve their capacity for learning effective EEG representations, or applying Hebbian learning to further enhance these representations [23]. Spiking Neural Networks, in particular, are gaining attention due to their intrinsic biological plausibility, as they mimic the structure and mechanism of biological neural circuits using computational neuron models like the Hodgkin–Huxley model, spike response model, and leaky integrate-and-fire (LIF) model, often employing Hebbian rules and spike timing-dependent plasticity (STDP) for learning [16]. This aligns with the broader field of neuromorphic computing, which leverages neural models in hardware and software for energy-efficient and high-performance solutions, relevant for real-time processing of neural activity [36]. Beyond network structure, biologically inspired principles can also inform graph construction, such as  

initializing adjacency matrices based on neuroscience theories about brain organization and connectivity, incorporating both local physical distances and global connections for improved network efficiency [8].  

Deep Reinforcement Learning offers a distinct approach to optimizing GNN models for EEG analysis, holding potential to improve performance and efficiency [4]. DRL can be employed to optimize aspects of the GNN architecture itself. For instance, a DRL framework can be integrated with GNNs to determine the optimal number of feature aggregation steps (equivalent to the number of GNN layers) for a given brain network [4]. This is formulated as a Markov Decision Process (MDP), where the state is the adjacency matrix of the brain network, the action space consists of different possible numbers of GNN layers, the reward signal quantifies the change in validation classification performance, and state transitions are handled via a heuristic strategy [4]. A meta-policy is learned using algorithms like Double DQN (DDQN) to guide this architectural search [4]. DRL has also been applied to train GNNs for solving combinatorial optimization problems expressed as single-person games, where the network learns to output approximate solutions for new graph instances in linear time without expert knowledge, demonstrating its potential for graph-based problem solving beyond typical supervised learning [19]. This broader application of RL in optimizing network performance and control systems underscores its relevance [3].  

Despite the potential, applying DRL to GNN optimization in the context of EEG analysis presents challenges. Key difficulties include defining appropriate reward functions that accurately reflect desired improvements in performance or efficiency for complex EEG tasks and developing effective exploration strategies to navigate the vast search space of possible GNN configurations or parameters [4]. Overcoming these challenges is crucial for successfully harnessing DRL's power to enhance GNN-based EEG analysis.  

# 6.6 Benchmarking and Evaluation  

Standardized benchmarks and consistent evaluation metrics are crucial for objectively comparing the performance of different Graph Neural Network (GNN) models applied to Electroencephalography (EEG) analysis [11]. The development of robust evaluation protocols is essential for tracking progress in the field and ensuring that proposed methods offer genuine improvements over existing techniques.  

A significant challenge in the application of deep learning, including GNNs, to EEG analysis is the issue of reproducibility [17]. Studies have indicated that a substantial portion of published research is not easily reproducible, often due to insufficient data and source code availability [17]. To enhance reproducibility, it is recommended that researchers provide access to source data and code, following guidelines such as those from FAIR (Findable, Accessible, Interoperable, Reusable) neuroscience and the Brain Imaging Data Structure (BIDS) [17]. Furthermore, the current landscape often lacks standardized evaluation protocols across diverse datasets [20]. Proposed solutions include the development of standardized benchmarks designed for evaluating models across varied datasets to better reflect the complexity of real-world EEG analysis tasks and enhance reproducibility in neurological diagnostics [11,20]. Initiatives like BrainGB aim to provide reproducible benchmarks for GNNs in brain network analysis [11].​  

A variety of EEG datasets are commonly utilized for benchmarking GNN models. Publicly available datasets frequently include SEED and DREAMER, which are often used for emotion recognition tasks [7,8]. BCI Competition datasets, such as BCI Iv2a and BCI2005desc-IIIa, are standard benchmarks for motor imagery classification [5,41]. The PhysioNet EEG Motor Movement/Imagery Dataset (EEG-MID) is another resource for motor imagery, typically featuring data from 64 electrodes [10]. For seizure detection and classification, datasets derived from the CHB-MIT database are frequently employed [31]. Beyond these public resources, researchers also utilize custom datasets, such as data collected in a simulated fatigue driving environment with 24 channels from 31 subjects [13] or large real clinical datasets for epileptic seizure detection comprising thousands of cases [2]. While datasets like DEAP are also widely used, specific details from the provided digests are unavailable. The characteristics of these datasets, including the number of channels, subjects, and the specific task (e.g., motor imagery, emotion recognition, seizure detection, cognitive state assessment), significantly influence model design and evaluation.​  

The performance of GNN models in EEG analysis is typically assessed using a set of standard evaluation metrics, particularly for classification tasks. Accuracy is one of the most frequently reported metrics, representing the proportion of correctly classified instances [1,2,4,5,7,8,10,31]. While intuitive, accuracy alone can be misleading in datasets with class imbalance. Other crucial metrics include precision, which measures the accuracy of positive predictions; recall (sensitivity), which measures the ability to identify all positive instances; and the F1-score, which is the harmonic mean of precision and recall, providing a balanced measure [10]. The Area Under the Receiver Operating Characteristic curve (AUC) is particularly  

valuable for evaluating classifier performance across various thresholds, offering a robust measure independent of class distribution, especially in diagnostic tasks like seizure detection [2]. Studies often report the average classification accuracy along with its standard deviation to indicate the robustness and variability of the model's performance across different subjects or trials [5,7]. Comparison with state-of-the-art methods on specific benchmarks is a common practice to demonstrate the effectiveness of proposed models [13]. However, performance can vary; for instance, a Siamese network achieved non-state-of-the-art accuracy on the BCI Iv2a dataset, highlighting the need for continuous model refinement [41]. In contrast, dynamic GCNNs have shown improved average accuracy compared to traditional CNNs on motor imagery datasets A and B [5].​  

Standard experimental settings are employed to ensure reliable evaluation. Cross-validation strategies, such as k-fold crossvalidation or leave-one-subject-out cross-validation, are widely used to assess model generalization ability and mitigate overfitting. Hyperparameter optimization techniques, like grid search or Bayesian optimization, are critical for finding the optimal model configurations for a given task and dataset. Models are typically trained and tested independently on predefined data splits, sometimes considering different states (e.g., eyes-open/closed) or data representations (e.g., frequency bands, different functional connectivity matrices) [1].  

In summary, while significant progress has been made, the field of GNNs for EEG analysis would benefit from enhanced standardization in benchmarking and evaluation protocols. Addressing reproducibility concerns through data and code sharing, establishing widely accepted benchmark datasets that capture real-world variability, and consistently applying a comprehensive set of evaluation metrics are crucial steps towards enabling more rigorous comparison and accelerating research advancements.  

# 7. Conclusion  

This survey has explored the burgeoning field of applying Graph Neural Networks to Electroencephalography analysis, summarizing key findings and highlighting the potential of this integration. GNNs present significant advantages for EEG signal processing due to their inherent ability to model the complex, non-Euclidean relationships between EEG channels, which can be represented as a graph structure [21,33]. They are particularly adept at capturing both local and global interchannel relationships [8] and modeling complex, nonlinear network dynamics through iterative information aggregation [18]. This capability is crucial for understanding brain functional connectivity, a key aspect often overlooked by traditional methods [1,24]. Furthermore, GNNs offer flexibility in handling graph structures of varying sizes and shapes and can process large-scale graph data efficiently [18]. Specific GNN architectures, such as Dynamic Graph Convolutional Neural Networks (DGCNN), have demonstrated improved accuracy and stability in tasks like emotion recognition by adaptively learning the intrinsic relationships between EEG channels [7]. Regularization techniques can enhance the robustness of GNN models to inter-subject variations and noisy labels [8].  

GNNs have shown considerable promise across a range of critical EEG analysis applications. Notably, they have demonstrated effectiveness in Brain-Computer Interfaces (BCI), particularly for motor imagery classification [5], an area of focus for research laboratories dedicated to neural information representation like the BCMI Laboratory [42]. In emotion recognition, GNN-based methods, including RGNNs and DGCNNs, have achieved superior performance compared to traditional techniques by effectively learning discriminative features from non-linear EEG data and leveraging connectivity information [7,8,37]. GNNs are also being successfully applied to brain disease diagnosis, such as utilizing Spatio-Temporal Graph Convolutional Networks (ST-GCN) combined with functional connectivity for Alzheimer's disease detection [1], and novel models like GGN enhancing spatiotemporal feature extraction for epileptic seizure detection [2]. Beyond this, GNNs are contributing to cognitive state decoding, sleep stage classification, and fatigue detection [24].​  

The integration of GNNs into EEG analysis holds the potential to significantly impact both fundamental EEG research and clinical practice [17]. By providing a more nuanced understanding of brain network dynamics, GNNs can aid in identifying subtle biomarkers associated with various neurological and psychological conditions [24]. This can lead to the development of more accurate, reliable, and intelligent diagnostic and therapeutic tools [20], potentially enabling real-time clinical support [2] and advancing the clinical usability of BCIs [16]. The significance of GNNs lies in their capacity to move beyond simple feature extraction to model the intricate functional architecture of the brain, thus potentially revolutionizing the field of EEG analysis [17].​  

Despite the demonstrated successes, the application of GNNs to EEG analysis is still evolving, and several challenges and limitations remain. Developing robust graph construction methods that accurately reflect functional or structural brain connectivity from noisy EEG data is crucial [8]. Many GNN models, like other deep learning approaches, may require substantial training data, necessitating the development of larger, well-annotated EEG databases or advanced transfer learning techniques [7,13]. Integrating the temporal dimension effectively with the spatial graph structure remains an active research area [8]. Furthermore, designing optimal and efficient GNN architectures for specific EEG tasks is vital, potentially involving adaptive methods guided by techniques like Deep Reinforcement Learning [4,21].​  

Looking forward, the future of GNNs in EEG analysis is exceptionally promising [12]. Key areas for future research include the exploration of more advanced graph construction techniques, novel methods for incorporating temporal dynamics into GNN models, and the integration of multi-modal physiological data to provide a more holistic view of brain states [8,28]. The development of foundation models for brain network analysis, leveraging large-scale self-supervised learning, offers a pathway to overcome data limitations and improve generalization across diverse tasks and datasets [14,23]. Research into dynamic graph processing, cross-modal learning, and even exploratory areas like quantum GNNs and causal reasoning within GNN frameworks could push the boundaries of what is possible [18]. Establishing standardized benchmarks and developing pre-trained models will also be essential for accelerating progress and enabling fair comparisons across studies [20]. Addressing these challenges and pursuing these future directions is critical to unlocking the full potential of GNNs for advancing our understanding of the brain and translating research findings into practical clinical applications. The continued development of advanced EEG analysis methods heavily relies on the expertise and dedicated research efforts of leading academics, such as Professor Zhongke Gao and his research team, who have significantly contributed to integrating complex network analysis and deep learning techniques, including GNNs, for various EEG applications [3,24], as well as other prominent experts like Professor She Qingshan [40].​  

# References  

[1] 基于时空图卷积神经网络和脑功能连接的阿尔茨海默症脑电诊断 https://mp.weixin.qq.com/s? _biz=Mzg2MTYwODc5Ng $= =$ &mid=2247523137&idx $\underline { { \underline { { \mathbf { \Pi } } } } }$ 2&sn $| = |$ 069dd636b714b6afae3c82957a63feee&chksm=ce165572f961dc64   
547b01d7c626db51f14c24a393573566e9a6e365a151f9b9c3d6e8dd7a4b&scene=27   
[2] 人工智能助力：黄铠团队Scientific Reports发表脑神经疾病检测新方法 https://airs.cuhk.edu.cn/article/921   
[3] 高忠科教授简介及科研成果 http://seea.tju.edu.cn/info/1013/1553.htm   
[4] 深度强化学习引导的脑网络分析图神经网络框架 https://blog.csdn.net/weixin_44466434/article/details/126393359   
[5] 基于动态图卷积神经网络的运动想象脑电信号研究 https://image.hanspub.org/Html/26-1543200_85524.htm   
[6] 脑电信号特征提取方法综述与应用 https://www.bilibili.com/read/cv23443889   
[7] 基于动态图卷积神经网络的脑电情绪识别学习报告 https://www.scholat.com/teamwork/teamwork/showPostMessage.html?   
id=10242   
[8] 基于正则化图神经网络的脑电情绪识别 https://blog.csdn.net/KPer_Yang/article/details/128637894   
[9] 脑电情绪识别深度学习研究综述 https://www.jos.org.cn/html/2023/1/6420.htm​   
[10] 基于注意力机制和深度学习的运动想象脑电信号分类 https://jns.nju.edu.cn/CN/10.13232/j.cnki.jnju.2022.01.004​   
[11] BrainGB代码复现：脑网络GNN基准测试 https://blog.csdn.net/Sherlily/article/details/135582174​   
[12] MLESP 2024: Machine Learning for EEG Signal Proces http://www.wikicfp.com/cfp/servlet/event.showcfp?   
eventid=182117   
[13] SACC-CapsNet: Self-Attentive Channel-Connectivity  https://pubmed.ncbi.nlm.nih.gov/37494165   
[14] BrainMass：基于大规模自监督学习的脑网络分析诊断基础模型   
https://blog.csdn.net/weixin_38594676/article/details/139931937​   
[15] EEG-based Emotion Recognition via Multiple Kernel  https://www.mi-research.net/article/doi/10.1007/s11633-022-1352-   
1​   
[17] 脑电分析的图神经网络：综述 https://www.bilibili.com/opus/718275856731996225​   
[18] 图神经网络(GNN)零基础入门详解 https://www.bilibili.com/opus/992135929278758918   
[19] 图注意力神经网络(GAT)综述：原理、应用及未来展望 https://mp.weixin.qq.com/s?   
__biz=MzI1MjQ2OTQ3Ng==&mid=2247610252&idx $\mathop { : = }$ 1&sn=ecaf6dec0ec25d3443aff1dcff5bf3f0&chksm=e9e02607de97af11e4e   
5b4a58df387663c375f170d74fe365288de1998a0876988d857036aba&scene=27​   
[20] Deep Learning for EEG/iEEG Neurological Diagnostic https://arxiv.org/abs/2502.17213   
[21] Graph Neural Networks: A New Model for Graph Domai https://dl.acm.org/doi/10.1109/TNN.2008.2005605​   
[22] ERTNet: Interpretable Transformer for EEG Emotion   
https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2024.1320645/full   
[23] Brain-Inspired Foundation Models for EEG Signal Pr   
https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2024.1507654/full​   
[24] Zhongke Gao研究团队学术成果概览 http://ains.tju.edu.cn/yjcg/xslz.htm​   
[25] 基于图神经网络的心电拓扑特征提取与分类 https://blog.csdn.net/m0_55245520/article/details/132580588​   
[26] EEG Emotion Recognition via 3DCNN-BLSTM Hybrid Neu https://journal  
n.scnu.edu.cn/en/article/doi/10.6054/j.jscnun.2021017​   
[27] EEG-Based Emotion Recognition in HRI with Optimize https://dl.acm.org/doi/10.1007/978-3-031-35894-4_21   
[28] 基于脑电信号时频分析和机器学习的情感识别研究报告 https://www.scholat.com/teamwork/showPostMessage.html?   
$\mathrm { i d } { = } 9 7 3 1$   
[29] 图神经网络 (GNN) 概述   
https://baike.baidu.com/item/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/59091829​   
[30] BCI2021：第九届国际冬季脑机接口会议 https://blog.csdn.net/zyb228/article/details/110459447​   
[31] EEG Seizure Detection and Classification via DTCWT http://www.jbr-pub.org.cn/article/doi/10.7555/JBR.34.20190026​   
[32] 深度学习脑电波分析：从预处理到模型优化 https://download.csdn.net/blog/column/12294299/130781469   
[33] 图神经网络(GNNs): 原理与实践 https://blog.csdn.net/universsky2015/article/details/140580475​   
[34] 第七届神经信息国际会议：脑器交互与心身医学 https://mp.weixin.qq.com/s?   
__biz $: =$ MzIzMjQyNzQ5MA $\scriptstyle 1 = =$ &mid=2247632660&idx $\underline { { \underline { { \mathbf { \Pi } } } } } =$ 3&sn=188d272894144ce229b4805fe21c492d&chksm $\scriptstyle 1 =$ e8999d99dfee148f7   
0ac3221f7ec680f117b3d33becea7f9dc7e43a47770df8a5bbeb5aae0a5&scene=27   
[35] 基于深度学习的生物电信号分类在智慧医疗中的应用 https://www.aminer.cn/topic/6082daaa92c7f9be21f0b71e?f=cs​   
[36] Neuromorphic Computing for Neurological Disorder M https://link.springer.com/article/10.1007/s10462-024-10948-3​   
[37] 基于脑连接和空间信息的CNN脑电情绪识别 https://blog.csdn.net/Cratial/article/details/91558381​   
[38] 首届“计算智能与控制论”国际学术研讨会成功举办 http://imds.aia.hust.edu.cn/info/1041/2354.htm   
[39] 2020 Publications: Machine Learning, Pattern Recog http://parnec.nuaa.edu.cn/3021/list.htm​   
[40] 佘青山教授简介 https://auto.hdu.edu.cn/2019/0403/c3803a93084/page.htm​   
[41] Siamese Network：首次用于脑电运动想象分类的孪生神经网络   
https://blog.csdn.net/mantoudamahou/article/details/135816817​   
[42] BCMI Laboratory: Brain-like Computing and Machine  https://bcmi.sjtu.edu.cn/​   
[43] 运动想象脑电信号：基于共空间模式算法的研究进展 https://blog.csdn.net/oh__NO/article/details/84310982​  