# Graph Neural Network-based EEG Classification: A Survey  

Dominik Klepl,1 Min Wu,2 and Fei $\mathrm { H e ^ { 1 } }$ , $*$ $^ { 1 }$ Centre for Computational Science and Mathematical Modelling, Coventry University, Coventry CV1 2JH, UK $^ 2$ Institute for Infocomm Research, Agency for Science, Technology and Research (A\*STAR), 138632, Singapore  

Graph neural networks (GNN) are increasingly used to classify EEG for tasks such as emotion recognition, motor imagery and neurological diseases and disorders. A wide range of methods have been proposed to design GNN-based classifiers. Therefore, there is a need for a systematic review and categorisation of these approaches. We exhaustively search the published literature on this topic and derive several categories for comparison. These categories highlight the similarities and differences among the methods. The results suggest a prevalence of spectral graph convolutional layers over spatial. Additionally, we identify standard forms of node features, with the most popular being the raw EEG signal and differential entropy. Our results summarise the emerging trends in GNN-based approaches for EEG classification. Finally, we discuss several promising research directions, such as exploring the potential of transfer learning methods and appropriate modelling of cross-frequency interactions.  

Keywords: graph neural network, classification, EEG, neuroscience, deep learning  

# I. INTRODUCTION  

Electroencephalography (EEG) is a non-invasive technique used for recording electrical brain activity with a wide range of applications in cognitive neuroscience [1], clinical diagnosis [2, 3], and brain-computer interfaces [4, 5]. However, analysing EEG signals poses several challenges, including a low signal-to-noise ratio, nonstationarity resulting from brain dynamics, and the multivariate nature of the signals [6, 7]. In this review, we focus on the classification of EEG, such as emotion recognition, motor imagery recognition or neurological disorders and diseases.  

ships in EEG data is crucial for more accurate classification and analysis.  

Traditional feature extraction methods for EEG classification, such as common spatial patterns [6], wavelet transform [8], and Hilbert-Huang transform [9], have been commonly employed. These methods aim to extract meaningful features from EEG signals [10, 11], with key features like power spectral density (PSD) [7] to characterise brain states. However, relying on such manually defined features to train machine learning classifiers has several limitations. Subjectivity and biases in feature selection, along with time-consuming engineering and selection processes, limit scalability and generalisation [7, 12]. Automated feature extraction methods are needed to overcome these limitations, improve efficiency, reduce bias, and enhance classifier adaptability to different EEG datasets.  

Deep learning architectures, such as convolutional neural networks (CNN) and long short-term memory (LSTM) networks, have also been explored for EEG analysis [13, 14]. However, they face challenges in effectively capturing the spatial dependencies between electrodes and handling the temporal dynamics of EEG signals [7]. Modelling the complex sequential and spatial relation  

Network neuroscience offers an alternative approach to EEG modelling by framing the signals as a graph. The brain exhibits a complex network structure, with neurons forming connections and communicating with each other [15]. Analysing EEG data as a graph enables the study of network properties, including functional connectivity, providing insights into brain function and dysfunction [12, 16, 17]. Graph-based analysis facilitates the examination of network features, node importance, community structure, and information flow, offering insights into brain organisation and dynamics. Such graph-theorybased features were shown to be powerful predictive features for EEG classification [12, 17–22]. However, these features have the same limitations as manually defined features based on traditional EEG analysis methods introduced above.  

Graph Neural Networks (GNNs) emerge as a powerful tool for modelling neurophysiological data [23], such as EEG, within the network neuroscience framework [7, 24]. GNNs are specifically designed to operate on graphstructured data. They can effectively leverage the spatial structure within EEG data to extract features, uncover patterns and make predictions based on the complex interactions between different electrodes. Designing GNN models for EEG classification will likely improve classification tasks and potentially uncover new insights in neuroscience.  

Motivated by the potential of GNNs and an increasing number of recent papers proposing GNN for various EEG classification tasks, there is an urgent need for a comprehensive review of GNN models for EEG classification. The main contributions of this paper include:  

• Identifying emerging trends of GNN models tailored for EEG classification. • Reviewing popular graph convolutional layers and their applicability to EEG data.  

![](images/9ece93f8bb4b6d7352d9851172cf00abaf7546925703310f56dc0884efba953b.jpg)  
FIG. 1: General architecture of a graph neural network model for classification of EEG. (A) The input to the model consists of node features and a possibly learnable brain graph structure. (B) Optionally, the node features can undergo pre-processing via a neural network. (C) Next, the node features are passed to a block of graph convolutional layers, where node embeddings are learned. (D) Then, a node pooling module can be utilised to coarsen the graph. Node pooling may contain learnable parameters as well. (E) Finally, the set of node embeddings forms a graph embedding, which can be used to predict the outcome.  

• Providing a unified overview of node feature and brain graph structure definitions in the context of EEG analysis.   
• Examining techniques for transforming sets of node feature embeddings into a single graph embedding for graph classification tasks.  

By addressing these essential aspects, this review paper will provide a comprehensive and in-depth analysis of the application of Graph Neural Network (GNN) models for EEG classification. The findings and insights gained from this review will serve as a resource to navigate this emerging field and identify promising future research directions.  

# II. OVERVIEW OF GRAPH NEURAL NETWORKS  

Graphs are widely used to capture complex relationships and dependencies in various domains, such as social networks, biological networks, and knowledge graphs. The problem of graph classification, which aims to assign a label to an entire graph, has gained attention in recent years. GNNs offer a promising solution to this problem by extending the concept of convolution from Euclidean inputs to graph-structured data. GNNs have been successfully applied in a wide range of fields, such as biology [23], bioinformatics [25], network neuroscience [26], chemistry [27, 28], drug design and discovery [29, 30], natural language processing [31, 32], recommendation systems [33, 34], traffic prediction [35, 36] and finance [37].  

In graph classification problems, the input is a set of graphs, each with its own set of nodes, edges, and node features. Let $G = ( V , E , H )$ denote a featured graph, where $V$ represents the set of nodes, $E$ represents the set of edges connecting the nodes, and $H$ represents the $V \times D$ matrix of $D$ -dimensional node features. In the case of EEG, the EEG channels are the nodes, and edges represent structural or functional connectivity between pairs of nodes. Each graph $G$ is associated with a label $y$ , indicating its class. The goal is to learn a function $f ( G ) \to y$ that can predict the class label $y$ given an input graph $G$ . A general structure of a GNN model for EEG classification is presented in Fig 1.  

Compared to other deep learning models, GNNs offer several advantages. First, GNNs were specifically designed for graph-structured inputs. This means that GNNs can adapt to irregularly structured inputs, i.e. graphs with varying numbers of nodes, compared to traditional deep learning, such as CNN, that require fixedsize inputs. Next, GNNs can simultaneously learn information from node features and the graph structure by accepting two inputs: node feature matrix and graph structure. Such simultaneous integration is not possible with traditional deep learning methods.  

Multiple types of GNNs have been well introduced in [38, 39]. In this survey, we briefly introduce the two main branches of GNNs, namely, spatial and spectral GNNs (Fig. 2). Other types of GNNs, such as attention GNNs [40], recurrent GNNs [41], and graph transformers [42], can be viewed as special cases of spatial GNNs, and thus we will not provide detailed discussion in this survey. Both spatial and spectral GNNs aim to extend the convolution mechanism to graph data. For a detailed review of their similarities and differences, see [43]. Moreover, for a comparison of GNNs in terms of computational complexity, see [38].  

Spatial GNNs aggregate information from neighbouring nodes, similar to traditional convolution applied to image data aggregating information from adjacent pixels. Stacking multiple spatial GNN layers leads to information aggregation from various scales going from local to global patterns being captured in early and later layers, respectively. In contrast, spectral GNNs perform information aggregation in the graph frequency domain, with low-frequency and high-frequency components capturing global and local patterns, respectively. However, both approaches learn to capture local and global patterns within the graph, i.e. high and low-frequency information in the spectral domain. The advantage of spectral GNNs is their connection to graph signal processing, allowing for interpretation from the perspective of graph filters. However, spectral GNNs do not generalise well to large graphs since they depend on the eigendecomposition of graph Laplacian. In contrast, spatial GNNs can be applied to large graphs since they perform only local message-passing. On the other hand, spatial GNNs may be challenging to interpret and prone to overfitting because of over-smoothing, where embeddings of all nodes become similar.  

# A. Spatial GNNs  

Spatial GNNs directly operate on the graph structure via the adjacency matrix operator. Given a set of nodes and associated features, spatial GNNs perform neighbourhood aggregation to derive node embeddings. This process is referred to as message passing. Intuitively, nodes connected by edges should have similar node embeddings, i.e. local node similarity. Message passing implements this idea by updating node embeddings with aggregated information collected from the node’s neighbourhood. Formally, the node update equation in $l ^ { \mathrm { t h } }$ layer of spatial GNN with $L$ layers is defined as follows:  

$$
h _ { i } ^ { ( l + 1 ) } = \sigma \left( W _ { 1 } ^ { ( l ) } h _ { i } ^ { ( l ) } + \sum _ { j \in \mathcal { N } ( v _ { i } ) } W _ { 2 } ^ { ( l ) } h _ { j } ^ { ( l ) } e _ { j i } \right) ,
$$  

where $h _ { i }$ is the node embedding vector, or when ${ \mathit { l } } = 1$ , this is the input node feature vector, $\sigma$ is the activation function, $\scriptstyle \sum$ is the aggregation function, $\mathcal { N } ( v _ { i } )$ is the neighbou hPood of node $v _ { i }$ , $W \in \mathbb { R } ^ { d _ { 1 } \times d _ { 2 } }$ is a learnable parameter matrix projecting node embeddings from input dimension $d _ { 1 }$ to hidden dimension $d _ { 2 }$ and $e _ { j i }$ is the edge weight ( $e _ { j i } = 1$ for unweighted graphs).  

A single spatial GNN layer aggregates information from the 1-hop neighbourhood. Thus, to increase the reception field of the model, $L$ spatial GNN layers can be stacked to aggregate information from up to $L$ -hop neighbourhoods. A disadvantage of spatial GNNs is the difficulty of training deep models with many layers. With an increasing number of layers, the node embeddings become increasingly smooth, i.e. variance among embeddings of all nodes decreases. This happens when the messages already contain aggregated information from the whole graph; continual message passing of such saturated messages leads to oversmoothing, i.e., all node embeddings becoming essentially identical.  

# B. Spectral GNNs  

Spectral GNNs can also be applied to EEG classification tasks by leveraging the spectral domain analysis of graph-structured data. The EEG graph is transformed into the spectral domain using the Graph Fourier Transform (GFT) and Graph Signal Processing (GSP) techniques. For a detailed review of spectral GNN methods, please refer to [44].  

The graph spectrum is defined as the eigendecomposition of the graph Laplacian matrix. The GFT is then defined as $\hat { \mathbf { H } } = \mathbf { U } ^ { T } \mathbf { H }$ , its inverse as $\mathbf { H } = \mathbf { U } \hat { \mathbf { H } }$ , where $\mathbf { U }$ is the orthonormal matrix of eigenvectors of the graph Laplacian $\mathbf { L }$ and $H \in \mathbf { R } ^ { N \times D }$ is the matrix of node feature vectors with $N$ and $D$ being the number of nodes and dimensionality of node features, respectively. The graph Laplacian is defined as $\mathbf { L } = \mathbf { D } - \mathbf { A }$ , but often the normalised version is preferred: Lˆ = I D−1/2AD−1/2 ( $\mathbf { A }$ and $\mathbf { D }$ are the adjacency and degree matrices, respectively).  

Spectral GNN is then typically defined as the convolution $( * )$ of a signal defined on graph $\mathbf { H }$ and a spatial kernel $g$ in the spectral domain, thus becoming an element-wise multiplication ( $\odot$ ):  

$$
\mathbf { H } \ast g = \mathbf { U } \left( \left( \mathbf { U } ^ { T } \mathbf { H } \right) \odot \left( \mathbf { U } ^ { T } g \right) \right) .
$$  

Generally, $\mathbf { U } ^ { T } g$ is defined as a learnable diagonal matrix $\mathbf { G } = d i a g ( g _ { 1 } , . . . , g _ { V } )$ spectral filter [44].  

However, the full spectral graph convolution can be computationally expensive. A popular approximation is the Chebyshev GNN (ChebConv) [45], which performs localised spectral filtering on the graph. The node embedding update equation of a ChebConv is defined as:  

$$
H * g \approx \sum _ { i = 1 } ^ { K } \Theta _ { i } T _ { i } ( \hat { \mathbf { L } ^ { \prime } } ) ,
$$  

where $\boldsymbol \Theta \in \mathbb { R } ^ { K \times d \times d }$ are learnable parameters, $T _ { i } ( \hat { \mathbf { L } ^ { \prime } } ) =$ $2 T _ { i - 1 } ( \hat { \mathbf { L ^ { \prime } } } ) - T _ { i - 2 } ( \hat { \mathbf { L ^ { \prime } } } )$ , $T _ { 1 } ( \hat { \mathbf { L } ^ { \prime } } ) = \mathbf { H }$ , $T _ { 2 } ( \hat { \mathbf { L } ^ { \prime } } ) = \hat { \mathbf { L } ^ { \prime } } \mathbf { H }$ , and $\begin{array} { r } { \hat { \mathbf { L } ^ { \prime } } = \frac { 2 \hat { \mathbf { L } } } { \lambda _ { m a x } } - \mathbf { I } } \end{array}$ ( $\lambda _ { m a x }$ is the largest eigenvalue of $\hat { \bf L }$ , often approximated as $\lambda _ { m a x } = 2$ ). The $K$ parameter controls the size of the Chebyshev filter.  

However, spectral GNNs are limited to input graphs with a fixed number of nodes. This is because of the explicit use of the graph Laplacian. This is in contrast to spatial GNNs, which do not rely on explicitly materialising the adjacency matrix.  

![](images/8dbbb815fd10ca954419b1e26c6f2415a0543f5a106b0cc583fd151d2bfb782a.jpg)  
FIG. 2: Illustration of core mechanisms of spatial and spectral GNNs. A) An undirected featured graph is given as an example input graph with node features shown as node labels and colours. B) Spatial GNNs operate in the graph domain directly using message passing to update node embeddings. 1) Messages, i.e. transformed node features or embeddings, are sent along edges. For simplicity, we show only one direction of the flow of messages. 2) The collected messages at each node are aggregated using a permutation-invariant function and are fused with the original node embedding to form an updated node embedding. Thus, one spatial GNN layer results in node embeddings containing information about the 1-hop neighbourhood of a given node. Thus, $L$ layers are required for node embeddings to access the information from the $L$ -hop neighbourhood. C) In contrast, spectral GNNs operate in the graph spectral domain. 1) Node features are treated as signals on top of a graph and are deconstructed into graph frequencies given by the eigendecomposition of the graph Laplacian. Graph frequencies can be interpreted as variations of the signals. 2) The contribution of each graph frequency is weighted by the set of learnable kernels $G$ that effectively function as graph filters. 3) Node embeddings are then obtained by aggregating the filtered graph frequencies and transforming them back to the spatial graph domain. Thus, full spectral GNNs can access information from $N$ -hop neighbourhoods where $N$ is the number of nodes of a given graph. However, in practice, approximations such as Chebyshev graph convolution restrict this to the chosen hop size.  

# III. SURVEY RESULTS  

This survey is based on a review of 63 articles. These articles were selected by title and abstract screening from a search on Google Scholar and ScienceDirect queried on November 1st, 2022. The search query for collecting the articles was defined as: (“Graph neural network” OR “Graph convolutional network”) AND (“Electroencephalography” OR ”EEG”). Both peer-reviewed articles and preprints were searched and utilised. All types of EEG classification tasks were included. We summarise the various types of EEG classification tasks identified in the surveyed papers in Fig 3. The most common classification tasks are emotion recognition, epilepsy diagnosis and detection and motor imagery. However, the type of classification task should have a relatively minor effect on the GNN architecture design. Thus, we do not analyse and discuss this in detail. Instead, we survey the various GNN-based methods for EEG classification, intending to systematically categorise the types of GNN modules and identify emerging trends in this field independent of the specific classification task.  

In the remaining portion of this paper, we report the categories of comparisons we identified in the surveyed papers. These are based on the different modules of the proposed GNN-based models. Specifically, these are:  

• Definition of brain graph structure   
• Type of node features   
• Type of graph convolutional layer   
• Node feature preprocessing   
• Node pooling mechanisms   
• Formation of graph embedding from the set of node embeddings  

The following sections will provide further details on these categories, and the paper will conclude by discussing trends and proposing plausible directions for future research.  

![](images/5cb55ae1448adba2f9ef8bb517cb9e12104f8854ee15a561e24950d7917797c2.jpg)  
FIG. 3: Classification tasks presented in the current EEG-GNN literature.  

SC graph is pre-defined such that electrodes are connected by an edge in the following way:  

$$
e _ { i j } = \left\{ \begin{array} { l l } { 1 \mathrm { o r } 1 / d _ { i j } , } & { \mathrm { i f } \ d _ { i j } \leq t } \\ { 0 , } & { \mathrm { o t h e r w i s e } } \end{array} , \right.
$$  

where $e _ { i j }$ is the edge weight connecting nodes $i$ and $j$ , $d _ { i j }$ is a measure of distance between EEG electrodes, and $t$ is a manually defined threshold controlling the graph sparsity.  

Such an approach offers several advantages. First, the SC graph is insensitive to any noise effects of EEG recording since it is independent of the actual signals. Second, all data samples share an identical graph structure, provided the same EEG montage was utilised during the recording. This offers explainability advantages when combined with spectral GNN since the graph frequency components defined by the eigenvectors of graph Laplacian are fixed. On the other hand, the SC graph is limited to short-range relationships. Thus, it might not accurately represent the underlying brain network. Some papers propose to overcome this limitation by manually inserting global [53, 56–58, 62] or inter-hemispheric edges [46, 54, 87].  

In contrast, an FC graph can be obtained from either classical FC measures (FC measure in Table I or learnable methods (e.g. feature concatenation/distance and attention methods in Table I). We refer to all of these methods as FC because they all measure the degree of interaction between two nodes, thus falling within the traditional definition of FC. Unlike SC, the FC graph is unique for each data sample and can contain both shortand long-range edges. On the other hand, since it is derived directly from EEG signals, it might be sensitive to noise.  

Learnable FC based on node feature distance or feature concatenation are generally computed as:  

# IV. DEFINITION OF BRAIN GRAPH STRUCTURE  

The first part of the input to a GNN model is the brain graph structure inferred from the EEG data itself (Fig. 1A). We summarise the methods for defining the brain graphs in Table I. These methods can be generally categorised as learnable or pre-defined.  

An alternative categorisation of the brain graph structures is the functional (FC) and the “structural” connectivity (SC). Generally, SC graphs are pre-defined, whereas FC graphs can be both pre-defined and learnable. SC in the classical sense of physical connections between brain regions is not possible to obtain using EEG signals since these are recorded at the scalp surface. Instead, we use the term to describe methods that construct brain graphs based on the physical distance between EEG electrodes. In contrast, FC refers to pairwise statistical relationships between EEG signals.  

$$
\begin{array} { l } { { e _ { i j } = \theta _ { 1 } ( | h _ { i } - h _ { j } | ) \mathrm { ~ a n d } } } \\ { { e _ { i j } = \theta _ { 2 } ( h _ { i } \parallel h _ { j } ) , } } \end{array}
$$  

respectively, where $\theta _ { 1 } ( \cdot )$ and $\theta _ { 2 } ( \cdot )$ are neural networks with input-output dimensions of $\mathbb { R } : d  1$ and $\mathbb { R } : 2 \times$ $d \to 1$ , respectively; $| \cdot |$ denotes absolute value; $\parallel$ denotes concatenation and $h _ { i }$ is the node feature/embedding of node $i$ . We discuss the attention-based graphs together with the types of graph convolutional layers in Section VI and thus skip these methods in this section.  

Special cases of brain graph definition are the sharedmask methods. These methods defined a matrix of learnable parameters with the same shape as the adjacency matrix of the input graphs that acts as a mask/filter by multiplying it with the adjacency matrix. This learnable matrix is a part of the model. Thus, the same mask is applied to all input graphs. However, a shared mask limits the size of the input graphs, i.e. the number of nodes must remain fixed so that the adjacency matrix can be multiplied with the shared mask.  

TABLE I: Overview of methods for obtaining the brain graph structure.   


<html><body><table><tr><td>Method</td><td>Learnable Pre-defined</td><td></td><td>Papers</td></tr><tr><td>Distance between electrode positions</td><td>X</td><td>√</td><td>[46-64]</td></tr><tr><td>Functional connectivity measure</td><td>X</td><td>√</td><td>[7,47,49,50,55,59,61,65-86]</td></tr><tr><td>Manually defined</td><td>X</td><td>√</td><td>[46,53,54,57,58,62,87]</td></tr><tr><td>Shared learnable mask</td><td>√</td><td>X</td><td>[46,63,69,72,82,88-92]</td></tr><tr><td>Feature similarity</td><td>√</td><td>X</td><td>[56, 63, 72,87, 92-94]</td></tr><tr><td>Feature distance</td><td>√</td><td>×</td><td>[64, 95–97]</td></tr><tr><td>Transformer-style attention</td><td>√</td><td>X</td><td>[98,99]</td></tr><tr><td>Concatenation attention</td><td>√</td><td>X</td><td>[81,100]</td></tr><tr><td>Dense projection</td><td>√</td><td>X</td><td>[101-103]</td></tr><tr><td>LSTM-based</td><td>√</td><td>X</td><td>[104]</td></tr><tr><td>Multiple/Combined graph</td><td></td><td></td><td></td></tr><tr><td>definitions</td><td>-</td><td></td><td>[47,49,53,54,57-59,61-64,67,69,72,79,81,82,87,92,102]</td></tr></table></body></html>  

TABLE II: Overview of methods in defining the input node features   


<html><body><table><tr><td>Method</td><td>Time domain</td><td>Frequency domain</td><td>Graph Domain</td><td>Papers</td></tr><tr><td>Differential entropy</td><td>√</td><td>X</td><td>×</td><td>[46,51,53,55,57,71,72,75,78,81,82,87,89, 90,92,93,95-99,101,102]</td></tr><tr><td>Raw signal Fourier Transform</td><td>√</td><td></td><td>X</td><td>[48, 52,56,60,62-64,66,67,69,72,76,77, 79, 80, 83,84,86,91,94,100,104-106]</td></tr><tr><td>Power Spectral Density/Band</td><td>X</td><td>√</td><td>X</td><td>[50,88,107]</td></tr><tr><td>Power Graph theory</td><td>×</td><td>√</td><td>X</td><td>[7, 49, 55,57-59,61, 78,85, 90]</td></tr><tr><td>metrics Descriptive</td><td>×</td><td>X</td><td>√</td><td>[65, 73]</td></tr><tr><td>statistics</td><td>√</td><td>X</td><td>×</td><td>[47, 58, 61]</td></tr></table></body></html>  

In the current stage, which method should be preferred for brain graph classification tasks is unclear. Some authors attempt to avoid this issue by combining multiple methods. However, we instead suggest that the researchers carefully consider each of the presented methods in the context of the given classification task, as each method poses its unique set of strengths and weaknesses.  

# V. NODE FEATURE DEFINITIONS  

The second part of the input to a GNN model is the node feature matrix (Fig. 1A). We summarise the various definitions of node features in Table II. We categorise these definitions based on which domain they are computed, i.e. time, frequency and graph domains.  

The time-domain methods are the most commonly used in the current literature. In particular, these are the differential entropy (DE) and raw signal methods. The popularity of DE is given by the fact that many of the open EEG datasets include this feature, such as the SEED [108] emotion recognition dataset. DE describes the complexity of a continuous variable and is defined as:  

$$
D E ( X ) = - \int _ { X } f ( x ) l o g ( f ( x ) ) d x
$$  

where $X$ is a random continuous variable and $f ( x )$ is the probability density function.  

Many papers define the node feature as the raw EEG signal. However, the raw signal can be too long for a GNN to process effectively. Thus, it is often coupled with node feature pre-processing module and spatio-temporal GNNs (See V A and VI respectively) to either reduce the dimensionality or to extract the temporal patterns contained within the signal effectively. An alternative to the raw signal node feature is descriptive statistics, such as mean, median or standard deviation.  

Frequency-domain node features are usually defined as the Fourier frequency components obtained by the Fourier transform or the power spectral density. Both of these methods attempt to quantify the strength of various frequency components within the EEG signal. An advantage of these representations is their relatively low dimensionality compared to the raw signal described previously.  

Finally, graph-theoretical features can be utilised to describe the nodes, e.g. mean node weight [65] and betweenness centrality [65, 73]. A severe limitation of this method is that the graph structure needs to be defined prior to node feature extraction. Thus, this node feature type is incompatible with learnable brain graph methods.  

TABLE III: Overview of node feature pre-processing before GNN layers.   


<html><body><table><tr><td>Method</td><td>Trained separately</td><td>Papers</td></tr><tr><td>1D CNN Feature-wise</td><td></td><td>[48,53,60,93,94,100, 104,106]</td></tr><tr><td>attention weighting</td><td>X</td><td></td></tr><tr><td>bidirectional</td><td></td><td>[73]</td></tr><tr><td>LSTM</td><td>√</td><td>[76]</td></tr><tr><td>Temporal CNN</td><td>X</td><td>[56, 91, 94]</td></tr><tr><td>WaveletCNN</td><td>X</td><td>[91]</td></tr><tr><td>SincCNN</td><td>X</td><td>[60]</td></tr><tr><td>MLP CNN Feature</td><td>X</td><td>[85]</td></tr></table></body></html>  

# A. Node Feature Preprocessing  

An optional next step after node features construction is some kind of node feature pre-processing module (NFP) (Fig. 1B). We summarise the types of NFPs in Table III.  

Most of the NFPs are integrated within the GNN architecture, thus allowing the model to be trained in an end-to-end manner. The exceptions are methods that utilise a pre-trained feature extraction neural network implemented as a bidirectional LSTM [76] or a CNN [64].  

The surveyed NFPs are all based on a neural network. In most cases, these are variants of a CNN and multilayer perceptron (MLP). These modules aim to (1) reduce the dimensionality of the node features and (2) enhance the node features, including potentially suppressing noise or redundant information.  

even a full spectral GNN would not be too computationally expensive for EEG classification. Therefore, it remains unclear why many authors opt for the ChebConv approximation of spectral GNN. We speculate that the influence of classical signal processing tools in EEG analysis might also serve as a sufficient argument for using spectral GNNs for EEG classification.  

On the other hand, the other half of the surveyed papers experiment with a wide range of spatial GNNs. The (simplified) GCN is a popular method amongst these, which is equivalent to a 1st-order ChebConv ( $K = 1$ ). A special case of spatial GNN is the graph attention network (GAT). GAT allows for adjusting the graph by reweighting the edges using an attention mechanism. Generally, the attention mechanism for computing the new softmax-normalised edge weight $e _ { i j }$ is defined as follows:  

$$
e _ { i , j } = \frac { \exp \left( \sigma \left( \mathbf { w } ^ { \top } [ \mathbf { W } h _ { i } \left. \mathbf { W } h _ { j } \right. \right) \right) } { \sum _ { k \in \mathcal { N } ( i ) } \exp \left( \sigma \left( \mathbf { w } ^ { \top } [ \mathbf { W } h _ { i } \left. \mathbf { W } h _ { k } \right. \right) \right) } ,
$$  

where $w$ and $W$ are the learnable parameters of the model, $\sigma$ is an activation function, $h$ is the node feature vector/embedding, and $N ( i )$ is the set of nodes connected to node $i$ . The resulting edge weights can then be passed to Equation 1.  

Next, the spatio-temporal GNNs were tested for EEG classification in several instances. A spatio-temporal block consists of one GCN layer and one 1D-CNN applied temporally. This structure allows the model to extract both spatial (i.e. graph) and temporal patterns. There are both spatial and spectral variants of spatio-temporal GNN, and there is no indication as to which one should be preferred as no comparative study exists to date.  

Finally, several papers adopt multi-branch architectures. These methods utilise multiple GCN layers applied in parallel to allow the model to focus on various aspects (also views) of the input graph. An example of such a model utilises two-branch GNN to learn from both FC- and SC-based brain graph structure [63]. Alternatively, the individual frequency bands of EEG signals can be used to construct various graph views [85].  

# VI. TYPE OF GRAPH CONVOLUTIONAL LAYER  

A core part of a GNN model are the graph convolutional layers (GCN) (Fig. 1C). We summarise the utilised types of GCNs in Table IV. We further categorise them based on the type of GNN as introduced in Section II, i.e. spatial, spectral. Additionally, we add the temporal category, which is not a type of standalone GCN layer but must be combined with spatial or spectral GCN.  

Interestingly, ChebConv is used in the majority of the surveyed papers (counting both ChebConv and spectral spatio-temporal GNN in Table IV). Since EEG typically uses 128 electrodes in high-density montages, the size of the brain graphs is relatively small. In such cases,  

# VII. NODE POOLING MECHANISMS  

In some instances, reducing the number of nodes in the graph might be desirable. This can be achieved with a node pooling module (Fig. 1D). We summarise the node pooling modules utilised in the surveyed papers in Table V.  

There are both learnable and non-learnable node pooling modules in the literature. Please see the corresponding papers for a detailed description of these methods (Table V). Node pooling modules remain a relatively unexplored topic in the EEG-GNN classification models. Node pooling can (1) remove redundant nodes, (2) reduce the size of the graph embedding in a setting where the concatenation of node embeddings forms it, and (3)  

TABLE IV: Overview of graph convolutional layers.   


<html><body><table><tr><td>Method</td><td>Spatial</td><td>Spectral Temporal</td><td></td><td>Papers</td></tr><tr><td rowspan="3">Graph Isomorphism Network (Simplified) Graph Convolution Network</td><td>√</td><td>X</td><td>X</td><td>[48, 65, 79]</td></tr><tr><td>√</td><td>X</td><td>X</td><td>[7,46,53,54,56,58,61,70,72,75,83,89,106]</td></tr><tr><td>×</td><td>√</td><td>×</td><td>[49,51,55,57,59,66,67,69,71,74,76- 78,80,82,85,90,97,99,104]</td></tr><tr><td rowspan="3">Chebyshev Graph Convolution Graph Attention Network Diffusion recurrent gated Spatio-temporal GNN</td><td>√</td><td>X</td><td>×</td><td>[60,62,73,84,88,94,98,100]</td></tr><tr><td>X</td><td>√</td><td>X</td><td>[50]</td></tr><tr><td>×</td><td>√</td><td>√</td><td>[52,81,86, 95, 96,107]</td></tr><tr><td>(Spectral) Spatio-temporal GNN (Spatial) Powers of Adjacency Matrix</td><td>√</td><td>×</td><td>√</td><td>[63,105]</td></tr><tr><td>GNN</td><td>√</td><td></td><td></td><td>[101,102]</td></tr><tr><td>GraphSAGE</td><td>√</td><td>×</td><td>X</td><td>[48,107]</td></tr><tr><td>Spectral GNN</td><td>X</td><td>√</td><td>×</td><td>[87, 93]</td></tr><tr><td>B-Spline Kernel GCN</td><td>√</td><td>X</td><td>X</td><td>[47]</td></tr><tr><td>Residual GCN</td><td>√</td><td>×</td><td>×</td><td>[91]</td></tr><tr><td>Multibranch architectures</td><td>-</td><td>-</td><td>-</td><td>[58,63,80,92,97,100]</td></tr></table></body></html>  

TABLE V: Overview of node pooling mechanisms.   


<html><body><table><tr><td>Method</td><td>Learnable</td><td>Papers</td></tr><tr><td>TopK Hierarchical tree pooling</td><td>√</td><td>[62, 67]</td></tr><tr><td></td><td>√</td><td>[65]</td></tr><tr><td>SortPool</td><td>√</td><td>[48]</td></tr><tr><td>EdgePool</td><td>√</td><td>[48]</td></tr><tr><td>SAGPool</td><td>√</td><td>[48, 54]</td></tr><tr><td>Set2Set</td><td>√</td><td>[48]</td></tr><tr><td>Manual Clustering</td><td>X</td><td>[101,102]</td></tr><tr><td>Graclus Clustering</td><td>X</td><td>[77, 80]</td></tr></table></body></html>  

aid in the explainability of the model by identifying node importance with respect to the classification task.  

# VIII. FROM NODE EMBEDDINGS TO GRAPH EMBEDDING  

The output of the graph convolutions is a set of learned node embeddings. Node embeddings in this form are suitable for tasks such as node classification and link prediction. However, for graph classification, the set of node features needs to be transformed into a unified graph representation (Fig. 1E). We summarise the methods for this transformation in Table VI.  

The most straightforward method to form a graph embedding is to simply concatenate the node features. This approach poses a few limitations. First, the resulting graph embedding grows with the number of nodes, thus, the classification layer requires a large number of parameters. Second, all input graphs need to have the same number of nodes, limiting the model’s generalisation to other datasets. Finally, such an approach is likely to include redundant or duplicated information in the graph embedding since GNN produces node embeddings by aggregating information from neighbouring nodes.  

A readout function is one of the methods to form a graph embedding that addresses these issues. A readout forms the embedding by passing the node features through a permutation-invariant function. A general definition of a readout to obtain graph embedding of a graph $G _ { i }$ from a set of $V$ node embeddings $H = [ h _ { 1 } , . . . , h _ { V } ]$ is given by:  

$$
G _ { i } = \sum _ { k = 1 } ^ { V } h _ { k } ,
$$  

where $\textstyle \sum$ can be any permutation-invariant function. In the surveyed papers, these functions were sum, average and maximum. A few papers also experiment with attention-weighted sum to attenuate the role of unimportant nodes within the graph embedding [88]. An interesting alternative is to apply CNN-style average or maximum pooling node-wise [105].  

Alternatively, researchers explored various neural network models to obtain graph embeddings, such as CNN [52, 69, 78], (bi-)LSTM [51, 83, 84, 99, 100], Transformer [89] and capsule networks [73]. Additionally, graph pooling methods, such as DiffPool [109], SAGPool [110], iPool [111], TAP [112] and HierCorrPool [113] can be used for this purpose.  

# IX. DISCUSSION  

Despite most of the surveyed papers being relatively recent, a wide range of GNN-based methods has already been proposed to classify EEG signals in a diverse set of tasks, such as emotion recognition, brain-computer interfaces, and psychological and neurodegenerative disorders and diseases (Fig 3). This recent rise in popularity of GNN models for EEG might be attributed to (1) the development of new GNN methods and (2) advances in network neuroscience inspired an extension of this framework to deep learning. GNNs offer unique advantages over other deep learning methods. This is mainly the possibility of modelling multivariate time series and interactions among them with a single GNN model, which is not possible with CNN or recurrent networks. Additionally, patterns learned by GNNs can readily be interpreted in the context of network neuroscience, thus enabling a wide range of avenues for model explainability.  

TABLE VI: Overview of methods for the formation of graph embedding from a set of node embeddings   


<html><body><table><tr><td>Method</td><td>Learnable</td><td>Papers</td></tr><tr><td>Sum readout</td><td>X</td><td>[46,65,82]</td></tr><tr><td>Average readout</td><td>X</td><td>[49,54,61,62,72,85,107]</td></tr><tr><td>Maximum readout Concatenate node</td><td>X</td><td>[7,54,62,76,106] [47, 55-60,64,66,67,70,74,77,80,81,86,87,90-93,98,100-</td></tr><tr><td>embeddings</td><td>X</td><td>102,104]</td></tr><tr><td>CNN-like Average/Maximum</td><td></td><td></td></tr><tr><td>Pooling</td><td>X</td><td>[83,105]</td></tr><tr><td>SortPool</td><td>√</td><td></td></tr><tr><td>Attention weighted</td><td>√</td><td>[68]</td></tr><tr><td>CNN</td><td>√</td><td>[63, 88, 97]</td></tr><tr><td>LSTM</td><td>√</td><td>[52, 69, 78] [51, 99]</td></tr><tr><td>Capsule Network</td><td>√</td><td>[73]</td></tr><tr><td>Transformer</td><td>√</td><td></td></tr><tr><td>BidirectionalLSTM</td><td>√</td><td>[89] [83, 84, 100]</td></tr></table></body></html>  

This survey categorises the proposed GNN models in terms of their inputs and modules. Specifically, these are brain graph structure, node features and their preprocessing, GCN layers, node pooling mechanisms, and formation of graph embeddings. This categorisation allows us to provide a quick and simple overview of the different methods presented in the EEG-GNN literature, appreciate the current state of the art in this field and identify promising future directions.  

# A. Limitations of Surveyed Papers  

Surprisingly, we have identified the least variety and innovation in the category of GCN layers (Table IV). A significant proportion of the surveyed papers utilise either ChebConv or “vanilla” spatial GCN. This might be due to the relative novelty of the EEG-GNN field, and thus, many papers explore other areas of model design, such as node features and brain graph definitions. A few papers seem to successfully experiment with more complex types of GCN layers [47, 50, 91] and multi-branch architectures [58, 63, 80, 92, 97, 100].  

A major limitation of most surveyed papers is the lack of generalisability to external datasets that might use a different number of EEG signals. This is caused by (1) the use of ChebConv and (2) forming graph embedding by node feature concatenation [47, 55–60, 64, 66, 67, 70, 74, 77, 80, 81, 86, 87, 90–93, 98, 100–102, 104]. (1) can be addressed by utilising spatial GCN layers as suggested above, and (2) can be solved by using a readout function or a suitable node pooling mechanism, which coarsens the graph to a fixed number of nodes. Additionally, there is a general lack of transfer learning experiments for EEGGNN models, which might be a promising direction for future research.  

Finally, we have identified an interesting gap in EEGGNN research: the lack of utilising frequency band information in a more complex way. A few papers train separate models for each frequency band in isolation [46, 47, 65]. Alternatively, they propose concatenating the graph embeddings generated from the frequencyband-GNN branches [52, 87, 101].  

# B. Future Directions  

Several promising directions can be identified in the rapidly evolving landscape of EEG-GNN research. First, a comprehensive comparison of the various GCN layers (e.g. spatial GNN, ChebConv, GAT and graph transformer) with respect to their influence on classification performance should be carried out to address this crucial design question in a systematic manner.  

Second, enhancing the generalisability of models by addressing issues related to the varying number of EEG signals/electrodes and exploring transfer learning approaches can open new avenues for research. For instance, pre-trained GNN models on cheap-to-obtain large datasets, such as open databases for emotion recognition or BCI applications, would allow the application of complex GNN architectures to problems with limited data availability due to the high costs or small populations (e.g. clinical data, rare diseases and disorders). Focusing on these issues would likely improve the generalisability of the models when evaluated on a diverse set of EEG datasets and different classification tasks.  

Lastly, the rich frequency information of EEG signals should be explored more. For instance, we suggest a plausible utility of integrating cross-frequency coupling (CFC) approaches into EEG-GNN models. There is growing evidence in the literature concerning the advanced brain functions (e.g. learning, memory) enabled by CFC [114]. Thus, integrating findings from neuroscience research into the EEG-GNN design promises both performance and explainability gains.  

# C. Limitations of Our Survey  

It is worth noting that this paper does not follow a systematic review methodology; therefore, we do not assert that our findings are exhaustive. Instead, our objective is to offer a succinct and cohesive overview of the current research on EEG-GNN models to facilitate the development of innovative approaches and assist researchers new to this field.  

One of the major parts of EEG-GNN models we omit in this survey is the model explainability. We suggest that a survey paper is not well suited for comprehensively covering this aspect of research. Instead, we suggest a comparative experimental study to be better suited to explore the various explainability options of GNN explainability. However, to maintain the comprehensiveness of this survey, we list the papers that report the use of certain methods of model explainability: [50, 55, 89, 105, 106].  

# X. CONCLUSION  

In conclusion, this survey examined the current research on EEG-GNN models for classifying EEG signals.  

Various GNN-based methods have been proposed for tasks such as emotion recognition, brain-computer interfaces, and psychological and neurodegenerative disorders. The surveyed papers were categorised based on inputs and modules, including brain graph structure, node features, GCN layers, node pooling mechanisms, and graph embeddings.  

GNNs offer a unique method for analysing and classifying EEG in the graph domain, thus allowing the exploitation of complex spatial information in brain networks that other neural networks do not. Additionally, GNNs can be easily extended with CNN and recurrent network-based modules at various stages of the GNN architecture, such as for node feature pre-processing, node embedding post-processing and graph embedding formation.  

However, limitations and areas for improvement were identified. There is a lack of variety and innovation in GCN layers, with many papers utilising ChebConv or “simple” spatial GCN without clear justification. Generalisability to external datasets with varying numbers of EEG electrodes is limited. Transfer learning experiments and integration of cross-frequency coupling approaches are potential future research to enhance the performance and explainability of GNN.  

[1] Santiago Morales and Maureen E. Bowers. Timefrequency analysis methods and their application in developmental EEG data. Developmental Cognitive Neuroscience, 54:101067, April 2022.   
[2] S. J. M. Smith. EEG in the diagnosis, classification, and management of patients with epilepsy. Journal of Neurology, Neurosurgery & Psychiatry, 76(suppl 2):ii2– ii7, June 2005. Publisher: BMJ Publishing Group Ltd.   
[3] Sandra K. Loo and Russell A. Barkley. Clinical Utility of EEG in Attention Deficit Hyperactivity Disorder. Applied Neuropsychology, 12(2):64– 76, June 2005. Publisher: Routledge eprint: https://doi.org/10.1207/s15324826an1202 2.   
[4] D. J. McFarland and J. R. Wolpaw. EEG-based brain–computer interfaces. Current Opinion in Biomedical Engineering, 4:194–200, December 2017.   
[5] F. Lotte, L. Bougrain, A. Cichocki, M. Clerc, M. Congedo, A. Rakotomamonjy, and F. Yger. A review of classification algorithms for EEG-based brain–computer interfaces: a 10 year update. Journal of Neural Engineering, 15(3):031005, April 2018. Publisher: IOP Publishing.   
[6] Wojciech Samek, Carmen Vidaurre, Klaus-Robert M¨uller, and Motoaki Kawanabe. Stationary common spatial patterns for brain–computer interfacing. Journal of Neural Engineering, 9(2):026013, 2012.   
[7] Dominik Klepl, Fei He, Min Wu, Daniel J Blackburn, and Ptolemaios Sarrigiannis. EEG-based Graph Neural Network Classification of Alzheimer’s Disease: An Empirical Evaluation of Functional Connectivity Methods. IEEE Transactions on Neural Systems and Rehabilitation Engineering, 30:2651–2660, 2022.   
[8] Murugappan Murugappan, Nagarajan Ramachandran, Yaacob Sazali, et al. Classification of human emotion from EEG using discrete wavelet transform. Journal of Biomedical Science and Engineering, 3(04):390, 2010.   
[9] Rami J Oweis and Enas W Abdulhay. Seizure classification in EEG signals utilizing Hilbert-Huang transform. Biomedical Engineering Online, 10:1–15, 2011.   
[10] Mohammad-Parsa Hosseini, Amin Hosseini, and Kiarash Ahi. A Review on Machine Learning for EEG Signal Processing in Bioengineering. IEEE Reviews in Biomedical Engineering, 14:204–218, 2021.   
[11] Khansa Rasheed, Adnan Qayyum, Junaid Qadir, Shobi Sivathamboo, Patrick Kwan, Levin Kuhlmann, Terence O’Brien, and Adeel Razi. Machine Learning for Predicting Epileptic Seizures Using EEG Signals: A Review. IEEE Reviews in Biomedical Engineering, 14:139–155, 2021.   
[12] Dominik Klepl, Fei He, Min Wu, Daniel J Blackburn, and Ptolemaios G Sarrigiannis. Cross-frequency multilayer network analysis with bispectrum-based functional connectivity: a study of Alzheimer’s disease. Neuroscience, 521:77–88, 2023.   
[13] Vernon J Lawhern, Amelia J Solon, Nicholas R Waytowich, Stephen M Gordon, Chou P Hung, and Brent J Lance. EEGNet: a compact convolutional neural network for EEG-based brain–computer interfaces. Journal of Neural Engineering, 15(5):056013, 2018.   
[14] Ryan G Hefron, Brett J Borghetti, James C Christensen, and Christine M Schubert Kabban. Deep long short-term memory structures model temporal dependencies improving cognitive workload estimation. Pattern Recognition Letters, 94:96–104, 2017.   
[15] Danielle S Bassett and Olaf Sporns. Network neuroscience. Nature Neuroscience, 20(3):353–364, 2017.   
[16] Rui Cao, Yan Hao, Xin Wang, Yuan Gao, Huiyu Shi, Shoujun Huo, Bin Wang, Hao Guo, and Jie Xiang. EEG functional connectivity underlying emotional valance and arousal using minimum spanning trees. Frontiers in Neuroscience, 14:355, 2020.   
[17] Abdulyekeen T. Adebisi and Kalyana C. Veluvolu. Brain network analysis for the discrimination of dementia disorders using electrophysiology signals: A systematic review. Frontiers in Aging Neuroscience, 15, 2023.   
[18] Berke Kılıc¸ and Serap Aydın. Classification of contrasting discrete emotional states indicated by EEG based graph theoretical network measures. Neuroinformatics, pages 1–15, 2022.   
[19] Mahdi Jalili. Graph theoretical analysis of Alzheimer’s disease: Discrimination of AD patients from healthy subjects. Information Sciences, 384:145–156, 2017.   
[20] Fatemeh Hasanzadeh, Maryam Mohebbi, and Reza Rostami. Graph theory analysis of directed functional brain networks in major depressive disorder based on EEG signal. Journal of Neural Engineering, 17(2):026010, 2020.   
[21] Sou Nobukawa, Teruya Yamanishi, Shinya Kasakawa, Haruhiko Nishimura, Mitsuru Kikuchi, and Tetsuya Takahashi. Classification methods based on complexity and synchronization of electroencephalography signals in Alzheimer’s disease. Frontiers in Psychiatry, 11:255, 2020.   
[22] Supriya Supriya, Siuly Siuly, Hua Wang, and Yanchun Zhang. Epilepsy Detection From EEG Using Complex Network Techniques: A Review. IEEE Reviews in Biomedical Engineering, 16:292–306, 2023.   
[23] Rui Li, Xin Yuan, Mohsen Radfar, Peter Marendy, Wei Ni, Terrence J. O’Brien, and Pablo M. CasillasEspinosa. Graph Signal Processing, Graph Neural Network and Graph Learning on Biological Data: A Systematic Review. IEEE Reviews in Biomedical Engineering, 16:109–135, 2023.   
[24] Dominik Klepl, Fei He, Min Wu, Daniel J Blackburn, and Ptolemaios G Sarrigiannis. Adaptive Gated Graph Convolutional Network for Explainable Diagnosis of Alzheimer’s Disease using EEG Data. arXiv preprint arXiv:2304.05874, 2023.   
[25] Xiao-Meng Zhang, Li Liang, Lin Liu, and Ming-Jing Tang. Graph Neural Networks and Their Current Applications in Bioinformatics. Frontiers in Genetics, 12, 2021.   
[26] Alaa Bessadok, Mohamed Ali Mahjoub, and Islem Rekik. Graph Neural Networks in Network Neuroscience. IEEE Transactions on Pattern Analysis and Machine Intelligence, 45(5):5833–5848, May 2023.   
[27] Oliver Wieder, Stefan Kohlbacher, M´elaine Kuenemann, Arthur Garon, Pierre Ducrot, Thomas Seidel, and Thierry Langer. A compact review of molecular property prediction with graph neural networks. Drug Discovery Today: Technologies, 37:1–12, December 2020.   
[28] Patrick Reiser, Marlen Neubert, Andr´e Eberhard, Luca Torresi, Chen Zhou, Chen Shao, Houssam Metni, Clint van Hoesel, Henrik Schopmans, Timo Sommer, and Pascal Friederich. Graph neural networks for materials science and chemistry. Communications Materials, 3(1):1– 18, November 2022. Number: 1 Publisher: Nature Publishing Group.   
[29] Jiacheng Xiong, Zhaoping Xiong, Kaixian Chen, Hualiang Jiang, and Mingyue Zheng. Graph neural networks for automated de novo drug design. Drug Discovery Today, 26(6):1382–1393, June 2021.   
[30] Mengying Sun, Sendong Zhao, Coryandar Gilvary, Olivier Elemento, Jiayu Zhou, and Fei Wang. Graph convolutional networks for computational drug development and discovery. Briefings in Bioinformatics, 21(3):919–935, May 2020.   
[31] Masoud Malekzadeh, Parisa Hajibabaee, Maryam Heidari, Samira Zad, Ozlem Uzuner, and James H Jones. Review of Graph Neural Network in Text Classification. In 2021 IEEE 12th Annual Ubiquitous Computing, Electronics & Mobile Communication Conference (UEMCON), pages 0084–0091, December 2021.   
[32] Lingfei Wu, Yu Chen, Kai Shen, Xiaojie Guo, Hanning Gao, Shucheng Li, Jian Pei, and Bo Long. Graph Neural Networks for Natural Language Processing: A Survey. Foundations and Trends® in Machine Learning, 16(2):119–328, January 2023. Publisher: Now Publishers, Inc.   
[33] Chen Gao, Yu Zheng, Nian Li, Yinfeng Li, Yingrong Qin, Jinghua Piao, Yuhan Quan, Jianxin Chang, Depeng Jin, Xiangnan He, and Yong Li. A Survey of Graph Neural Networks for Recommender Systems: Challenges, Methods, and Directions. ACM Transactions on Recommender Systems, 1(1):3:1–3:51, March 2023.   
[34] Shiwen Wu, Fei Sun, Wentao Zhang, Xu Xie, and Bin Cui. Graph Neural Networks in Recommender Systems: A Survey. ACM Computing Surveys, 55(5):97:1–97:37, December 2022.   
[35] Weiwei Jiang and Jiayun Luo. Graph neural network for traffic forecasting: A survey. Expert Systems with Applications, 207:117921, November 2022.   
[36] Mingqi Lv, Zhaoxiong Hong, Ling Chen, Tieming Chen, Tiantian Zhu, and Shouling Ji. Temporal Multi-Graph Convolutional Network for Traffic Flow Prediction. IEEE Transactions on Intelligent Transportation Systems, 22(6):3337–3348, June 2021.   
[37] Jianian Wang, Sheng Zhang, Yanghua Xiao, and Rui Song. A Review on Graph Neural Network Methods in Financial Applications, April 2022. arXiv:2111.15367 [cs, q-fin, stat].   
[38] Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, and Philip S. Yu. A Comprehensive Survey on Graph Neural Networks. IEEE Transactions on Neural Networks and Learning Systems, 32(1):4–24, January 2021.   
[39] Jie Zhou, Ganqu Cui, Shengding Hu, Zhengyan Zhang, Cheng Yang, Zhiyuan Liu, Lifeng Wang, Changcheng Li, and Maosong Sun. Graph neural networks: A review methes LOm 2020.   
[40] Petar Velicˇkovic´, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Li\`o, and Yoshua Bengio. Graph Attention Networks, February 2018. arXiv:1710.10903 [cs, stat].   
[41] Youngjoo Seo, Micha¨el Defferrard, Pierre Vandergheynst, and Xavier Bresson. Structured Sequence Modeling with Graph Convolutional Recurrent Networks. In Long Cheng, Andrew Chi Sing Leung, and Seiichi Ozawa, editors, Neural Information Processing, Lecture Notes in Computer Science, pages 362–373, Cham, 2018. Springer International Publishing.   
[42] Yunsheng Shi, Zhengjie Huang, Shikun Feng, Hui Zhong, Wenjin Wang, and Yu Sun. Masked Label Prediction: Unified Message Passing Model for SemiSupervised Classification, May 2021. arXiv:2009.03509 [cs, stat].   
[43] Zhiqian Chen, Fanglan Chen, Lei Zhang, Taoran Ji, Kaiqun Fu, Liang Zhao, Feng Chen, Lingfei Wu, Charu Aggarwal, and Chang-Tien Lu. Bridging the Gap between Spatial and Spectral Domains: A Survey on Graph Neural Networks, July 2021. arXiv:2002.11867 [cs, stat].   
[44] Deyu Bo, Xiao Wang, Yang Liu, Yuan Fang, Yawen Li, and Chuan Shi. A Survey on Spectral Graph Neural Networks, February 2023.   
[45] Micha¨el Defferrard, Xavier Bresson, and Pierre Vandergheynst. Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering. In Advances in Neural Information Processing Systems, volume 29. Curran Associates, Inc., 2016.   
[46] Peixiang Zhong, Di Wang, and Chunyan Miao. EEGbased emotion recognition using regularized graph neural networks. IEEE Transactions on Affective Computing, 2020.   
[47] Zhiqiang Lin, Taorong Qiu, Ping Liu, Lingyun Zhang, Siwei Zhang, and Zhendong Mu. Fatigue driving recognition based on deep learning and graph neural network. Biomedical Signal Processing and Control, 68:102598, 2021.   
[48] Andac Demir, Toshiaki Koike-Akino, Ye Wang, Masaki Haruna, and Deniz Erdogmus. EEG-GNN: Graph Neural Networks for Classification of Electroencephalogram (EEG) Signals. In 2021 43rd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC), pages 1061–1067. IEEE, 2021.   
[49] Khadijeh Raeisi, Mohammad Khazaei, Pierpaolo Croce, Gabriella Tamburro, Silvia Comani, and Filippo Zappasodi. A GRAPH CONVOLUTIONAL NEURAL NETWORK FOR THE AUTOMATED DETECTION OF SEIZURES IN THE NEONATAL EEG. Computer Methods and Programs in Biomedicine, page 106950, 2022.   
[50] Siyi Tang, Jared Dunnmon, Khaled Kamal Saab, Xuan Zhang, Qianying Huang, Florian Dubost, Daniel Rubin, and Christopher Lee-Messer. Self-Supervised Graph Neural Networks for Improved Electroencephalographic Seizure Analysis. In International Conference on Learning Representations, 2021.   
[51] Yongqiang Yin, Xiangwei Zheng, Bin Hu, Yuang Zhang, and Xinchun Cui. EEG emotion recognition using fusion model of graph convolutional neural networks and LSTM. Applied Soft Computing, 100:106954, 2021.   
[52] Biao Sun, Han Zhang, Zexu Wu, Yunyan Zhang, and Ting Li. Adaptive spatiotemporal graph convolutional networks for motor imagery classification. IEEE Signal Processing Letters, 28:219–223, 2021.   
[53] Guanglong Du, Jinshao Su, Linlin Zhang, Kang Su, Xueqian Wang, Shaohua Teng, and Peter Xiaoping Liu. A Multi-Dimensional Graph Convolution Network for EEG Emotion Recognition. IEEE Transactions on Instrumentation and Measurement, 71:1–11, 2022.   
[54] Tao Xu, Wang Dang, Jiabao Wang, and Yun Zhou. DAGAM: A Domain Adversarial Graph Attention Model for Subject Independent EEG-Based Emotion Recognition. arXiv preprint arXiv:2202.12948, 2022.   
[55] Soobeom Jang, Seong-Eun Moon, and Jong-Seok Lee. EEG-based video identification using graph signal modeling and graph convolutional neural network. In 2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 3066–3070. IEEE, 2018.   
[56] Yi Ding, Neethu Robinson, Qiuhao Zeng, and Cuntai Guan. LGGNet: learning from Local-global-graph representations for brain-computer interface. arXiv preprint arXiv:2105.02786, 2021.   
[57] Fa Zheng, Bin Hu, Shilin Zhang, Yalin Li, and Xiangwei Zheng. EEG Emotion Recognition based on Hierarchy Graph Convolution Network. In 2021 IEEE International Conference on Bioinformatics and Biomedicine (BIBM), pages 1628–1632. IEEE, 2021.   
[58] Difei Zeng, Kejie Huang, Cenglin Xu, Haibin Shen, and Zhong Chen. Hierarchy graph convolution network and tree classification for epileptic detection on electroencephalography signals. IEEE Transactions on Cognitive and Developmental Systems, 13(4):955–968, 2020.   
[59] Jingjing Jia, Bofeng Zhang, Hehe Lv, Zhikang Xu, Shengxiang Hu, and Haiyan Li. CR-GCN: ChannelRelationships-Based Graph Convolutional Network for EEG Emotion Recognition. Brain Sciences, 12(8):987, 2022.   
[60] Darshana Priyasad, Tharindu Fernando, Simon Denman, Sridha Sridharan, and Clinton Fookes. Affect recognition from scalp-EEG using channel-wise encoder networks coupled with geometric deep learning and multi-channel feature fusion. Knowledge-Based Systems, page 109038, 2022.   
[61] Manhua Jia, Wenjian Liu, Junwei Duan, Long Chen, CL Philip Chen, Qun Wang, and Zhiguo Zhou. Efficient graph convolutional networks for seizure prediction using scalp EEG. Frontiers in Neuroscience, 16:967116– 967116, 2022.   
[62] Tao Chen, Yanrong Guo, Shijie Hao, and Richang Hong. Exploring Self-Attention Graph Pooling With EEGBased Topological Structure and Soft Label for Depression Detection. IEEE Transactions on Affective Computing, 2022.   
[63] Menglei Li, Hongbo Chen, and Zixue Cheng. An Attention-Guided Spatiotemporal Graph Convolutional Network for Sleep Stage Classification. Life, 12(5):622, 2022.   
[64] Ziyu Jia, Youfang Lin, Jing Wang, Xiaojun Ning, Yuanlai He, Ronghao Zhou, Yuhan Zhou, and H Lehman Liwei. Multi-view spatial-temporal graph convolutional networks with domain generalization for sleep stage classification. IEEE Transactions on Neural Systems and Rehabilitation Engineering, 29:1977–1986, 2021.   
[65] Hanjie Liu, Jinren Zhang, Qingshan Liu, and Jinde Cao. Minimum spanning tree based graph neural network for emotion classification using EEG. Neural Networks, 145:308–318, 2022.   
[66] Youngchul Kwak, Woo-Jin Song, and Seong-Eun Kim. Graph Neural Network with Multilevel Feature Fusion for EEG based Brain-Computer Interface. In 2020 IEEE International Conference on Consumer Electronics-Asia (ICCE-Asia), pages 1–3. IEEE, 2020.   
[67] Qi Chang, Cancheng Li, Qing Tian, Qijing Bo, Jicong Zhang, Yanbing Xiong, and Chuanyue Wang. Classification of first-episode schizophrenia, chronic schizophrenia and healthy control based on brain network of mismatch negativity by graph neural network. IEEE Transactions on Neural Systems and Rehabilitation Engineering, 29:1784–1794, 2021.   
[68] Jinying Bi, Fei Wang, Xin Yan, Jingyu Ping, and Yongzhao Wen. Multi-domain fusion deep graph convolution neural network for EEG emotion recognition. Neural Computing and Applications, pages 1–15, 2022.   
[69] Shiva Asadzadeh, Tohid Yousefi Rezaii, Soosan Beheshti, and Saeed Meshgini. Accurate emotion recognition using Bayesian model based EEG sources as dynamic graph convolutional neural network nodes. Scientific Reports, 12(1):1–14, 2022.   
[70] Yanna Zhao, Changxu Dong, Gaobo Zhang, Yaru Wang, Xin Chen, Weikuan Jia, Qi Yuan, Fangzhou Xu, and Yuanjie Zheng. EEG-Based Seizure detection using linear graph convolution network with focal loss. Computer Methods and Programs in Biomedicine, 208:106277, 2021.   
[71] Jianhui Chen, Hui Qian, and Xiaoliang Gong. Bayesian Graph Neural Networks for EEG-Based Emotion Recognition. In Clinical Image-Based Procedures, Distributed and Collaborative Learning, Artificial Intelligence for Combating COVID-19 and Secure and Privacy-Preserving Machine Learning, pages 24–33. Springer, 2021.   
[72] Rui Li, Yiting Wang, and Bao-Liang Lu. A multidomain adaptive graph convolutional network for EEGbased emotion recognition. In Proceedings of the 29th ACM International Conference on Multimedia, pages 5565–5573, 2021.   
[73] Sayantani Ghosh, Amit Konar, and Atulya K Nagar. Decoding Subjective Creativity Skill from Visuo-Spatial Reasoning Ability Using Capsule Graph Neural Network. In 2021 International Joint Conference on Neural Networks (IJCNN), pages 1–8. IEEE, 2021.   
[74] Nastaran Khaleghi, Tohid Yousefi Rezaii, Soosan Beheshti, and Saeed Meshgini. Developing an efficient functional connectivity-based geometric deep network for automatic EEG-based visual decoding. Biomedical Signal Processing and Control, 80:104221, 2023.   
[75] Dixin Wang, Chang Lei, Xuan Zhang, Hongtong Wu, Shuzhen Zheng, Jinlong Chao, and Hong Peng. Identification of Depression with a Semi-supervised GCN based on EEG Data. In 2021 IEEE International Conference on Bioinformatics and Biomedicine (BIBM), pages 2338–2345. IEEE, 2021.   
[76] Yimin Hou, Shuyue Jia, Xiangmin Lun, Yan Shi, and Yang Li. Deep feature mining via attention-based BiLSTM-GCN for human motor imagery recognition. arXiv preprint arXiv:2005.00777, 2020.   
[77] Yimin Hou, Shuyue Jia, Xiangmin Lun, Ziqian Hao, Va Shi Yang L B Z Jinglei Ly GCNs net: a graph convolutional neural network approach for decoding time-resolved eeg motor imagery signals. IEEE Transactions on Neural Networks and Learning Systems, 2022.   
[78] Wanzeng Kong, Min Qiu, Menghang Li, Xuanyu Jin, and Li Zhu. Causal Graph Convolutional Neural Network For Emotion Recognition. IEEE Transactions on Cognitive and Developmental Systems, 2022.   
[79] Tian-li Tao, Liang-hu Guo, Qiang He, Han Zhang, and Lin Xu. Seizure detection by brain-connectivity analysis using dynamic graph isomorphism network. In 2022 44th Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC), pages 2302–2305. IEEE, 2022.   
[80] Bo Wang, Hui Shen, Gai Lu, Yingxin Liu, et al. Graph Learning with Co-Teaching for EEG-Based Motor Imagery Recognition. IEEE Transactions on Cognitive and Developmental Systems, 2022.   
[81] Yan Li, Ning Zhong, David Taniar, and Haolan Zhang. Mutualgraphnet: a novel model for motor imagery classification. arXiv preprint arXiv:2109.04361, 2021.   
[82] Guangcheng Bao, Kai Yang, Li Tong, Jun Shu, Rongkai Zhang, Linyuan Wang, Bin Yan, and Ying Zeng. Linking Multi-Layer Dynamical GCN With Style-Based Recalibration CNN for EEG-Based Emotion Recognition. Frontiers in Neurorobotics, 16, 2022.   
[83] Lin Feng, Cheng Cheng, Mingyan Zhao, Huiyuan Deng, and Yong Zhang. EEG-Based Emotion Recognition Using Spatial-temporal Graph Convolutional LSTM with Attention Mechanism. IEEE Journal of Biomedical and Health Informatics, 2022.   
[84] Jiatong He, Jia Cui, Gaobo Zhang, Mingrui Xue, Dengyu Chu, and Yanna Zhao. Spatial-temporal seizure detection with graph attention network and bidirectional LSTM architecture. Biomedical Signal Processing and Control, 78:103908, 2022.   
[85] Xinlin Sun, Chao Ma, Peiyin Chen, Mengyu Li, He Wang, Weidong Dang, Chaoxu Mu, and Zhongke Gao. A Novel Complex Network-Based Graph Convolutional Network in Major Depressive Disorder Detection. IEEE Transactions on Instrumentation and Measurement, 2022.   
[86] Xiaocai Shan, Jun Cao, Shoudong Huo, Liangyu Chen, Ptolemaios Georgios Sarrigiannis, and Yifan Zhao. Spatial–temporal graph convolutional network for Alzheimer classification based on brain functional connectivity imaging of electroencephalogram. Human Brain Mapping, 2022.   
[87] Hanyu Li, Xu Zhang, and Ying Xia. EEG Emotion Recognition Based on Dynamically Organized Graph Neural Network. In International Conference on Multimedia Modeling, pages 344–355. Springer, 2022.   
[88] Chao Li, Yong Sheng, Haishuai Wang, Mingyue Niu, Peiguang Jing, Ziping Zhao, and Bj¨orn W Schuller. EEG Emotion Recognition Based on Self-attention Dynamic Graph Neural Networks. In 2022 44th Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC), pages 292–296. IEEE, 2022.   
[89] Mingyi Sun, Weigang Cui, Shuyue Yu, Hongbin Han, Bin Hu, and Yang Li. A Dual-Branch Dynamic Graph Convolution Based Adaptive Transformer Feature Fusion Network for EEG Emotion Recognition. IEEE Transactions on Affective Computing, 2022.   
[90] Tong Zhang, Xuehan Wang, Xiangmin Xu, and CL Philip Chen. GCB-Net: Graph convolutional broad network and its application in emotion recognition. IEEE Transactions on Affective Computing, 13(1):379– 388, 2019.   
[91] Yang Li, Yu Liu, Yu-Zhu Guo, Xiao-Feng Liao, Bin Hu, and Tao Yu. Spatio-temporal-spectral hierarchical graph convolutional network with semisupervised active learning for patient-specific seizure prediction. IEEE Transactions on Cybernetics, 2021.   
[92] Yunlong Xue, Wenming Zheng, Yuan Zong, Hongli Chang, and Xingxun Jiang. Adaptive Hierarchical Graph Convolutional Network for EEG Emotion Recognition. In 2022 International Joint Conference on Neural Networks (IJCNN), pages 1–8. IEEE, 2022.   
[93] Jingcong Li, Shuqi Li, Jiahui Pan, and Fei Wang. Crosssubject EEG emotion recognition with self-organized graph neural network. Frontiers in Neuroscience, page 689, 2021.   
[94] Jianchao Lu, Yuzhe Tian, Shuang Wang, Michael Sheng, and Xi Zheng. PearNet: A Pearson Correlationbased Graph Attention Network for Sleep Stage Recognition. arXiv preprint arXiv:2209.13645, 2022.   
[95] Ziyu Jia, Youfang Lin, Jing Wang, Ronghao Zhou, Xiaojun Ning, Yuanlai He, and Yaoshuai Zhao. GraphSleepNet: Adaptive Spatial-Temporal Graph Convolutional Networks for Sleep Stage Classification. In IJCAI, pages 1324–1330, 2020.   
[96] Tomasz Wierci´nski, Mateusz Rock, Robert Zwierzycki, Teresa Zawadzka, and Micha  Zawadzki. Emotion Recognition from Physiological Channels Using Graph Neural Network. Sensors, 22(8):2980, 2022.   
[97] Hong Zeng, Qi Wu, Yanping Jin, Haohao Zheng, Mingming Li, Yue Zhao, Hua Hu, and Wanzeng Kong. SiamGCAN: a Siamese Graph Convolutional Attention Network for EEG Emotion Recognition. IEEE Transactions on Instrumentation and Measurement, 2022.   
[98] Yiwen Zhu, Kaiyu Gan, and Zhong Yin. Locally temporal-spatial pattern learning with graph attention mechanism for EEG-based emotion recognition. arXiv preprint arXiv:2208.11087, 2022.   
[99] Xiaoxu Li, Wenming Zheng, Yuan Zong, Hongli Chang, and Cheng Lu. Attention-based Spatio-Temporal Graphic LSTM for EEG Emotion Recognition. In 2021 International Joint Conference on Neural Networks (IJCNN), pages 1–8. IEEE, 2021.   
[100] Xiang Li, Jing Li, Yazhou Zhang, and Prayag Tiwari. Emotion Recognition from Multi-channel EEG Data through A Dual-pipeline Graph Attention Network. In 2021 IEEE International Conference on Bioinformatics and Biomedicine (BIBM), pages 3642–3647. IEEE, 2021.   
[101] Tengfei Song, Suyuan Liu, Wenming Zheng, Yuan Zong, and Zhen Cui. Instance-adaptive graph for EEG emotion recognition. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 34(03), pages 2701– 2708, 2020.   
[102] Tengfei Song, Suyuan Liu, Wenming Zheng, Yuan Zong, Zhen Cui, Yang Li, and Xiaoyan Zhou. Variational instance-adaptive graph for EEG emotion recognition. IEEE Transactions on Affective Computing, 2021.   
[103] Qi Lian, Yu Qi, Gang Pan, and Yueming Wang. Learning graph in graph convolutional neural networks for robust seizure prediction. Journal of Neural Engineering, 17(3):035004, 2020.   
[104] Theekshana Dissanayake, Tharindu Fernando, Simon Denman, Sridha Sridharan, and Clinton Fookes. Geometric Deep Learning for Subject Independent Epileptic Seizure Prediction Using Scalp EEG Signals. IEEE Journal of Biomedical and Health Informatics, 26(2):527–538, 2021.   
[105] Xiaoyu Li, Buyue Qian, Jishang Wei, An Li, Xuan Liu, and Qinghua Zheng. Classify EEG and reveal latent graph structure with spatio-temporal graph convolutional neural network. In 2019 IEEE International Conference on Data Mining (ICDM), pages 389–398. IEEE, 2019.   
[106] Maksim Zhdanov, Saskia Steinmann, and Nico Hoffmann. Investigating Brain Connectivity with Graph Neural Networks and GNNExplainer. In 2022 26th International Conference on Pattern Recognition (ICPR), pages 5155–5161. IEEE, 2022.   
[107] Ian C Covert, Balu Krishnan, Imad Najm, Jiening Zhan, Matthew Shore, John Hixson, and Ming Jack Po. Temporal graph convolutional networks for automatic seizure detection. In Machine Learning for Healthcare Conference, pages 160–180. PMLR, 2019.   
[108] Wei-Long Zheng and Bao-Liang Lu. Investigating Critical Frequency Bands and Channels for EEGBased Emotion Recognition with Deep Neural Networks. IEEE Transactions on Autonomous Mental Development, 7(3):162–175, September 2015.   
[109] Zhitao Ying, Jiaxuan You, Christopher Morris, Xiang Ren, Will Hamilton, and Jure Leskovec. Hierarchical Graph Representation Learning with Differentiable Pooling. In Advances in Neural Information Processing Systems, volume 31. Curran Associates, Inc., 2018.   
[110] Junhyun Lee, Inyeop Lee, and Jaewoo Kang. SelfAttention Graph Pooling. In Proceedings of the 36th International Conference on Machine Learning, pages 3734–3743. PMLR, May 2019. ISSN: 2640-3498.   
[111] Xing Gao, Wenrui Dai, Chenglin Li, Hongkai Xiong, and Pascal Frossard. iPool–Information-Based Pooling in Hierarchical Graph Neural Networks. IEEE Transactions on Neural Networks and Learning Systems, 33(9):5032–5044, September 2022.   
[112] Hongyang Gao, Yi Liu, and Shuiwang Ji. TopologyAware Graph Pooling Networks. IEEE Transactions on Pattern Analysis and Machine Intelligence, 43(12):4512–4518, December 2021.   
[113] Yucheng Wang, Min Wu, Xiaoli Li, Lihua Xie, and Zhenghua Chen. Multivariate Time Series Representation Learning via Hierarchical Correlation Pooling Boosted Graph Neural Network. IEEE Transactions on Artificial Intelligence, pages 1–13, 2023.   
[114] Viktor Jirsa and Viktor M¨uller. Cross-frequency coupling in real and virtual brain networks. Frontiers in Computational Neuroscience, 7, 2013.  