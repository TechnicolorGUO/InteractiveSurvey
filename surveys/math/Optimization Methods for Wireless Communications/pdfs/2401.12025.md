# A Survey of Recent Advances in Optimization Methods for Wireless Communications  

Ya-Feng Liu, Senior Member, IEEE, Tsung-Hui Chang, Fellow, IEEE, Mingyi Hong, Senior Member, IEEE, Zheyu Wu, Graduate Student Member, IEEE, Anthony Man-Cho So, Fellow, IEEE, Eduard A. Jorswieck, Fellow, IEEE, and Wei Yu, Fellow, IEEE  

Abstract—Mathematical optimization is now widely regarded as an indispensable modeling and solution tool for the design of wireless communications systems. While optimization has played a significant role in the revolutionary progress in wireless communication and networking technologies from 1G to 5G and onto the future 6G, the innovations in wireless technologies have also substantially transformed the nature of the underlying mathematical optimization problems upon which the system designs are based and have sparked significant innovations in the development of methodologies to understand, to analyze, and to solve those problems. In this paper, we provide a comprehensive survey of recent advances in mathematical optimization theory and algorithms for wireless communication system design. We begin by illustrating common features of mathematical optimization problems arising in wireless communication system design. We discuss various scenarios and use cases and their associated mathematical structures from an optimization perspective. We then provide an overview of recently developed optimization techniques in areas ranging from nonconvex optimization, global optimization, and integer programming, to distributed optimization and learning-based optimization. The key to successful  

Manuscript submitted to IEEE Journal on Selected Areas in Communications on January 16, 2024, revised April 14, 2024 and May 29, 2024, accepted May 30, 2024. The work of Ya-Feng Liu and Zheyu Wu was supported by the National Natural Science Foundation of China (NSFC) under Grant 12371314, Grant 12022116, Grant 12021001, and Grant 12288201. The work of TsungHui Chang was supported by the Shenzhen Science and Technology Program under Grant RCJC20210609104448114 and ZDSYS20230626091302006, the NSFC under Grant 62071409, and by the Guangdong Provincial Key Laboratory of Big Data Computing. The work of Mingyi Hong was supported by the NSF under Grant EPCN-2311007 and Grant CNS-2003033. The work of Eduard A. Jorswieck was supported by the Federal Ministry of Education and Research of Germany in the program of “Souveraen. Digital. Vernetzt.” Joint project 6G-RIC, project identification number: 16KISK031. The work of Wei Yu was supported by the Natural Sciences and Engineering Research Council (NSERC) via a Discovery grant and via the Canada Research Chairs program. (Corresponding author: Wei Yu)  

Ya-Feng Liu and Zheyu Wu are with the State Key Laboratory of Scientific and Engineering Computing, Institute of Computational Mathematics and Scientific/Engineering Computing, Academy of Mathematics and Systems Science, Chinese Academy of Sciences, Beijing 100190, China (e-mails: yafliu, wuzy @lsec.cc.ac.cn).  

Tsung-Hui Chang is with the School of Science and Engineering, The Chinese University of Hong Kong, Shenzhen, Shenzhen, China, and Shenzhen Research Institute of Big Data (e-mail: tsunghui.chang@ieee.org).  

Mingyi Hong is with the Department of Electrical and Computer Engineering, University of Minnesota, Minneapolis, MN, 55455, USA (e-mail: mhong@umn.edu).  

Anthony Man-Cho So is with the Department of Systems Engineering and Engineering Management, The Chinese University of Hong Kong, HKSAR, China (e-mail: manchoso@se.cuhk.edu.hk).  

Eduard A. Jorswieck is with the Institute for Communication Technology, Technische Universitat Braunschweig, Germany (email: e.jorswieck@tubraunschweig.de).  

Wei Yu is with The Edward S. Rogers Sr. Department of Electrical and Computer Engineering, University of Toronto, Toronto, Ontario M5S 3G4, Canada (e-mail: weiyu $@$ ece.utoronto.ca).  

solution of mathematical optimization problems is in carefully choosing or developing suitable algorithms (or neural network architectures) that can exploit the underlying problem structure. We conclude the paper by identifying several open research challenges and outlining future research directions.  

Index Terms—Beamforming, distributed optimization, global optimization, learning-based optimization, integer optimization, nonconvex nonsmooth optimization, power control, resource allocation, scheduling, sparse optimization, wireless communications.  

# I. INTRODUCTION  

# A. Evolution of Wireless Cellular Communication Systems: From 1G to 6G  

Wireless communication technology has progressed dramatically in the last several decades. Wireless communication systems have impacted our society in profound ways and have become an integral part of our daily lives. The development of wireless communication technology is continuously driven by the requirements imposed by newly emerging use cases— such as aggregate/peak data rate, latency, cost and energy consumption, spectrum and energy efficiency, connectivity density, and many others. These ever more stringent key performance indicators (KPIs) have propelled innovations in both the physical and networking layer technologies from 1G to current 5G [1] in the past several decades, and will continue to do so into the era of future 6G wireless systems [2]–[6]. These innovations include but are not limited to: advanced massive multiple-input multiple-output (MIMO) technologies [7]–[9] such as coordinated/cooperative beamforming [10], [11], hybrid beamforming [12] and symbol-level precoding [13], new waveforms [14] ranging from time-division multiple access, code-division multiple access, orthogonal frequencydivision multiple access to nonorthogonal multiple access, novel access protocols and paradigms [15], [16] such as grant-free multiple access, new networking architectures [17], [18] such as cloud radio access network (C-RAN) and cellfree (massive) MIMO, as well as advanced signal processing algorithms such as efficient compressed sensing techniques.  

The 5G cellular system is currently being standardized and deployed worldwide. It can provide services for enhanced mobile broadband (eMBB), massive machine-type communication (mMTC), as well as ultra-reliable and low-latency communication (URLLC) for both the conventional humantype and new Internet-of-Things (IoT) users. The 6G, as the successor of 5G and to be commercialized around 2030, is now in the research spotlight. A recent milestone in the development of 6G is the Recommendation for IMT-2030 [6]. It is drafted by the International Telecommunication Union and provides guidelines on the framework and overall objectives of 6G. In particular, it defines six major usage scenarios of 6G, as shown in Fig. 1. The additional use cases of integrated sensing and communications (ISAC), integrated AI, and ubiquitous connectivity, at the intersections of eMBB, URLLC, and mMTC, are expected to be the drivers of wireless technology developments in the coming decade.  

![](images/9a0a9e00c9edb3e5a516888f250f54a3601ff660efdaaf98c4dd59475ba9241e.jpg)  
Fig. 1. Six usage scenarios and overarching goals of IMT-2030 [6].  

# B. Central Role of Mathematical Optimization in Wireless Communication System Design  

Mathematical optimization is at the core of all of the above mentioned wireless communication technologies. It is widely recognized as a powerful and indispensable modeling and solution tool in the systematic design of wireless communication systems. Indeed, many problems arising from wireless communication system design can be formulated as mathematical optimization problems and efficiently solved by leveraging suitable optimization algorithms and techniques. Mathematical programming is in fact now a common language for wireless communication researchers. Fig. 2 illustrates the progression of major (of course, not all) optimization methods that play central roles in and make strong impacts on different generations of wireless communication systems. The boundaries between these generations are of course porous.  

Convex optimization has played a vital role in 3G wireless research and has been by far the most extensively adopted paradigm for tackling wireless communication applications; see [19]–[22] and the references therein. In some sense, once the problem is formulated and recognized as a convex optimization problem, efficient solutions are often in sight, as convex optimization problems, even complex ones such as second-order cone programs (SOCPs) and semidefinite programs (SDPs), possess favorable theoretical and computational properties and can be tackled by efficient and mature solvers such as SeDuMi, SDPT3, and SDPNAL+. Indeed, many problems of practical interest in 3G wireless communication system design have been shown to admit convex formulations/reformulations or good convex approximations/relaxations [23].  

Compared to 3G, technological advancements in previous 4G, current 5G, and future 6G wireless communication systems have substantially changed the structures and nature of mathematical optimization problems behind the system design and posed serious challenges in understanding, analyzing, and solving the corresponding optimization problems. For instance, most of the problems become “non-” problems, i.e., they are nonconvex, nonsmooth, non-Lipschitz, nonseparable, and nondeterministic, and the design variables of the problems range from continuous to integer or even mixed. These new features of mathematical optimization problems urgently call for and indeed have driven the development of many new and advanced optimization theory, algorithms, and techniques such as nonconvex nonsmooth optimization, fractional programming (FP), global and integer optimization, distributed optimization, sparse optimization, and learning-based optimization. These form the subject of this paper.  

# C. Goals of the Paper  

The goals of this paper are as follows:  

Provide an overview of recent advances in mathematical optimization theory and algorithms: The first goal of this paper is to provide a survey of recent advances in mathematical optimization theory and algorithms for wireless communication system design. In particular, this paper surveys recent advances in nonconvex nonsmooth optimization, global optimization, distributed optimization, and learning-based optimization. The focus is on their theoretical properties as well as successful applications of mathematical optimization techniques in the design of wireless communication systems.  

Guide the choice and development of suitable algorithms for solving structured optimization problems: The second goal of this paper is to give some guidance on how to choose or to develop suitable algorithms for solving mathematical optimization problems based on their special structures and features. To achieve this goal, the current paper analyzes and highlights the structures and features of the underlying optimization problems and clarify how the associated algorithms utilize these unique problem structures and features.  

Promote the cross-fertilization of ideas in mathematical optimization and wireless communications: The final goal of this paper is to promote the cross-fertilization of research agendas in mathematical optimization and wireless communications. On the one hand, advanced optimization tools and techniques enable innovations in understanding, analyzing, and solving optimization problems from wireless communications; on the other hand, novel applications arising from wireless communications have driven and will continue to drive the development of new optimization theory and algorithms. As can be seen from Fig. 2, the evolution of wireless communication systems and the development of optimization methods are closely interwoven. The cross-fertilization of ideas in mathematical optimization and wireless communications have led and will continue to lead to fruitful outcomes.  

![](images/fc28314aa9ff651c259a6356c107d549e12166659c07e714d233d85b9c0664ad.jpg)  
Fig. 2. The evolution of wireless communication systems and the development of optimization methods are closely interwoven with each other. In particular, convex optimization techniques influenced the design of 3G communication system, whereas mathematical optimization problems arising from 4G–6G communication system design call for and have driven the development of new and advanced optimization theory, algorithms, and techniques such as nonconvex nonsmooth optimization, global and integer optimization, parallel and distributed optimization, and learning-based optimization.  

# D. Structure of the Paper  

The structure of this paper is as follows. We first list some mathematical optimization problems arising from wireless communication system design and discuss their special structures and challenges from the mathematical optimization perspective in Section II. Then we review recent advances in structured nonconvex optimization in Section III, which covers FP, sparse optimization, proximal gradient (PG) algorithms, penalty methods, and duality-based algorithms. Next, we review recent advances in global optimization and distributed optimization in Sections IV and V, respectively; we review learning-based optimization with and without the channel state information (CSI) in Sections VI and VII, respectively. In Section VIII, we give some open research questions and future research directions. Finally, we conclude the paper in Section IX.  

This survey differs from many others in the wireless communications literature that typically target specific technologies (e.g., ISAC [24], reconfigurable intelligent surfaces (RIS) [25], non-orthogonal multiple-access (NOMA) [14], massive connectivity [15], massive random access [16], etc.). Perhaps the most relevant survey papers to this paper are [19]–[22], which provide the state-of-the-art in convex optimization for communications and signal processing at the time. However, it has been more than a decade since those works are published, while significant innovations have taken place in wireless technology (from 3G to 5G and beyond) as well as in mathematical optimization theory and algorithms. The topics of this paper include nonconvex nonsmooth optimization, global optimization, distributed optimization, and learningbased optimization, all of which have not been covered in [19]–[22].  

Notation. We adopt the following standard notation in this paper. Lower and upper case letters in bold are used for vectors and matrices, respectively. For any given matrix A, $\mathbf { A } ^ { \dagger } , \mathbf { A } ^ { \mathsf { T } }$ , and $\mathbf { A } ^ { - 1 }$ denote the conjugate transpose, the transpose, and the inverse (if invertible) of A, respectively; $\mathbf { A } ^ { ( m , n ) }$ denotes the entry on the $m$ -th row and the $n$ -th column of $\mathbf { A }$ ; and $\mathbf { A } ^ { ( m _ { 1 } : m _ { 2 } ^ { \bullet } , n _ { 1 } : n _ { 2 } ) }$ denotes a submatrix of $\mathbf { A }$ by taking the rows from $m _ { 1 }$ to $m _ { 2 }$ and columns from $n _ { 1 }$ to $n _ { 2 }$ , respectively. For any given complex matrix $\mathbf { A }$ , we use $\operatorname { R e } ( \mathbf { A } )$ and $\operatorname { I m } ( \mathbf { A } )$ to denote its real and imaginary parts, respectively. All of the above usages also apply to vectors and scalars. $\| \mathbf { x } \| _ { 2 }$ denotes the $\ell _ { 2 }$ -norm of the vector $\mathbf { x }$ . In some cases, the index 2 is omitted. $\mathbf { A } \bullet \mathbf { B } = \operatorname { t r } ( \mathbf { A B } )$ is the trace matrix product. We use $\mathcal { C N } ( \mu , \mathbf { Q } )$ to denote the complex Gaussian distribution with mean $\pmb { \mu }$ and covariance $\mathbf { Q }$ . Finally, we use $\mathbf { I }$ to denote the identity matrix of an appropriate size, 0 to denote the all-zero matrix of an appropriate size, and i to denote the imaginary unit (which satisfies $\mathrm { i } ^ { 2 } = - 1 \mathrm { i }$ ).  

# II. OPTIMIZATION PROBLEMS IN WIRELESS COMMUNICATIONS: STRUCTURES AND CHALLENGES  

In this section, we first list some of the mathematical optimization problems arising from wireless communication system design in various use cases in Section II-A. Some of these problems are classic in communication system design but unique challenges appear due to the new communication scenarios in 5G or 6G; some of these problems are new. We then summarize the challenging features of these problems from the optimization perspective in Sections II-B and II-C. Recognizing the specific structures of the optimization problems is the first step towards their efficient solution.  

# A. Optimization Problems in Wireless Communications  

Optimization problems can be classified according to the nature of the optimization variables and the analytic properties of the objective and constraint functions, e.g., linear vs. nonlinear, unconstrained vs. constrained, smooth vs. nonsmooth, convex vs. nonconvex, stochastic vs. deterministic, integer vs. continuous, etc. Below we give important examples of optimization problems commmonly encountered in wireless communication system design according to such classification.  

1) Optimization Problems with Continuous Variables: Beamforming refers to a signal processing technique which combines elements in an antenna array to shape and focus an electromagnetic wave toward certain desired directions/locations and eliminate interferences to the others [11]. Recent advances in beamforming techniques in wireless communications lead to many interesting structured signal processing and optimization problems [10], [11]. Beamformer design, which is often coupled with power control, is an example of continuous optimization problems.  

a) Downlink Beamforming: Consider the downlink multi-user MIMO system in Fig. 3(a), where the transmitter is equipped with $M$ antennas,1 and sends the data to $K$ individual users/receivers each equipped with a single antenna. Let ${ \cal K } = \{ 1 , 2 , \dots , K \}$ denote the set of the receivers. The transmitter can direct a beam to each receiver in such a way that its own signal is enhanced and the interference to the other receivers is depressed. Let $\mathbf { h } _ { k } \in \mathbb { C } ^ { M }$ denote the channel vector between the transmitter and the $k$ -th receiver, and let $\mathbf { v } _ { k } \in \mathbb { C } ^ { M }$ denote the beamforming vector (also called the precoding vector) used for receiver $k$ by the transmitter. Assume that $s _ { k } \sim \mathcal { C N } ( 0 , 1 )$ is the signal information for user $k$ . The transmitted signal is given by $\begin{array} { r } { \mathbf { x } = \sum _ { j \in \mathcal { K } } \mathbf { v } _ { j } s _ { j } } \end{array}$ , and the received signal at the $k$ -th receiver is given by  

![](images/836716b941476c986c8d20130a85758d0eb2d6b985f4e1a8dc0b46a469e9a838.jpg)  
Fig. 3. Beamforming in wireless communication systems: (a) Downlink multi-user MIMO system considered in problems (3), (4), and (16); (b) Cooperative cellular system considered in problem (7); and (c) Cooperative cellular system with finite-capacity fronthaul links considered in problem (10).  

$$
y _ { k } = \mathbf { h } _ { k } ^ { \dagger } \mathbf { x } + z _ { k } = \mathbf { h } _ { k } ^ { \dagger } \left( \sum _ { j \in \mathcal { K } } \mathbf { v } _ { j } s _ { j } \right) + z _ { k } , \ k \in \mathcal { K } ,
$$  

where $z _ { k }$ is the additive white Gaussian noise (AWGN) with variance $\sigma _ { k } ^ { 2 }$ . Then, the signal-to-interference-and-noise-ratio (SINR) of the $k$ -th receiver can be written as  

$$
\mathrm { S I N R } _ { k } \left( \left\{ \mathbf { v } _ { k } \right\} \right) = \frac { | \mathbf { h } _ { k } ^ { \dagger } \mathbf { v } _ { k } | ^ { 2 } } { \sum _ { j \neq k } | \mathbf { h } _ { k } ^ { \dagger } \mathbf { v } _ { j } | ^ { 2 } + \sigma _ { k } ^ { 2 } } , \ k \in \mathcal { K } .
$$  

There are two well-studied formulations of the downlink beamforming design problem, which arise from different perspectives. From the perspective of the system operator, the downlink beamforming design problem is often formulated as a system utility maximization problem under a total power constraint. For example, adopting the sum rate of all users as the system utility, the downlink beamforming design problem can be formulated as  

$$
\begin{array} { r l r } { \displaystyle \operatorname* { m a x } _ { \{ \mathbf { v } _ { k } \} } } & { \displaystyle \sum _ { k \in \cal K } \log \left( 1 + \mathrm { S I N R } _ { k } ( \{ \mathbf { v } _ { k } \} ) \right) } & \\ { \mathrm { s . t . } } & { \displaystyle \sum _ { k \in \cal K } \| \mathbf { v } _ { k } \| ^ { 2 } \leq P , } \end{array}
$$  

where $P$ is the transmitter’s power budget.  

From a different perspective, the downlink beamforming design problem can also be formulated as a total power min  

imization problem under the users’ quality-of-service (QoS) constraints as follows:  

$$
\begin{array} { r l } { \displaystyle \operatorname* { m i n } _ { \{ \mathbf { v } _ { k } \} } } & { \displaystyle \sum _ { k \in \mathcal { K } } \| \mathbf { v } _ { k } \| ^ { 2 } } \\ { \mathrm { s . t . } } & { \mathrm { S I N R } _ { k } ( \{ \mathbf { v } _ { k } \} ) \geq \gamma _ { k } , \ k \in \mathcal { K } , } \end{array}
$$  

where $\gamma _ { k }$ is the SINR target of user $k$ . It is worth noting that the optimization formulation (4) is considerably more tractable from a computational point of view than (3), because the former can often be converted into a convex form [21], while no convex reformulation is known for the latter.  

$b$ ) Hybrid Beamforming: Massive MIMO, which deploys hundreds or even thousands of antennas at the BS, is a key technology for significantly improving the spectrum and energy efficiency of wireless communication systems [1], [26], [27]. However, scaling the numbers of radio-frequency (RF) chains and analog-to-digital converters (ADCs)/digitalto-analog converters (DACs) with the number of antennas would result in high hardware complexity and high power consumption. For this reason, instead of using the classical fully-digital beamforming technique, massive MIMO systems are often implemented in a hybrid analog-digital beamforming architecture [12], [28]–[30] in which a large-antenna array is driven by only a limited number of RF chains, call it $N _ { \mathrm { R F } }$ . In this case, the transmit signal, instead of being the form $\begin{array} { r } { \mathbf { x } = \sum _ { j \in \mathcal { K } } \mathbf { v } _ { j } s _ { j } } \end{array}$ , now has the following structure:  

$$
\mathbf { x } = \mathbf { V } _ { \mathrm { R F } } \sum _ { j \in \mathcal { K } } \mathbf { v } _ { j } s _ { j } ,
$$  

where $\mathbf { V } _ { \mathrm { R F } }$ is an $M \times N _ { \mathrm { R F } }$ analog beamforming matrix, typically implemented using phase shifters, i.e., its entries are complex numbers with unit magnitude, while $\{ \mathbf { v } _ { j } \}$ are digital beamformers of dimension $N _ { \mathrm { R F } }$ . The joint design of analog beamformer $\mathbf { V } _ { \mathrm { R F } }$ and digital beamformers $\{ \mathbf { v } _ { j } \}$ poses a unique challenge in optimization.  

c) RIS Beamforming: An RIS is a metasurface, consisting of many small reconfigurable passive low-cost reflecting elements that can easily introduce a controlled individual phase shift to the impinging electromagnetic wave [25]. These RIS elements can jointly provide passive beamforming that can effectively enhance the propagation condition over wireless channels by directing electromagnetic radiation toward the intended direction. Structurally, the optimization of RIS phase shifts to maximize the signal-to-noise-ratio (SNR) has a similar form as the optimization of hybrid beamformers.  

The overall downlink channel model for an RIS-assisted communication scenario has the following form. Let $\mathbf { h } _ { k } ^ { \mathrm { d } } \in$ $\mathbb { C } ^ { M }$ denote the direct channel from the BS to user $k$ , and $\mathbf { h } _ { k } ^ { \mathrm { r } } \ \in \ \mathbb { C } ^ { N _ { \mathrm { R I S } } }$ denote the channel from the RIS to user $k$ an $\mathbf { G } ~ \in ~ \mathbb { C } ^ { N _ { \mathrm { R I S } } \times M }$ denote the channel from the BS to the RIS. Let the RIS reflection coefficients be denoted by $\boldsymbol \Omega = [ e ^ { \mathrm { i } \omega _ { 1 } } , e ^ { \mathrm { i } \omega _ { 2 } } , \dots , e ^ { \mathrm { i } \omega _ { N _ { \mathrm { R I S } } } } ] ^ { \intercal }$ , where $\omega _ { i } ~ \in ~ \left( - \pi , \pi \right]$ is the phase shift of the $i$ -th element. Then, the received signal at user $k$ can be represented as  

$$
y _ { k } = ( \mathbf { h } _ { k } ^ { \mathrm { d } } + \mathbf { G } ^ { \mathsf { T } } \mathrm { d i a g } ( \pmb { \Omega } ) \mathbf { h } _ { k } ^ { \mathrm { r } } ) ^ { \dagger } \sum _ { j \in { \mathcal { K } } } \mathbf { v } _ { j } s _ { j } + n _ { k } .
$$  

It would be of interest to jointly optimize the unit-modulus RIS phase shifters matrix $\pmb { \Omega }$ and the beamformers $\{ \mathbf { v } _ { j } \}$ .  

d) Joint BS Clustering and Beamformer Design: Beamforming can also be performed across multiple BSs. Consider a cooperative cellular network consisting of a (large) set of densely deployed BSs (e.g., macro/micro/pico BSs), denoted by $B = \{ 1 , 2 , \ldots , B \}$ , that provide services to a set of users, denoted by $\mathcal { K } ~ = ~ \{ 1 , 2 , \ldots , K \}$ , as depicted in Fig. 3(b). Assume that each BS is equipped with $M$ antennas and each user is equipped with a single antenna. Let $\mathbf { h } _ { k , b } \ \in \ \mathbb { C } ^ { M }$ be the channel between BS $b$ and user $k$ , and let $\mathbf { h } _ { k } = [ \mathbf { h } _ { k , 1 } ^ { \mathsf { T } } , \mathbf { h } _ { k , 2 } ^ { \mathsf { T } } , \ldots , \mathbf { h } _ { k , B } ^ { \mathsf { T } } ] ^ { \mathsf { T } } \in \mathbb { C } ^ { M B }$ be the channel between all the BSs and user $k$ . In addition, let $\mathbf { v } _ { k , b } \in \mathbb { C } ^ { M }$ be the beamforming vector of $\mathbf { B S } \ b$ for user $k$ , and let $\mathbf { v } _ { k } = [ \mathbf { v } _ { k , 1 } ^ { \mathsf { T } } , \mathbf { v } _ { k , 2 } ^ { \mathsf { T } } , \ldots , \mathbf { v } _ { k , B } ^ { \mathsf { T } } ] ^ { \mathsf { T } } \in \mathbb { C } ^ { M B }$ . If all the $B$ BSs are allowed to share data and fully cooperate with each other, then they can be treated as a virtual BS with $M B$ antennas. In this case, the network reduces to the downlink multi-user MIMO channel in Fig. 3(a). In practice, full cooperation among all the BSs is impractical, as it would result in a large signaling overhead. A popular strategy to reduce the overhead of the above network is user-centric BS clustering [31], [32], i.e., each user is served by only a small number of BSs.  

With the above setup, the SINR of user $k$ can be expressed as (2). If we wish to pursue a sparse solution in which each user is served by a small cluster of BSs, we can consider an optimization problem similar to (3), but with an additional mixed $\ell _ { 2 } / \ell _ { 1 }$ regularization term to induce a group-sparse structure in each $\mathbf { v } _ { k }$ . Specifically, the problem is formulated in [33] as  

$$
\begin{array} { r l } { \displaystyle \underset { \{ \mathbf { v } _ { k } \} } { \operatorname* { m a x } } } & { \displaystyle \sum _ { k \in \mathcal { K } } \left( \log ( 1 + \mathrm { S I N R } _ { k } \left( \left\{ \mathbf { v } _ { k } \right\} \right) ) - \rho \sum _ { b \in \mathcal { B } } \| \mathbf { v } _ { k , b } \| _ { 2 } \right) } \\ { \mathrm { s . t . ~ } } & { \displaystyle \sum _ { k \in \mathcal { K } } \| \mathbf { v } _ { k , b } \| _ { 2 } ^ { 2 } \leq P _ { b } , \ b \in \mathcal { B } , } \end{array}
$$  

where $P _ { b }$ is the power budget of $\mathbf { B S } \ b$ and $\rho$ is the parameter that controls the group sparsity of the vectors $\{ \mathbf { v } _ { k , b } \}$ , i.e., the coordination overhead between different BSs. In particular, if $\mathbf { v } _ { k , b } = \mathbf { 0 }$ , then $\boldsymbol { \mathrm { B S } } \boldsymbol { \ b }$ does not cooperate in serving user $k$ . We want to point out that the regularizer $\sum _ { b \in B } \| \mathbf { v } _ { k , b } \| _ { 2 }$ in problem (7) is nonsmooth.  

e) Joint Downlink Beamforming and Fronthaul Compression: Consider now a more practical cooperative cellular network (e.g., C-RAN) consisting of one central processor (CP) and $M$ single-antenna relay-like BSs (called relays for short in the rest of the paper), which cooperatively serve $K$ single-antenna users, as shown in Fig. 3(c). In such a network, the users and the relays are connected by noisy wireless channels, and the relays and the CP are connected by noiseless fronthaul links of finite capacities. Let $\mathcal { M } = \{ 1 , 2 , \dots , M \}$ denote the set of relays (i.e., antennas).  

The compression model from the CP to the relays plays a central role in formulating the joint beamforming and compression problem. The ideal beamformed signal at the CP is $\textstyle \sum _ { k \in { \mathcal { K } } } \mathbf { v } _ { k } s _ { k }$ , where $\mathbf { v } _ { k } = [ v _ { k , 1 } , v _ { k , 2 } , \ldots , v _ { k , M } ] ^ { \mathsf { T } } \in \mathbb { C } ^ { M }$ is the beamforming vector for user $k$ . However, the transmitted signal from the CP to the relays needs to be first compressed (through quantization) due to the limited capacities of the fronthaul links. Let the compression error be modeled as $\mathbf { e } = [ e _ { 1 } , e _ { 2 } , \ldots , e _ { M } ] ^ { \mathsf { T } } \sim { \mathcal { C N } } ( \mathbf { 0 } , \mathbf { Q } )$ , where $\boldsymbol { e _ { m } }$ denotes the quantization noise for compressing the signal to relay $m$ , and $\mathbf { Q }$ is the covariance matrix of the quantization noise. Then, the transmitted signal (by treating all relays as a virtual transmitter) is  

$$
\mathbf { x } = \sum _ { j \in \mathcal { K } } \mathbf { v } _ { j } s _ { j } + \mathbf { e }
$$  

and the received signal at user $k$ is  

$$
y _ { k } = \mathbf { h } _ { k } ^ { \dagger } \left( \sum _ { j \in \mathcal { K } } \mathbf { v } _ { j } s _ { j } \right) + \mathbf { h } _ { k } ^ { \dagger } \mathbf { e } + z _ { k } , \ k \in \mathcal { K } .
$$  

In this case, the SINR of user $k$ is  

$$
\mathrm { S I N R } _ { k } \left( \left\{ \mathbf { v } _ { k } \right\} , \mathbf { Q } \right) = \frac { \vert \mathbf { h } _ { k } ^ { \dagger } \mathbf { v } _ { k } \vert ^ { 2 } } { \sum _ { j \neq k } \vert \mathbf { h } _ { k } ^ { \dagger } \mathbf { v } _ { j } \vert ^ { 2 } + \mathbf { h } _ { k } ^ { \dagger } \mathbf { Q } \mathbf { h } _ { k } + \sigma _ { k } ^ { 2 } } , \ k \in \mathcal { K } ,
$$  

and the compression rate of relay $m \in { \mathcal { M } }$ can be expressed below, if we adopt the information-theoretically optimal multivariate compression strategy (with the compression order from relay $M$ to relay 1) [34]:  

$$
C _ { m } \left( \left\{ \mathbf { v } _ { k } \right\} , \mathbf { Q } \right) = \log _ { 2 } \left( \frac { \sum _ { k \in K } \vert v _ { k , m } \vert ^ { 2 } + \mathbf { Q } ^ { ( m , m ) } } { \mathbf { Q } ^ { ( m : M , m : M ) } / \mathbf { Q } ^ { ( m + 1 : M , m + 1 : M ) } } \right) ,
$$  

where $\mathbf { Q } ^ { ( m : M , m : M ) } / \mathbf { Q } ^ { ( m + 1 : M , m + 1 : M ) }$ $\textbf { Q } ^ { ( m , m ) } \mathrm { ~ - ~ }$ $\mathbf { Q } ^ { ( m , m + 1 : M ) } ( \mathbf { Q } ^ { ( m + 1 : M , \overbar { m } + 1 : M ) } ) ^ { - 1 } \mathbf { Q } ^ { ( m + 1 : M , m ) }$ . The QoSconstrained joint beamforming and compression design problem can then be formulated as  

$$
\begin{array} { l } { \displaystyle \operatorname* { m i n } _ { \left\{ \mathbf { v } _ { k } \right\} , \mathbf { Q } \geq 0 } \sum _ { k \in { \mathcal { K } } } \| \mathbf { v } _ { k } \| ^ { 2 } + \displaystyle \mathrm { t r } ( \mathbf { Q } ) } \\ { \mathrm { s . t . } \qquad \mathrm { S I N R } _ { k } \left( \left\{ \mathbf { v } _ { k } \right\} , \mathbf { Q } \right) \geq \gamma _ { k } , ~ k \in { \mathcal { K } } , } \\ { \displaystyle C _ { m } \left( \left\{ \mathbf { v } _ { k } \right\} , \mathbf { Q } \right) \leq C _ { m } , ~ m \in { \mathcal { M } } , } \end{array}
$$  

where $C _ { m }$ is the fronthaul capacity of relay $m$ .  

2) Optimization Problems with Integer Variables: When optimization is performed at the level of constellation symbols, which comes from a discrete set, it gives rise to a discrete optimization problem. In the following, we describe two optimization problems with integer/discrete variables in the context of massive MIMO.  

a) MIMO Detection: MIMO detection is an example of a discrete optimization problem in digital communications. Although MIMO detection has been extensively studied for more than two decades, it has gained renewed interest in the context of massive MIMO [35], [36]. Consider a (massive) MIMO channel model in the uplink:  

$$
\mathbf { y } = \mathbf { H } \mathbf { s } + \mathbf { z } ,
$$  

where $\mathbf { y } \in \mathbb { C } ^ { M }$ is the vector of received signals, $\mathbf { H } \in \mathbb { C } ^ { M \times K }$ is an $M \times K$ complex channel matrix (for $K$ inputs and $M$ outputs with $M \geq K )$ ), $\mathbf { s } \in \mathcal { S } ^ { K }$ is the vector of transmitted symbols by the user terminals, and $\mathbf { z } \in \mathbb { C } ^ { M }$ is an AWGN with zero mean. We consider the cases where $s$ is the $( 4 u ^ { 2 } )$ -QAM constellation  

$$
\mathcal { Q } _ { u } = \{ z \in \mathbb { C } \mid \mathrm { R e } ( z ) , \mathrm { I m } ( z ) = \pm 1 , \pm 3 , \ldots , \pm ( 2 u - 1 ) \}
$$  

or the $L$ -PSK constellation $ { \boldsymbol { S } } _ { L }$  

$$
\mathcal S _ { L } = \{ \exp ( 2 \pi \mathrm { i } ( \ell - 1 ) / L ) \mid \ell = 1 , 2 , \ldots , L \} .
$$  

The MIMO detection problem is to recover the vector of transmitted symbols s from the vector of received signals $\mathbf { y }$ based on the knowledge of the channel matrix $\mathbf { H }$ . The standard mathematical formulation of the MIMO detection problem is  

$$
\begin{array} { r l } { \underset { \mathbf { x } \in \mathbb { C } ^ { K } } { \operatorname* { m i n } } } & { \left\| \mathbf { H } \mathbf { x } - \mathbf { y } \right\| _ { 2 } ^ { 2 } } \\ { \mathrm { s . t . } } & { \mathbf { x } \in \mathcal { S } ^ { K } . } \end{array}
$$  

One of the new challenges of solving the above problem in the massive MIMO context is the large problem size, which prevents the use of many algorithms (e.g., semidefinite programming relaxation (SDR)-based algorithms [37], [38]) that may be efficient when the problem size is small to medium.  

b) Symbol-Level Precoding: In the downlink, when the CSI is available at the transmitter, it is also possible to formulate an optimization problem of designing the transmitted signal, so that the desired received signal aligns with the constellation point. Consider a downlink scenario and let $\mathbf { s } \in \mathbb { C } ^ { K }$ be a set of desired constellation points (corresponding to multiple users), the BS may try to construct the downlink transmit signal $\mathbf { x }$ so that after going through the channel $\mathbf { H }$ , the received signal would align with the desired s as closely as possible. This technique is called symbol-level precoding [13], because a different $\mathbf { x }$ is designed for each symbol s— in contrast to the beamforming technique where the same beamformer is used for the entire channel coherence time. This formulation is appealing in the massive MIMO context. When the BS is equipped with many antennas, it is possible to restrict the transmit signal to be discrete, e.g., $\chi = \{ \pm 1 \pm \mathrm { i } \}$ , which simplifies implementation, and still provides excellent performance. In this case, the problem formulation becomes [39]  

$$
\begin{array} { r l } { \underset { \mathbf { x } \in \mathbb { C } ^ { M } } { \operatorname* { m i n } } } & { \left\| \mathbf { H } \mathbf { x } - \mathbf { s } \right\| _ { 2 } ^ { 2 } } \\ { \mathrm { s . t . } } & { \mathbf { x } \in \mathcal { X } ^ { M } , } \end{array}
$$  

which is a discrete optimization problem. We mention here that it is possible to consider also the joint optimization of constellation range [40] in this problem formulation.  

3) Optimization Problems with Mixed Variables: In power control and beamforming design problems, when admission control, user scheduling, and/or BS-user association are involved, the corresponding optimization problems would have mixed variables, i.e., both continuous and integer (in particular, binary on-and-off) variables. Let us consider two examples.  

a) Joint Admission Control and Multicast Beamforming: Consider the same downlink multi-user MIMO system in Fig. 3(a) as in problems (3) and (4). Different from problems (3) and (4), here we assume that the intended information from the transmitter to all of the $K$ users is the same, i.e., the transmitter multicasts the common information to $K$ users simultaneously [41]. Let w be the multicast beamforming vector used by the transmitter. In this case, the SNR of the $k$ -th user is given by  

$$
\mathrm { S N R } _ { k } ( \mathbf { w } ) = \frac { \vert \mathbf { h } _ { k } ^ { \dagger } \mathbf { w } \vert ^ { 2 } } { \sigma _ { k } ^ { 2 } } .
$$  

If user $k$ is admitted to be served by the transmitter, then its QoS constraint $\mathrm { S N R } _ { k } ( \mathbf { w } ) \geq \gamma _ { k }$ should be satisfied, where $\gamma _ { k }$ is the given SNR threshold of user $k$ . When the transmitter cannot simultaneously support all users (because, e.g., the number of users is too large), admission control [42], [43] is needed to select a subset of users to serve at their SNR targets.  

One possible problem formulation for admission control is to maximize the number of admitted users under the power budget constraint [44], [45], and another possible formulation is to select a subset of users with a given cardinality to minimize the total transmit power [46], [47]. In particular, given $1 \le \hat { K } \le K$ , the joint admission control and multicast beamforming (JABF) design problem of selecting a subset of $\hat { K }$ users with the minimum total transmit power is formulated in [47] as  

$$
\begin{array} { r l } & { \displaystyle \operatorname* { m i n } _ { \mathbf { w } , \beta } ~ \| \mathbf { w } \| ^ { 2 } } \\ & { \mathrm { s . t . } ~ | \tilde { \mathbf { h } } _ { k } ^ { \dagger } \mathbf { w } | ^ { 2 } \geq \beta _ { k } , ~ k \in \mathcal { K } , } \\ & { ~ \displaystyle ~ \sum _ { k \in \mathcal { K } } \beta _ { k } \geq \hat { K } , ~ \beta _ { k } \in \{ 0 , 1 \} , ~ k \in \mathcal { K } , } \end{array}
$$  

where $\beta ~ = ~ [ \beta _ { 1 } , \beta _ { 2 } , \ldots , \beta _ { K } ] ^ { \mathsf { T } }$ is a binary vector with $\beta _ { k }$ modeling whether user $k$ is selected, w is a continuous multicast beamforming vector, and $\tilde { \mathbf { h } } _ { k }$ is redefined as ${ \bf h } _ { k } / ( \sigma _ { k } \sqrt { \gamma _ { k } } )$ for ease of notation. This is a mixed continuous/discrete optimization problem.  

$b$ ) Joint Uplink Scheduling and Power Control: Consider the uplink of a wireless cellular network, where a singleantenna BS is associated with several single-antenna users in each cell, and the users are scheduled for uplink transmission within each cell. Let $\boldsymbol { B }$ denote the set of cells/BSs in the network, $\textstyle \mathcal { K } _ { i }$ denote the set of users who are associated with BS i, $\kappa _ { i } \in \mathcal { K } _ { i }$ denote the user to be scheduled for transmission at cell $i$ , and $p _ { k }$ denote the transmit power of the scheduled user $k$ . Assume that $s _ { \kappa _ { i } } \sim \mathcal { C N } ( 0 , 1 )$ is the transmitted signal of user $\kappa _ { i }$ . Then, the received signal at $\boldsymbol { \mathrm { B S } } \ i$ is  

$$
y _ { i } = \sum _ { j \in \boldsymbol { B } } p _ { \kappa _ { j } } h _ { i , \kappa _ { j } } s _ { \kappa _ { j } } + z _ { i } ,
$$  

where $h _ { i , \kappa _ { j } }$ is the uplink channel coefficient from user $\kappa _ { j }$ to $_ { \mathrm { ~ B S ~ } i }$ and $z _ { i } \sim \mathcal { C N } ( 0 , \sigma _ { i } ^ { 2 } )$ is the AWGN. Given a set of weights $\{ w _ { k } \}$ that reflects the user priorities and adopting the weighted sum rate as the system performance metric, the joint uplink scheduling and power control problem is formulated in [48] as  

$$
\begin{array} { r l } { \displaystyle \operatorname* { m a x } _ { \kappa , \mathbf { p } } } & { \displaystyle \sum _ { i \in \mathcal { B } } w _ { \kappa _ { i } } \log \left( 1 + \frac { | h _ { i , \kappa _ { i } } | ^ { 2 } p _ { \kappa _ { i } } } { \sum _ { j \neq i } | h _ { i , \kappa _ { j } } | ^ { 2 } p _ { \kappa _ { j } } + \sigma _ { i } ^ { 2 } } \right) } \\ { \mathrm { s . t . ~ } } & { 0 \leq p _ { k } \leq P _ { k } , \ k \in \cup _ { i \in \mathcal { B } } \mathcal { K } _ { i } , } \\ & { \quad \quad \quad \kappa _ { i } \in \mathcal { K } _ { i } \cup \{ \varnothing \} , \ i \in \mathcal { B } , } \end{array}
$$  

where $\kappa _ { i } = \varnothing$ means that no user in cell $\mathbf { \chi } _ { i }$ is scheduled for transmission. The discrete scheduling variables $\left\{ \kappa _ { i } \right\}$ and the continuous power control variables $\left\{ p _ { k } \right\}$ are coupled in problem (17), making it a mixed continuous/discrete optimization problem.  

4) Remarks: In the above, we have only listed a few of wireless communication scenarios that give rise to interesting optimization formulations. As device technology, network architecture, deployment use cases, and new application scenarios for 5G and 6G continue to evolve, novel optimization formulations will continue to emerge. For example, the incorporation of RIS in the wireless environment not only makes the optimization problem high-dimensional but also poses challenges in channel modeling and estimation, which motivate learning-based optimization without explicit channel estimation. As another example, mMTC service with sporadic device activities gives rise to sparse optimization problems. For eMBB services, large-scale C-RAN or cell-free networks give rise to novel formulations of the joint optimization of fronthaul compression and data transmission. Moreover, the incorporation of artificial intelligence (AI) into wireless networks (e.g., federated learning) gives rise to interesting distributed optimization problem settings. Finally, deep learning may provide an alternative path to the traditional optimization paradigm. These novel problem settings and their associated solution techniques will be the main focus of the rest of this paper.  

# B. Challenges from the Optimization Perspective  

The innovations in the wireless communication system architecture (from 3G to 5G and beyond) in the last two decades have substantially changed the structures and the nature of optimization problems arising from system design. This makes these problems more challenging to analyze and to solve. We briefly summarize these challenges below.  

Large dimensionality and high nonlinearity. The dimension of optimization problems becomes much larger, and the objective and constraint functions become highly nonlinear. The larger dimensionality comes from the larger number of system parameters and variables, such as the large number of antennas deployed at the BS in the massive MIMO system and the large number of users [7], the large number of devices in the massive machine-type communication network with a potentially sparsity structure [15], the large number of subcarriers, and the large number of passive reflection elements in the RIS-aided communication system [25], [49]. Nonlinearity may be caused by the coupling of design variables and complicated expressions of the objective function and constraints with respect to the variables. For instance, reflective beamforming vectors and transmit beamforming vectors are multiplicatively coupled and further composed with fractional and logarithmic functions in RIS-aided communication systems [25], [49]; the performance metric of target estimation (e.g., the Crame´r-Rao bound of radar sensing [50]) is usually a highly nonlinear function of the design variables in ISAC systems [24].  

Lack of favorable properties. Many of the aforementioned optimization problems become “non-” problems, i.e., they are either nonconvex, nonsmooth, non-Lipschitz, nonseparable, or nondeterministic. There are two reasons for the frequent occurrences of these new types of optimization problems. First, some nonconvex nonsmooth non-Lipschitz regularization terms are often needed in optimization problems to promote certain desired structures in their solutions (e.g., sparsity, low-rankness, and fairness) [31]–[33], especially in cooperative communication networks (see, e.g., problem (7)). Second, nonconvex and nonsmooth terms are helpful in transforming certain structured optimization problems with discrete variables into “easy” (globally/locally) equivalent problems with continuous variables, which facilitates algorithm design. The lack of favorable properties (see, e.g., [51] for a discussion) necessitates a judicious treatment of both the theoretical and algorithmic aspects of optimization.  

Mixed-integer variables. In various system design scenarios, both continuous and discrete variables can appear in the associated optimization problems. Some examples include the admission control and user scheduling problems (16) and (17). The integer variables often make the optimization problems significantly more difficult to solve than their continuous counterparts. For problems with only integer variables, the “brute force” enumeration (of all feasible points) is guaranteed to find a global solution. However, this approach is not feasible for solving largescale problems, as its complexity grows exponentially with the number of variables. Therefore, special attention and advanced optimization theory and techniques are needed to tackle large-scale problems with (mixed) integer variables.  

# C. Structural Properties of Optimization Problems  

The unique difficulties and structural features of optimization problems arising from wireless system design have driven the development of many new and advanced optimization theory and algorithms. The basic features include analytic properties of the functions in its objective and constraints (e.g., convexity, smoothness, and monotonicity), type of its design variables (e.g., continuous, integer, or both), and the degree of coupling of its design variables (e.g., the variables are fully separable or coupled in a structured manner). More advanced features include (but are not limited to) hidden convexity2 (of a seemingly nonconvex problem) and zero duality gap, computational complexity status, easy projection property (onto its feasible set), tight global bounds (of its objective function), and “simple” structured conditions that its solution(s) should satisfy.  

Recognizing the special structures of optimization problems is of paramount importance, as it allows us to select suitable tools for analyzing them and algorithms for tackling them. In the remaining part of this subsection, we use some problems listed in Section II-A to elucidate the above discussion.  

Consider the (massive) MIMO detection problem (14). Although it has integer (discrete) variables, different variables are fully decoupled in the constraint and thus the feasible set enjoys an easy-projection property. Moreover, the objective function of problem (14) is quadratic and hence has a Lipschitz-continuous gradient. These features suggest that problem (14) is amenable to the gradient projection (GP) algorithm. We introduce GP and the more general PG algorithms in Section III-C.  

As another example, consider the RIS and hybrid beamforming problems (5) and (6). To account for the phase-only constraint (which is quadratic), it is possible to use SDR [53], [54], but its complexity is not scalable. Alternatively, GP can be used. A straightforward GP optimization for the analog beamformer would involve taking a gradient step and then projecting the result onto the unit-modulus domain by retaining only its phases. However, a better approach is to recognize that the unit-modulus constraints form a Riemannian manifold [55], so instead of taking a Euclidean gradient followed by projection, a faster algorithm can be devised by first projecting the gradient vector onto the tangent space of the complex circle manifold. To further speed up convergence, the conjugate gradient version of this idea may be used. This gives the so-called Riemannian conjugate gradient method; see [55] and a specific application of this algorithm in [56]. This is an example of how taking advantage of the problem structure can enable faster convergence of the algorithm.  

Hidden convexity is an important feature to recognize (if it exists). Consider the beamforming design problems (4) and (10). While the objective functions are convex (and very simple) and design variables are continuous, the constraints are complicated and the number of constraints (related to the numbers of users and relays in the considered system) is large. By examining the constraints in problems (4) and (10) more carefully, both of them turn out to admit convex reformulations (assuming that the constraints are feasible), and we can show that the duality gap between the primal and dual problems is zero. These features suggest that duality-based algorithms are suitable for solving problems (4) and (10). We introduce duality-based algorithms in Section III-E.  

Before leaving this subsection, let us comment on the computational complexity of optimization problems that arise in wireless communication system design. Determining the complexity class of an optimization problem (e.g., (strongly) NP-hard or polynomial-time solvable) provides valuable information about what lines of approaches are more promising. Once a problem is shown to be “hard”, the search for an efficient exact algorithm should often be accorded lower priority. Instead, less ambitious goals, such as looking for algorithms that can solve various special cases of the general problem efficiently; looking for algorithms that, though not guaranteed to have a polynomial-time complexity, run quickly most of the time; or relaxing the problem and looking for an algorithm that can find an approximate solution efficiently, should be considered. Compared with convexity and nonconvexity, which can provide useful intuition on the easiness/hardness of an optimization problem, computational complexity theory is a more robust and reliable tool for characterizing the tractability/intractability of an optimization problem. Back to the optimization problems discussed in this section, although problems (4) and (10) and some special cases of other problems admit simple closed-form solutions or are polynomial-time solvable [42], [43], [57]–[65], a small variant of these problems (e.g., (3)) can be (strongly) NP-hard [41], [66]–[75], which means that there does not exist a (pseudo-) polynomial-time algorithm that can solve the corresponding problem to global optimality unless $\mathcal { P } = \mathcal { N P }$ . Understanding this complexity analysis is essential for algorithm design.  

# III. STRUCTURED NONCONVEX OPTIMIZATION  

Although the optimization problems presented in the previous section are nonconvex in general, in this section, we discuss how their special structures can be exploited to design tailored algorithms that can find high-quality locally optimal or suboptimal solutions of those problems in an efficient manner. We should point out that these algorithms do not involve global optimization techniques and are generally not guaranteed to find a globally optimal solution. We survey advanced global optimization algorithms and techniques in Section IV.  

This section is organized as follows. We first review two useful transformations for tackling FPs in Section III-A. These transformations can then be used to efficiently solve the sumrate maximization problem (3) and the corresponding scheduling problem (17). Second, we review sparse optimization theory and techniques in Section III-B. Sparse optimization is useful for solving and analyzing optimization problems whose solutions admit a sparse structure, e.g., sparse channel estimation and sparse device activity detection problems. Third, we review the PG algorithm in Section III-C, which is suitable for solving (not necessarily convex) optimization problems with a “simple” nonsmooth term in their objectives or a “simple” constraint. These include the MIMO detection problem (14) and the BS clustering and beamforming design problem (7). Fourth, we review the penalty method in Section III-D. Such a method is generally suitable for tackling optimization problems in which the constraint can be decomposed into a simple convex constraint plus a simple penalty function. We demonstrate how the penalty method can be used to tackle the MIMO detection problem (14). Finally, we review the (Lagrangian) duality-based algorithm in Section III-E, which can be used to solve (hidden) convex problems with many complicated constraints, such as the QoS-constrained joint beamforming and compression problem (10).  

# A. Fractional Programming  

FP refers to a specific class of optimization problems that involve ratio terms. It plays a vital role in the design and optimization of wireless communication systems due to the ubiquitous fractional structure of various performance metrics related to communication links. Notably, the SINR (e.g., in (2)), which is naturally defined by a fractional function, is an essential quantity for the performance evaluation of wireless communication systems. In addition, energy efficiency (EE), defined as the ratio between the amount of transmitted data and consumed energy, is an important performance metric in the design of wireless communication systems [76], [77].  

Early works on FP mainly focus on single-ratio problems, particularly concave-convex single-ratio maximization problems, where the objective function contains a single ratio term with a nonnegative concave numerator and a positive convex denominator. To deal with single-ratio FP problems, two classic techniques are the Charnes-Copper transform and the Dinkelbach’s transform. Both methods ensure the convergence to the global optimum of concave-convex single-ratio FP problems and have been extensively applied to solve EE maximization problems for wireless communication systems [76]. Though working well for single-ratio FP, the aforementioned techniques cannot be easily generalized to multiple-ratio cases, which are more prevalent in system-level communication network design (as the overall system performance typically involves multiple ratio terms). A prominent recent advance in FP is [48], [78], where new transforms for solving multipleratio FP problems are developed. In this subsection, we review the transforms and methods proposed in [48], [78] and their applications in solving two important problems arising from wireless communication system design.  

1) Two FP Transforms: We now review the two FP transforms proposed in [48], [78].  

a) Quadratic Transform: The first transform is designed for the sum-of-ratio FP problem  

$$
\operatorname* { m a x } _ { \mathbf { x } \in \mathcal { X } } \ \sum _ { i = 1 } ^ { I } \frac { A _ { i } ( \mathbf { x } ) } { B _ { i } ( \mathbf { x } ) } ,
$$  

where $A _ { i } ( \cdot ) \geq 0$ and $B _ { i } ( \cdot ) > 0$ on $\chi$ for all $i \in \{ 1 , 2 , \ldots , I \}$ . The quadratic transform [78] of the multi-ratio FP problem (18) is defined as  

$$
\operatorname* { m a x } _ { \mathbf { x } \in \mathcal { X } , \mathbf { y } \in \mathbb { R } } \ \sum _ { i = 1 } ^ { I } \left( 2 y _ { i } \sqrt { A _ { i } ( \mathbf { x } ) } - y _ { i } ^ { 2 } B _ { i } ( \mathbf { x } ) \right) .
$$  

It has been shown in [78] that the problem (19) is equivalent to the sum-of-ratio FP problem (18), which can be easily seen by substituting the optimal solution  

$$
y _ { i } ^ { * } = \frac { \sqrt { A _ { i } ( \mathbf { x } ) } } { B _ { i } ( \mathbf { x } ) } , \ i = 1 , 2 , . . . , I
$$  

into the objective function of problem (19). The quadratic transform decouples the numerator and the denominator of each ratio term and is of particular interest when the transformed problem (19) is convex in $\mathbf { x }$ for a given $\mathbf { y }$ (e.g., each $A _ { i } ( \cdot )$ is concave and so is $\sqrt { A _ { i } ( \cdot ) }$ , each $B _ { i } ( \cdot )$ is convex, and $\mathcal { X }$ is convex), in which case alternating optimization (AO)  

over $\mathbf { x }$ and $\mathbf { y }$ can be efficiently performed and is guaranteed to converge to a stationary point of problems (18) and (19). It is worth noting that the quadratic transform can be extended to tackle more general sum-of-functions-of-ratio problems (where the functions are required to be nondecreasing) [78, Corollary 2] and to the matrix case [79, Theorem 1].  

$b$ ) Lagrangian Dual Transform: This second transform is tailored for the sum-rate maximization problem. Specifically, consider the general sum-of-logarithm maximization problem  

$$
\operatorname* { m a x } _ { \mathbf { x } \in \mathcal { X } } \ \sum _ { i = 1 } ^ { I } \log \left( 1 + \frac { A _ { i } ( \mathbf { x } ) } { B _ { i } ( \mathbf { x } ) } \right) ,
$$  

where $A _ { i } ( \cdot ) ~ \geq ~ 0$ , $B _ { i } ( \cdot ) ~ > ~ 0$ on $\mathcal { X }$ , and $A _ { i } ( \cdot ) / B _ { i } ( \cdot )$ can be physically interpreted as an SINR term (which includes the SINRs in problems (3) and (17) as special cases). The Lagrangian dual transform of problem (21) is defined as [48]  

$$
\operatorname* { m a x } _ { \mathbf { x } \in \mathcal { X } , \gamma } \ \sum _ { i = 1 } ^ { I } \left( \log \left( 1 + \gamma _ { i } \right) - \gamma _ { i } \right) + \sum _ { i = 1 } ^ { I } \frac { ( 1 + \gamma _ { i } ) A _ { i } ( \mathbf { x } ) } { A _ { i } ( \mathbf { x } ) + B _ { i } ( \mathbf { x } ) } ,
$$  

where $\gamma ~ = ~ [ \gamma _ { 1 } , \gamma _ { 2 } , \ldots , \gamma _ { I } ] ^ { \mathsf { T } } ~ \in ~ \mathbb { R } ^ { I }$ . The Lagrangian dual transform in (22) is equivalent to problem (21), which can be seen by substituting the optimal solution  

$$
\gamma _ { i } ^ { * } = \frac { A _ { i } ( \mathbf { x } ) } { B _ { i } ( \mathbf { x } ) } , \ i = 1 , 2 , . . . , I
$$  

into the objective function of problem (22). Compared with problem (21), its Lagrangian dual transform (22) has the advantage of moving the SINRs outside of the logarithmic functions, which allows for a subsequent quadratic transform.  

2) Application Examples: Now, let us apply the quadratic transform and the Lagrangian dual transform to solve two important problems in wireless communications.  

a) Downlink Beamforming for Sum-Rate Maximization: Consider first the sum-rate downlink beamforming design problem (3). An efficient FP-based approach for solving the sum-rate maximization problem (3) is to first reformulate the sum-of-logarithm form into a sum-of-ratio form using the Lagrangian dual transform and then apply the quadratic transform to the latter. More specifically, by applying the Lagrangian dual transform to problem (3), we obtain  

$$
\begin{array} { r l r } { \displaystyle \operatorname* { m a x } _ { \{ { \mathbf { v } } _ { k } \} , \gamma } } & { \displaystyle \sum _ { k \in K } \left( \log ( 1 + \gamma _ { k } ) - \gamma _ { k } \right) + \sum _ { k \in K } \frac { ( 1 + \gamma _ { k } ) | \mathbf { h } _ { k } ^ { \dagger } \mathbf { v } _ { k } | ^ { 2 } } { \sum _ { j \in K } | \mathbf { h } _ { k } ^ { \dagger } \mathbf { v } _ { j } | ^ { 2 } + \sigma _ { k } ^ { 2 } } } & \\ { \mathrm { s . t . ~ } } & { \displaystyle \sum _ { k \in K } \| \mathbf { v } _ { k } \| ^ { 2 } \leq P . } & \end{array}
$$  

When $\left\{ \mathbf { v } _ { k } \right\}$ is fixed, the optimal $\gamma$ of problem (24) has a closed-form solution, which takes the form in (23). To update $\left\{ \mathbf { v } _ { k } \right\}$ for a fixed $\gamma$ , the quadratic transform can be applied to the sum-of-ratio term in (24). In particular, by treating $( 1 +$ $\gamma _ { k } ) | \mathbf { h } _ { k } ^ { \dagger } \mathbf { v } _ { k } | ^ { 2 }$ as the numerator and $\begin{array} { r } { \dot { \sum } _ { j \in \mathcal { K } } | \mathbf { h } _ { k } ^ { \dagger } \mathbf { v } _ { j } | ^ { 2 } + \sigma _ { k } ^ { 2 } } \end{array}$ as the denominator and applying the quadratic transform, we obtain the problem  

$$
\begin{array} { c } { { \displaystyle \operatorname* { m a x } _ { \{ { \bf v } _ { k } \} , { \bf y } } \quad \displaystyle \sum _ { k \in { \mathcal K } } \left( 2 \sqrt { 1 + \gamma _ { k } } \mathrm { R e } ( y _ { k } ^ { \dagger } { \bf h } _ { k } ^ { \dagger } { \bf v } _ { k } ) \right. } } \\ { { \displaystyle \qquad \left. - | y _ { k } | ^ { 2 } \left( \displaystyle \sum _ { j \in { \mathcal K } } | { \bf h } _ { k } ^ { \dagger } { \bf v } _ { j } | ^ { 2 } + \sigma _ { k } ^ { 2 } \right) \right) } } \\ { { \mathrm { s . t . } \quad \displaystyle \sum _ { k \in { \mathcal K } } \| { \bf v } _ { k } \| ^ { 2 } \leq P , } } \end{array}
$$  

where a constant term depending on $\gamma$ is omitted. With $\left\{ \mathbf { v } _ { k } \right\}$ fixed, the above problem has a closed-form solution in $\mathbf { y }$ , which takes the form in (20) with $A _ { k } \ : = \ : ( 1 + \gamma _ { k } ) \vert \mathbf { h } _ { k } ^ { \dagger } \mathbf { v } _ { k } \vert ^ { 2 }$ and $\begin{array} { r } { B _ { k } = \sum _ { j \in \mathcal { K } } | \mathbf { h } _ { k } ^ { \dagger } \mathbf { v } _ { j } | ^ { 2 } + \sigma _ { k } ^ { 2 } } \end{array}$ . When $\mathbf { y }$ is fixed, the above problem has the following solution in $\left\{ \mathbf { v } _ { k } \right\}$ :  

$$
\mathbf { v } _ { k } = y _ { k } \sqrt { 1 + \gamma _ { k } } \left( \sum _ { j \in K } | y _ { j } | ^ { 2 } \mathbf { h } _ { j } \mathbf { h } _ { j } ^ { \dagger } + \lambda \mathbf { I } \right) ^ { - 1 } \mathbf { h } _ { k } , \ k \in \mathcal { K } ,
$$  

where $\lambda \geq 0$ is the optimal Lagrange multiplier associated with the total power constraint that can be efficiently determined by a bisection search. By updating $\boldsymbol { \gamma } , \boldsymbol { \textbf { y } }$ , and $\{ \mathbf { v } _ { k } \}$ in an alternating fashion as described above, we obtain an efficient FP algorithm, which is guaranteed to converge to a stationary point of the sum-rate maximization problem (24) [48, Appendix A]. We wish to remark here that, in addition to the downlink MIMO channel, the above FP techniques can be applied to solve sum-rate maximization problems in much more general channels (e.g., the MIMO interfering broadcast channel).  

It is interesting to note that the above FP algorithm is equivalent to the well-known weighted minimum-mean-squareerror (WMMSE) algorithm [80], [81]. In fact, the WMMSE algorithm, which is originally derived based on a signal minimum mean-square-error analysis, can also be derived by applying the quadratic and Lagrangian dual transforms in a similar way as the above FP algorithm. The only difference is that, when applying the quadratic transform to problem (24), the WMMSE algorithm treats $| \mathbf h _ { k } ^ { \dagger } \mathbf v _ { k } | ^ { 2 }$ as the numerator and $( 1 + \gamma _ { k } )$ as a scaling factor in front of the fractional term, which leads to a problem different from (25) and hence different update rules for $\mathbf { y }$ and $\mathbf { v } _ { k }$ ; see the details in [48, Section VI]. While the two algorithms are fundamentally equivalent for the sum-rate maximization problem (3), their different treatments of the term $( 1 + \gamma _ { k } ) | \mathbf { h } _ { k } ^ { \dagger } \mathbf { v } _ { k } | ^ { 2 }$ lead to different algorithms for solving sum-rate maximization problems in more complicated scenarios. The above FP algorithm is thus preferable from a practical perspective, because it often yields a problem amenable to distributed optimization, as demonstrated below.  

b) Joint Uplink Scheduling and Power Control for SumRate Maximization: We now briefly review the application of FP techniques to solving the joint uplink scheduling and power control problem (17). The main idea is to reformulate the problem appropriately with the aid of the two FP transforms, so that the resulting problem is amenable to AO and is in a distributed form that allows for per-cell scheduling and power update. To be specific, by first applying the Lagrangian dual transform to problem (17), we get  

$$
\begin{array} { r l } { \underset { \kappa , \mathbf { p } , \gamma } { \operatorname* { m a x } } } & { \displaystyle \sum _ { i \in \mathcal { B } } w _ { \kappa _ { i } } \left( \log ( 1 + \gamma _ { i } ) - \gamma _ { i } \right) } \\ & { \quad \quad \quad + \displaystyle \sum _ { i \in \mathcal { B } } \frac { w _ { \kappa _ { i } } ( 1 + \gamma _ { i } ) | h _ { i , \kappa _ { i } } | ^ { 2 } p _ { \kappa _ { i } } } { \sum _ { j \in \mathcal { B } } | h _ { i , \kappa _ { j } } | ^ { 2 } p _ { \kappa _ { j } } + \sigma _ { i } ^ { 2 } } } \\ { \mathrm { s . t . } } & { 0 \leq p _ { k } \leq P , \ k \in \cup _ { i \in \mathcal { B } } \ \mathcal { K } _ { i } , } \\ & { \kappa _ { i } \in \mathcal { K } _ { i } \cup \{ \varnothing \} , \ i \in \mathcal { B } . } \end{array}
$$  

When $( \kappa , \mathbf { p } )$ are fixed, the optimal $\gamma$ of problem (26) has a closed-form solution that takes the form in (23). To optimize $( \kappa , \mathbf { p } )$ in (26) with a fixed $\gamma$ , we further apply the quadratic transform to the sum-of-ratio term in (26), which, after some simple manipulations, yields the following equivalent problem:  

$$
\begin{array} { r l } { \displaystyle \underset { \kappa , \mathbf { p } , \mathbf { y } } { \operatorname* { m a x } } } & { \displaystyle \sum _ { i \in B } \left( w _ { \kappa _ { i } } ( \log ( 1 + \gamma _ { i } ) - \gamma _ { i } ) \right. } \\ & { \left. \phantom { \displaystyle \sum _ { \alpha \in B } \sum _ { i } \Biggl ( w _ { \kappa _ { i } } ( 1 + \gamma _ { i } ) \lvert h _ { i , \kappa _ { i } } \rvert ^ { 2 } p _ { \kappa _ { i } } } \right. } \\ & { \left. \phantom { \displaystyle \sum _ { \alpha \in B } \sum _ { i } \sigma _ { i } ^ { 2 } } - \sum _ { j \in B } y _ { j } ^ { 2 } \lvert h _ { j , \kappa _ { i } } \rvert ^ { 2 } p _ { \kappa _ { i } } \right) } \\ { \mathrm { s . t . } } & { 0 \leq p _ { k } \leq P , k \in \cup _ { i \in B } K _ { i } , } \\ & { \kappa _ { i } \in K _ { i } \cup \{ \boldsymbol { \theta } \} , i \in B . } \end{array}
$$  

A favorable structure of problem (27) is that the scheduling and power variables of each cell, i.e., $( \kappa _ { i } , p _ { \kappa _ { i } } )$ , are decoupled when $\mathbf { y }$ is fixed, thus allowing the scheduling and power optimization to be performed independently within each cell. More details on the solution of the scheduling and power control subproblem (27) and the AO algorithm for solving the joint uplink scheduling and power control problem (17) can be found in [48].  

3) Remarks: We conclude this subsection with further remarks on the quadratic and Lagrangian dual transforms from both optimization and application perspectives. From the optimization perspective, the principle behind the two transforms is to lift complicated low-dimensional problems to equivalent high-dimensional ones where optimization is easier to do by appropriately introducing some auxiliary variables. The key is to ensure that the lifted high-dimensional problem is easy to solve with respect to each variable block (e.g., being convex or admitting closed-form solutions) so that AO techniques such as the block coordinate descent (BCD) algorithm can be applied. AO algorithms can efficiently find a stationary point of the lifted problem, which is also a stationary point of the original problem. It is also interesting to note that the BCD algorithm for solving the quadratic problem (19) lies in the minorization-maximization (MM) framework for solving the original problem (18) [79].  

From the application perspective, the quadratic and Lagrangian dual transforms are crucial tools for solving problems with fractional structures that arise from wireless communication system design. For instance, the Lagrangian dual transform significantly simplifies the structure of the sumrate maximization problem by moving the SINRs outside the nonlinear logarithmic functions. This is particularly advantageous when complicated variables are involved in the SINR expressions, such as the discrete scheduling variables in (17), the multiplicatively coupled variables in RIS-aided systems [82], and hybrid beamforming [83]. Moreover, when appropriately utilized and implemented, the two transforms can enable the problem to be reformulated into a form that allows for distributed optimization (e.g., within each cell), which is favorable for the design and optimization of wireless cellular networks.  

# B. Sparse Optimization  

Sparse optimization refers to a class of problems whose solution exhibits an inherent sparse structure. Here, sparsity means that only a small fraction of the entries in the solution vector is nonzero. Driven by the emergence and success of compressed sensing (CS) [84]—a signal acquisition paradigm designed to recover a sparse signal from a small set of incomplete measurements—sparse optimization has received significant attention over the past few decades. In this subsection, we first briefly review the theory and models associated with CS and sparse optimization. Then, we introduce two successful applications of CS and sparse optimization to wireless communication system design, which are localized statistical channel modeling [85] and device activity detection in mMTC [86].  

1) Compressed Sensing and Recovery Conditions: In various real-world applications, signals are (approximately) sparse or have a sparse representation under a certain basis. By exploiting the inherent sparsity of the true signal, CS enables the reconstruction of the original signal from only a small number of observations (e.g., from an underdetermined linear system), thereby significantly reducing the burden of sample acquisition, data storage, and computation. Mathematically, the reconstruction process of the sparse signal can be formulated as the following optimization problem:  

$$
\begin{array} { r l } & { \underset { \mathbf { x } } { \mathrm { m i n } } ~ \| \mathbf { x } \| _ { 0 } } \\ & { ~ \mathrm { s . t . } ~ \mathbf { A x } = \mathbf { y } . } \end{array}
$$  

Here, $\textbf { x } \in \ \mathbb { R } ^ { n }$ is the sparse signal to be recovered, $\| \mathbf { x } \| _ { 0 }$ denotes the $\ell _ { 0 }$ -norm that counts the numbers of nonzero entries in $\mathbf { x }$ , $\mathbf { y } = \mathbf { A x }$ is an underdetermined system with the observation $\mathbf { y } \in \mathbb { R } ^ { m }$ , $\mathbf { A } \in \mathbb { R } ^ { m \times n }$ is the sensing matrix, and $m \ll n$ . It is generally NP-hard to solve problem (28) [87]. An alternative model that enables the design of computationally efficient recovery algorithms is given by  

$$
\begin{array} { r l } & { \underset { \mathbf { x } } { \mathrm { m i n } } ~ \| \mathbf { x } \| _ { 1 } } \\ & { ~ \mathrm { s . t . } ~ \mathbf { A x } = \mathbf { y } , } \end{array}
$$  

where the nonconvex term $\| \cdot \| _ { 0 }$ in (28) is replaced by the convex term $\| \cdot \| _ { 1 }$ in (29). In practice, the measurements may include some noise, i.e., $\mathbf { y } = \mathbf { A } \mathbf { x } + \mathbf { z }$ with $\| { \mathbf z } \| _ { 2 } \leq \epsilon$ . In this case, the reconstruction problem can be formulated as  

$$
\begin{array} { r l } & { \underset { \mathbf { x } } { \mathrm { m i n } } ~ \| \mathbf { x } \| _ { 1 } } \\ & { \mathrm { s . t . } ~ \| \mathbf { A x } - \mathbf { y } \| _ { 2 } \leq \epsilon . } \end{array}
$$  

The above constrained problem can be further recast into the unconstrained problem  

$$
\operatorname* { m i n } _ { \mathbf { x } } \ \| \mathbf { A x } - \mathbf { y } \| _ { 2 } ^ { 2 } + \lambda \| \mathbf { x } \| _ { 1 } ,
$$  

where $\lambda > 0$ is a parameter that trades off the data fidelity term $\| \mathbf { A x } - \mathbf { y } \| _ { 2 } ^ { 2 }$ and the sparsity term $\| \mathbf { x } \| _ { 1 }$ . Problems (30) and (31) are connected in that for any $\epsilon$ , there exists a $\lambda$ such that the two problems have the same solutions [88].  

Two fundamental questions for the above reconstruction problems are (i) under what conditions can the formulations (28) and (29) precisely recover any $k$ -sparse signal $\mathbf { x }$ (i.e., $\| \mathbf { x } \| _ { 0 } ~ \leq ~ k )$ and (ii) how large is the recovery error when there is some noise in the measurements. These questions have been extensively studied, yielding numerous remarkable and insightful results. One of the most well-known recovery conditions is the restricted isometry property (RIP) [89] of the sensing matrix A. Specifically, a matrix $\mathbf { A }$ is said to satisfy the RIP of order $k$ if there exists a constant $\delta _ { k } \in ( 0 , 1 )$ such that  

$$
( 1 - \delta _ { k } ) \| { \mathbf { x } } \| _ { 2 } ^ { 2 } \leq \| { \mathbf { A } } { \mathbf { x } } \| _ { 2 } ^ { 2 } \leq ( 1 + \delta _ { k } ) \| { \mathbf { x } } \| _ { 2 } ^ { 2 }
$$  

holds for all $k$ -sparse vector $\mathbf { x }$ . Intuitively, RIP can be viewed as a characteristic that preserves the geometry (i.e., the distance) between sparse vectors. A smaller $\delta _ { k }$ implies better preservation capability, making A a more effective sensing matrix. An intriguing recovery result characterized by RIP is that when A satisfies RIP of order $2 k$ with $\delta _ { 2 k } < 1$ , any $k$ - sparse signal can be exactly recovered by the $\ell _ { 0 }$ minimization problem (28). Furthermore, if $\delta _ { 2 k } < \sqrt { 2 } - 1$ , then the solution of the $\ell _ { 1 }$ minimization problem (29) is the same as that of (28), i.e., the $k$ -sparse signal can also be recovered from (29). When the measurements are corrupted with noise, the recovery error is in the order of ${ \mathcal O } ( \epsilon )$ for problem (30) [90]. The upper bound on the above RIP constant can be further improved; see, e.g., [91]. It is worth mentioning that the RIP can be satisfied with high probability for a wide class of random matrices, including the i.i.d. Gaussian/Bernoulli matrices [92] and the partial Fourier matrix [93], when the number of measurements satisfies  

$$
m > \mathcal { O } ( k \log ( n / k ) ) .
$$  

Finally, we remark that there are also many other important conditions based on which recovery results are established. Interested readers are referred to a comprehensive review of these conditions as well as efficient sparse signal recovery algorithms for solving the previous models in [88].  

2) Application Examples: Sparse optimization and CS have found broad applications in wireless communication systems [94]. In this subsection, we showcase the important role of sparse optimization and CS approaches in formulating and analyzing two optimization problems—localized statistical channel modeling [85] and device activity detection in mMTC [86].  

a) Localized Statistical Channel Modeling: In network optimization [95], it is desirable to have a channel model that captures the specific multi-path topography and statistical properties of the targeted communication environment. The so-called localized statistical channel modeling (LSCM) [85] aims to leverage the beam-wise reference signal received power (RSRP) measurements to estimate the angular power spectrum (APS) of the channel between the BS and the user.  

Consider a scenario in which the BS is equipped with a uniform rectangular array possessing $N _ { T } = N _ { 1 } \times N _ { 2 }$ antennas, and the user has only a single antenna. The downlink channel between the $( x , y )$ -th antenna and the user is denoted as $h _ { x , y } ( t )$ , where $x = 0 , 1 , \ldots , N _ { 1 } - 1$ and $y = 0 , 1 , \dotsc , N _ { 2 } - 1$ . In 5G networks, synchronization signals and CSI reference beam signals are regularly transmitted to the user. The measured RSRP of the $m$ -th beam at the $t$ -th time slot is given by [85]  

$$
\mathrm { r s r p } _ { m } ( t ) = P \left| \sum _ { x = 0 } ^ { N _ { 1 } - 1 } \sum _ { y = 0 } ^ { N _ { 2 } - 1 } h _ { x , y } ( t ) W _ { x , y } ^ { ( m ) } \right| ^ { 2 } ,
$$  

where $W _ { x , y } ^ { ( m ) } = e ^ { j \phi _ { x , y } ^ { ( m ) } }$ is the $( x , y )$ -th entry of the precoding matrix $\pmb { W } ^ { ( m ) } \in \mathbb { C } ^ { N _ { x } \times N _ { y } }$ for the $m$ -th beam, $\phi _ { x , y } ^ { ( m ) }$ is the weight of DFT matrix, and $P$ represents the transmit power. Suppose that there are $M$ directional beams in total. The expected beam-wise RSRP measurements rsr $\mathbf { \Phi } _ { \mathbf { \lambda } } ) \in \mathbb { R } ^ { M \times 1 }$ is  

$$
\mathbf { r s r p } = \left[ \mathrm { R S R P } _ { 1 } , \mathrm { R S R P } _ { 2 } , \ldots , \mathrm { R S R P } _ { m } , \ldots , \mathrm { R S R P } _ { M } \right] ^ { \mathrm { T } } ,
$$  

where $\mathrm { R S R P } _ { m } \triangleq \mathbb { E } \left[ \mathrm { r s r p } _ { m } ( t ) \right]$ . As demonstrated in [85], the beam-wise average RSRP measurements and the channel APS have the linear relationship  

$$
\mathbf { r s r p } = \mathbf { A x } ,
$$  

where $\mathbf { A } \in \mathbb { R } ^ { M \times N }$ is a sensing matrix depending on the beam waveform and antenna gains, and $\mathbf { x } \in \mathbb { R } ^ { N }$ is the channel APS to be estimated. Here, the free space is discretized by $N$ equally spaced directions, and $N$ is usually a large number $N \gg M )$ for a high angular resolution. Due to the presence of a limited number of scatters around the BS, there is a small angular spread in the angular domain, resulting in a sparse channel $\mathsf { A P S ~ x }$ . To construct the localized statistical channel model, we can formulate the sparse recovery problem as  

$$
\begin{array} { r l } & { \underset { \mathbf { x } } { \mathrm { m i n } } ~ \| \mathbf { A x } - \mathbf { r s r p } \| _ { 2 } ^ { 2 } } \\ & { \mathrm { s . t . } \quad \| \mathbf { x } \| _ { 0 } \leq K , ~ \mathbf { x } \geq \mathbf { 0 } , } \end{array}
$$  

where $K$ is the maximum number of nonzero entries, representing the maximum number of channel paths; and the constraint $\textbf { x } \geq \textbf { 0 }$ is because the expectation of channel gain with respect to different angles is nonnegative. Efficient algorithms for solving problem (34) are proposed in [85].  

The localized statistical channel model exhibits statistical indistinguishability from the true propagation environment, generating channels that are similar to real-world scenarios. The construction of the localized statistical channel model enables precise evaluation of the network performance and effectively facilitates the simulation for offline network optimization [95]–[97].  

b) Device Activity Detection in mMTC: Consider an uplink single-cell massive random access scenario [16] with $K \gg 1$ single-antenna devices potentially accessing a BS equipped with $M$ antennas, which corresponds to the uplink counterpart of the wireless system in Fig. 3(a). A key feature of mMTC is that at any given time, only a small subset of users are active. To reduce the communication latency, grantfree random access schemes have been proposed in [15], [98], where the active devices directly transmit the data signals after transmitting their preassigned nonorthogonal signature sequences without first obtaining permissions from the BS. The BS identifies the active devices based on the received signature sequences. We now introduce two formulations of the device activity detection problem and their related detection theory.  

We begin with the system model. For the purpose of device identification, each device $k$ is preassigned a unique signature sequence sk = [s1k, s2k, . . . , sLk]T ∈ CL, where L is the sequence length. Let $a _ { k } \in \{ 0 , 1 \}$ denote the activity of device $k$ , i.e., $a _ { k } = 1$ if the device is active and $a _ { k } = 0$ otherwise, and let $\mathbf { h } _ { k } \in \mathbb { C } ^ { M }$ denote the (unknown) channel vector between device $k$ and the BS. Then, the received signals $\mathbf { Y } \in \mathbb { C } ^ { L \times M }$ at the BS (in the pilot phase) can be expressed as  

$$
\mathbf { Y } = \sum _ { k = 1 } ^ { K } a _ { k } \mathbf { s } _ { k } \mathbf { h } _ { k } ^ { \mathsf { T } } + \mathbf { Z } ,
$$  

where $\mathbf { Z } \in \mathbb { C } ^ { L \times M }$ is the normalized effective i.i.d. Gaussian noise with variance $\sigma _ { z } ^ { 2 } \mathbf { I }$ .  

Define $\begin{array} { c c c c c } { { { \bf S } } } & { { = } } & { { [ { \bf s } _ { 1 } , { \bf s } _ { 2 } , \ldots , { \bf s } _ { K } ] } } & { { \in } } & { { { \mathbb C } ^ { L \times K } } } \end{array}$ and $\mathrm { ~ \bf ~ X ~ } { \bf \Psi } = { \bf \Psi }$ $[ a _ { 1 } \mathbf { h } _ { 1 } , a _ { 2 } \mathbf { h } _ { 2 } , \ldots , a _ { K } \mathbf { h } _ { K } ] ^ { \mathsf { T } } \in \mathbb { C } ^ { K \times M }$ . The received signals in (35) can then be rewritten as $\mathbf { Y } = \mathbf { S } \mathbf { X } + \mathbf { Z }$ . Since the user traffic is sporadic, i.e., only $K _ { a } \ll K$ devices are active during each coherence interval, most rows of $\mathbf { X }$ will be zero. Based on this observation, the device activity detection problem can be formulated and analyzed using sparse optimization and CS approaches [99], [100]. For instance, the device activity detection problem can be formulated as  

$$
\operatorname* { m i n } _ { \mathbf { X } } ~ \| \mathbf { S } \mathbf { X } - \mathbf { Y } \| _ { F } ^ { 2 } + \lambda \| \mathbf { X } \| _ { 2 , 1 } ,
$$  

where $\begin{array} { r } { \| { \bf X } \| _ { 2 , 1 } ~ = ~ \sum _ { k = 1 } ^ { K } \sqrt { \sum _ { m = 1 } ^ { M } X _ { k , m } ^ { 2 } } } \end{array}$ is the $\ell _ { 2 , 1 }$ -norm, which is effective   promoting the group sparsity of $\mathbf { X }$ . The works [99], [100] propose to use the (vector) approximate message passing (AMP) algorithm to solve the device activity detection problem and analyze the detection performance by utilizing the state evolution analysis. It has been shown in [99] that as the number of antennas $M$ goes to infinity, the missed detection and false alarm probabilities can always be made to go to zero by the AMP approach that exploits the sparsity in the user activity pattern. Problem (36) can also be solved by the PG algorithm (see Section III-C), which comes with strong convergence guarantees [101], [102]. Recent progress on using sparse optimization and CS approaches to solve the device activity problem has been made in [103]–[107].  

Note that the sparse optimization approach described above recovers not only the user activities, but also an estimate of their channels. If we are only interested in the user activities and not the channels, then an alternative approach is to formulate the device activity detection problem as a maximum likelihood estimation (MLE) problem of the user activities only [108]. Instead of treating $\mathbf { h } _ { k }$ as a deterministic unknown variable as in the above CS approach, the MLE approach exploits the distribution information in ${ \bf h } _ { k }$ , i.e., $\mathbf { h } _ { k } = \sqrt { g _ { k } } \tilde { \mathbf { h } } _ { k }$ , where $g _ { k } \geq 0$ is the large-scale fading component, and $\tilde { \mathbf { h } } _ { k } \in$ $\mathbb { C } ^ { M }$ is the Rayleigh fading component following $\mathcal { C N } ( \mathbf { 0 } , \mathbf { I } )$ . In this case, the received signals in (35) can be rewritten as $\mathbf { Y } = \mathbf { S } \mathbf { T } ^ { 1 / 2 } \tilde { \mathbf { H } } + \mathbf { Z }$ , where $\mathbf { { \Gamma } } ^ { \Gamma } = \operatorname { d i a g } ( \gamma _ { 1 } , \gamma _ { 2 } , \ldots , \gamma _ { K } ) \in \mathbb { R } ^ { K \times K }$ with $\gamma _ { k } = a _ { k } g _ { k }$ being a diagonal matrix indicating both the device activity $a _ { k }$ and the large-scale fading component $g _ { k }$ , and $\tilde { \mathbf { H } } \ = \ [ \tilde { \tilde { \mathbf { h } } } _ { 1 } , \tilde { \mathbf { h } } _ { 2 } , \hdots , \tilde { \mathbf { h } } _ { K } ] ^ { \mathsf { T } } \ \in \ \mathbb { C } ^ { K \times M }$ is the normalized channel matrix. Note that the columns of $\mathbf { Y }$ , denoted by $\mathbf { y } _ { m } \in \mathbb { C } ^ { L }$ , $1 \leq m \leq M$ , are independent and each column ${ \bf y } _ { m }$ follows the complex Gaussian distribution $\mathbf { y } _ { m } \sim \mathcal { C N } ( \mathbf { 0 } , \pmb { \Sigma } )$ with covariance matrix  

$$
\pmb { \Sigma } = \mathbb { E } \left[ \pmb { \mathrm { y } } _ { m } \pmb { \mathrm { y } } _ { m } ^ { \dag } \right] = \pmb { \mathrm { S } } \pmb { \Gamma } \pmb { \mathrm { S } } ^ { \dag } + \sigma _ { z } ^ { 2 } \pmb { \mathrm { I } } .
$$  

Therefore, the problem of maximizing the likelihood $p ( \mathbf { Y } \mid \mathbf { r } )$ can be equivalently formulated as  

$$
\begin{array} { l } { \displaystyle \operatorname* { m i n } _ { \bf { \sigma } } \log \operatorname* { d e t } \left( { \Sigma } \right) + \mathrm { t r } \left( { \Sigma } ^ { - 1 } \widehat { \Sigma } \right) } \\ { \mathrm { s . t . ~ } { \Gamma } \geq { \bf { 0 } } , } \end{array}
$$  

where $\widehat { \pmb { \Sigma } } = \pmb { \mathrm { Y } } \pmb { \mathrm { Y } } ^ { \dagger } / M$ is the sample covariance matrix of the receiv db signals averaged over different antennas. The formulation (37) leads to the so-called covariance-based approach in the literature because it depends on $\mathbf { Y }$ only through its covariance $\widehat { \pmb { \Sigma } }$ . It has been shown in [109], [110] that when $\left\{ \mathbf { s } _ { k } \right\}$ is un bormly drawn from the sphere of radius $\sqrt { L }$ in an i.i.d. fashion and the number of active devices satisfies  

$$
K _ { a } \leq c _ { 1 } L ^ { 2 } / \log ^ { 2 } ( e K / L ^ { 2 } ) ,
$$  

then the MLE formulation in (37) is able to successfully detect the active devices with probability at least $1 - \exp ( - c _ { 2 } L )$ , where $c _ { 1 }$ and $c _ { 2 }$ are two constants whose values do not depend on $K _ { a } , \ K$ , and $L$ . This result shows that if the number of antennas $M$ at the BS goes to infinity, then the number of active devices that can be detected by the covariancebased approach scales quadratically with the length of the devices’ signature sequence $L$ . Covariance-based approaches and analyses have also been extended to the joint activity and data detection case [109], the multi-cell scenario [111], the more practical ways of generating signature sequences [112], the asynchronous scenario [113], [114], the case where the BS is equipped with low-resolution ADCs [115], and the unsourced random access scenario [110].  

3) Remarks: We conclude this subsection with a summary highlighting the crucial role that sparse optimization and CS play in wireless communication system design and analysis. First, sparse optimization is helpful in formulating optimization problems in wireless communications to promote desirable sparse structures in the solution, e.g., sparsity in the localized statistical channel model problem (34) and group sparsity in the joint BS clustering and beamformer design problem (7) and device activity detection problem (36). Compared to traditional formulations without exploiting sparsity (in the appropriate domain), sparse optimization formulations can significantly reduce signaling and training overhead associated with channel estimation [85], [94], [116]–[118]. Second, analytical tools derived from CS, including recovery conditions and the AMP-based high-dimensional analysis, are useful for understanding and analyzing the theoretical performance of certain optimization models/algorithms in wireless communications. As an example, these tools are employed in the device activity detection problem to theoretically characterize the detection performance of both CS and covariance-based approaches [99], [100], [109], [110].  

# C. Proximal Gradient Algorithms  

In this subsection, we first motivate the development of the PG algorithm. Then, we demonstrate how two optimization problems from wireless communication system design can be tackled by the PG algorithm.  

1) PG Algorithm, Interpretation, and Convergence Property: Consider the problem  

$$
\operatorname* { m i n } _ { \mathbf { x } \in \mathbb { R } ^ { n } } f ( \mathbf { x } ) + g ( \mathbf { x } ) ,
$$  

where $f ( \cdot )$ is a smooth function with Lipschitz continuous gradient and $g ( \cdot )$ is a nonsmooth function. In (38), none of the functions $f ( \cdot ) , \ g ( \cdot )$ , and $f ( \cdot ) + g ( \cdot )$ is required to be convex. For $r \geq 1$ , the $r$ -th iteration of the PG algorithm reads  

$$
\mathbf { x } ^ { r + 1 } \in \mathrm { p r o x } _ { \alpha _ { r } g } \left( \mathbf { x } ^ { r } - \alpha _ { r } \nabla f ( \mathbf { x } ^ { r } ) \right) ,
$$  

where $\alpha _ { r }$ is the step size at the $r$ -iteration and $\mathrm { p r o x } _ { \alpha _ { r } g } ( \cdot )$ is the so-called proximal operator defined as  

$$
\mathrm { p r o x } _ { \alpha _ { r } g } ( \mathbf { v } ) \in \arg \operatorname* { m i n } _ { \mathbf { y } \in \mathbb { R } ^ { n } } \left\{ g ( \mathbf { y } ) + \frac { 1 } { 2 \alpha _ { r } } \Vert \mathbf { y } - \mathbf { v } \Vert _ { 2 } ^ { 2 } \right\} .
$$  

By definition of the proximal operator in (40), we can rewrite (39) into the following equivalent form:  

$$
\begin{array} { r } { \mathbf { x } ^ { r + 1 } \in \arg \underset { \mathbf { x } \in \mathbb { R } ^ { n } } { \operatorname* { m i n } } \left\{ f ( \mathbf { x } ^ { r } ) + \nabla f ( \mathbf { x } ^ { r } ) ^ { \mathsf { T } } ( \mathbf { x } - \mathbf { x } ^ { r } ) \right. } \\ { \left. + \frac { 1 } { 2 \alpha _ { r } } \| \mathbf { x } - \mathbf { x } ^ { r } \| _ { 2 } ^ { 2 } + g ( \mathbf { x } ) \right\} . } \end{array}
$$  

Then, it is clear that the update in (39) can be interpreted as minimizing an approximation of the original objective function at each iteration. In particular, the right-hand side of (41) approximates the smooth term $f ( \cdot )$ by its first-order Taylor’s expansion at point $\mathbf { x } ^ { r }$ plus a quadratic term and keeps the nonsmooth term $g ( \cdot )$ unchanged. In addition, when $\alpha _ { r } \in ( 0 , 1 / L ]$ , where $L$ is the Lipschitz constant of $\nabla f$ , the minimized function on the right-hand side of (41) is an upper bound of the objective function in (38). As such, the PG algorithm falls under the MM framework [119, Section 4.2]. Obviously, the efficiency of the PG algorithm highly depends on that of computing the proximal operator in (40). Fortunately, for many nonsmooth functions of practical interest, their proximal operators either admit a closed-form solution (e.g., $\Vert \cdot \Vert _ { 0 . 5 }$ , $\| \cdot \| _ { 1 } , \| \cdot \| _ { 2 } , \| \cdot \| _ { \infty } )$ or can be efficiently computed; see [120, Page 177] for a summary of such examples.  

The PG algorithm enjoys nice theoretical convergence properties. In the case where both $f$ and $g$ are closed proper convex functions, the PG algorithm with a fixed step size $\alpha _ { r } = \alpha \in ( 0 , 2 / L ]$ is guaranteed to converge to the optimal solution of problem (38) [121]. For the nonconvex case, it is shown in [122] that the iterates generated by the PG algorithm converge to a critical point of problem (38) with  

$0 ~ < ~ \underline { { \alpha } } ~ < ~ \alpha _ { r } ~ < ~ \bar { \alpha } ~ < ~ 1 / L$ , as long as $f + g$ is proper, closed, and satisfies the Kurdyka-Łojasiewicz property. These conditions are quite mild and are satisfied by a rich class of functions (e.g., semi-algebraic functions) [123]. Furthermore, there have been efforts in establishing the convergence of the inexact PG algorithm [122]. These results allow for an error in the calculation of the proximal operator at each iteration, thus offering flexibility in cases where the proximal operator lacks a closed-form solution and needs to be computed numerically.  

It is worth noting an interesting special case where the nonsmooth term $g ( \cdot )$ in problem (38) is the indicator function of a closed set $\mathcal { C } \subseteq \mathbb { R } ^ { n }$ . In this case, problem (38) reduces to the constrained problem  

$$
\operatorname* { m i n } _ { \mathbf { x } \in \mathcal { C } } f ( \mathbf { x } ) ,
$$  

the proximal operator in (40) reduces to the familiar projection operator  

$$
\mathrm { p r o j } _ { \mathcal { C } } ( \mathbf { v } ) = \arg \operatorname* { m i n } _ { \mathbf { y } \in \mathcal { C } } \left\{ \frac { 1 } { 2 } \| \mathbf { y } - \mathbf { v } \| _ { 2 } ^ { 2 } \right\} ,
$$  

and the PG algorithm reduces to the GP algorithm where (39) is replaced by  

$$
\mathbf { x } ^ { r + 1 } \in \mathrm { p r o j } _ { \mathcal { C } } \left( \mathbf { x } ^ { r } - \alpha _ { r } \nabla f ( \mathbf { x } ^ { r } ) \right) .
$$  

Due to its simple implementation, computational efficiency, and appealing theoretical properties, the PG algorithm is widely adopted for solving optimization problems that involve simple (nonconvex) nonsmooth terms (e.g., smooth problems with simple constraints).  

2) Application Examples: In this subsection, we apply the PG and GP algorithms to solve two fundamental problems in wireless communications, namely, massive MIMO detection (14) and joint BS clustering and beamformer design (7).  

a) Massive MIMO Detection: We first review the application of the GP algorithm for solving the MIMO detection problem in (14). As discussed in Section II-A, a new challenge for MIMO detection is the significant increase in problem size driven by the massive MIMO technology. In the context of massive MIMO, classic MIMO detection algorithms/techniques that work well for small-to-median scale systems (e.g., SDR-based algorithms [37], [38]) become impractical, as their computational complexities grow quickly with the problem size.  

Motivated by the above, the following low-complexity GP algorithm  

$$
\mathbf { x } ^ { r + 1 } = \operatorname { P r o j } _ { \mathcal { S } ^ { K } } \left( \mathbf { x } ^ { r } - 2 \alpha _ { r } \mathbf { H } ^ { \dagger } ( \mathbf { H } \mathbf { x } ^ { r } - \mathbf { y } ) \right) ,
$$  

is proposed in [35] to solve the massive MIMO detection problem, where $\alpha _ { r } \ > \ 0$ is the step size, $\mathrm { P r o j } _ { S ^ { K } } ( \cdot )$ denotes the projection operator onto the set ${ { \mathcal { S } } ^ { K } }$ , and $s$ is either the PSK constellation set in (13) or the QAM constellation set in (12). The dominant computational cost at each iteration of the above GP algorithm lies in two matrix-vector multiplications and one projection onto $\mathcal { S } ^ { K }$ . Since the set ${ { \mathcal { S } } ^ { K } }$ is fully decoupled among different components, the projection onto $\mathcal { S } ^ { K }$ reduces to $K$ projections onto $s$ . Moreover, the discrete set $s$ is symmetric and highly structured. Hence, the projection $\mathrm { P r o j } _ { \mathcal { S } } ( \cdot )$ and consequently the projection $\mathrm { P r o j } _ { S ^ { K } } ( \cdot )$ are easily computable. This makes the above GP algorithm extremely efficient and particularly suitable for solving largescale MIMO detection problems arising from massive MIMO systems.  

In addition to its low per-iteration computational complexity, the above GP algorithm enjoys strong theoretical guarantees. It has been shown in [35] that under mild conditions (roughly speaking, when the noise variance is small and the ratio $M / K$ is large), the iterates generated by the GP algorithm will converge to the true symbol vector s within a finite number of iterations. This result is somewhat surprising and is much stronger than the general convergence result for GP algorithms. First, the GP algorithm for solving nonconvex problems is generally not guaranteed to converge to an optimal solution but only to a critical point. Second, there is generally no theoretical guarantee that the maximum likelihood (ML) estimator (i.e., the optimal solution of problem (14)) is the true symbol vector s. This strong convergence result in [35] is obtained by carefully exploiting the structure of problem (14), particularly the special structure of the discrete set $s$ and the statistical property of the channel matrix $\mathbf { H }$ ; see the detailed proof in [35, Theorem 1].  

b) Joint BS Clustering and Beamformer Design: The PG algorithm plays an important role in solving the joint BS clustering and beamformer design problem (7). Observe that problem (7) is challenging to solve, as the variables $\{ \mathbf { v } _ { k , b } \}$ are coupled in both the objective function and the constraint, and the objective function has a nonsmooth term and is highly nonlinear. To tackle problem (7), it is useful to reformulate it into the following equivalent form using the technique similar to that in the FP and WMMSE approaches [78], [80], [81]:  

$$
\begin{array} { r l } { \displaystyle \operatorname* { m i n } _ { \{ u _ { k } \} , \{ w _ { k } \} , \{ \mathbf { v } _ { k } \} } } & { \displaystyle \sum _ { k \in \mathcal { K } } \left( w _ { k } e _ { k } - \log w _ { k } + \rho \sum _ { b \in \mathcal { B } } \| \mathbf { v } _ { k , b } \| _ { 2 } \right) } \\ { \mathrm { s . t . } } & { \displaystyle \sum _ { k \in \mathcal { K } } \| \mathbf { v } _ { k , b } \| _ { 2 } ^ { 2 } \leq P _ { b } , ~ b \in \mathcal { B } , } \end{array}
$$  

where $\boldsymbol { e } _ { k }$ is the mean squared error (MSE) for user $k$ given by  

$$
e _ { k } = \Big | u _ { k } \mathbf h _ { k } ^ { \dagger } \mathbf v _ { k } - 1 \Big | ^ { 2 } + \sum _ { j \neq k } \Big | u _ { k } \mathbf h _ { k } ^ { \dagger } \mathbf v _ { j } \Big | ^ { 2 } + \sigma ^ { 2 } | u _ { k } | ^ { 2 } .
$$  

A desirable property of the above reformulation (42) is that the problem is convex with respect to each of the variable blocks $\mathbf { v } = \{ \mathbf { v } _ { k } \}$ , $\mathbf { u } = \{ u _ { k } \}$ , and $\textbf { w } = \{ w _ { k } \}$ (with the other two blocks being fixed), making it amenable to the BCD algorithm. In particular, when $\mathbf { u }$ and $\mathbf { v }$ are fixed, the problem in terms of w admits the closed-form solution $w _ { k } = \bar { e } _ { k } ^ { - 1 }$ for all $k \in \mathcal { K }$ when w and $\mathbf { v }$ are fixed, the problem in terms of $\mathbf { u }$ also has a closed-form solution. Below we consider the solution of the problem in terms of $\mathbf { v }$ with fixed $\mathbf { u }$ and w.  

Since the constraint in (42) is separable in the beamforming vectors of different BSs, we can apply the BCD algorithm again to solve the $\mathbf { v }$ -subproblem by treating $\{ \mathbf { v } _ { k , b } \} _ { k \in \mathcal { K } }$ as one block of variables. Specifically, the $b$ -th subproblem takes the form  

$$
\begin{array} { r l r } & { \underset { \{ \mathbf { v } _ { k , b } \} _ { k \in \mathcal { K } } } { \operatorname* { m i n } } } & { \displaystyle \sum _ { k \in \mathcal { K } } \left( \mathbf { v } _ { k , b } ^ { \dagger } \mathbf { Q } _ { k , b } \mathbf { v } _ { k , b } - 2 \mathrm { R e } \left( \mathbf { d } _ { k , b } ^ { \dagger } \mathbf { v } _ { k , b } \right) + \rho \| \mathbf { v } _ { k , b } \| _ { 2 } \right) } \\ & { \mathrm { s . t . } } & { \displaystyle \sum _ { k \in \mathcal { K } } \| \mathbf { v } _ { k , b } \| _ { 2 } ^ { 2 } \leq P _ { b } , } \end{array}
$$  

where $\mathbf { Q } _ { k , b } \in \mathbb { C } ^ { M \times M }$ and $\mathbf { d } _ { k , b } \in \mathbb { C } ^ { M }$ are constants depending on the other blocks of the variables; see their explicit expressions in [33]. The objective function in (43) is separable among different $k \in \mathcal { K }$ and each of them is a simple quadratic function plus a convex nonsmooth $\ell _ { 2 }$ -norm. However, the presence of the quadratic constraint complicates the solution of the problem and makes the PG algorithm not efficient.3 To overcome this difficulty, we consider the dual of problem (43) as follows:  

$$
\begin{array} { r } { \displaystyle \underset { \lambda _ { b } \geq 0 } { \operatorname* { m a x } } \displaystyle \operatorname* { m i n } _ { \{ \mathbf { v } _ { k , b } \} } \sum _ { k \in \mathcal { K } } \left( \mathbf { v } _ { k , b } ^ { \dagger } \mathbf { Q } _ { k , b } \mathbf { v } _ { k , b } - 2 \mathrm { R e } \left( \mathbf { d } _ { k , b } ^ { \dagger } \mathbf { v } _ { k , b } \right) + \rho \| \mathbf { v } _ { k , b } \| _ { 2 } \right) } \\ { + \lambda _ { b } \left( \displaystyle \sum _ { k \in \mathcal { K } } \| \mathbf { v } _ { k , b } \| _ { 2 } ^ { 2 } - P _ { b } \right) . } \end{array}
$$  

The above dual reformulation leads to an efficient algorithm for solving the subproblem in (43). First, for a given $\lambda _ { b } \geq 0$ , the inner minimization problem over $\{ \mathbf { v } _ { k , b } \}$ is separable among different $k \in \mathcal { K }$ , unconstrained, and convex. Hence, it can be efficiently solved to global optimality using the PG algorithm (as the proximal operator of the $\ell _ { 2 }$ -norm admits a closed-form solution). Second, the outer maximization problem over $\lambda _ { b } \geq 0$ is a one-dimensional convex problem, whose solution can be quickly found via a simple bisection search. We remark here that even without the nonsmooth term in (43), the solution of the corresponding $\mathbf { v }$ -subproblem (as in the FP and WMMSE approaches) also requires a bisection search; see the discussion below problem (25) and [78], [80], [81] for more details.  

3) Remarks: We conclude this subsection with some remarks and conclusions drawn from the above two examples. First, in addition to the general theoretical convergence properties of the PG and GP algorithms [121], [122], it is often possible to derive tailored results by carefully exploiting the special structure of the underlying problem. This is illustrated by the MIMO detection problem discussed earlier. Second, many problems arising from wireless communication system design, though nonconvex and/or nonsmooth, have structured objective functions and/or constraints. Even though the PG and GP algorithms may not be directly applicable to tackling these problems, they can still play a vital role in solving these problems. By employing some approximations, equivalent reformulations, splitting techniques, or optimization frameworks like BCD or MM, these complicated problems often boil down to simple forms/subproblems that can be efficiently solved via the PG/GP algorithm; see more examples in [33], [124], [125].  

# D. Penalty Methods  

Penalty methods are an important class of methods for solving constrained optimization problems. The penalty methods look for the solution of the (complicated) constrained optimization problem by replacing it with a sequence of (relatively easy) unconstrained penalty subproblems. The objective function in the penalty subproblem is called the penalty function, which is formed by adding a penalty term to the objective function of the original constrained problem. The penalty term usually is a measure of the violation of the constraints of the original problem multiplied by a penalty parameter. Some important algorithms in this class include the quadratic penalty method and the augmented Lagrangian method.  

Due to its simplicity, the penalty method has been widely studied and used to solve constrained optimization problems from various applications. A crucial concept associated with the penalty method is the exactness of the penalty function. A penalty function is said to be exact if the unconstrained penalty problem with a sufficiently large penalty parameter would eventually share the same solution with the original constrained problem. The exactness of the penalty function plays a vital role in reducing and avoiding the ill-conditioning in the corresponding penalty method. Therefore, the choice of the penalty function in the corresponding penalty method is of fundamental importance to its numerical performance, and different choices of penalty terms would generally lead to different penalty methods. In this subsection, instead of reviewing the classic quadratic penalty methods, we review the recent penalty method developed in [126] for solving problems with integer/discrete variables arising from wireless communication system design.  

1) Penalty Methods for a Class of Optimization Problems with Structured Constraints: Let us first take the MIMO detection problem (14) as an example to illustrate how the penalty method can be applied to solve the optimization problem with binary variables. Consider the case in which the constellation is $L$ -PSK given in (13). For notational simplicity, let $\mathbf { s } = [ s _ { 1 } , s _ { 2 } , \ldots , s _ { L } ] ^ { \mathsf { T } } \in \mathbb { C } ^ { L }$ be the vector of all constellation symbols, where $s _ { \ell } = \exp ( 2 \pi \mathrm { i } ( \ell - 1 ) / L )$ . We introduce the auxiliary variable $\mathbf { t } = [ \mathbf { t } _ { 1 } ^ { \mathsf { T } } , \mathbf { t } _ { 2 } ^ { \mathsf { T } } , \ldots , \mathbf { t } _ { n } ^ { \mathsf { T } } ] ^ { \mathsf { T } } \in \mathbb { R } ^ { L n }$ , where $\mathbf { t } _ { i } = [ t _ { i , 1 } , t _ { i , 2 } , \ldots , t _ { i , L } ] ^ { \mathsf { T } } \in \mathbb { R } ^ { L }$ . Then, for each $\boldsymbol { x } _ { i } ^ { * }$ of $\mathbf { x } ^ { * }$ , we have $x _ { i } ^ { * } = \mathbf { t } _ { i } ^ { \mathsf { T } } \mathbf { s }$ for some $\mathbf { t } _ { i } \in \mathbb { R } ^ { L }$ that has one entry equal to one and all other entries equal zero. Then, problem (14) with $ { \boldsymbol { S } } =  { \boldsymbol { S } } _ { L }$ can be equivalently rewritten as [127]  

$$
\begin{array} { r l } & { \underset { \mathbf { t } } { \operatorname* { m i n } } \quad \mathbf { t } ^ { \mathsf { T } } \mathbf { Q } \mathbf { t } + 2 \mathbf { c } ^ { \mathsf { T } } \mathbf { t } } \\ & { \quad \mathrm { s . t . } \quad \mathbf { e } ^ { \mathsf { T } } \mathbf { t } _ { i } = 1 , ~ \mathbf { t } _ { i } \in \{ 0 , 1 \} ^ { L } , ~ i = 1 , 2 , \hdots , n , } \end{array}
$$  

where $\mathbf { Q } \in \mathbb { R } ^ { L n \times L n }$ and $\mathbf { c } \in \mathbb { R } ^ { L n }$ are constants depending on the problem inputs $\mathbf { H } , \mathbf { r }$ , and s. The constraints in (44) with respect to $\mathbf { t } _ { i }$ (for $i = 1 , 2 , \ldots , n )$ enforce an assignment, where each agent (corresponding to each of the $n$ users in (44)) can only choose one and only one item from a given set of items (corresponding to the constellation set $ { \boldsymbol { S } } _ { L }$ ). Using the same trick, problem (14) with $\mathcal { S } = \mathcal { Q } _ { u }$ has a reformulation similar to (44).  

We can apply the popular negative square penalty [126], [128] to the objective function of problem (44) and obtain the penalty problem  

$$
\begin{array} { r l } { \underset { \mathbf { t } } { \operatorname* { m i n } } } & { \mathbf { t } ^ { \top } \mathbf { Q } \mathbf { t } + 2 \mathbf { c } ^ { \top } \mathbf { t } - \lambda \sum _ { i = 1 } ^ { n } \| \mathbf { t } _ { i } \| _ { 2 } ^ { 2 } } \\ { \mathrm { s . t . } } & { \mathbf { e } ^ { \top } \mathbf { t } _ { i } = 1 , \ \mathbf { 0 } \leq \mathbf { t } _ { i } \leq \mathbf { 1 } , \ i = 1 , 2 , \ldots , n , } \end{array}
$$  

where $\lambda \geq 0$ is the penalty parameter. The penalty problem in (45) can be understood via the following relaxation-tightening procedure. First, problem (44) is relaxed to obtain problem (45) without the negative square penalty term (and the feasible set of (45) is the convex hull of the feasible set of (44)). Then, the negative square penalty term $\begin{array} { r } { - \lambda \sum _ { i = 1 } ^ { n } \| \mathbf { t } _ { i } \| _ { 2 } ^ { 2 } } \end{array}$ is added to the objective function of the relax ed problem in order to minimize/penalize the relaxation gap and tighten the relaxation. Note that any $\mathbf { t } _ { i }$ that is feasible for problem (44) is the solution of the problem of minimizing $- \| \mathbf { t } _ { i } \| _ { 2 } ^ { 2 }$ over the simplex constraint, which is the intuition why the tighten procedure works.  

The classic penalty methods usually eliminate a constraint by penalizing it in the objective function. However, the goal of penalty methods here is to transform (or relax) the hard constrained problems into easier constrained subproblems (whose feasible sets are usually convex relaxations of the original ones) and, at the same time, appropriately minimize/penalize the relaxation gap. It can be seen that if the penalty parameter $\lambda$ is greater than the largest eigenvalue of $\mathbf { Q }$ in (45), then the objective function in (45) is strictly concave in its variable. Consequently, the solution of problem (45) is achieved on the boundary of the feasible set, which is also the feasible set of problem (44). This shows the equivalence of the two problems and the exactness of the penalty function in (45). It has been shown in [129] that in the case where ${ \boldsymbol { \mathcal { S } } } = { \boldsymbol { \mathcal { S } } } _ { L }$ , problem (45) with the diagonal entries of $\mathbf { Q }$ being set to zero always has a binary solution (even though $\lambda = 0 ,$ . In this way, the ill-conditioning in the penalty method has been fully eliminated by judiciously exploiting the special structure of the PSK constellation. Compared to the GP algorithm in [35] for solving the MIMO detection problem (14) with $ { \boldsymbol { S } } =  { \boldsymbol { S } } _ { L }$ , the algorithm in [129] is more robust to the choice of the initial point and can generally achieve a better detection performance at the cost of a higher computational time (as it is based on the higher-dimensional problem reformulation (44)).  

From the above example and discussion, we can conclude that the penalty method is suitable for solving an optimization problem whose constraint can be decomposed into a simple convex constraint and a simple penalty function, i.e., the solution set of minimizing the penalty function over the simple convex constraint is equal to the feasible set of the original problem. Therefore, in addition to the above MIMO detection problem whose feasible set can be equivalently characterized by the assignment constraint, the penalty method and related ideas can be used to solve problems in much more general setups [126], [128], [130]. First, the constraint in the problem can be more general; e.g., each agent $\mathbf { \chi } _ { i }$ can choose at most $k \geq 1$ items from a given set (i.e., $\bar { \mathbf { e } } ^ { \mathsf { T } } \mathbf { t } _ { i } \leq k$ , $\mathbf { t } _ { i } \in \{ 0 , 1 \} ^ { L } )$ , or different $\mathbf { t } _ { i }$ and $\mathbf { t } _ { j }$ need to satisfy some linear constraints like in the permutation matrix case [130]. Second, the objective function in the problem needs not be quadratic but can be any smooth function (with a bounded Hessian in the bounded feasible set) [126], [128]. Finally, in addition to the negative square penalty, there are other kinds of penalty functions such as the $\ell _ { q }$ penalty [130] $\begin{array} { r } { \| \mathbf { t } _ { i } \| _ { q } ^ { q } \triangleq \sum _ { \ell = 1 } ^ { L } \dot { t } _ { i , \ell } ^ { q } } \end{array}$ with $q \in ( 0 , 1 )$ .  

2) Remarks: We conclude this subsection with some remarks on the advantages of applying the penalty methods to solve optimization problems with integer variables. The exactness result of the penalty function in the corresponding penalty method serves as a necessary theoretical guarantee that one can focus on the smooth/continuous model (e.g., problem (45)) of the original discrete problem (e.g., problem (44)) for the purpose of algorithm design. This is important and beneficial for the following reasons. First, it gives more freedom to design algorithms, since smooth/continuous problems are generally easier to handle than discrete problems. Second and more importantly, solving the smooth/continuous problem is more likely to find a high-quality suboptimal solution of the original problem with integer variables because the former has a larger search space in which the homotopy (sometimes called warm-start) technique [130], [131] can help bypass bad local solutions. For instance, problem (45) can be efficiently solved by the GP algorithm.  

The recent work [73] proposes a negative $\ell _ { 1 }$ penalty method for solving the one-bit precoding problem formulated in [132], which is a special case of symbol-level precoding [13]. The optimization problem has a nonsmooth objective function and discrete variables. The resulting penalty problem in [73] can be efficiently solved by the single-loop AO algorithm [73], [133], [134], where a projection subproblem onto the simplex needs to be solved at each iteration. The above negative $\ell _ { 1 }$ penalty method can also be extended to solve problems with more general discrete constraints such as the quantized constant envelope (QCE) precoding problem [135]. Recent progress on the analysis of diversity order and (asymptotic) symbol error probability on one-bit and QCE precoding can be found in [136] and [137], respectively.  

# E. Duality-Based Algorithms  

Lagrangian duality, a principle that (convex) optimization problems can be viewed from either the primal or dual perspective, is a powerful tool for revealing the intrinsic structures of optimization problems arising from wireless communications. The celebrated uplink-downlink duality [138]–[140] in the power control and beamforming design for wireless communications can be interpreted via Lagrangian duality [141], [142]. The uplink-downlink duality refers to the fact that the minimum total power required to achieve a set of SINR targets in the downlink channel is equal to that to achieve the same set of SINR targets in a virtual dual uplink channel, when the uplink and downlink channels are the conjugate transpose of each other. Usually, uplink problems, e.g., the transmit power minimization problems subject to QoS constraints, can be solved efficiently and globally (via the fixed-point iteration algorithm). The uplink-downlink duality thus allows downlink problems to be efficiently solved by solving the relatively easy uplink counterparts.  

The line of algorithms based on Lagrangian duality and uplink-downlink duality generally enjoys two key features.  

One is its high computational efficiency as the algorithm often only involves simple fixed-point iterations, and the other is its global optimality. Therefore, duality-based algorithms have been widely studied for solving power control and beamforming design problems in various communication networks; see [62]–[65] and the references therein. In this section, we demonstrate how uplink-downlink duality [143] leads to a duality-based fixed-point iteration algorithm [61] for solving the QoS-constrained joint beamforming and compression problem (10) in the cooperative cellular network.  

1) Uplink-Downlink Duality: The main results in [143] are several duality relationships between the achievable rate regions of the multiple-access relay channel and the broadcast relay channel, as shown in [143, Fig. 2], under the same sum-power constraint and individual fronthaul constraints. A complete summary of the obtained duality relationships can be found in [143, Table I]. Below we state one of the main results in [143]. Under the same sum-power constraint and individual fronthaul capacity constraints, the achievable rate region of the multiple-access relay channel implementing Wyner-Ziv compression across the relays and linear decoding at the CP and that of the broadcast relay channel implementing multivariate compression across the relays and linear encoding at the CP are identical. The duality result is proved by showing that given the same fixed beamformers $\left\{ \bar { \mathbf { u } } _ { k } \right\}$ and under the same set of rate targets $\{ R _ { k } \}$ , the optimal values of the downlink problem (10) and its uplink counterpart (46) (at the top of the next page) are the same, where  

$$
{ \displaystyle { \bf \cal T } = \sum _ { k \in { \cal K } } p _ { k } ^ { \mathrm { u l } } { \bf h } _ { k } { \bf h } _ { k } ^ { \dagger } + \sigma ^ { 2 } { \bf \cal I } + \mathrm { d i a g } ( q _ { 1 } ^ { \mathrm { u l } } , q _ { 2 } ^ { \mathrm { u l } } , \dots , q _ { M } ^ { \mathrm { u l } } ) } ,
$$  

$p _ { k } ^ { \mathrm { u l } }$ denotes the transmit power of user $k$ , and $q _ { m } ^ { \mathrm { u l } }$ denotes the variance of the compression noise at relay $m$ .  

2) Duality-Based Algorithms: Now, we review the dualitybased algorithm in [61] for solving the joint beamforming and compression problem (10). There are two key steps in the algorithm proposed in [61]. In the first step, the seemingly nonconvex problem (10) is shown to be equivalent to the convex SDP [61], [143]  

$$
\begin{array} { r l } { \displaystyle \operatorname* { m i n } _ { \{ \mathbf { V } _ { k } \} , \mathbf { Q } } } & { \displaystyle \sum _ { k \in \mathcal { K } } \mathrm { t r } ( \mathbf { V } _ { k } ) + \mathrm { t r } ( \mathbf { Q } ) } \\ { \mathrm { s . t . } } & { a _ { k } \big ( \{ \mathbf { V } _ { k } \} , \mathbf { Q } \big ) \geq 0 , \ k \in \mathcal { K } , } \\ & { \mathbf { B } _ { m } \big ( \{ \mathbf { V } _ { k } \} , \mathbf { Q } \big ) \succeq \mathbf { 0 } , \ m \in \mathcal { M } , } \\ & { \mathbf { V } _ { k } \succeq \mathbf { 0 } , \ k \in \mathcal { K } , } \end{array}
$$  

where  

$$
\begin{array} { r l r } & { } & { a _ { k } \big ( \{ { \bf V } _ { k } \} , { \bf Q } \big ) = - \left( \displaystyle \sum _ { j \ne k } \mathrm { t r } \big ( { \bf V } _ { k } { \bf H } _ { k } \big ) + \mathrm { t r } \big ( { \bf Q } { \bf H } _ { k } \big ) + \sigma _ { k } ^ { 2 } \right) } \\ & { } & { + \frac { 1 } { \gamma _ { k } } \mathrm { t r } \big ( { \bf V } _ { k } { \bf H } _ { k } \big ) , } \\ & { } & { { \bf B } _ { m } \big ( \{ { \bf V } _ { k } \} , { \bf Q } \big ) = \eta _ { m } \left[ \displaystyle \begin{array} { c } { { \bf 0 } } \\ { { \bf Q } } \end{array} \mathrm { \bf ~ Q } ^ { ( m ; M , m ; M ) } \right] } \\ & { } & { - { \bf E } _ { m } ^ { \dagger } \left( \displaystyle \sum _ { k \in \mathbb { K } } \mathrm { \bf v } _ { k } { \bf v } _ { k } ^ { \dagger } + { \bf Q } \right) { \bf E } _ { m } , } \end{array}
$$  

$\mathbf { H } _ { k } = \mathbf { h } _ { k } \mathbf { h } _ { k } ^ { \dagger } , ~ k \in \mathcal { K }$ and $\eta _ { m } = 2 ^ { C _ { m } } , ~ m \in \mathcal { M }$ .  

In the above, $\mathbf { E } _ { m }$ denotes the all-zero matrix except the $m$ - th diagonal entry being one. Combining the classic KarushKuhn-Tucker (KKT) conditions with the specific structure of problem (47), we obtain a set of enhanced KKT conditions; see Eqs. (7)–(16) in [61] for details. The second step is to separate the enhanced KKT conditions into two sets. We first solve equations involving the dual variables. Then, we solve equations involving the primal variables. It is interesting and somewhat surprising that each set can be solved elegantly via a fixed-point iteration algorithm [61].  

3) Remarks: In order for the above (Lagrangian) dualitybased algorithms to globally and efficiently solve the underlying problems, there are generally two technical challenges. The first is to reformulate the problem of interest into an equivalent convex form. This step is essential to ensure the global optimality of the algorithm but can be highly nontrivial. The SDR [23] turns out to be a rather useful tool here. The second is to judiciously explore the problem’s solution structure and carefully exploit it in algorithm design. Making use of the solution structure is of paramount importance to the computational efficiency of the algorithm.  

Duality is just one way that the KKT conditions can reveal structural insight of an optimization problem. For solving power allocation and beamforming problems in multi-user communication scenarios, it is always worthwhile to carefully examine the KKT conditions. This holds true not only for convex but also for nonconvex optimization problems. In some cases, the problem structure reflected in the optimality conditions allows us to reformulate the problem into a convex form and to develop an efficient algorithm to find the global optimum. In the domain of power control for multiuser networks, this approach has successfully led to optimal algorithms like the iterative water-filling algorithms for both the multiple-access channel [144] and the interference channel [145], [146].  

While the sum-rate maximization problem for the interference channel is already known to be NP-hard [66], [74], modern multiple-access technologies, such as NOMA, lead to additional challenges [147] that include discrete variables to determine the optimal decoding orders. In a typical multicarrier downlink setup, NOMA can specialize to different variants, including single-carrier NOMA (SC-NOMA), FDMANOMA, and hybrid-NOMA [148]. In the single-cell setup, the optimum decoding order for each subchannel can be determined easily, and the optimal power control problem turns out to be a convex optimization problem. However, one would expect, in the multi-cell setup [149], that the optimization of the decoding order and power allocation will be an NP-hard mixed-integer nonlinear optimization problem [149, Corollary 1]. Nevertheless, in specific cases, for fixed decoding orders, by exploiting the KKT conditions, the optimal power allocation can be computed in closed form [149, Proposition 1]. Then, the optimal decoding order only depends on the total power consumption at the BSs and the search space is significantly reduced, which can potentially lead to centralized or distributed algorithms for solving the joint rate and power allocation problem for multi-cell NOMA-assisted downlink networks.  

$$
\begin{array} { r l } { \underset { \{ p _ { k } ^ { ( 1 ) } \} , \{ q _ { m } ^ { ( 1 ) } \} } { \operatorname* { m i n } } } & { \displaystyle \sum _ { k \in \mathcal { K } } p _ { k } ^ { \mathrm { u l } } } \\ { \mathrm { s . t . } \ } & { \displaystyle \sigma ^ { 2 } + \sum _ { j \not = k } p _ { j } ^ { \mathrm { u l } } \big | \bar { \mathbf { u } } _ { k } ^ { \dagger } \mathbf { h } _ { j } \big | ^ { 2 } + \sum _ { m \in \mathcal { M } } q _ { m } ^ { \mathrm { u l } } \big | \bar { u } _ { k , m } \big | ^ { 2 } - \frac { p _ { k } ^ { \mathrm { u l } } \big | \bar { \mathbf { u } } _ { k } ^ { \dagger } \mathbf { h } _ { k } \big | ^ { 2 } } { 2 R \kappa } \leq 0 , \ k \in \mathcal { K } , } \\ & { \displaystyle 2 ^ { C _ { m } } q _ { m } ^ { \mathrm { u l } } \geq { \mathbf { r } } ^ { ( m , m ) } - { \mathbf { r } } ^ { ( m , 1 : m - 1 ) } \left( { \mathbf { r } } ^ { ( 1 : m - 1 , 1 : m - 1 ) } \right) ^ { - 1 } { \mathbf { r } } ^ { ( 1 : m - 1 , m ) } , \ m \in \mathcal { M } , } \\ & { \displaystyle p _ { m } ^ { \mathrm { u l } } \geq 0 , \ k \in \mathcal { K } , } \\ & { \displaystyle q _ { m } ^ { \mathrm { u l } } \geq 0 , \ m \in \mathcal { M } . } \end{array}
$$  

# IV. PROBLEM-SPECIFIC GLOBAL OPTIMIZATION  

Global optimization algorithms and techniques aim to find global solutions of (hard) optimization problems. Global optimization distinguishes itself from local or heuristic optimization by its focus on finding a global solution, as opposed to finding a local or suboptimal solution. Global optimization usually is much more difficult and requires more careful algorithmic design than local optimization.  

In this section, we survey recent advances in problemspecific global optimization techniques that are closely related to wireless communication system design. We do not survey general-purpose global optimization techniques. Before delving into the detailed survey, we first list the reasons why there is a strong interest in computing the global solution of problems, even though the complexity may be high. First, the computed global solution is helpful in assessing the fundamental limits of the performance of the considered wireless communication system. Second, global optimization algorithms provide important benchmarks for performance evaluation of existing local and suboptimal algorithms for the same problem. The above two would be impossible without the global optimality guarantee. Third, fast global optimization algorithms can generate high-quality samples for end-to-end supervised learning, which is covered in Section VI.  

This section is organized as follows. We first introduce two most commonly used global optimization frameworks— namely, branch-and-bound (B&B) [150] and branch-and-cut (B&C) [151]—in Section IV-A. These frameworks underlie all the problem-specific global techniques surveyed in this section. Then, we review two vital components, bounds and cuts, within the above two frameworks. Specifically, we use a class of complex quadratic problems (CQPs) as an example to illustrate how to derive tight bounds in the B&B framework by employing the SDR technique in Section IV-B, use mixed monotonic programming (MMP) as an example to illustrate how to get efficient bounds in the B&B framework by exploiting the problem structure in Section IV-C, and use a class of mixed-integer problems as an example to illustrate how to generate valid cuts in the B&C framework in Section IV-D.  

# A. Introduction to B&B and B&C Frameworks  

In this section, we briefly introduce the B&B and B&C frameworks, which are the two most popular frameworks for designing global optimization algorithms. All of the problemspecific global optimization algorithms and techniques to be surveyed in Sections IV-B to IV-D lie within the above two frameworks.  

1) B&B Algorithmic Framework: The B&B algorithmic framework is an implicit enumeration procedure that employs a tree search strategy. During the enumeration procedure, the feasible region of unexplored nodes stored in a tree is partitioned into smaller subregions, and children subproblems over the partitioned subregions are explored recursively. Pruning rules are used to eliminate regions of the search space that cannot lead to a better solution. Once all nodes in the tree have been explored, the global solution is found and returned.  

Let us use the following example to illustrate how the B&B algorithmic framework works. Consider an optimization problem of minimizing the objective function $f$ over the feasible set $\mathcal { Z }$ . The goal of B&B is to find the global solution of  

$$
\mathbf { z } ^ { * } \in \arg \operatorname* { m i n } _ { \mathbf { z } \in \mathcal { Z } } f ( \mathbf { z } ) .
$$  

To do so, B&B builds a search tree of subproblems (i.e., the problem list $\mathcal { P }$ ) defined over subsets of the search space in an iterative fashion. More specifically, at each iteration, the algorithm selects a new subproblem defined over the set $\mathcal { Z } ^ { \prime } \subset$ $\mathcal { Z }$ to explore from the unexplored problem list $\mathcal { P }$ :  

• If a solution $\mathbf { z } ^ { \prime } \in \mathcal { Z } ^ { \prime }$ can be found (e.g., by some local optimization/heuristic algorithm) with a better objective value than the best known feasible solution, called the incumbent solution, then the incumbent solution is updated to be $\mathbf { z } ^ { \prime }$ .   
• Otherwise, – if no solution better than the incumbent solution exists in $\mathcal { Z } ^ { \prime }$ , then the corresponding subproblem is pruned; – else, children subproblems are generated by partitioning $\mathcal { Z } ^ { \prime }$ into a set of subproblems defined over $\left\{ \mathcal { Z } _ { t } ^ { \prime } \right\} _ { t = 1 } ^ { \tilde { T } }$ and the newly obtained subproblems are added to the problem list $\mathcal { P }$ .  

The above procedure terminates until the problem list $\mathcal { P }$ becomes empty, and the incumbent solution is returned as the global solution.  

The steps of a vanilla B&B algorithm for solving problem (48) with a continuous variable $\textbf { z }$ are summarized as follows:  

(i) Initialize an outer box $\mathcal { M } _ { 0 } \supseteq \mathcal { Z }$ and a tolerance $\epsilon > 0$ , set the incumbent solution $\bar { \mathbf { z } } ^ { 0 }$ and value $\gamma _ { 0 } = f ( \bar { \bf z } ^ { 0 } )$ .   
(ii) Select box $\mathcal { M } _ { r }$ that has the smallest bound $\beta ( \mathcal { M } _ { r } )$ (of the objective value of problem (48)) for branching, i.e., $r = \arg \operatorname* { m i n } _ { j } \beta ( \mathcal { M } _ { j } )$ .   
(iii) Bisect $\mathcal { M } _ { r }$ .   
(iv) Reduce new boxes (optional).   
(v) Compute bound $\begin{array} { r } { \beta ( \mathcal { M } ) \le \operatorname* { m i n } _ { { \bf z } \in \mathcal { M } \cap \mathcal { Z } } f ( { \bf z } ) } \end{array}$ for all new boxes $\mathcal { M }$ .   
(vi) Update the incumbent solution $\bar { \mathbf { z } } ^ { r }$ and value $\gamma _ { r } = f ( \bar { \mathbf { z } } ^ { r } )$ .   
(vii) Delete infeasible ${ \mathcal { M } } \cap { \mathcal { Z } } = \emptyset ,$ ) and suboptimal (i.e., $\beta ( \mathcal { M } ) \ge \gamma _ { r } + \epsilon )$ new boxes.   
(viii) Terminate if no box is left or $\mathrm { m i n } _ { \mathcal { M } } \beta ( \mathcal { M } ) \geq \gamma _ { r }$ . Then, $\bar { \mathbf { z } } ^ { r }$ is a global $\epsilon$ -optimal solution.  

Due to their modularity, B&B algorithms are very flexible. The design choices comprise the subdivision procedure, the selection step, the bounding step, the reduction procedure, the feasibility check, and the finding of a feasible point. They need to be adapted to the properties and context of the considered global optimization problem. For a detailed overview of B&B algorithms, please refer to the survey paper [150] and the textbook [152].  

Several remarks on the above B&B algorithmic framework are in order. First of all, it is simple to see that the algorithm actually implicitly enumerates all the feasible solutions via a tree search strategy and hence the global optimality of the returned solution is guaranteed. However, the worst-case complexity of the B&B algorithmic framework is generally exponential. In particular, the worst-case complexity of any B&B algorithm in the above framework is $\mathcal { O } \left( C T ^ { d } \right)$ [150], where $T$ is the maximum number of generated children at any node, $d$ is the length of the longest path from the root of the tree to a leaf, and $C$ is the upper bound on the complexity of exploring/solving each subproblem. The length $d$ here usually depends on the given error tolerance $1 / \epsilon$ .  

Second, there are usually two phases of any B&B algorithm. The first is the search phase, where the algorithm seeks the (nearly) global solution. The second is the verification phase, in which the algorithm verifies that the found incumbent solution (in the first phase) is indeed (nearly globally) optimal. Note that an incumbent solution cannot be proven to be globally optimal if the unexplored problem list is nonempty. The verification of the global optimality of the incumbent solution is the price that needs to be paid in global optimization, which is unnecessary in local optimization.  

Last but not least, the pruning rule employed in the B&B algorithm plays an essential role in its computational efficiency. In particular, if there is no solution better than the incumbent solution, then the corresponding subproblem can be safely pruned from the problem list and all of its children problems do not need to be explored. Therefore, an efficient pruning rule is helpful in reducing the total number of explored subproblems and accelerating the verification process. The most common way to prune is to compute a lower bound on the objective function value of each subproblem and use it to prune those subproblems whose lower bound is worse than the objective value at the incumbent solution.  

2) B&C Algorithmic Framework: B&C is another widely used global optimization algorithmic framework for solving linear integer programs.4 A key concept in B&C is the cutting plane, also called valid cut or valid inequality. The cutting plane is defined as “a linear constraint that can be added to an integer program to tighten the feasible region without removing any integer solutions” [150] (including the optimal solution of the original problem). The B&C algorithmic framework often consists of two steps: using cutting planes to tighten the LP relaxations and running B&B. More specifically, the B&C algorithm first iteratively generates and adds cutting planes to the LP relaxation of the integer program and starts the B&B process at some point (e.g., when the number of generated cuts is too large to be added or when it is computationally expensive to generate new cuts). Note that cutting planes are generated and added gradually based on the solution of the current LP relaxation problem. If the solution is already integer, then it must be optimal to the original problem; otherwise, new cutting planes are generated to exclude the current fractional solution to tighten the LP relaxation. It is evident that the efficiency of the B&C algorithm considerably relies on the efficiency and quality of the generated cutting planes.  

In view of their central roles in global optimization algorithms, we survey some recent advances in problem-specific pruning rules and cutting planes for wireless communication system design. In particular, we review recent advances in deriving high-quality lower bounds for a class of CQPs by employing the SDR technique in Section IV-B, efficiently computing lower bounds for the MMP problems by using the problem’s monotonicity structure in Section IV-C, and generating valid cutting planes for a class of mixed-integer problems in Section IV-D.  

# B. SDRs for a Class of CQPs  

As discussed in Section IV-A, an efficient pruning rule in the B&B algorithm is of great importance to the algorithm’s computational efficiency, and the most common way to prune is to estimate a lower bound on the (optimal) objective value of each subproblem. Since convex optimization problems possess favorable theoretical and computational properties and efficient and mature solvers, the lower bound on the objective value of each subproblem is often computed by solving a convex relaxation of the corresponding subproblem. The quality of the lower bound depends on the tightness of the convex relaxation. Designing convex relaxations that provide valid lower bounds with satisfactory tightness is an important research topic in global optimization. In this subsection, we review several SDRs for a class of nonconvex CQPs developed in [153].  

We consider the following general CQP as in [153]:  

$$
\begin{array} { r l } & { \underset { \mathbf { x } \in \mathbb { C } ^ { n } } { \operatorname* { m i n } } ~ \mathbf { x } ^ { \dagger } \mathbf { Q } \mathbf { x } } \\ & { \quad \mathrm { s . t . } ~ \ell _ { i } \leq \left| x _ { i } \right| \leq u _ { i } , ~ i = 1 , 2 , \ldots , n , } \\ & { \quad \quad \quad \quad \quad \mathrm { a r g } ( x _ { i } ) \in \mathcal { A } _ { i } , ~ i = 1 , 2 , \ldots , n , } \end{array}
$$  

where $\mathbf { x } = [ x _ { 1 } , x _ { 2 } , \ldots , x _ { n } ] ^ { \mathsf { T } } \in \mathbb { C } ^ { n }$ is the $n$ -dimensional complex (unknown) variable; $\ell _ { i }$ and $u _ { i }$ $( i = 1 , 2 , \dotsc , n )$ satisfying $u _ { i } \geq \ell _ { i } \geq 0$ are $2 n$ real numbers; $\mathbf { \mathcal { A } } _ { i }$ $( i = 1 , 2 , \dotsc , n )$ is either an interval of the form $[ \underline { { \theta } } _ { i } , \bar { \theta } _ { i } ] \subseteq [ 0 , 2 \pi )$ or a set of discrete points of the form $\{ \theta _ { i } ^ { 1 } , \theta _ { i } ^ { 2 } , \ldots , \theta _ { i } ^ { M } \} \ \subseteq \ [ 0 , 2 \pi )$ ; and $\arg ( \cdot )$  

denotes the argument of a complex number. Many problems arising from wireless communications and signal processing can be formulated as problem (49) with special choices of $\ell _ { i } , \ u _ { i }$ , and $\mathbf { \mathcal { A } } _ { i }$ $( i = 1 , 2 , \ldots , n )$ ; see [153, Section II] and the references therein. For example, the argument constraints are useful for specifying the phases of the symbols to be detected in the MIMO detection problem, or for specifying regions for branching in B&B.  

The difficulty of developing an SDR for CQP (49) that can provide a good lower bound lies in its last argument constraint. Indeed, an SDR for CQP (49) with the argument constraint dropped is also an SDR for the problem itself. However, the bound provided by the above naive SDR is generally not tight enough. The idea of developing an enhanced SDR for CQP (49) in [153] is to represent the complex variable in polar coordinates and derive valid inequalities by exploiting the special structure of the argument constraint under the polar-coordinate representation. More specifically, we introduce the polarcoordinate representation of each variable $x _ { i } = r _ { i } \exp ( \mathrm { i } \theta _ { i } )$ and a lifted matrix $\textbf { X } = \textbf { x x } ^ { \dagger } \ \in \ \mathbb { C } ^ { n \times n }$ . Then, for each $i = 1 , 2 , \dots , n$ , we get  

$$
X _ { i i } = r _ { i } ^ { 2 } ~ \mathrm { a n d } ~ \theta _ { i } \in \mathcal { A } _ { i } .
$$  

We now relax the two types of nonconvex constraints in (50) in order to obtain a convex relaxation of CQP (49).  

First, for each $i = 1 , 2 , \dots , n$ , consider the nonconvex set  

$$
\begin{array} { r } { \mathcal { S } _ { i } : = \left\{ ( X _ { i i } , r _ { i } ) \ : | \ : X _ { i i } = r _ { i } ^ { 2 } , \ : r _ { i } \in [ \ell _ { i } , u _ { i } ] \right\} . } \end{array}
$$  

It has been shown in [154] that the convex $\mathrm { \ h u l l ^ { 5 } }$ of $\boldsymbol { S } _ { i }$ can be represented as  

$$
\mathrm { C o n v } ( S _ { i } ) = \left\{ ( X _ { i i } , r _ { i } ) \bigg | X _ { i i } \geq r _ { i } ^ { 2 } , \right.
$$  

Second, consider the nonconvex set  

$$
\mathcal { T } _ { i } : = \Big \{ ( x _ { i } , r _ { i } ) | x _ { i } = r _ { i } e ^ { \mathrm { i } \theta _ { i } } , \theta _ { i } \in \mathcal { A } _ { i } , r _ { i } \geq 0 \Big \} .
$$  

We have the following results on the convex hull of $\mathcal { T } _ { i }$ [153]. In particular, for the continuous case where $\begin{array} { r } { A _ { i } \ = \ [ \underline { { \theta } } _ { i } , \bar { \theta } _ { i } ] \ \subseteq } \end{array}$ $[ 0 , 2 \pi )$ , we have  

$$
\mathrm { C o n v } ( \mathcal { T } _ { i } ) = \left\{ ( x _ { i } , r _ { i } ) \bigg | a _ { i } \mathrm { R e } \left( x _ { i } \right) + b _ { i } \mathrm { I m } \left( X _ { i } \right) \right\} ,
$$  

where  

$$
\begin{array} { l } { { a _ { i } = \displaystyle \cos \left( \frac { \theta _ { i } + \bar { \theta } _ { i } } { 2 } \right) , ~ b _ { i } = \sin \left( \frac { \theta _ { i } + \bar { \theta } _ { i } } { 2 } \right) , } } \\ { { c _ { i } = \displaystyle \cos \left( \frac { \bar { \theta } _ { i } - \underline { { { \theta } } } _ { i } } { 2 } \right) ; } } \end{array}
$$  

for the discrete case where $\mathcal { A } _ { i } = \{ \theta _ { i } ^ { 1 } , \theta _ { i } ^ { 2 } , \dots , \theta _ { i } ^ { M } \}$ with $0 \leq$ $\theta _ { i } ^ { 1 } < \theta _ { i } ^ { 2 } < \cdot \cdot \cdot < \theta _ { i } ^ { M } < 2 \pi$ , we have  

$$
\operatorname { C o n v } ( \mathcal { T } _ { i } ) = \left\{ ( x _ { i } , r _ { i } ) \begin{array} { l l } { \displaystyle \left| a _ { i } ^ { m } \mathrm { R e } \left( x _ { i } \right) + b _ { i } ^ { m } \mathrm { I m } \left( x _ { i } \right) \right. } \\ { \displaystyle \left. \leq c _ { i } ^ { m } r _ { i } , m = 1 , 2 , . . . , M \right\} , } \end{array} \right.
$$  

5The convex hull of a set is the smallest convex set that contains the given set.  

where $\theta _ { i } ^ { M + 1 } = \theta _ { i } ^ { 1 } + 2 \pi$ and  

$$
\begin{array} { l } { { a _ { i } ^ { m } = \cos \left( \frac { \theta _ { i } ^ { m } + \theta _ { i } ^ { m + 1 } } { 2 } \right) , \ b _ { i } ^ { m } = \sin \left( \frac { \theta _ { i } ^ { m } + \theta _ { i } ^ { m + 1 } } { 2 } \right) , } } \\ { { c _ { i } ^ { m } = \cos \left( \frac { \theta _ { i } ^ { m + 1 } - \theta _ { i } ^ { m } } { 2 } \right) . } } \end{array}
$$  

The valid cuts shown in (53) and (54) have been named argument cuts in [155], [156] because they exploit the structure of the argument constraint. An illustration of the argument cuts in (53) and (54) can be found in [153, Fig. 1]. Putting all of the above together, we obtain the enhanced SDR for CQP (49) as follows [153]:  

$$
\begin{array} { r l } & { \underset { \mathbf { x } , \mathbf { r } , \mathbf { x } } { \mathrm { m i n } } \mathrm { t r } ( \mathbf { Q } \mathbf { X } ) } \\ & { \quad \mathrm { s . t . } \ell _ { i } \leq r _ { i } \leq u _ { i } , i = 1 , 2 , \ldots , n , } \\ & { \quad \quad \quad ( X _ { i i } , r _ { i } ) \in \mathrm { C o n v } ( S _ { i } ) , i = 1 , 2 , \ldots , n , } \\ & { \quad \quad ( x _ { i } , r _ { i } ) \in \mathrm { C o n v } ( \mathcal { T } _ { i } ) , i = 1 , 2 , \ldots , n , } \\ & { \quad \quad \quad \mathbf { X } \succeq \mathbf { x } \mathbf { x } ^ { \dagger } . } \end{array}
$$  

The SDR in (55) is closely related to other types of SDRs in the literature, e.g., [154], [157], [158]. An SDR for an even more general CQP than (49) is provied in [158, Section 3]. As an extreme case where CQP (49) reduces to the MIMO detection problem (14) with $ { \boldsymbol { S } } \ = \  { \boldsymbol { S } } _ { L }$ , the corresponding SDR in (55) then reduces to (CSDP2) in [157]. Thanks to the argument cuts in (54), (CSDP2) is shown to be tight6 for the general case where $L \ge 3$ if the condition $\lambda _ { \operatorname* { m i n } } ( \mathbf { H } ^ { \dagger } \mathbf { H } ) \sin ( \pi / L ) \geq \| \mathbf { H } ^ { \dagger } \mathbf { z } \| _ { 1 }$ holds true. The above sufficient condition for (CSDP2) in [157] to be tight is intuitive. It basically says that if the channel matrix $\mathbf { H }$ is well conditioned and if the constellation level $L$ and the level of the noise $\textbf { z }$ are not too large, then solving the corresponding SDR can find the global solution of problem (14), which is also the true vector of transmitted signals s in (11).  

As a final remark on the use of the argument cuts in (53) and (54) and the SDR in (55) to deal with nonconvex CQPs, we note that significant efforts have been made in the literature to design efficient global optimization algorithms for this class of problems. Among them, [155] and [153] are most closely related to wireless communication applications. In particular, the argument cuts (53) have been embedded in the B&B framework in [155] to globally solve the NP-hard single-group multicast problem; efficient B&B algorithms based on the argument cuts (53) and (54) have been developed in [153] to solve a class of nonconvex CQPs with signal processing and wireless communication applications. When applied to solve the MIMO detection problem (14) with ${ \boldsymbol { \mathcal { S } } } = { \boldsymbol { \mathcal { S } } } _ { L }$ , the proposed global optimization algorithm in [153] significantly outperforms the state-of-the-art tailored global optimization algorithm in the hard cases (where the number of inputs and outputs is equal or the SNR is low).  

# C. Mixed Monotonic Programming  

In this subsection, we continue with the discussion on computing a valid lower bound on the optimal objective value  

6The tightness of the SDR here means that the gap between the SDR and problem (14) is zero and the SDR recovers the true vector of transmitted signals.  

of each subproblem in order to do efficient pruning in the B&B algorithmic framework. In Section IV-B, lower bounds are derived by developing convex relaxations of the corresponding subproblems that are as tight as possible. However, the computational cost of solving the convex relaxation problems (e.g., the SDP in (55)) might be high. Different from the previous subsection, the goal of this subsection is to derive the lower bound on the optimal objective value of each subproblem with a low computational cost to achieve high computational efficiency in computing the lower bound. This is possible when the problem at hand has certain special structure, e.g., monotonicity and mixed monotonicity. In particular, we use the MMP problem [159] as an example to illustrate how to exploit the monotonicity structure in MMP problems to obtain an easily computable lower bound. The results in this subsection are mainly from [159].  

We use problem (48) as our example again, where the objective function $f : \mathbb { R } ^ { n } \to \mathbb { R }$ is assumed to be continuous and the feasible set $\mathcal { Z }$ is assumed to be compact (i.e., closed and bounded). A given function $F \colon \mathbb { R } ^ { n } \times \mathbb { R } ^ { n } \to \mathbb { R }$ is called a mixed monotonic function if it satisfies  

$$
\begin{array} { r l } & { F ( \mathbf { z } , \mathbf { w } ) \leq F ( \mathbf { z } ^ { \prime } , \mathbf { w } ) , \ \forall \ \mathbf { z } \leq \mathbf { z } ^ { \prime } , } \\ & { F ( \mathbf { z } , \mathbf { w } ) \geq F ( \mathbf { z } , \mathbf { w } ^ { \prime } ) , \ \forall \ \mathbf { w } \leq \mathbf { w } ^ { \prime } . } \end{array}
$$  

Moreover, problem (48) is said to be an MMP problem if its objective function $f$ satisfies $f ( { \bf z } ) = F ( { \bf z } , { \bf z } )$ for all $\textbf { z }$ , where $F ( \cdot , \cdot )$ is some mixed monotonic function defined in (a set containing) its feasible region. For the MMP problem, the lower bound can be easily obtained over rectangular sets. To be specific, let $B = [ \boldsymbol { \ell } , { \mathbf { u } } ]$ . Then  

$$
\operatorname* { m i n } _ { \mathbf { z } \in B \cap \mathcal { Z } } f ( \mathbf { z } ) \geq \operatorname* { m i n } _ { \mathbf { z } \in B } F ( \mathbf { z } , \mathbf { z } ) \geq \operatorname* { m i n } _ { \mathbf { z } , \mathbf { w } \in B } F ( \mathbf { z } , \mathbf { w } ) \geq F ( \boldsymbol { \ell } , \mathbf { u } )
$$  

gives a lower bound on the optimal objective value of the subproblem defined over $B \cap { \mathcal { Z } }$ , i.e., $\scriptstyle \operatorname* { m i n } _ { \mathbf { z } \in B \cap \mathcal { Z } } f ( \mathbf { z } )$ .  

Below we apply the MMP framework to globally solve the sum-rate maximization problem in the $K$ -user interference channel. In fact, all we need to do is to find an MMP representation of the objective function of the interested problem and all the others are standard B&B components.7 The sumrate maximization problem takes a similar form as problem (17) but with all scheduling variables $\left\{ \kappa _ { i } \right\}$ being given and fixed. For ease of presentation, we explicitly write down the rate expression of user $k$ as follows:  

$$
r _ { k } ( \mathbf { p } ) = \log _ { 2 } \left( 1 + \frac { \alpha _ { k } p _ { k } } { \sigma _ { k } ^ { 2 } + \sum _ { j \in \mathcal { K } } \beta _ { k j } p _ { j } } \right) ,
$$  

where $p _ { k }$ is the transmit power of user $k$ , $\alpha _ { k } \geq 0$ is the gain of the intended channel, and $\beta _ { k j } \ge 0$ is the gain of the unintended channel for $j \neq k$ . In the above, $\beta _ { k k } \ge 0$ is included for modeling the self-interference or hardware impairment. It is simple to verify that  

$$
R _ { k } ( \mathbf { p } , \mathbf { q } ) = \log _ { 2 } \left( 1 + \frac { \alpha _ { k } p _ { k } } { \sigma _ { k } ^ { 2 } + \beta _ { k k } p _ { k } + \sum _ { j \neq k } \beta _ { k j } q _ { j } } \right)
$$  

7There are two implementations of MMP including the complete B&B algorithm available. The first is a $^ { C + + }$ implementation available at https: //github.com/bmatthiesen/mixed-monotonic. The second provides a Python framework for disciplined programming with MMP and B&B, which can be easily applied and extended https://github.com/Ciaoc/mmp framework.  

is an MMP representation of $r _ { k } ( \mathbf { p } )$ in (57). With the lower bounds provided by the above representation, the sum-rate maximization problem can now be globally solved by utilizing the MMP framework [159, Algorithm 1].  

It is worth mentioning the other existing global optimization algorithms for solving the same sum-rate maximization problem and comparing them with the MMP framework. One global algorithm is MAPEL [160], which approximates the original problem from outside by means of the polyblock algorithm (PA) [161]. Another one is to use the monotonic optimization framework [161], which first rewrites $r _ { k } ( \mathbf { p } )$ in (57) into difference-of-monotonic (DM) functions  

$$
\begin{array} { l } { { \displaystyle r _ { k } ^ { \mathrm { D M } } ( { \bf p } ) = \log _ { 2 } \left( \alpha _ { k } p _ { k } + \sigma _ { k } ^ { 2 } + \sum _ { j \in K } \beta _ { k j } p _ { j } \right) } } \\ { { \displaystyle ~ - \log _ { 2 } \left( \sigma _ { k } ^ { 2 } + \sum _ { j \in K } \beta _ { k j } p _ { j } \right) } } \end{array}
$$  

and applies the B&B algorithm to solve the reformulated DM problem. It is interesting and somewhat surprising that the MMP bound is always better than the DM bound when they are applied to solve the sum-rate maximization problem. Again, the convergence speed of the B&B algorithm depends strongly on the quality of the bounds, and tighter bounds generally lead to faster global optimization. This explains why the MMP algorithm [159] outperforms the B&B algorithm equipped with the DM bound [161] for solving the sum-rate maximization problem.  

We conclude this subsection with further remarks on the MMP framework and representation. First, the MMP framework covers many existing problem formulations and frameworks as special cases, among which the most well-known one is the so-called DM programs, i.e., problem (48) where the objective function $f$ can be written as $f = f ^ { + } - f ^ { - }$ with both of $f ^ { + }$ and $f ^ { - }$ being nondecreasing functions. An MMP representation of the objective function in DM programs is $F ( \mathbf { z } , \mathbf { w } ) = f ^ { + } ( \mathbf { z } ) - f ^ { - } ( \mathbf { w } )$ . Second, the MMP representation is not unique. In particular, if $F ( \mathbf { z } , \mathbf { w } )$ is an MMP representation of $f ( \mathbf { z } )$ , then  

$$
\tilde { F } ( \mathbf { z } , \mathbf { w } ) = F ( \mathbf { z } , \mathbf { w } ) + \sum _ { i } \left( z _ { i } - w _ { i } \right)
$$  

is also an MMP representation of $f ( \mathbf { z } )$ . However, different MMP representations will lead to different bounds. A subtlety here is how to choose the MMP representation that leads to the tightest bound. Finally, we refer the reader to [159] for more detailed discussions on the MMP framework, including the functional operations that preserve the mixed monotonic properties and more application examples in wireless communication system design.  

# D. Valid Cuts for Mixed-Integer Problems  

Generating valid inequalities to strengthen the relaxation of a mixed-integer problem (MIP) is generally nontrivial, as it requires a judicious exploitation of the problem’s special structure in order to tighten the corresponding relaxation yet without excluding the true solution. For mixed linear integer programs (MILPs), many different types of valid inequalities have been investigated in the literature. In particular, Gomory cuts [162] have been extensively studied and included in all modern MIP solvers (e.g., Gurobi, CPLEX, and SCIP) due to its capability of significantly improving the solvers’ practical numerical performance. Surveys on valid inequalities for general MIPs can be found in [163], [164]. In this subsection, we use MIPs coming from wireless communication system design as examples to illustrate how to exploit structural information in the corresponding problems to generate valid inequalities. The results in this subsection are mainly from [47].  

Consider the JABF problem (16). Compared to relaxing both the binary variables and the nonconvex quadratic constraints in (16) as in [46], an arguably better way is to keep the binary variables unchanged and apply the SDR to the nonconvex quadratic constraints, which leads to the following mixedinteger SDR:  

$$
\begin{array} { r l } { \displaystyle \min } & { \displaystyle \mathrm { m i n ~ t r } ( \tilde { \mathbf { W } } ) } \\ { \displaystyle \quad \mathrm { s . t . ~ } \operatorname { t r } ( \tilde { \mathbf { H } } _ { k } \tilde { \mathbf { W } } ) \geq \beta _ { k } , ~ k \in { \mathcal { K } } , } \\ { \displaystyle } & { \displaystyle \sum _ { k \in { \mathcal { K } } } \beta _ { k } \geq \hat { K } , ~ \beta _ { k } \in \{ 0 , 1 \} , ~ k \in { \mathcal { K } } , } \\ { \displaystyle } & { \displaystyle \tilde { \mathbf { W } } \succeq \mathbf { 0 } , } \end{array}
$$  

where $\begin{array} { r } { \tilde { \mathbf { W } } = [ \mathbf { W } \mathbf { \Sigma }  \quad \mathbf { w } ] \in \mathbb { S } _ { + } ^ { M + 1 } } \end{array}$ and $\tilde { \mathbf { H } } _ { k } = \left[ \begin{array} { c c } { \mathbf { h } _ { k } \mathbf { h } _ { k } ^ { \dagger } } & { \mathbf { 0 } } \\ { \mathbf { 0 } } & { 1 } \end{array} \right] \in$ S+M+1 for all k ∈ K. In the following, we focus on designing a B&C algorithm for globally solving problem (60). Then, based on the solution we can apply the Gaussian randomization procedure to obtain a feasible solution to the JABF problem (16) with a provable guarantee [47, Theorem 2].  

The first step in the design of a B&C algorithm for solving mixed-integer SDR (60) is to find a relaxation of the problem. This can be easily achieved due to the following fact: For any $\mathcal { T } \subset \mathbb { S } _ { + } ^ { M }$ , the constraint  

$$
\operatorname { t r } ( \mathbf { T } \mathbf { W } ) - \mathbf { w } ^ { \dagger } \mathbf { T } \mathbf { w } \geq 0 , \ \mathbf { T } \in \mathcal { T }
$$  

is an outer approximation of the last constraint $\tilde { \textbf { W } } \succeq \textbf { 0 }$ in (60). As such, for any given $\mathcal { T } \subset \mathbb { S } _ { + } ^ { M }$ , the problem  

$$
\begin{array} { r l } { \displaystyle \min _ { \bf \phi } \mathrm { t r } ( \tilde { \bf W } ) } & { } \\ { \displaystyle \quad \mathrm { s . t . } ~ \mathrm { t r } ( \tilde { \bf H } _ { k } \tilde { \bf W } ) \geq \beta _ { k } , ~ k \in { \cal K } , } \\ { \displaystyle \quad } & { \displaystyle \sum _ { k \in { \cal K } } \beta _ { k } \geq \hat { \cal K } , ~ \beta _ { k } \in \{ 0 , 1 \} , ~ k \in { \cal K } , } \\ { \displaystyle } & { \displaystyle \mathrm { t r } ( { \bf T } { \bf W } ) - { \bf w } ^ { \dagger } { \bf T } { \bf w } \geq 0 , ~ { \bf T } \in { \cal T } } \end{array}
$$  

is a relaxation of problem (60). Moreover, with the decomposition $\mathbf { T } = \mathbf { U } \mathbf { U } ^ { \dagger }$ at hand, each constraint in (61) can be expressed as the SOC constraint  

$$
\left\| \left[ \mathbf { 1 } - \operatorname { t r } ( \mathbf { T W } ) \right] \right\| \leq 1 + \operatorname { t r } ( \mathbf { T W } ) .
$$  

If the chosen set $\tau$ in (62) is a finite set of $\mathbb { S } _ { + } ^ { M }$ , then the problem is a mixed-integer SOCP, which can be efficiently solved (e.g., by Gurobi).  

The second step in the design of a B&C algorithm for globally solving mixed-integer SDR (60) is to iteratively generate valid inequalities and add them in (62) to tighten the relaxation. More specifically, after obtaining an optimal solution $( \tilde { \bf W } _ { \mathcal { T } } , \beta _ { \mathcal { T } } )$ of problem (62), we solve problem (60) with $\beta = \beta _ { \tau }$ , i.e.,  

$$
\begin{array} { r l } & { \underset { \tilde { \mathbf { W } } } { \mathrm { m i n ~ t r } } ( \tilde { \mathbf { W } } ) } \\ & { \mathrm { s . t . ~ } \ \mathrm { t r } ( \tilde { \mathbf { H } } _ { k } \tilde { \mathbf { W } } ) \geq [ \beta _ { \tau } ] _ { k } , \ k \in \mathcal { K } , } \\ & { \quad \quad \quad \tilde { \mathbf { W } } \succeq \mathbf { 0 } , } \end{array}
$$  

which is an inner approximation of problem (60). The SDP (63) plays a central role in the design of the B&C algorithm, as solving the SDP either verifies the global optimality of the incumbent solution $\beta _ { \tau }$ or generates a valid inequality to eliminate $\beta _ { T }$ and tighten the relaxation if $\beta _ { T }$ is not optimal. In particular, we check the integrality gap (i.e., the difference between the optimal values) of problems (63) and (62). If the gap is zero, then $( \tilde { \bf W } _ { \mathcal { T } } , \beta _ { \mathcal { T } } )$ is the optimal solution of problem (60); otherwise a valid inequality $\mathbf { T }$ is generated based on the dual information of the SDP (63) and added to $\tau$ to strengthen the relaxation problem (62) [47, Proposition 1]. Specifically, if the SDP (63) is feasible, then let  

$$
\tilde { \mathbf { T } } = \left[ \begin{array} { l l } { \mathbf { T } } & { \mathbf { \Delta t } } \\ { \mathbf { t ^ { \dagger } } } & { \mathbf { \Delta } t } \end{array} \right] \in \mathbb { S } _ { + } ^ { M + 1 }
$$  

be the optimal Lagrange multiplier corresponding to the constraint $\tilde { \textbf { W } } \succeq \bar { \textbf { 0 } }$ ; if not, then there exists a $\begin{array} { r l } { \lambda ^ { * } } & { { } = } \end{array}$ $[ \lambda _ { 1 } ^ { * } , \lambda _ { 2 } ^ { * } , \ldots , \lambda _ { K } ^ { * } ] ^ { \mathsf { T } }$ such that $\begin{array} { r } { \tilde { \mathbf { T } } = \sum _ { k } \lambda _ { k } ^ { * } \tilde { \mathbf { H } } _ { k } } \end{array}$ and $( \lambda ^ { * } ) ^ { \mathsf { T } } \beta _ { \mathcal { T } } <$ 0.  

Since the total number of feasible binary solutions of problem (60) is finite and one binary solution is eliminated at each iteration, the above B&C algorithm will return an optimal solution of problem (60) in a finite number of iterations. In the above algorithm, problems (63) and (62) are two important subproblems, which need to be solved at each iteration and are closely related. In particular, solving problem (62) can return a subset of users to serve based on which problem (63) is defined; solving problem (63) is to find the multicast beamforming vector to support the selected subset of users and solving it either verifies the optimality of the selected subset of users or returns a valid inequality for problem (62) that cuts off the current suboptimal or infeasible solution. In the above algorithm, problem (62) acts like a leader while problem (63) acts like a follower. Therefore, these two problems are named the master and follower problems in the literature. The above technique and idea can be extended to solve many other problems involving mixed-integer variables. For instance, an efficient global algorithm has been proposed for solving largescale mixed-integer network slicing (NS) problems [165]. The algorithm proceeds by decomposing the original NS problem into the relatively easy function placement and traffic routing subproblems and iteratively solving these subproblems using the information obtained from each other.  

# V. DISTRIBUTED OPTIMIZATION AND FEDERATED LEARNING  

In the past decade, distributed optimization methods have garnered significant attention in wireless communications [166], [167]. These methods provide the potential for scalability and efficiency by allowing multiple entities to solve global optimization problems using localized computations collectively. For example, in multi-cell coordinated systems or cell-free MIMO systems, the BSs collaborate to mitigate inter-cell interference, so as to improve the QoS of cell-edge users. In contrast to centralized optimization methods, which require all users’ CSI to be pooled at a central node, distributed optimization methods can provide certain advantages such as reducing the backhaul information exchange [168], [169] and providing robustness against time-varying environments [170]. Since distributed optimization methods can usually be implemented in parallel, they are also low-complexity alternatives (in terms of computational time) for solving some large-scale wireless communication system design problems. Below, in Section V-A, we present two distributed optimization methods—namely, the dual decomposition method [171] and the alternating direction of method of multipliers (ADMM) [172]—and also their variants [173]–[176], which are often adopted in distributed wireless designs. We then demonstrate their applications in multi-cell coordinated beamforming.  

Distributed optimization methods will play an important role in future wireless networks. For example, edge intelligence, which leverages the capabilities of AI at the network’s edge, is considered as a pivotal element of next-generation wireless networks [177]. In intelligent edge networks, AI services are not limited to centralized data centers but extend to edge nodes, enabling real-time decision-making and latency reduction. This is a vital technology for emerging applications like autonomous vehicles and augmented reality, which demand ultra-low latency and high reliability. Federated learning (FL) is a key enabler of edge intelligence. FL is a distributed optimization methodology employed in wireless networks for collaborative AI model training across distributed edge devices. Compared to the cloud-based centralized learning paradigm, FL does not require users’ data to be collected at the cloud center and therefore provides enhanced data privacy and security at the network’s edge [178]. However, efficient implementation of FL is challenging because the learning process would involve iterative communications between the edge server and a massive number of user clients. Besides, the local data owned by the clients may have different statistical distributions, which can greatly degrade the learning performance [179]. In Section V-B, from the distributed optimization perspective, we review the seminal FL algorithm FedAvg [180] and present its variants [181], [182] that aim to improve the learning performance in heterogeneous edge networks.  

# A. Decomposition Methods  

1) Dual Decomposition, ADMM, and Their Variants: Dual decomposition [171], [172] is a simple method to obtain a decentralized algorithm for convex optimization problems with separable structures. Specifically, consider the problem  

$$
\begin{array} { l } { \displaystyle \underset { \mathbf { x } } { \mathrm { m i n } } \ \displaystyle \sum _ { i = 1 } ^ { n } f _ { i } ( \mathbf { x } _ { i } ) } \\ { \mathrm { s . t . } \ \mathbf { x } _ { i } \in \mathcal { X } _ { i } , i = 1 , 2 , \ldots , n , } \\ { \displaystyle \quad \quad \mathbf { A } \mathbf { x } = \mathbf { b } , } \end{array}
$$  

where $\{ f _ { i } \}$ are convex functions, $\{ \mathcal { X } _ { i } \}$ are given convex sets, $\mathbf { A } = [ \mathbf { A } _ { 1 } , \mathbf { A } _ { 2 } , \ldots , \mathbf { A } _ { n } ]$ are given matrices, and ${ \textbf { x } } =$ $[ \mathbf { x } _ { 1 } ^ { \mathsf { T } } , \mathbf { x } _ { 2 } ^ { \mathsf { T } } , \ldots , \mathbf { x } _ { n } ^ { \mathsf { T } } ] ^ { \mathsf { T } }$ is the design variable. Both the objective function $\begin{array} { r } { \mathbf { x } \mapsto \sum _ { i = 1 } ^ { n } f _ { i } \big ( \mathbf { x } _ { i } \big ) } \end{array}$ and the constraint $\mathbf { A x } \ =$ $\begin{array} { r } { \sum _ { i = 1 } ^ { n } \mathbf { A } _ { i } \mathbf { x } _ { i } \ = \ \mathbf { b } } \end{array}$ are separable with respect to $\left\{ { \bf x } _ { i } \right\}$ . The dual decomposition method aims to exploit the separable structure of problem (64) via its Lagrangian dual. Specifically, the Lagrangian dual of problem (64) decouples the problem into $n$ individual subproblems, each involves only a single variable $\mathbf { x } _ { i }$ and its associated function $f _ { i }$ and constraint matrix $\mathbf { A } _ { i }$ . This enables parallel or distributed processing of each subproblem, followed by a coordination step to ensure that the global constraint is satisfied. The obtained algorithm can be summarized as follows:  

(i) Initialization: Set $\mathbf { \nabla } \lambda ^ { 0 } = \mathbf { 0 }$ (initial Lagrange multiplier). (ii) Repeat until convergence:  

– For each $i = 1 , 2 , \dots , n$ , solve the local problem  

$$
\mathbf { x } _ { i } ^ { r + 1 } = \arg \operatorname* { m i n } _ { \mathbf { x } _ { i } \in \mathcal { X } _ { i } } \left\{ f _ { i } ( \mathbf { x } _ { i } ) + ( \mathbf { \mathbf { \mathbf { \lambda } } } ^ { \Gamma } ) ^ { \mathsf { T } } \mathbf { A } _ { i } \mathbf { x } _ { i } \right\} .
$$  

– Update the Lagrange multiplier via  

$$
\pmb { \lambda } ^ { r + 1 } = \pmb { \lambda } ^ { r } + \alpha _ { r } ( \mathbf { A } \mathbf { x } ^ { r + 1 } - \mathbf { b } ) ,
$$  

where $\alpha _ { r }$ is a step size.  

In general (e.g., when problem (64) is not strictly convex), tohuetputp $\{ \mathbf { x } _ { 1 } ^ { r + 1 } , \mathbf { x } _ { 2 } ^ { r + 1 } , \ldots , \mathbf { x } _ { n } ^ { r + 1 } \}$ lioswnoctognuvaeragnetneced. oBebseidfesa, tbhle (i.e., satisfying $\mathbf { A x } = \mathbf { b } $ ) [172]. Though being simple, due to these issues, the dual decomposition method may become unfavorable in practice.  

The ADMM is an improved decomposition method that relaxes the strict convexity assumption and has a faster convergence rate. The vanilla version of ADMM considers an optimization problem of the following form  

$$
\underset { { \bf x } \in \mathcal { X } , { \bf z } \in \mathcal { Z } } { \operatorname* { m i n } } ~ f ( { \bf x } ) + g ( { \bf z } )
$$  

where $f$ and $g$ are convex functions, and A and $\mathbf { B }$ are given matrices. The ADMM is an iterative method that splits this problem into simpler subproblems, which can then be solved in a decoupled or even parallel fashion. Unlike the dual decomposition method, the ADMM considers the augmented Lagrangian  

$$
\begin{array} { l } { \displaystyle \mathcal { L } ( \mathbf { x } , \mathbf { z } , \lambda ) = ~ f ( \mathbf { x } ) + g ( \mathbf { z } ) + \lambda ^ { \mathsf { T } } ( \mathbf { A } \mathbf { x } + \mathbf { B } \mathbf { z } - \mathbf { c } ) } \\ { \displaystyle + \frac { \rho } { 2 } \| \mathbf { A } \mathbf { x } + \mathbf { B } \mathbf { z } - \mathbf { c } \| ^ { 2 } , } \end{array}
$$  

where $\rho ~ > ~ 0$ is the penalty parameter. By updating the variables $\{ \mathbf { x } , \mathbf { z } \}$ in an alternating manner and applying the method of multipliers to the constraints, the ADMM converges to a solution of the original problem under mild assumptions [172]. The ADMM algorithm is given below.  

(i) Initialization: Choose initial points $\mathbf { x } ^ { 0 }$ and $ { \mathbf { z } } ^ { 0 }$ , and set $\mathbf { \nabla } \lambda ^ { 0 } = \mathbf { 0 }$ .   
(ii) Repeat until convergence:  

– Update $\mathbf { x }$ :  

$$
\mathbf { x } ^ { r + 1 } = \arg \operatorname* { m i n } _ { \mathbf { x } \in \mathcal { X } } \mathcal { L } ( \mathbf { x } , \mathbf { z } ^ { r } , \pmb { \lambda } ^ { r } ) .
$$  

– Update $\mathbf { z }$ :  

$$
\mathbf { z } ^ { r + 1 } = \arg \operatorname* { m i n } _ { \mathbf { z } \in \mathcal { Z } } \mathcal { L } ( \mathbf { x } ^ { r + 1 } , \mathbf { z } , \pmb { \lambda } ^ { r } ) .
$$  

– Update the Lagrange multiplier:  

$$
\begin{array} { r } { \pmb { \lambda } ^ { r + 1 } = \pmb { \lambda } ^ { r } + \alpha _ { r } ( \mathbf { A } \mathbf { x } ^ { r + 1 } + \mathbf { B } \mathbf { z } ^ { r + 1 } - \mathbf { c } ) . } \end{array}
$$  

(iii) Output: $\mathbf { x } ^ { r + 1 }$ and $\mathbf { z } ^ { r + 1 }$ .  

Thanks to the augmented Lagrangian, the update in (67) is an inexact gradient ascent step, enabling the ADMM to have a faster convergence rate than the dual decomposition method.  

When the objective function and the constraint have separable structures, e.g., $\begin{array} { r } { f ( \mathbf { x } ) = \sum _ { i = 1 } ^ { n } f _ { i } ( \mathbf { x } _ { i } ) } \end{array}$ , $\textstyle \mathbf { A } \mathbf { x } = \sum _ { i = 1 } ^ { n } \mathbf { A } _ { i } \mathbf { x } _ { i }$ and $\mathcal { X } = \mathcal { X } _ { 1 } \times \mathcal { X } _ { 2 } \times \cdot \cdot \cdot \times \mathcal { X } _ { n }$ , the update of $\mathbf { x }$ in (66) can be decomposed into $n$ Gauss-Seidel steps, which are given by  

$$
\mathbf { x } _ { i } ^ { r + 1 } = \arg \operatorname* { m i n } _ { \mathbf { x } _ { i } \in \mathcal { X } _ { i } } \mathcal { L } ( \mathbf { x } _ { < i } ^ { r + 1 } , \mathbf { x } _ { i } , \mathbf { x } _ { > i } ^ { r } , \mathbf { z } ^ { r } , \lambda ^ { r } )
$$  

for $i = 1 , 2 , \dots , n$ . Here, $\mathbf { x } _ { < i }$ contains all $\mathbf { x } _ { j }$ with $j ~ < ~ i$ and $\mathbf { x } _ { > i }$ contains all $\mathbf { x } _ { j }$ with $j > i$ . A disadvantage of the Gauss-Seidel update is that the variables $\left\{ { \bf x } _ { i } \right\}$ are updated one after another, which is not amenable for parallelization. To have a parallel algorithm, one can consider Jacobian-type updates. However, a direct Jacobian ADMM is not guaranteed to converge in general. To fix this, the proximal ADMM method is proposed [173], [174], [183]. Specifically, one can replace (66) by  

$$
\mathbf { x } ^ { r + 1 } = \arg \operatorname* { m i n } _ { \mathbf { x } \in \mathcal { X } } \left\{ \mathcal { L } ( \mathbf { x } , \mathbf { z } ^ { r } , \lambda ^ { r } ) + \frac { 1 } { 2 } \| \mathbf { x } - \mathbf { x } ^ { r } \| _ { \mathbf { P } } ^ { 2 } \right\} ,
$$  

where  

$$
\| \mathbf { x } _ { i } - \mathbf { x } _ { i } ^ { r } \| _ { \mathbf { P } } ^ { 2 } = ( \mathbf { x } _ { i } - \mathbf { x } _ { i } ^ { r } ) ^ { \mathsf { T } } \mathbf { P } ( \mathbf { x } _ { i } - \mathbf { x } _ { i } ^ { r } )
$$  

and $\mathbf { P }$ is a positive definite matrix. In particular, if one chooses $\mathbf { P }$ to satisfy $\mathbf { P } = c \mathbf { I } - \rho \mathbf { A } ^ { \mathsf { T } } \mathbf { A } \succ \mathbf { 0 }$ for some parameter $c > 0$ , then the update in (68) can be decomposed into $n$ parallel subproblems.  

2) Application Example: Next, we present one application of the ADMM and its variants in distributed wireless system design, which is multi-cell coordinated beamforming.  

Consider the same cellular system as in Fig. 3(b). The difference here is that data sharing is not allowed among different BSs, so as to reduce the signaling overhead. Assume that each user $k$ is assigned to a specific BS $b = b _ { k }$ and let $\mathcal { K } _ { b }$ denote the subset of users allocated to $\mathbf { B S } \ b$ . In this case, for each $k \in \mathcal { K }$ , we have $\mathbf { v } _ { k , b } = \mathbf { 0 }$ for all $b \neq b _ { k }$ . To simplify the notation in problem (7), we use $\mathbf { v } _ { k }$ to denote $\mathbf { v } _ { k , b _ { k } }$ . Then, the SINR of user $k$ is given by  

$$
\begin{array} { r l } & { \mathrm { S I N R } _ { k } = } \\ & { \frac { \left| { \bf { h } } _ { k , b _ { k } } ^ { \dagger } { \bf { v } } _ { k } \right| ^ { 2 } } { \sum _ { j \in { \cal K } _ { b _ { k } } \backslash k } \left| { \bf { h } } _ { k , b _ { k } } ^ { \dagger } { \bf { v } } _ { j } \right| ^ { 2 } + \sum _ { b \not = b _ { k } } \sum _ { i \in { \cal K } _ { b } } \left| { \bf { h } } _ { k , b } ^ { \dagger } { \bf { v } } _ { i } \right| ^ { 2 } + \sigma _ { k } ^ { 2 } } . } \end{array}
$$  

Let us introduce the inequality  

$$
\begin{array} { r } { \tau _ { k , b } \geq \sum _ { i \in \mathcal { K } _ { b } } \left| \mathbf { h } _ { k , b } ^ { \dagger } \mathbf { v } _ { i } \right| ^ { 2 } , } \end{array}
$$  

where the right-hand side denotes the inter-cell interference term from $\mathbf { B } \mathbf { S  { b } }$ to user $k$ for $k \notin \mathcal { K } _ { b }$ . Then, the SINR formula in (69) is modified as  

$$
\mathrm { S I N R } _ { k } = \frac { \left| \mathbf { h } _ { k , b _ { k } } ^ { \dagger } \mathbf { v } _ { k } \right| ^ { 2 } } { \sum _ { j \in \mathcal { K } _ { b _ { k } } \backslash k } \left| \mathbf { h } _ { k , b _ { k } } ^ { \dagger } \mathbf { v } _ { j } \right| ^ { 2 } + \sum _ { b \neq b _ { k } } \tau _ { k , b } + \sigma _ { k } ^ { 2 } } .
$$  

Therefore, the minimum power beamforming design problem under the per-user SINR constraint can be reformulated as [170], [184]  

$$
\begin{array} { r l } { \displaystyle \operatorname* { m i n } _ { \left\{ \mathbf { v } _ { k } , \tau _ { k , b } \right\} } } & { \displaystyle \sum _ { b \in \mathcal { B } } \displaystyle \sum _ { k \in \mathcal { K } _ { b } } \left\| \mathbf { v } _ { k } \right\| _ { 2 } ^ { 2 } } \\ { \mathrm { s . t . } } & { \displaystyle \mathrm { S I N R } _ { k } \geq \gamma _ { k } , \ k \in \mathcal { K } , } \\ & { \displaystyle \sum _ { i \in \mathcal { K } _ { b } } \left| \mathbf { h } _ { k , b } ^ { \dag } \mathbf { v } _ { i } \right| ^ { 2 } \leq \tau _ { k , b } , \ k \notin \mathcal { K } _ { b } , \ b \in \mathcal { B } , } \end{array}
$$  

where constraint (70c) guarantees that the inter-cell interference generated from a given BS $b$ cannot exceed the user specific thresholds $\tau _ { k , b }$ for all $k \notin \ K _ { b }$ . The above reformulation can be handled by the ADMM, which will yield a distributed algorithm.  

Observe that the BSs are coupled in the SINR constraints (70b) by the interference terms $\{ \tau _ { k , b } \}$ . By introducing local auxiliary variables and additional equality constraints, the coupling in the SINR constraints is transferred to the coupling in the equality constraints, which is easy to decouple by the dual decomposition or ADMM. Specifically, note that each inter-cell interference term $\tau _ { k , b }$ couples exactly two BSs, i.e., the serving BS $b _ { k }$ and the interfering BS for the two BSs, i.e., $b$ . Therefore, it is enough to introduce local copies of $\bar { t } _ { k , b } ^ { ( b ) }$ and $t _ { k , b } ^ { ( b _ { k } ) }$ , and enforce the two $\tau _ { k , b }$ local copies to be equal via $t _ { k , b } ^ { ( b ) } ~ = ~ \tau _ { k , b }$ and $t _ { k , b } ^ { ( b _ { k } ) } ~ = ~ \tau _ { k , b }$ [170], [185]. More compactly, define $\tau \in \mathbb { R } ^ { K ( \vec { B } - 1 ) }$ as an aggregate vector that contain all interference terms $\{ \tau _ { k , b } \}$ , and let ${ \bf t } \ = \ \left[ { { \left( { { \bf t } ^ { \left( 1 \right) } } \right) } ^ { \mathsf { T } } } , { { \left( { { \bf t } ^ { \left( 2 \right) } } \right) } ^ { \mathsf { T } } } , \ldots , { { \left( { { \bf t } ^ { \left( B \right) } } \right) } ^ { \mathsf { T } } } \right] ^ { \mathsf { T } } \ \in \ { \bf R } ^ { 2 K \left( B - 1 \right) }$ where $\mathbf { t } ^ { ( b ) }$ contains $\{ t _ { k , b } ^ { ( b ) } \} _ { k \notin { \mathcal K } _ { b } }$ and $\{ t _ { k , b ^ { \prime } } ^ { ( b ) } \} _ { k \in \mathcal { K } _ { b } , b ^ { \prime } \ne b }$ . Then, the consistency between $\mathbf { t }$ and $\tau$ can be compactly expressed using the equality $\mathbf { E } \tau = \mathbf { t }$ , where $\mathbf { E } \in \mathbb { R } ^ { 2 K ( B ^ { \bullet } - 1 ) \times ^ { \bullet } K ( B ^ { \bullet } - 1 ) }$ is a matrix whose elements are $\{ 0 , 1 \}$ that maps the elements of $\tau$ in the positions corresponding to the copies in t. Consequently, problem (70) can be reformulated as  

$$
\begin{array} { r l } { \displaystyle \min _ { \{ \mathbf { v } _ { k } \} , \mathbf { t } , \tau } } & { \displaystyle \sum _ { b \in \mathcal { B } } \displaystyle \sum _ { k \in \mathcal { K } _ { b } } \left\| \mathbf { v } _ { k } \right\| ^ { 2 } } \\ { \mathrm { s . t . ~ } } & { \mathrm { S I N R } _ { k } ^ { ( b ) } \geq \gamma _ { k } , ~ k \in \mathcal { K } _ { b } , ~ b \in \mathcal { B } , } \\ & { \displaystyle \sum _ { i \in \mathcal { K } _ { b } } \left| \mathbf { h } _ { k , b } ^ { \dagger } \mathbf { v } _ { i } \right| ^ { 2 } \leq t _ { k , b } ^ { ( b ) } , ~ k \notin \mathcal { K } _ { b } , ~ b \in \mathcal { B } , } \\ & { \mathbf { E } \tau = \mathbf { t } , } \end{array}
$$  

where the variables t(b,bk) }k / and the terms  

$$
\mathrm { S I N R } _ { k } ^ { ( b ) } = \frac { \left| { \bf h } _ { k , b } ^ { \dagger } { \bf v } _ { k } \right| ^ { 2 } } { \sum _ { j \in { \cal K } _ { b } \backslash k } \left| { \bf h } _ { k , b } ^ { \dagger } { \bf v } _ { j } \right| ^ { 2 } + \sum _ { b ^ { \prime } \neq b } t _ { k , b ^ { \prime } } ^ { ( b ) } + \sigma _ { k } ^ { 2 } }
$$  

are local for each $\boldsymbol { \mathrm { B S } } \boldsymbol { \ b }$ .  

Notice that the objective and the constraints in (71) are now separable with respect to $\{ \mathbf { v } _ { i } \} _ { i \in \mathcal { K } _ { b } }$ and $\mathbf { t } ^ { ( b ) }$ across the BSs. Thus, problem (71) can be solved distributedly at each $\mathbf { B S } \ b$ using the ADMM:  

$$
\begin{array} { r l r } { \displaystyle \operatorname* { m i n } _ { \mathbf { t } ^ { ( b ) } , \left\{ \mathbf { v } _ { k } \right\} _ { k \in \mathcal { K } _ { b } } } } & { \displaystyle \sum _ { k \in \mathcal { K } _ { b } } \left\| \mathbf { v } _ { k } \right\| ^ { 2 } + \left( \nu _ { b } \right) ^ { \mathsf { T } } \left( \mathbf { t } ^ { ( b ) } - \mathbf { E } _ { b } \boldsymbol { \tau } \right) } & \\ { \displaystyle } & { \quad \quad + \frac { \rho } { 2 } \left\| \mathbf { t } ^ { ( b ) } - \mathbf { E } _ { b } \boldsymbol { \tau } \right\| ^ { 2 } } & \\ { \mathrm { s . t . } \quad } & { \displaystyle \operatorname { S I N R } _ { k } ^ { ( b ) } \geq \gamma _ { k } , ~ k \in \mathcal { K } _ { b } , } & \\ { \quad \quad } & { \quad \sum _ { i \in \mathcal { K } _ { b } } \left| \mathbf { h } _ { k , b } ^ { \dagger } \mathbf { v } _ { i } \right| ^ { 2 } \leq t _ { k , b } ^ { ( b ) } , ~ k \notin \mathcal { K } _ { b } . } & \end{array}
$$  

Here, $\pmb { \nu } = [ \pmb { \nu } _ { 1 } ^ { \top } , \pmb { \nu } _ { 2 } ^ { \top } , \dots , \pmb { \nu } _ { B } ^ { \top } ] ^ { \top } \in \mathbb { R } ^ { 2 K ( B - 1 ) }$ is the Lagrange multiplier associated with the equality constraint $\boldsymbol \tau = \mathbf t$ in (71). Once each $\boldsymbol { \mathrm { B S } } \boldsymbol { \ b }$ obtains $\{ \mathbf { v } _ { i } \} _ { i \in \mathcal { K } _ { b } }$ and $\mathbf { t } ^ { ( b ) }$ , they will share the relevant elements within $\mathbf { t } ^ { ( b ) }$ with other BSs, which are further used to compute ${ \boldsymbol { \tau } } = \mathbf { E } ^ { + } \mathbf { t }$ , where ${ \bf E } ^ { + }$ denotes the pseudo-inverse of $\mathbf { E }$ . Then, we perform the update $\nu _ { b } \gets$ $\pmb { \nu } _ { b } \overset { - } { + } \mu \left( \mathbf { t } ^ { ( b ) } - \mathbf { E } _ { b } \pmb { \tau } \right)$ until convergence, where $\mu > 0$ is the step size to update the multiplier.  

While problem (70) can also be handled by the dual decomposition method as shown in [184], it is demonstrated in [170] that the ADMM can track the solution variation in a dynamic environment with time-varying CSI. The ADMM can also be applied, together with the SDR technique, to handle the multi-cell coordinated robust beamforming problem under imperfect CSI; see [185] for details. It is noteworthy that distributed optimization methods can also be employed to develop algorithms that leverage parallel computing resources to tackle large-scale optimization problems, such as the multiUAV power and trajectory control problem discussed in [186].  

# B. Federated Learning in Wireless Edge Networks  

Consider a wireless edge network, as illustrated in Fig. 4, where an edge server orchestrates $N$ edge clients to collaboratively address a distributed learning problem via FL. The problem of interest is given by  

$$
\operatorname* { m i n } _ { \mathbf { w } \in \mathbb { R } ^ { m } } F ( \mathbf { w } ) = \sum _ { i = 1 } ^ { N } p _ { i } F _ { i } ( \mathbf { w } ) .
$$  

Here, $p _ { i }$ represents the weight assigned to the $i$ -th client, which satisfies $p _ { i } \geq 0$ and $\begin{array} { r } { \sum _ { i = 1 } ^ { N } p _ { i } = \overline { { 1 } } } \end{array}$ . The parameter $\mathbf { w } \in \mathbb { R } ^ { m }$ signifies the $m$ -dimensional model parameter targeted for learning. The local cost function $F _ { i } ( \cdot ) = \mathbb { E } _ { \mathcal { D } _ { i } } [ \mathcal { L } ( \cdot ; \mathcal { D } _ { i } ) ]$ is the expectation of a (possibly nonconvex) loss function $\mathcal { L }$ and operates on the local dataset $\mathcal { D } _ { i }$ . The global cost function $F ( \cdot ) =$ $\mathbb { E } _ { \mathcal { D } } [ \mathcal { L } ( \cdot ; \mathcal { D } ) ]$ considers the global dataset $\textstyle { \mathcal { D } } \triangleq \bigcup _ { i = 1 } ^ { N } { \mathcal { D } } _ { i }$ . When utilizing mini-batch samples $\pmb { \xi } _ { i }$ with size $b$ , the local loss function is defined as $\begin{array} { r } { F _ { i } ( \cdot ; \pmb { \xi } _ { i } ) = \frac { 1 } { b } \sum _ { j = 1 } ^ { b } \mathcal { L } ( \cdot ; \xi _ { i j } ) } \end{array}$ , where $\xi _ { i j }$ represents the $j$ -th randomly selected sample from the dataset of client $i$ , and $\mathcal { L } ( \cdot ; \xi _ { i j } )$ is the model loss function with respect to ξij .  

![](images/101b4ed39db846da10e4fa2c04e2fac4403fde8606646ef47cb9f142714f3f12.jpg)  
Fig. 4. An illustration of an FL wireless edge network, where an edge server orchestrates multiple edge clients to solve a distributed learning problem collaboratively via FL.  

In this subsection, we first present the seminal FL algorithm FEDAVG [180] for solving problem (73) and then analyze the factors that influence its convergence performance. Finally, we present several improved FL algorithms.  

1) FEDAVG Algorithm: FEDAVG is an extension of the consensus-based distributed stochastic gradient descent (SGD) method [187] to the star network as depicted in Fig. 4. It involves three essential steps in each communication round:  

(i) Broadcasting: In the $r$ -th communication round, the server randomly chooses $K$ clients, represented by the set $\textstyle \mathcal { K } _ { r }$ , where $| \mathcal { K } _ { r } | = K$ . It then broadcasts the global model $\bar { \mathbf { w } } ^ { r - 1 }$ from the previous iteration to each client in $\textstyle { \mathcal { K } } _ { r }$ . (ii) Local model updating: Each client $\textit { i } \in \ K _ { r }$ updates its local model using local SGD. This involves the $E$ consecutive SGD updates $\begin{array} { r l } & { \mathbf { w } _ { i } ^ { r , 0 } = \bar { \mathbf { w } } ^ { r - 1 } , } \\ & { \mathbf { w } _ { i } ^ { r , t } = \mathbf { w } _ { i } ^ { r , t - 1 } - \alpha \nabla F _ { i } ( \mathbf { w } _ { i } ^ { r , t - 1 } ; \xi _ { i } ^ { r , t } ) , \ t = 1 , 2 , \ldots , E , } \end{array}$ where $\alpha > 0$ represents the learning rate.   
(iii) Aggregation: The selected clients upload their locally updated model $\mathbf { w } _ { i } ^ { r , E }$ to the server, which then aggregates these models to produce a new global model based on a specific aggregation principle. Notably, FEDAVG employs two aggregation schemes, de  
pending on whether all clients participate or not: Full participation: All clients actively participate in the aggregation process, i.e., ${ \mathcal { K } } _ { r } = { \mathcal { N } } \triangleq \{ 1 , 2 , \dots , N \}$ for all $r$ . The global model is updated by  

$$
\bar { \mathbf { w } } ^ { r } = \sum _ { i = 1 } ^ { N } p _ { i } \mathbf { w } _ { i } ^ { r , E } .
$$  

However, this scheme may pose feasibility challenges due to a limited communication bandwidth for uplink channels, given the large number of participants.  

• Partial participation: With $| \mathcal { K } _ { r } | \ll N$ , the global model is updated by  

$$
\bar { \mathbf { w } } ^ { r } = \frac { 1 } { K } \sum _ { i \in \mathcal { K } _ { r } } \mathbf { w } _ { i } ^ { r , E } .
$$  

Here, all $K$ clients in $\textstyle { \mathcal { K } } _ { r }$ are selected with replacement based on the probability distribution $\{ p _ { i } \} _ { i = 1 } ^ { N }$ . It is important to note that the averaging scheme in (75) provides an unbiased estimate of $\bar { \mathbf { w } } ^ { r }$ in (74) [188].  

2) Performance Analysis: Several factors influence the performance of FEDAVG, including the number of clients $K$ , the number of local updating steps $E$ , and data heterogeneity [188]. Moreover, there are interactive relationships between data heterogeneity and other training factors. For instance, a larger $E$ exacerbates the negative impact of data heterogeneity, while a smaller $E$ increases the communication cost of transmitting model parameters. To conduct a thorough analysis of the influence of data heterogeneity on FL’s convergence, we can utilize the difference between local and global function gradients, i.e., $\mathbb { E } [ \| \nabla F _ { i } ( \mathbf { w } ) - \nabla F ( \mathbf { w } ) \| ^ { 2 } ]$ , as a metric to quantify data heterogeneity [179]. Up to now, extensive research has been conducted on FL’s convergence; see, e.g., [179], [189]–[194]. Here, we present a key result that unveils the fundamental properties of FL, whose validity has been examined in [179].  

To begin, let us state the assumptions:  

Each local function $F _ { i }$ is lower bounded by $\underline { { \boldsymbol { F } } }$ and the local gradient $\nabla F _ { i }$ is Lipschitz continuous with a constant $L$ . • The local SGD is unbiased, i.e., $\begin{array} { r l } { \mathbb { E } [ \nabla F _ { i } ( \mathbf { w } , \xi _ { i j } ) ] } & { = } \end{array}$ $\nabla F _ { i } ( \mathbf { w } )$ , and has a bounded variance, i.e., $\mathbb { E } [ \| \nabla F _ { i } ( \mathbf { w } , \xi _ { i j } ) - \nabla F _ { i } ( \mathbf { w } ) \| ^ { 2 } ] \le \sigma ^ { 2 }$ . The data heterogeneity metric is upper bounded, i.e., $\begin{array} { r } { \mathbb { E } [ \| \nabla F _ { i } ( { \mathbf { w } } ) - \nabla F ( { \mathbf { w } } ) \| ^ { 2 } ] \leq D _ { i } ^ { 2 } } \end{array}$ for all $i \in \mathcal N$ .  

Let $R$ denote the number of iterations and $T = R E$ denote the total number of SGD updates per client. Suppose that $\alpha = K ^ { \frac { 1 } { 2 } } / ( 8 L T ^ { \frac { 1 } { 2 } } )$ and $E \le T ^ { \frac { 1 } { 4 } } / \dot { K } ^ { \frac { 3 } { 4 } }$ . Then, the inequality (76) (at the top of the page) holds [179]. The terms (a) and (b) in (76) reveal that the influence of mini-batch SGD variance $\sigma ^ { 2 } / b$ and data heterogeneity $\{ D _ { i } \}$ can be alleviated by increasing the number of selected clients $K$ . This allows FEDAVG to achieve a linear speed-up with respect to $K$ . Furthermore, due to the presence of the partial participation term (c) in (76), the convergence rate is $\mathcal { O } ( 1 / \dot { T } ^ { \frac { 1 } { 4 } } )$ . In the scenario where full participation (i.e., (74)) is adopted, the term (c) would disappear, leading to an improved convergence rate of $\mathcal { O } ( 1 / T ^ { \frac { 1 } { 2 } } )$ .  

3) Improved FL Algorithms: In recent research, wireless resource allocation in non-ideal wireless environments has garnered attention within the context of $\mathrm { F L }$ , where diverse perspectives have been explored. For instance, the work [189] delves into the impact of packet error rates on the convergence of FEDAVG and proposed a novel approach that integrates joint resource allocation and client selection to enhance the convergence speed of FEDAVG. On another front, research efforts have been directed toward exploring compressed transmission through quantization and evaluating its influence on FL’s performance. For instance, the work [192] proposes FEDPAQ, a communication-efficient FL method that transmits the quantized global model in the downlink, with a subsequent analysis of the quantization error’s effect on FL’s convergence. The work [193] explores layered quantized transmissions for communication-efficient FL, where distinct quantization levels are assigned to various layers of the trained neural network. Different from these, the work [179] considers both transmission outage and quantization error concurrently, undertaking joint allocation of wireless resources and quantization bits to achieve robust FL performance. In the quest to enhance FL’s performance within heterogeneous data networks, researchers have explored more advanced algorithms that aim to surpass the capabilities of the conventional FEDAVG. See [181], [195], [196] and the references therein for improved FL algorithms which can better tackle data and system heterogeneity in problem (73).  

# VI. OPTIMIZATION VIA LEARNING  

In the last few years, new machine learning (ML) and AI techniques have powered nothing short of a technological revolution in a number of application areas including speech recognition [197], image classification [198], and natural language processing [199]. In particular, well-trained deep neural networks (DNNs) are capable of utilizing limited knowledge about the underlying model to effectively transform a large amount of data to latent informative feature spaces. Remarkably, deep learning-based AI has exceeded humanlevel performance in many nontrivial tasks.  

Unlike classic communication modeling and computational tools that are mainly model-driven, ML-based methods such as DNNs and deep reinforcement learning (DRL) are largely data-driven [197], [198]. A natural question then arises: Can data-driven ML/AI-based methods significantly enhance the capacity and performance of communication networks? Recent surge of research suggests that these methods can achieve significant gains for tasks such as encoding/decoding, equalization, power control, and beamforming.  

One of the most important tasks in wireless networking is to determine, in each time period, which subset of links to activate and what subcarriers and transmit powers those links should use. Evidently, deactivating a link or a subcarrier is equivalent to setting its transmit power to zero. While there are closed-form solutions under a few special settings, optimal spectrum and power allocations are NP-hard to compute in general interference-limited networks [66]. Most of the bestknown power allocation algorithms such as WMMSE [81], SCALE [200], FlashLinQ [201], ITLinQ [202], majorizationminimization [79], and those that have been surveyed in this work in the previous sections, require complete model knowledge and are computationally very challenging. If the model parameters are only partially known, e.g., when the channel coefficients are time-varying, a principled, efficient design is yet to be found in the literature [75], [203], [204]. Today’s cellular networks dynamically allocate subcarriers to each link and step up/down the transmit power primarily based on this link’s own receiver feedback, which is far from being globally optimal.  

To address both computational complexity and model uncertainty issues, data-driven approaches such as DNN can provide a much-needed solution for next-generation wireless networks. To be concrete, consider the multi-user multi-carrier  

$$
\frac { 1 } { R } \sum _ { r = 1 } ^ { R } \left\| \nabla _ { \mathbf { w } } F ( \bar { \mathbf { w } } ^ { r - 1 } ) \right\| ^ { 2 } \leq \ \frac { 4 9 6 L \left( F ( \bar { \mathbf { w } } ^ { 0 } ) - \underline { { F } } \right) } { 1 1 \left( T K \right) ^ { \frac { 1 } { 2 } } } + \left( \frac { 3 9 } { 8 8 \left( T K \right) ^ { \frac { 1 } { 2 } } } + \frac { 1 } { 8 8 \left( T K \right) ^ { \frac { 3 } { 4 } } } \right) \frac { \sigma ^ { 2 } } { b } .
$$  

(b) (caused by data heterogeneity)  

(c) (caused by partial participation)  

interference network with $K$ transmitters, and each using power $p _ { k } ^ { \ell } \ge 0$ to transmit to its associated receiver on the $\ell$ -th subcarrier. Let $h _ { k j } ^ { \ell } ~ \in ~ \mathbb { C }$ denote the channel between transmitter $j$ and receiver $k$ on subcarrier $\ell$ . Then, the sum-rate maximization problem is given by  

$$
\begin{array} { l } { \displaystyle \operatorname* { m a x } _ { \left\{ p _ { k } ^ { \ell } \right\} } \mathrm { W S R } ( p , h ) \triangleq \sum _ { k } w _ { k } \sum _ { \ell } \log \left( 1 + \mathrm { S I N R } _ { k } ^ { \ell } \right) } \\ { \mathrm { s . t . } \quad \displaystyle \sum _ { \ell } p _ { k } ^ { \ell } \leq P _ { k } , \ k \in \mathcal { K } , } \end{array}
$$  

where  

$$
\mathrm { S I N R } _ { k } ^ { \ell } = \frac { | h _ { k k } ^ { \ell } | ^ { 2 } p _ { k } ^ { \ell } } { \sum _ { j \neq k } | h _ { k j } ^ { \ell } | ^ { 2 } p _ { j } ^ { \ell } + \sigma _ { k } ^ { 2 } }
$$  

is the SINR of receiver $k$ over subcarrier $\ell$ , and $w _ { k }$ and $P _ { k }$ are the weight and power budget of user $k$ , respectively. This problem and its various generalizations such as the BF problem (3) are NP-hard [66], [68], [75]. A closer look at the popular and computationally more affordable WMMSE algorithm [81] reveals a number of relatively expensive operations including taking the magnitude, thresholding, re-weighting, and matrix inversion. More importantly, implementing the WMMSE algorithm requires precise knowledge of the parameters (e.g., channel coefficients) and may use an unknown number of iterations—which varies from instance to instance. A question that many researchers have started asking around 2017 is: Can neural networks help, and if so, to what extent? Since then, extensive literature has been developed to address both the computational and model uncertainty issues.  

In the rest of this section, we focus on learning-based power control and beamforming methods that leverage the instantaneous CSI to enhance the performance of wireless systems. In Section VII, we switch to more recent developments in learning methods that do not require the CSI.  

# A. Black-Box Based Approaches  

The first line of work started with the learning to optimize approach proposed in [205]. In this approach, an (potentially computationally expensive) optimization algorithm is treated as a nonlinear mapping—which takes problem specification as the input, and outputs the (hopefully optimal) decision variables. Formally, let $\mathcal { T } ( h ) = p ^ { * }$ denote a nonlinear relationship of the input (i.e., the channel coefficients) and output (i.e., the optimized powers) for an algorithm solving (77). Due to DNNs’ superior ability to learn compact representation of nonlinear relations [206], in principle it is possible to use it as a “black-box” to learn the relation $\tau ( \cdot )$ using a DNN without going into iterations to mimic the “lower level operations”. If we could use a very simple network, say a few layers and neurons to well-approximate a power control algorithm which normally runs for more than 100 iterations, then substantial saving in real-time computation can be achieved. In [205], a DNN-based approach is developed to approximate WMMSE in the special case of a single carrier. Specifically, a supervised learning approach is used, where the training pairs are generated using simulated channel and the WMMSE algorithm (where the $i$ -th snapshot of the simulated channel is denoted as $\boldsymbol { h } ^ { ( i ) }$ , and the resulting WMMSE solution is denoted as $\pmb { p } ^ { ( i ) }$ ), and then they are used to train a DNN that mimics the behavior of WMMSE. Let $\tau ( \cdot , \pmb \theta )$ denote the DNN, where $\pmb \theta$ collects all the parameters of the DNN. Then, the training problem can be expressed as  

$$
\begin{array} { r l } & { \underset { \theta } { \operatorname* { m i n } } \ \displaystyle \sum _ { i = 1 } ^ { I } \| \tau ( \pmb { h } ^ { ( i ) } , \pmb { \theta } ) - \pmb { p } ^ { ( i ) } \| ^ { 2 } } \\ & { \mathrm { s . t . } \ \tau ( \pmb { h } ^ { ( i ) } , \pmb { \theta } ) \in \mathcal { P } , } \end{array}
$$  

where $\mathcal { P }$ denotes the feasible set of the transmit power vectors and $I$ is the total number of training samples.  

The approach is tested on a variety of scenarios in [205], including real-data experiments, and the results are very encouraging. The key findings are as follows: (i) It is indeed possible to closely approximate a highly complex iterative power control algorithm by using a relatively simple DNN (in this case, a network with only three hidden layers). (ii) The DNN-based implementation is typically 25 to 250 times faster than the best C language implementation of the WMMSE.  

Subsequently, a number of works have been developed to improve the learning to optimize techniques discussed above. For example, in [207] an unsupervised learning approach is developed, which directly optimizes some system utilities such as the WSR over the training set. More specifically, the training problem is given by  

$$
\begin{array} { r l } { \underset { \theta } { \operatorname* { m i n } } } & { - \displaystyle \sum _ { i = 1 } ^ { I } \mathrm { W S R } ( \tau ( h ^ { ( i ) } , \theta ) , h ^ { ( i ) } ) } \\ { \mathrm { s . t . } } & { \tau ( h ^ { ( i ) } , \theta ) \in \mathcal { P } , } \end{array}
$$  

where $\mathrm { W S R } ( \cdot )$ is defined in (77). It has been shown that by using the negative WSR as the loss function, it is possible to find power allocation strategies whose performance goes beyond that of WMMSE. It is worth highlighting that the above unsupervised approach has been designed specifically for the interference management problem because the task of wireless system utility optimization (which includes the WSR maximization as a special case) offers a natural training objective to work with. Since it does not require any existing algorithms to help generate high-quality labels, it is much preferred when training samples are difficult to generate. On the other hand, the associated training objective appears to be difficult to optimize, since the WSR is a highly nonlinear function with respect to the transmit power or the beamformer, which in turn is a highly nonlinear function of the DNN parameters. Therefore, in the future, it is worth understanding the tradeoffs between the two formulations (79) and (80).  

In [208], the fully connected neural networks used in the previous works are replaced by certain random edge graph neural network (REGNN), which performs convolutions on random graphs created by the network’s fading interference patterns. REGNN-based policies maintain an important permutation equivariance property, facilitating their transference to different networks. The key benefit of the proposed architecture is that only a small neural network is needed, and the dimensionality of the network does not scale with the network size. It is worth mentioning that there are other recent works that apply graph neural networks to learn algorithms that are capable of learning globally optimal beamformers; see, e.g., [209], [210]. In [211], the supervised deep learning approach is extended from the power control problem to a multi-user beamforming problem by utilizing convolutional neural networks and expert knowledge such as uplink-downlink duality (which has been reviewed in Section III-E). In particular, three beamforming neural networks are developed for optimizing the SINR, power minimization, and sum rate. Similarly as in (79), the beamforming neural networks employ supervised learning for SINR and power minimization and a hybrid approach for sum-rate maximization. In [212], in view of the fact that the previous learning-based algorithms have only been developed in the static environment, where parameters like the CSI are assumed to be constant, a methodology for continuous learning and optimization in certain “episodically dynamic” settings is introduced, where the environment changes in “episodes”, and in each episode the environment is stationary. The work proposed to incorporate the technique of continual learning into the model to enable incremental adaptation to new episodes without forgetting previous knowledge. By further utilizing certain specific structures of the optimal beamforming solution (e.g., the low-dimensional structure and/or the invariance property under the permutation of users’ indices) and embedding these structures into the network, the constructed neural network can have better scalability to different numbers of transmit antennas and BSs and can tackle more difficult QoS constraints. Some recent progress in this direction has been made in [213], [214].  

# B. Unfolding-Based Approaches  

Different from the above black-box DNN approach, where DNN is used as a black box to approximate the input-output relationship of certain algorithms or systems, another line of work leverages the deep unfolding technique, which builds  

DNNs based on finer-grained approximation of a known iterative algorithm with a finite number of iterations. Specifically, the neural network to be built will have multiple stages, where each stage consists of function blocks that imitate a given step of the target optimization algorithm. For example, the work [215] unfolds the GP algorithm to build learning networks for the MIMO detection problem in (14). For a single-cell multi-user beamforming problem, the work [216] proposes a learning network by unfolding the WMMSE algorithm. To overcome the difficulty of matrix inversion involved in the WMMSE algorithm, they approximate the matrix inversion by its first-order Taylor’s expansion. Another recent work [217] proposes to unfold the WMMSE algorithm to solve the coordinated beamforming problem in MISO interference channels. In [218], certain GP algorithm is unfolded for the multiuser beamforming problem. Again, by utilizing certain lowdimensional structure of the optimal beamforming solution, the constructed neural network can be made independent of the numbers of transmit antennas and BSs.  

Overall, the advantage of these deep unfolding methods is that they can leverage existing algorithms to guide the design of neural networks. In this way, the number of parameters to be learned can be much smaller as compared to black-box-based DNN methods.  

# VII. LEARNING-BASED OPTIMIZATION WITHOUT EXPLICIT CHANNEL ESTIMATION  

While the focus of the previous section is on using the neural network to mimic a sophisticated optimization solver, the true benefit of the ML approach for optimizing communication system design goes much further. In this section, we point out that the practical advantage of the ML-based solver lies not necessarily in that a data-driven approach may provide a more efficient way to solve complex optimization problems, but more importantly, a learning-based approach allows communication channels to be modeled and to be parameterized differently (and potentially more effectively), so that relevant channel characteristics that are otherwise difficult to build into an analytic model can now be taken into account in the optimization process. In fact, the learning-based approach can allow the optimization of wireless communication systems to be performed without explicit channel estimation. This ability to bypass the CSI estimation process is where the true promise of ML lies.  

In many optimization problems for wireless communication system design, the estimation of CSI is a highly nontrivial process for the following reasons. As modern systems move toward massive MIMO with many antenna elements, while also incorporating novel devices such as RIS with many tunable reflectors, the number of parameters in the overall channel has exploded. Yet, as next-generation wireless services increasingly demand agility to support ultra-reliable low-latency communications and cater toward high-mobility applications where the channel coherence time is severely limited, the amount of time available for CSI acquisition has effectively been shortened, making the estimation task ever more challenging. Furthermore, modern wireless communication networks often involve a large number of independent transmitter-receiver links. To facilitate interference management, the CSI between each transmit and each receive device would need to be estimated and collected at a centralized controller. The coordination required for channel estimation and feedback will become increasingly complex as the network size grows.  

Therefore, the bottlenecks in the optimization of wireless communication networks are often not only the efficiency of the optimization algorithms for achieving either global or local optimal solutions of a particular system-level optimization problem—they could well also be the availability of an accurate CSI across the entire network. In this section, we first discuss the issue of channel modeling, then highlight several approaches of using learning-based methods for the optimization of wireless communication networks that are model-free.  

# A. Channel Modeling and CSI Estimation  

Communication engineers have invested heavily in the study of channel models. Cellular and WiFi standards include sophisticated electromagnetic propagation models under which the transceiver designs must perform well. At a system level, radio propagation maps for outdoor and indoor environments have been carefully developed and used for deployment planning purposes. However, these established channel models are typically statistical in nature. At a link level, when optimizing the transceivers for a specific channel realization, we must rely on pilots to estimate the channel within the coherence time.  

One of the key questions for channel estimation is how to parameterize a wireless channel. For a MIMO channel with $M$ antennas at the transmitter and $M$ antennas at the receiver, the conventional method is to capture the complex channel coefficients from each transmit antenna to each receive antenna. Thus, an $M \times M$ channel has $\mathcal { O } ( M ^ { 2 } )$ complex parameters. While such a parameterization may be suitable for a rich-scattering environment when antenna spacing is at least half wavelength apart so that the channels across the antennas are uncorrelated, at higher frequencies such as the mmWave band, the propagation environment becomes increasingly sparse. This means that the channels across the antennas would exhibit strong correlations, and the overall MIMO channel can be parameterized by a much smaller number of parameters. Toward this end, sparse channel models and sparse optimization techniques (which have been reviewed in Section III-B) have proved to be useful for CSI estimation in such channels.  

A convenient approach to the modeling of sparse channels is to use a ray-tracing model, in which the wireless propagation environment is characterized by a limited number of rays from the transmitter to the receiver via the reflective paths. However, these model assumptions are susceptible to variations in the deployment scenario, e.g., it is difficult to determine the number of paths in advance. Also, as the Bayesian parameter estimation process would require a prior distribution on the model parameters, it is not obvious how these prior distributions should be chosen.  

In general, choosing the most suitable channel model is an art rather than science. There is a delicate balance between choosing a model with many parameters, which may be more accurate but also makes channel estimation harder, versus choosing a model with fewer parameters, which may be less accurate but makes parameter estimation easier. Moreover, as a mobile transceiver can easily move from a limited scattering location to a rich-scattering location, identifying the suitable channel model for each specific situation is a highly nontrivial task.  

# B. Model-Free Optimization  

A learning-based approach can potentially circumvent the difficulty posed by model-based optimization. Instead of optimizing the transceiver parameters such as power and beamforming based on the CSI acquired in the channel estimation phase, modern neural networks can be efficiently trained to allow the possibilities of taking a variety of relevant information about the channel as the input, while producing an optimized solution based on these inputs.  

This new data-driven paradigm is illustrated in Fig. 5 [219]. While traditional optimization methods must rely on a specific parameterization of the channel, the data-driven approach can take any representation of the problem instance as the input, then map the problem instance to an optimization solution. This opens up the possibility of using not only the CSI but also relevant information such as the locations of mobile devices, visual images of the surrounding environment, or sensing data from radar/lidar in autonomous vehicles, to aid the specification of the propagation channel.  

This ability for the neural network to merge the multitude of different kinds of information is a key advantage of the proposed data-driven paradigm. In effect, once properly trained over many problem instances, the first layers of the neural network can act as feature-extraction layers to find the most prominent features of the optimization problem, while the later layers would act as optimization layers to find an optimized solution. Such an approach allows the potential of reducing the reliance or completely eliminating the need for explicit channel estimation. This is where ML-based optimization would have the potential to have the largest impact.  

In the remainder of this section, we survey several examples of how a variety of different information can be taken as the problem specification to allow for an effective solution of the optimization problem.  

1) Scheduling and Power Control Using Geographic Information: As already discussed in detail in the previous section, power control for the interference channel is one of the longstanding optimization problems in the wireless domain. In fact, when formulated as an integer programming problem of deciding whether a device should be on or off, it can be readily seen that the sum-rate maximization problem (and many of its variations) is NP-hard [66], [74].  

However, the difficulty of the power control problem goes beyond algorithmic complexity. In an interfering environment with $K$ transmitter-receiver pairs, the acquisition of the CSI would require transmitting pilots from each of the $K$ transmitters to each of the $K$ receivers, in order to estimate the $\mathcal { O } ( K ^ { 2 } )$ channel parameters. Not only would such a channel acquisition phase consumes valuable coherence time, it also requires careful coordination, which is often costly in itself. Further, these estimated channel parameters need to be collected at one central location so that a centralized optimization problem may be formulated and solved. Finally, the solution needs to be communicated back to the devices. These tasks are often cost-prohibitive in a distributed networking environment.  

![](images/9960fd9a8788bc8963d620a376f97215a11c4c9a55dcdd709c16d7d564d1ad17.jpg)  
Fig. 5. Traditional wireless system design follows the paradigm of model-then-optimize. The ML-based approach is capable of directly learning the optimal solution based on a representation of the problem instance. The neural network is trained over many problem instances, by adjusting its weights according to the overall system objective as a function of the representation of the problem instances [219].  

The core of the power control problem is scheduling, i.e., to decide which set of transmitter-receiver pairs should be active at any given time, so as to balance the need for throughput provisioning and interference mitigation. To this end, the work [220] makes a crucial observation that the transmission decision of each transmitter-receiver pair is essentially a function of the locations of nearby transmitters relative to the receiver and the locations of nearby receivers relative to the transmitter. Such geographic location information already tells us a great deal about the interference level each receiver would experience, and likewise the interference pattern these transmitters would emit depending on which ones are turned on. Thus, instead of using exact CSI to formulate an optimization problem of maximizing the network utility, it ought to be possible to provide the location information as the input to a neural network, and to train the neural network to arrive at an approximately optimal solution. This is an example where precise channel information, which is difficult to obtain, may be replaced by geographic spatial maps of the potentially interfering transmitters and the potentially interfered receivers as a representation of the optimization problem. These maps already contain sufficient amount of information to derive a reasonable schedule, as shown in [220]. The benefit of not having to estimate CSI would outweigh the cost in terms of loss in optimality.  

The idea of modeling the spatial relationship between transceiver pairs as a graph in order to aid a network-wide optimization has found relevance in many related works, e.g., in using graph embedding based on the distances between nodes as features to perform link scheduling [221], and in using GNNs to account for the interference landscape in a network [208], [222]. Neural networks have also been found useful for estimating the radio map of a complex environment [223].  

2) Beamforming and RIS Reconfiguration with Implicit Channel Estimation: The traditional optimization paradigm always assumes a channel estimation phase based on the pilots, followed by an optimization phase based on the estimated channel. The CSI serves as the intermediary interface between the two phases. However, as already mentioned, choosing the most appropriate channel model and the channel estimation method involves many tradeoffs, so it is not a trivial task.  

The capability of neural networks for taking diverse types of information as the inputs to the optimization process gives rise to a new possibility. Instead of explicitly estimating the channel based on the received pilots and then performing optimization, a better idea is to feed the received pilots directly into the neural network and to train the neural network to produce an optimized solution based on the information about the channel implicitly contained in the received pilots. Such a model-free optimization paradigm would bypass explicit channel estimation and let the neural network perform both feature extraction (i.e., finding the most relevant information about the channel) and optimization together at the same time.  

The optimization of RIS is an example in which this new approach can be much more effective than the traditional channel estimation-based approach. The deployment of RIS in a communication setting allows real-time re-focusing of electromagnetic beam from a transmitter through the reflecting surface to an intended receiver, thereby enhancing the overall SINR. In a traditional optimization paradigm, the channel between the transmitter and the receiver would need to be parameterized by all the reflective paths. To explicitly estimate these channel parameters would have cost a large number of pilots [224]. If instead, the received pilots are used as a representation of the channel as the input to the neural network, then it would result in a much more efficient optimization process.  

Experimentally, this approach has been shown in [225] to be able to produce optimized configurations for the RIS using a much smaller number of pilots than traditional channel estimation-based approaches. The model-free approach produces a higher overall rate than sophisticated manifold optimization and block coordinate descent techniques [226], [227] for optimizing RIS—when the channel estimation error is taken into account. Interestingly, the neural network produces highly interpretable results; it can effectively track the users and further cancel the interference between the users. It is also possible to use this framework to include scheduling [228], which is a difficult discrete optimization problem. Moreover, the locations of the users can be used as an additional input to the neural network to further reduce the length of pilots.  

3) Sensing, Localization, and Beam Alignment with Massive MIMO: Model-free deep learning-based optimization has an important role to play not only for wireless communication applications but also for sensing and localization tasks, which are crucial application areas for future wireless networks. The framework discussed earlier in this section applies naturally to sensing applications, because model-free deep learning is capable of implicitly estimating the channel, and channel estimation is an example of sensing. In sensing applications, typically a known signal is transmitted, then possibly reflected off a target object, and finally received and processed. The goal is to identify or to characterize some properties of the transmitter, or the reflecting object, or the environment, based on the received signal. Traditional optimization techniques can be used if a model of the target or the environment is available, and if the sensing objective can be stated in a mathematical form (e.g., in terms of the MSE). However, because the validity of these models is subject to assumptions, it would have been much more preferable to train a neural network to accomplish the same task. The premise here is of course that the training data for realistic sensing scenarios are available or can be easily generated. Historically, image/speech recognition is among the first successful applications of deep learning [197], [198]—broadly speaking, these are all sensing tasks.  

Sensing applications for which deep learning has been shown to provide substantial benefit, as compared to handcrafted model-based optimization, include localization and mmWave massive MIMO initial beam alignment [229], [230], which is a problem of designing a beamformer to align with the incoming ray during the pilot stage.  

A further consideration in many sensing tasks is that sensing operations are often sequential in nature. The sensing strategies can be adaptively designed depending on the observations made so far. The sequential optimization of sensing strategies, if formulated as an analytic optimization problem, would have been a high-dimensional problem that is impossible to solve analytically. Given the right neural network architecture, however, they can be readily tackled using deep learning methods. For example, the work [231] demonstrates that in a massive MIMO channel where both the transmitter and receiver are equipped only with a single radio-frequency chain (so they can only perform analog beamforming), it is possible to design a sequence of analog sensing beamformers so that the transmitter and receiver can jointly discover the strongest direction in a high-dimensional channel. In effect, deep learning is capable of performing singular value decomposition over the air—without explicitly estimating the channel matrix.  

The dynamic nature of the sensing task is especially important in applications involving object tracking. In this realm, the work [232] demonstrates that a deep learning approach can incorporate visual imaging data for beam tracking and beam alignment. This speaks to the utility of learning-based optimization—the ability to incorporate imaging data for RF beamforming would have been very difficult to achieve using traditional model-based approaches.  

# C. Neural Network Architecture Considerations  

A crucial consideration in the design of deep learning methods for solving optimization problems is the choice of the neural network architecture. The general principle is that the neural network architecture should match the structure of the optimization task at hand. As already being alluded to, the GNN [208], [222] that captures the spatial relationship between the interfering links is a well-suited architecture for scheduling and power control in device-to-device ad-hoc networks and for beamforming pattern design in RIS-assisted communication scenarios. By tying the weights of different branches of the GNN together, it would facilitate faster training and a more generalizable solution. For sequential optimization in sensing applications, neural network architectures such as long short-term memory [233] have shown to be effective for capturing the correlation over time [229]–[231], [234]. Modern attention-based neural network architectures can potentially offer even further improvements.  

The field of modern ML is evolving rapidly. Unquestionably, future wireless communication system design will incorporate elements of learning-based approaches soon and will likely go beyond the present model-based methodology.  

# VIII. OPEN PROBLEMS AND RESEARCH DIRECTIONS  

In this section, we present some open problems and future research directions for mathematical optimization theory and algorithms for wireless communication system design.  

# A. Open Problems  

While many advanced mathematical optimization theory and various algorithms have been developed in the past decades, there are still many open problems.  

With the help of quadratic and Lagrangian dual transforms reviewed in Section III-A, we can transform a complicated low-dimensional (e.g., sum-rate maximization) problem into an equivalent, relatively easy highdimensional problem and further apply the AO algorithm to efficiently solve the latter. It is pointed out in [78] that, when applied to solve a univariate toy example, the AO algorithm (based on the two FP transforms) converges sublinearly and thus slower than the conventional Dinkelbach’s algorithm. A rigorous proof of the convergence rate of the AO algorithm when applied to more general (sum-rate maximization) problems remains open. Another question is how to accelerate the AO algorithm to achieve a faster convergence rate.  

As mentioned at the end of Section III-E, reformulating the problem under consideration into a convex form (if necessary) and exploring its solution structure in algorithm design are two major technical obstacles for duality-based algorithms to work [143]. However, the constantly evolving structures and nature of optimization problems due to architecture and networking innovations in wireless communication systems lead to significant challenges in the application of duality-based algorithms. More efforts are still needed to push the boundary of uplink-downlink duality towards more general scenarios (e.g., ISAC and RIS-assisted systems) and develop duality-based algorithms for solving (possibly nonconvex) optimization problems in these scenarios.  

While we have explored various distributed optimization methods for wireless communication system design in Section V-A, it is worth noting that only a few of them have found practical implementation. This limited deployment can be attributed to the challenges posed by the interconnection between BSs in multi-cell systems, where backhaul bandwidth constraints often lead to significant communication delays. In real-world scenarios, BSs cannot engage in frequent message exchanges due to these constraints, so iterative algorithms in Section V-A are not favored. Consequently, a critical question arises: How can we effectively optimize the transmission strategies of multiple BSs with minimal or even no message exchanges [235]? Similar challenges also arise in the context of user scheduling within multi-cell systems, particularly for cell-edge users who require coordinated optimization across multiple BSs to be simultaneously allocated to the same resource block. These issues underscore the complexity of achieving efficient wireless system design and user scheduling in practical resource-constrained environments.  

Most evidence on the effectiveness of neural networks is empirical. There are still many open questions, such as whether there can be any theoretical guarantee in the performance of learning-based approaches, how to choose the best neural network architecture that would require the fewest training samples, how to account for constraints in a data-driven approach [236], how to combine data-driven and model-driven methodologies (an example of which is by unfolding existing algorithmic structures [217], [237]; see Section VI-B for more details), the possible role of reinforcement learning in solving optimization problems, etc.  

# B. Research Directions  

In this subsection, we point out some potential directions for future work on next-generation wireless communication system design.  

1) Distributed Signal Processing and Optimization for Extremely Large-Scale Antenna Array (ELAA) Systems: To support multiple services with diverse and customized QoS requirements in next-generation wireless communication systems, there is a growing trend in increasing the number of antennas at BSs, which has led to the emergence of ELAA systems. However, as mentioned in Section V, as the number of antennas increases, traditional centralized baseband processing (CBP) architectures encounter bottlenecks in terms of high fronthaul costs and computational complexities. To address these challenges, decentralized baseband processing (DBP) architectures have emerged as a promising approach [238]–[243]. In the DBP architecture, the antennas at the BS are divided into several antenna clusters, each equipped with an independent and more affordable baseband processing unit (BBU) and connected with other BBUs as a star network or as a daisy-chain network.  

Compared to the CBP architecture, the DBP approach has several advantages. First, the DBP architecture only requires distributed units (DUs) to exchange some locally processed (low-dimensional) intermediate results, thereby reducing the interconnection cost. Second, since each DU only needs to process a low-dimensional received signal, the computational complexity in each DU can be significantly reduced. Last but not least, the DBP architecture improves the scalability and robustness of ELAA systems, as adding or removing antenna elements simply amounts to adding or removing computing units.  

Despite the promising initial advancements in ELAA systems with DBP architectures, interconnection costs, which increases rapidly with the expansion of the array size, is a key issue. More specifically, most of developed distributed algorithms are based on iterative implementations that suffer from frequent message exchanges and high computational complexities [238]–[244], although some attempts have been made recently to overcome these bottlenecks [245], [246]. In addition, tight synchronization is required among distributed nodes and corresponding synchronization signals must be implemented across the DUs. For example, to perform coherent beamforming, high-accuracy time synchronization and phase calibration are crucial [247], [248]. Furthermore, when additional components such as network-controlled repeaters, RISs, and backscatter communication are introduced to distributed MIMO systems [249], the integration of these techniques with the distributed architecture will present new challenges. All of these are fresh opportunities for optimization algorithm development.  

The ELAA system is used in the above as an example to illustrate that new wireless communication applications and scenarios will lead to new mathematical optimization problems and drive the development of distributed signal processing and optimization theory and algorithms. Indeed, there are many interesting applications as well as signal processing and optimization problems in all of the six major usage scenarios of 6G (see Fig. 1), which call for new and novel signal processing and optimization theory and algorithms. As Alan V. Oppenheim reminds us [250], “There will always be signals, they will always need processing, and there will always be new applications, new mathematics, and new implementation technologies.”  

2) Quantum Optimization and ML [251]–[254]: ML and AI techniques have significantly changed and will continue to change the way that mathematical optimization problems are formulated and solved. As reviewed in Sections VI and VII, data-driven approaches have provided an efficient way of solving complex optimization problems from wireless communication system design that cannot be accurately modeled and/or efficiently solved by traditional optimization approaches. There are new ideas on the horizon that can change the research landscape for mathematical optimization. An example of this is quantum computing. A grand research challenge, as well as opportunity, is the co-design of quantum computer architectures and quantum optimization and ML algorithms such that optimization problems can be efficiently solved by quantum optimization and ML algorithms on quantum computers.  

Emerging paradigms of ML, quantum computing, and quantum ML, and their synergies with wireless communication systems might become enablers for future networks. This speculative vision of a quantum internet is outlined in [255]. On one hand, quantum information theory will give rise to new optimization problem formulations [256]. For the optimization community, it often leads to novel and exciting mathematical optimization problems involving matrix-valued functions (e.g., functions involving input density matrices or operators). Quantum-assisted optimization for wireless communications and networking has already been investigated in [251], [252]. On the other hand, quantum-assisted (e.g., annealing-based) computational models can lead to more efficient solutions to problems in wireless communications and networking. Typical optimization problems include quantum-assisted multi-user detection, quantum-aided multi-user transmission in combination with multiple-access technologies including channel estimation, quantum-assisted indoor localization for mmWave and visible light communications, and quantum-assisted joint routing, load balancing, and scheduling [252].  

Finally, quantum ML [253] defines complex artificial neural network structures to perform quantum supervised, unsupervised, reinforcement, federated, and deep learning. The work [254] presents a perspective on quantum ML methodologies and their applications for wireless communications.  

# IX. CONCLUSION  

Mathematical optimization is a powerful modeling and solution tool for the design of wireless communication systems. Mathematical optimization theory, algorithms, and techniques play central roles in formulating the right optimization problems behind wireless communication system design, obtaining structural insights into their solutions, developing efficient, provable, yet interpretable algorithms for solving them, as well as understanding analytic properties of optimization problems and convergence behaviors of optimization algorithms. This paper provides a survey of recent advances in mathematical optimization theory and algorithms for wireless communication system design. More specifically, we review recent advances in nonconvex nonsmooth optimization (including fractional programming, sparse optimization, proximal gradient algorithms, penalty methods, and duality-based algorithms), global optimization (including branch-and-bound and branch-and-cut algorithms), distributed optimization (and federated learning), learning-based optimization (with and without CSI), and their successful application examples in wireless communication system design. More importantly, a goal of this paper is to give guidance on how to choose and/or develop suitable algorithms (and neural network architectures) for solving structured optimization problems from wireless communications and to promote the cross-fertilization of ideas in mathematical optimization and wireless communications.  

# REFERENCES  

[1] J. G. Andrews, S. Buzzi, W. Choi, S. V. Hanly, A. Lozano, A. C. K. Soong, and J. C. Zhang, “What will 5G be?” IEEE J. Sel. Areas Commun., vol. 32, no. 6, pp. 1065–1082, Jun. 2014.   
[2] W. Saad, M. Bennis, and M. Chen, “A vision of 6G wireless systems: Applications, trends, technologies, and open research problems,” IEEE Netw., vol. 34, no. 3, pp. 134–142, May/Jun. 2020.   
[3] S. Dang, O. Amin, B. Shihada, and M.-S. Alouini, “What should 6G be?” Nature Electron., vol. 3, no. 1, pp. 20–29, Jan. 2020.   
[4] X. You, C.-X. Wang, J. Huang, X. Gao, Z. Zhang, M. Wang, Y. Huang, C. Zhang et al., “Towards 6G wireless communication networks: Vision, enabling technologies, and new paradigm shifts,” Sci. China Inf. Sci., vol. 64, pp. 1–74, Jan. 2021.   
[5] W. Jiang, B. Han, M. A. Habibi, and H. D. Schotten, “The road towards 6G: A comprehensive survey,” IEEE Open J. Commun. Soc., vol. 2, pp. 334–366, Feb. 2021.   
[6] Framework and Overall Objectives of the Future Development of IMT for 2030 and Beyond, ITU-R Std. M.2160-0, Nov. 2023.   
[7] E. Bj¨ornson, J. Hoydis, and L. Sanguinetti, “Massive MIMO networks: Spectral, energy, and hardware efficiency,” Found. Trends Signal Process., vol. 11, no. 3-4, pp. 154–655, 2017.   
[8] J. Zhang, E. Bjo¨rnson, M. Matthaiou, D. W. K. Ng, H. Yang, and D. J. Love, “Prospective multiple antenna technologies for beyond 5G,” IEEE J. Sel. Areas Commun., vol. 38, no. 8, pp. 1637–1660, Aug. 2020. [9] E. Bjo¨rnson, Y. C. Eldar, E. G. Larsson, A. Lozano, and H. V. Poor, “Twenty-five years of signal processing advances for multiantenna communications: From theory to mainstream technology,” IEEE Signal Process. Mag., vol. 40, no. 4, pp. 107–117, Jun. 2023.   
[10] A. B. Gershman, N. D. Sidiropoulos, S. Shahbazpanahi, M. Bengtsson, and B. Ottersten, “Convex optimization-based beamforming,” IEEE Signal Process. Mag., vol. 27, no. 3, pp. 62–75, May 2010.   
[11] A. M. Elbir, K. V. Mishra, S. A. Vorobyov, and R. W. Heath, “Twentyfive years of advances in beamforming: From convex and nonconvex optimization to learning techniques,” IEEE Signal Process. Mag., vol. 40, no. 4, pp. 118–131, Jun. 2023.   
[12] X. Zhang, A. Molisch, and S.-Y. Kung, “Variable-phase-shift-based RFbaseband codesign for MIMO antenna selection,” IEEE Trans. Signal Process., vol. 53, no. 11, pp. 4091–4103, Nov. 2005.   
[13] A. Li, D. Spano, J. Krivochiza, S. Domouchtsidis, C. G. Tsinos, C. Masouros, S. Chatzinotas, Y. Li, B. Vucetic, and B. Ottersten, “A tutorial on interference exploitation via symbol-level precoding: Overview, state-of-the-art and future directions,” IEEE Commun. Surveys Tuts., vol. 22, no. 2, pp. 796–839, 2nd Quart. 2020.   
[14] Y. Liu, S. Zhang, X. Mu, Z. Ding, R. Schober, N. Al-Dhahir, E. Hossain, and X. Shen, “Evolution of NOMA toward next generation multiple access (NGMA) for 6G,” IEEE J. Sel. Areas Commun., vol. 40, no. 4, pp. 1037–1071, Apr. 2022.   
[15] L. Liu, E. G. Larsson, W. Yu, P. Popovski, C. Stefanovi´c, and E. de Carvalho, “Sparse signal processing for grant-free massive connectivity: A future paradigm for random access protocols in the internet of things,” IEEE Signal Process. Mag., vol. 35, no. 5, pp. 88–99, Sept. 2018.   
[16] X. Chen, D. W. K. Ng, W. Yu, E. G. Larsson, N. Al-Dhahir, and R. Schober, “Massive access for 5G and beyond,” IEEE J. Sel. Areas Commun., vol. 39, no. 3, pp. 615–637, Mar. 2021.   
[17] O. Simeone, A. Maeder, M. Peng, O. Sahin, and W. Yu, “Cloud radio access network: Virtualizing wireless access for dense heterogeneous systems,” J. Commun. Netw., vol. 18, no. 2, pp. 135–149, Apr. 2016.   
[18] H. Q. Ngo, A. Ashikhmin, H. Yang, E. G. Larsson, and T. L. Marzetta, “Cell-free massive MIMO versus small cells,” IEEE Trans. Wireless Commun., vol. 16, no. 3, pp. 1834–1850, Mar. 2017.   
[19] Z.-Q. Luo, “Applications of convex optimization in signal processing and digital communication,” Math. Program., vol. 97, no. 1-2, pp. 177– 207, 2003.   
[20] M. Chiang, “Geometric programming for communication systems,” Found. Trends Commun. Inf. Theory, vol. 2, no. 1–2, pp. 1–154, 2005.   
[21] Z.-Q. Luo and W. Yu, “An introduction to convex optimization for communications and signal processing,” IEEE J. Sel. Areas Commun., vol. 24, no. 8, pp. 1426–1438, Aug. 2006.   
[22] D. P. Palomar and Y. C. Eldar, Convex Optimization in Signal Processing and Communications. New York, NY, USA: Cambridge University Press, 2010.   
[23] Z.-Q. Luo, W.-K. Ma, A. M.-C. So, Y. Ye, and S. Zhang, “Semidefinite relaxation of quadratic optimization problems,” IEEE Signal Process. Mag., vol. 27, no. 3, pp. 20–34, May 2010.   
[24] F. Liu, Y. Cui, C. Masouros, J. Xu, T. X. Han, Y. C. Eldar, and S. Buzzi, “Integrated sensing and communications: Toward dualfunctional wireless networks for 6G and beyond,” IEEE J. Sel. Areas Commun., vol. 40, no. 6, pp. 1728–1767, Jun. 2022.   
[25] M. Di Renzo, A. Zappone, M. Debbah, M.-S. Alouini, C. Yuen, J. De Rosny, and S. Tretyakov, “Smart radio environments empowered by reconfigurable intelligent surfaces: How it works, state of research, and the road ahead,” IEEE J. Sel. Areas Commun., vol. 38, no. 11, pp. 2450–2525, Nov. 2020.   
[26] F. Rusek, D. Persson, B. K. Lau, E. G. Larsson, T. L. Marzetta, O. Edfors, and F. Tufvesson, “Scaling up MIMO: Opportunities and challenges with very large arrays,” IEEE Signal Process. Mag., vol. 30, no. 1, pp. 40–60, Jan. 2013.   
[27] L. Lu, G. Y. Li, A. L. Swindlehurst, A. Ashikhmin, and R. Zhang, “An overview of massive MIMO: Benefits and challenges,” IEEE J. Sel. Topics Signal Process., vol. 8, no. 5, pp. 742–758, Oct. 2014.   
[28] O. El Ayach, S. Rajagopal, S. Abu-Surra, Z. Pi, and R. W. Heath, “Spatially sparse precoding in millimeter wave MIMO systems,” IEEE Trans. Wireless Commun., vol. 13, no. 3, pp. 1499–1513, Mar. 2014.   
[29] S. Han, C.-l. I, Z. Xu, and C. Rowell, “Large-scale antenna systems with hybrid analog and digital beamforming for millimeter wave 5G,” IEEE Commun. Mag., vol. 53, no. 1, pp. 186–194, Jan. 2015.   
[30] F. Sohrabi and W. Yu, “Hybrid digital and analog beamforming design for large-scale antenna arrays,” IEEE J. Sel. Topics Signal Process., vol. 10, no. 3, pp. 501–513, Apr. 2016.   
[31] J. Zhang, R. Chen, J. G. Andrews, A. Ghosh, and R. W. Heath, “Networked MIMO with clustered linear precoding,” IEEE Trans. Wireless Commun., vol. 8, no. 4, pp. 1910–1921, Apr. 2009.   
[32] C. T. $\mathrm { N g }$ and H. Huang, “Linear precoding in cooperative MIMO cellular networks with limited coordination clusters,” IEEE J. Sel. Areas Commun., vol. 28, no. 9, pp. 1446–1454, Dec. 2010.   
[33] M. Hong, R. Sun, H. Baligh, and Z.-Q. Luo, “Joint base station clustering and beamformer design for partial coordinated transmission in heterogeneous networks,” IEEE J. Sel. Areas Commun., vol. 31, no. 2, pp. 226–240, Jan. 2013.   
[34] S.-H. Park, O. Simeone, O. Sahin, and S. Shamai, “Joint precoding and multivariate backhaul compression for the downlink of cloud radio access networks,” IEEE Trans. Signal Process., vol. 61, no. 22, pp. 5646–5658, Nov. 2013.   
[35] H. Liu, M.-C. Yue, A. M.-C. So, and W.-K. Ma, “A discrete first-order method for large-scale MIMO detection with provable guarantees,” in Proc. IEEE Workshop Signal Process. Adv. Wireless Commun. (SPAWC), Sapporo, Japan, Jul. 2017, pp. 669–673.   
[36] M. A. Albreem, M. Juntti, and S. Shahabuddin, “Massive MIMO detection techniques: A survey,” IEEE Commun. Surveys Tuts., vol. 21, no. 4, pp. 3109–3132, 4th Quart. 2019.   
[37] W.-K. Ma, P.-C. Ching, and Z. Ding, “Semidefinite relaxation based multiuser detection for M-ary PSK multiuser systems,” IEEE Trans. Signal Process., vol. 52, no. 10, pp. 2862–2872, Oct. 2004.   
[38] J. Jald´en, “Detection for multiple input multiple output channels: Analysis of sphere decoding and semidefinite relaxation,” Ph.D. dissertation, KTH, Stockholm, Sweden, 2006.   
[39] S. Jacobsson, G. Durisi, M. Coldrey, T. Goldstein, and C. Studer, “Quantized precoding for massive MU-MIMO,” IEEE Trans. Commun., vol. 65, no. 11, pp. 4670–4684, Nov. 2017.   
[40] F. Sohrabi, Y.-F. Liu, and W. Yu, “One-bit precoding and constellation range design for massive MIMO with QAM signaling,” IEEE J. Sel. Top. Signal Process., vol. 12, no. 3, pp. 557–570, Jun. 2018.   
[41] N. D. Sidiropoulos, T. N. Davidson, and Z.-Q. Luo, “Transmit beamforming for physical-layer multicasting,” IEEE Trans. Signal Process., vol. 54, no. 6, pp. 2239–2251, Jun. 2006.   
[42] J. Zander, “Performance of optimum transmitter power control in cellular radio systems,” IEEE Trans. Veh. Technol., vol. 41, no. 1, pp. 57–62, Feb. 1992.   
[43] “Distributed cochannel interference control in cellular radio systems,” IEEE Trans. Veh. Technol., vol. 41, no. 3, pp. 305–311, Aug. 1992.   
[44] I. Mitliagkas, N. D. Sidiropoulos, and A. Swami, “Joint power and admission control for ad-hoc and cognitive underlay networks: Convex approximation and distributed implementation,” IEEE Trans. Wireless Commun., vol. 10, no. 12, pp. 4110–4121, Dec. 2011.   
[45] Y.-F. Liu, Y.-H. Dai, and Z.-Q. Luo, “Joint power and admission control via linear programming deflation,” IEEE Trans. Signal Process., vol. 61, no. 6, pp. 1327–1338, Mar. 2013.   
[46] Z. Xu, M. Hong, and Z.-Q. Luo, “Semidefinite approximation for mixed binary quadratically constrained quadratic programs,” SIAM J. Optim., vol. 24, no. 3, pp. 1265–1293, 2014.   
[47] S. X.-Y. Ni and A. M.-C. So, “Mixed-integer semidefinite relaxation of joint admission control and beamforming: An SOC-based outer approximation approach with provable guarantees,” in Proc. IEEE Workshop Signal Process. Adv. Wireless Commun. (SPAWC), Kalamata, Greece, Jun. 2018, pp. 1–5.   
[48] K. Shen and W. Yu, “Fractional programming for communication systems—Part II: Uplink scheduling via matching,” IEEE Trans. Signal Process, vol. 66, no. 10, pp. 2631–2644, Mar. 2018.   
[49] Q. Wu and R. Zhang, “Towards smart and reconfigurable environment: Intelligent reflecting surface aided wireless network,” IEEE Commun. Mag., vol. 58, no. 1, pp. 106–112, Jan. 2020.   
[50] F. Liu, Y.-F. Liu, A. Li, C. Masouros, and Y. C. Eldar, “Cram´er-Rao bound optimization for joint radar-communication beamforming,” IEEE Trans. Signal Process., vol. 70, pp. 240–253, 2022.   
[51] J. Li, A. M.-C. So, and W.-K. Ma, “Understanding notions of stationarity in nonsmooth optimization: A guided tour of various constructions of subdifferential for nonsmooth functions,” IEEE Signal Process. Mag., vol. 37, no. 5, pp. 18–31, Sept. 2020.   
[52] Y. Xia, “A survey of hidden convex optimization,” J. Oper. Res. Soc. China, vol. 8, no. 1, pp. 1–28, 2020.   
[53] Q. Wu and R. Zhang, “Intelligent reflecting surface enhanced wireless network via joint active and passive beamforming,” IEEE Trans. Wireless Commun., vol. 18, no. 11, pp. 5394–5409, Nov. 2019.   
[54] H. Xie, J. Xu, and Y.-F. Liu, “Max-min fairness in IRS-aided multi-cell MISO systems with joint transmit and reflective beamforming,” IEEE Trans. Wireless Commun., vol. 20, no. 2, pp. 1379–1393, Feb. 2021.   
[55] X. Yu, J.-C. Shen, J. Zhang, and K. B. Letaief, “Alternating minimization algorithms for hybrid precoding in millimeter wave MIMO systems,” IEEE J. Sel. Top. Signal Process., vol. 10, no. 3, pp. 485–500, Apr. 2016.   
[56] T. Jiang, F. Sohrabi, and W. Yu, “Interference nulling using reconfigurable intelligent surface,” IEEE J. Sel. Areas Commun., vol. 40, no. 5, pp. 1392–1406, May 2022.   
[57] S. V. Hanly and D. Tse, “Power control and capacity of spread spectrum wireless networks,” Automatica, vol. 35, pp. 1987–2012, 1999.   
[58] S. V. Hanly, “An algorithm for combined cell-site selection and power control to maximize cellular spread spectrum capacity,” IEEE J. Sel. Areas Commun., vol. 13, no. 7, pp. 1332–1340, Sept. 1995.   
[59] G. Foschini and Z. Miljanic, “A simple distributed autonomous power control algorithm and its convergence,” IEEE Trans. Veh. Tech., vol. 42, no. 4, pp. 641 –646, Nov. 1993.   
[60] Y.-F. Liu, M. Hong, and Y.-H. Dai, “Max-min fairness linear transceiver design problem for a multi-user SIMO interference channel is polynomial time solvable,” IEEE Signal Process. Lett., vol. 20, no. 1, pp. 27–30, Jan. 2013.   
[61] X. Fan, Y.-F. Liu, and L. Liu, “Efficiently and globally solving joint beamforming and compression problem in the cooperative cellular network via Lagrangian duality,” in Proc. IEEE Int. Conf. Acoust., Speech, Signal Process. (ICASSP), Singapore, Singapore, May 2022, pp. 5388–5392.   
[62] A. Wiesel, Y. Eldar, and S. Shamai, “Linear precoding via conic optimization for fixed MIMO receivers,” IEEE Trans. Signal Process., vol. 54, no. 1, pp. 161–176, Jan. 2006.   
[63] M. Schubert and H. Boche, “Iterative multiuser uplink and downlink beamforming under SINR constraints,” IEEE Trans. Signal Process., vol. 53, no. 7, pp. 2324–2334, Jul. 2005.   
[64] W. Yu and T. Lan, “Transmitter optimization for the multi-antenna downlink with per-antenna power constraints,” IEEE Trans. Signal Process., vol. 55, no. 6, pp. 2646–2660, Jun. 2007.   
[65] H. Dahrouj and W. Yu, “Coordinated beamforming for the multicell multi-antenna wireless system,” IEEE Trans. Wireless Commun., vol. 9, no. 5, pp. 1748–1759, May 2010.   
[66] Z.-Q. Luo and S. Zhang, “Dynamic spectrum management: Complexity and duality,” IEEE J. Sel. Top. Signal Process., vol. 2, no. 1, pp. 57–73, Feb. 2008.   
[67] Y.-F. Liu, “Dynamic spectrum management: A complete complexity characterization,” IEEE Trans. Inf. Theory, vol. 63, no. 1, pp. 392– 403, Jan. 2017.   
[68] Y.-F. Liu and Y.-H. Dai, “On the complexity of joint subcarrier and power allocation for multi-user OFDMA systems,” IEEE Trans. Signal Process., vol. 62, no. 3, pp. 583–596, Feb. 2014.   
[69] Y.-F. Liu, Y.-H. Dai, and Z.-Q. Luo, “Coordinated beamforming for MISO interference channel: Complexity analysis and efficient algorithms,” IEEE Trans. Signal Process., vol. 59, no. 3, pp. 1142–1157, Mar. 2011.   
[70] “Max-min fairness linear transceiver design for a multi-user MIMO interference channel,” IEEE Trans. Signal Process., vol. 61, no. 9, pp. 2413–2423, May 2013.   
[71] S. Verdu´, “Computational complexity of optimum multiuser detection,” Algorithmica, vol. 4, no. 1, pp. 303–312, 1989.   
[72] Z.-Q. Luo, N. D. Sidiropoulos, P. Tseng, and S. Zhang, “Approximation bounds for quadratic optimization with homogeneous quadratic constraints,” SIAM J. Optim., vol. 18, no. 1, pp. 1–28, 2007.   
[73] Z. Wu, B. Jiang, Y.-F. Liu, M. Shao, and Y.-H. Dai, “Efficient CI-based one-bit precoding for multiuser downlink massive MIMO systems with PSK modulation,” IEEE Trans. Wireless Commun., vol. 23, no. 5, pp. 4861–4875, May 2024.   
[74] P. C. Weeraddana, M. Codreanu, M. Latva-aho, A. Ephremides, and C. Fischione, “Weighted sum-rate maximization in wireless networks: A review,” Found. Trends Netw., vol. 6, no. 1–2, pp. 1–163, 2012.   
[75] M. Hong and Z.-Q. Luo, “Signal processing and optimal resource allocation for the interference channel,” in Academic Press Library in Signal Processing. Elsevier, 2014, vol. 2, pp. 409–469.   
[76] A. Zappone and E. Jorswieck, “Energy efficiency in wireless networks via fractional programming theory,” Found. Trends Commun. Inf. Theory, vol. 11, no. 3, pp. 185–396, 2015.   
[77] J. Zou, S. Sun, C. Masouros, Y. Cui, Y.-F. Liu, and D. W. K. Ng, “Energy-efficient beamforming design for integrated sensing and communications systems,” IEEE Trans. Commun. (early access), 2024.   
[78] K. Shen and W. Yu, “Fractional programming for communication systems—Part I: Power control and beamforming,” IEEE Trans. Signal Process, vol. 66, no. 10, pp. 2616–2630, Mar. 2018.   
[79] K. Shen, W. Yu, L. Zhao, and D. P. Palomar, “Optimization of MIMO device-to-device networks via matrix fractional programming: A minorization–maximization approach,” IEEE ACM Trans. Netw., vol. 27, no. 5, pp. 2164–2177, Oct. 2019.   
[80] S. S. Christensen, R. Argawal, E. de Carvalho, and J. M. Cioffi, “Weighted sum-rate maximization using weighted MMSE for MIMOBC beamforming design,” IEEE Trans. Wireless Commun., vol. 7, no. 12, pp. 1–7, Dec. 2008.   
[81] Q. Shi, M. Razaviyayn, Z.-Q. Luo, and C. He, “An iteratively weighted MMSE approach to distributed sum-utility maximization for a MIMO interfering broadcast channel,” IEEE Trans. Signal Process., vol. 59, no. 9, pp. 4331–4340, Sep. 2011.   
[82] H. Guo, Y.-C. Liang, J. Chen, and E. G. Larsson, “Weighted sumrate maximization for reconfigurable intelligent surface aided wireless networks,” IEEE Trans. Wireless Commun., vol. 19, no. 5, pp. 3064– 3076, Feb. 2020.   
[83] H. Li, M. Li, and Q. Liu, “Hybrid beamforming with dynamic subarrays and low-resolution PSs for mmWave MU-MISO systems,” IEEE Trans. Commun., vol. 68, no. 1, pp. 602–614, Nov. 2020.   
[84] D. Donoho, “Compressed sensing,” IEEE Trans. Inf. Theory, vol. 52, no. 4, pp. 1289–1306, Apr. 2006.   
[85] S. Zhang, X. Ning, X. Zheng, Q. Shi, T.-H. Chang, and Z.-Q. Luo, “A physics-based and data-driven approach for localized statistical channel modeling,” IEEE Trans. Wireless Commun. (early access), pp. 1–16, 2023.   
[86] C. Bockelmann, N. Pratas, H. Nikopour, K. Au, T. Svensson, C. Stefanovi´c, P. Popovski, and A. Dekorsy, “Massive machine-type communications in 5G: Physical and MAC-layer solutions,” IEEE Commun. Mag., vol. 54, no. 9, pp. 59–65, Sep. 2016.   
[87] B. K. Natarajan, “Sparse approximate solutions to linear systems,” SIAM J. Comput., vol. 24, no. 2, pp. 227–234, 1995.   
[88] Y. C. Eldar and G. Kutyniok, Compressed Sensing: Theory and Applications. Cambridge, U.K.: Cambridge Univ. Press, 2012.   
[89] E. J. Candes and T. Tao, “Decoding by linear programming,” IEEE Trans. Inf. Theory, vol. 51, no. 12, pp. 4203–4215, Dec. 2005. [90] E. J. Candes, “The restricted isometry property and its implications for compressed sensing,” C.R. Math. Acad. Sci. Paris, vol. 346, no. 9-10, pp. 589–592, May 2008. [91] Q. Mo and S. Li, “New bounds on the restricted isometry constant $\delta _ { 2 k }$ ,” Appl. Comp. Har. Anal., vol. 31, no. 3, pp. 460–468, 2011. [92] R. Baraniuk, M. Davenport, R. DeVore, and M. Wakin, “A simple proof of the restricted isometry property for random matrices,” Constr. Approx., vol. 28, pp. 253–263, Dec. 2008. [93] E. J. Candes and T. Tao, “Near-optimal signal recovery from random projections: Universal encoding strategies?” IEEE Trans. Inf. Theory, vol. 52, no. 12, pp. 5406–5425, Dec. 2006. [94] J. W. Choi, B. Shim, Y. Ding, B. Rao, and D. I. Kim, “Compressed sensing for wireless communications: Useful tips and tricks,” IEEE Commun. Surv. Tutor., vol. 19, no. 3, pp. 1527–1550, 3rd Quart. 2017.   
[95] Z.-Q. Luo, X. Zheng, D. Lo´pez-Pe´rez, Q. Yan, X. Chen, N. Wang, Q. Shi, T.-H. Chang et al., “SRCON: A data-driven network performance simulator for real-world wireless networks,” IEEE Commun. Mag., vol. 61, no. 6, pp. 96–102, Jun. 2023. [96] Y. Li, S. Zhang, X. Ren, J. Zhu, J. Huang, P. He, K. Shen, Z. Yao et al., “Real-world wireless network modeling and optimization: From model/data-driven perspective,” Chin. J. Electron., vol. 31, no. 6, pp. 991–1012, Nov. 2022.   
[97] S. Zhang, Y. Xue, Q. Shi, and T.-H. Chang, “Statistical channel modeling methods in wireless network twinning: Current status and frontiers,” ZTE Technology Journal, vol. 29, no. 3, pp. 26–31, 2023. [98] K. Senel and E. G. Larsson, “Grant-free massive MTC-enabled massive MIMO: A compressive sensing approach,” IEEE Trans. Commun., vol. 66, no. 12, pp. 6164–6175, Dec. 2018. [99] L. Liu and W. Yu, “Massive connectivity with massive MIMO—Part I: Device activity detection and channel estimation,” IEEE Trans. Signal Process., vol. 66, no. 11, pp. 2933–2946, Jun. 2018.   
[100] , “Massive connectivity with massive MIMO—Part II: Achievable rate characterization,” IEEE Trans. Signal Process., vol. 66, no. 11, pp. 2947–2959, Jun. 2018.   
[101] Z. Zhou, Q. Zhang, and A. M.-C. So, $\cdot \ell _ { 1 , p }$ -norm regularization: Error bounds and convergence rate analysis of first-order methods,” in Proc. Int. Conf. Mach. Learn. (ICML), Lille, France, Jul. 2015, pp. 1501– 1510.   
[102] Z. Zhou and A. M.-C. So, “A unified approach to error bounds for structured convex optimization problems,” Math. Program., vol. 165, no. 2, pp. 689–728, 2017.   
[103] Z. Chen, F. Sohrabi, and W. Yu, “Sparse activity detection for massive connectivity,” IEEE Trans. Signal Process., vol. 66, no. 7, pp. 1890– 1904, Apr. 2018.   
[104] W. Zhu, M. Tao, X. Yuan, and Y. Guan, “Message passing-based joint user activity detection and channel estimation for temporally-correlated massive access,” IEEE Trans. Commun., vol. 71, no. 6, pp. 3576–3591, Jun. 2023.   
[105] A. Rajoriya and R. Budhiraja, “Joint AMP-SBL algorithms for device activity detection and channel estimation in massive MIMO mMTC systems,” IEEE Trans. Commun., vol. 71, no. 4, pp. 2136–2152, Apr. 2023.   
[106] S. Zhang, Y. Cui, and W. Chen, “Joint device activity detection, channel estimation and signal detection for massive grant-free access via BiGAMP,” IEEE Trans. Signal Process., vol. 71, pp. 1200–1215, Apr. 2023.   
[107] T. Li, J. Zhang, Z. Yang, Z. L. Yu, Z. Gu, and Y. Li, “Dynamic user activity and data detection for grant-free NOMA via weighted $\ell _ { 2 , 1 }$ minimization,” IEEE Trans. Wireless Commun., vol. 21, no. 3, pp. 1638–1651, Mar. 2022.   
[108] Y.-F. Liu, W. Yu, Z. Wang, Z. Chen, and F. Sohrabi, “Grant-free random access via covariance-based approach,” in Next Generation Multiple Access., (Editors: Yuanwei Liu, Liang Liu, Zhiguo Ding, and Xuemin (Sherman) Shen), Wiley, 2023.   
[109] Z. Chen, F. Sohrabi, Y.-F. Liu, and W. Yu, “Phase transition analysis for covariance based massive random access with massive MIMO,” IEEE Trans. Inf. Theory, vol. 68, no. 3, pp. 1696–1715, Mar. 2022.   
[110] A. Fengler, S. Haghighatshoar, P. Jung, and G. Caire, “Non-Bayesian activity detection, large-scale fading coefficient estimation, and unsourced random access with a massive MIMO receiver,” IEEE Trans. Inf. Theory, vol. 67, no. 5, pp. 2925–2951, May 2021.   
[111] Z. Chen, F. Sohrabi, and W. Yu, “Sparse activity detection in multicell massive MIMO exploiting channel large-scale fading,” IEEE Trans. Signal Process., vol. 69, pp. 3768–3781, 2021.   
[112] Z. Wang, Y.-F. Liu, Z. Wang, and W. Yu, “Covariance-based activity detection in cooperative multi-cell massive MIMO: Scaling rxiv.org/   
[113] Z. Wang, Y.-F. Liu, and L. Liu, “Covariance-based joint device activity and delay detection in asynchronous mMTC,” IEEE Signal Process. Lett., vol. 29, pp. 538–542, Jan. 2022.   
[114] Y. Li, Q. Lin, Y.-F. Liu, B. Ai, and Y.-C. Wu, “Asynchronous activity detection for cell-free massive MIMO: From centralized to distributed algorithms,” IEEE Trans. Wireless Commun., vol. 22, no. 4, pp. 2477– 2492, Apr. 2023.   
[115] Z. Wang, Y.-F. Liu, Z. Wang, L. Liu, H. Pan, and S. Cui, “Device activity detection in mMTC with low-resolution ADCs: A new protocol,” IEEE Trans. Wireless Commun. (early access), 2023.   
[116] X. Rao and V. K. Lau, “Distributed compressive CSIT estimation and feedback for FDD multi-user massive MIMO systems,” IEEE Trans. Signal Process., vol. 62, no. 12, pp. 3261–3271, Jun. 2014.   
[117] X. Cheng, J. Sun, and S. Li, “Channel estimation for FDD multi-user massive MIMO: A variational Bayesian inference-based approach,” IEEE Trans. Wireless Commun., vol. 16, no. 11, pp. 7590–7602, Nov. 2017.   
[118] J. Ma, S. Zhang, H. Li, F. Gao, and S. Jin, “Sparse Bayesian learning for the time-varying massive MIMO channels: Acquisition and tracking,” IEEE Trans. Commun., vol. 67, no. 3, pp. 1925–1938, Mar. 2019.   
[119] N. Parikh and S. Boyd, “Proximal algorithms,” Found. Trends Optim., vol. 1, no. 3, pp. 127–239, 2014.   
[120] A. Beck, First-Order Methods in Optimization. Philadelphia, PA, USA: SIAM, 2017.   
[121] P. L. Combettes and J.-C. Pesquet, “Proximal splitting methods in signal processing,” Fixed-Point Algorithms for Inverse Problems in Science and Engineering, pp. 185–212, 2011.   
[122] H. Attouch, J. Bolte, and B. F. Svaiter, “Convergence of descent methods for semi-algebraic and tame problems: Proximal algorithms, forward–backward splitting, and regularized Gauss–Seidel methods,” Math. Program., vol. 137, no. 1, pp. 91–129, 2013.   
[123] H. Attouch, J. Bolte, P. Redont, and A. Soubeyran, “Proximal alternating minimization and projection methods for nonconvex problems: An approach based on the Kurdyka-Łojasiewicz inequality,” Math. Oper. Res., vol. 35, no. 2, pp. 438–457, May 2010.   
[124] M. Hong, Q. Li, and Y.-F. Liu, “Decomposition by successive convex approximation: A unifying approach for linear transceiver design in heterogeneous networks,” IEEE Trans. Wireless Commun., vol. 15, no. 2, pp. 1377–1392, Oct. 2016.   
[125] M. S. Ibrahim, A. Konar, and N. D. Sidiropoulos, “Fast algorithms for joint multicast beamforming and antenna selection in massive MIMO,” IEEE Trans. Signal Process., vol. 68, pp. 1897–1909, Mar. 2020.   
[126] M. Shao, Q. Li, W.-K. Ma, and A. M.-C. So, “A framework for onebit and constant-envelope precoding over multiuser massive MISO channels,” IEEE Trans. Signal Process., vol. 67, no. 20, pp. 5309– 5324, Oct. 2019.   
[127] A. Mobasher, M. Taherzadeh, R. Sotirov, and A. K. Khandani, “A nearmaximum-likelihood decoding algorithm for MIMO systems based on semi-definite programming,” IEEE Trans. Inf. Theory, vol. 53, no. 11, pp. 3869–3886, Nov. 2007.   
[128] Y. Xia, “An efficient continuation method for quadratic assignment problems,” Comput. Oper. Res., vol. 37, no. 6, pp. 1027–1032, Jun. 2010.   
[129] P.-F. Zhao, Q.-N. Li, W.-K. Chen, and Y.-F. Liu, “An efficient quadratic programming relaxation based algorithm for large-scale MIMO detection,” SIAM J. Optim, vol. 31, no. 2, pp. 1519–1545, 2021.   
[130] B. Jiang, Y.-F. Liu, and Z. Wen, $\cdot _ { L _ { p } }$ -norm regularization algorithms for optimization over permutation matrices,” SIAM J. Optim., vol. 26, no. 4, pp. 2284–2313, 2016.   
[131] L. Xiao and T. Zhang, “A proximal-gradient homotopy method for the sparse least-squares problem,” SIAM J. Optim., vol. 23, no. 2, pp. 1062–1091, 2013.   
[132] A. Li, C. Masouros, F. Liu, and A. L. Swindlehurst, “Massive MIMO 1-bit DAC transmission: A low-complexity symbol scaling approach,” IEEE Trans. Wireless Commun., vol. 17, no. 11, pp. 7559–7575, Nov. 2018.   
[133] Z. Xu, H. Zhang, Y. Xu, and G. Lan, “A unified single-loop alternating gradient projection algorithm for nonconvex-concave and convexnonconcave minimax problems,” Math. Program., vol. 201, no. 1, pp. 635–706, 2023.   
[134] S. Lu, I. Tsaknakis, M. Hong, and Y. Chen, “Hybrid block successive approximation for one-sided non-convex min-max problems: Algorithms and applications,” IEEE Trans. Signal Process., vol. 68, pp. 3676–3691, Apr. 2020.   
[135] Z. Wu, Y.-F. Liu, W.-K. Chen, and C. Masouros, “Quantized constantenvelope waveform design for massive MIMO DFRC systems,” 2024. [Online]. Available: https://arxiv.org/abs/2403.06185   
[136] Z. Wu, J. Wu, W.-K. Chen, and Y.-F. Liu, “Diversity order analysis for quantized constant envelope transmission,” IEEE Open J. Signal Process., vol. 4, pp. 21–30, 2023.   
[137] Z. Wu, J. Ma, Y.-F. Liu, and A. L. Swindlehurst, “Asymptotic SEP analysis and optimization of linear-quantized precoding in massive MIMO systems,” IEEE Trans Inf. Theory, vol. 70, no. 4, pp. 2566– 2589, Apr. 2024.   
[138] F. Rashid-Farrokhi, K. R. Liu, and L. Tassiulas, “Transmit beamforming and power control for cellular wireless systems,” IEEE J. Sel. Areas Commun., vol. 16, no. 8, pp. 1437–1450, Oct. 1998.   
[139] P. Viswanath and D. Tse, “Sum capacity of the vector Gaussian broadcast channel and uplink–downlink duality,” IEEE Trans. Inf. Theory, vol. 49, no. 8, pp. 1912–1921, Aug. 2003.   
[140] S. Vishwanath, N. Jindal, and A. Goldsmith, “Duality, achievable rates, and sum-rate capacity of Gaussian MIMO broadcast channels,” IEEE Trans. Inf. Theory, vol. 49, no. 10, pp. 2658–2668, Oct. 2003.   
[141] B. Song, R. L. Cruz, and B. D. Rao, “Network duality for multiuser MIMO beamforming networks and applications,” IEEE Trans. Commun., vol. 55, no. 3, pp. 618–630, Mar. 2007.   
[142] W. Yu, “Uplink-downlink duality via minimax duality,” IEEE Trans. Inf. Theory, vol. 52, no. 2, pp. 361–374, Feb. 2006.   
[143] L. Liu, Y.-F. Liu, P. Patil, and W. Yu, “Uplink-downlink duality between multiple-access and broadcast channels with compressing relays,” IEEE Trans. Inf. Theory, pp. 7304–7337, Nov. 2021.   
[144] W. Yu, W. Rhee, S. Boyd, and J. Cioffi, “Iterative water-filling for Gaussian vector multiple-access channels,” IEEE Trans. Inf. Theory, vol. 50, no. 1, pp. 145–152, Jan. 2004.   
[145] W. Yu, G. Ginis, and J. Cioffi, “Distributed multiuser power control for digital subscriber lines,” IEEE J. Sel. Areas Commun., vol. 20, no. 5, pp. 1105–1115, 2002.   
[146] W. Yu and R. Lui, “Dual methods for nonconvex spectrum optimization of multicarrier systems,” IEEE Trans. Commun., vol. 54, no. 7, pp. 1310–1322, Jul. 2006.   
[147] B. Clerckx, Y. Mao, R. Schober, E. A. Jorswieck, D. J. Love, J. Yuan, L. Hanzo, G. Y. Li et al., “Is NOMA efficient in multi-antenna networks? A critical look at next generation multiple access techniques,” IEEE Open J. Commun. Soc., vol. 2, pp. 1310–1343, Jun. 2021.   
[148] S. Rezvani, E. A. Jorswieck, R. Joda, and H. Yanikomeroglu, “Optimal power allocation in downlink multicarrier NOMA systems: Theory and fast algorithms,” IEEE J. Sel. Areas Commun., vol. 40, no. 4, pp. 1162– 1189, Apr. 2022.   
[149] S. Rezvani, E. A. Jorswieck, N. M. Yamchi, and M. R. Javan, “Optimal SIC ordering and power allocation in downlink multi-cell NOMA systems,” IEEE Trans. Wireless Commun., vol. 21, no. 6, pp. 3553– 3569, Jun. 2022.   
[150] E. L. Lawler and D. E. Wood, “Branch-and-bound methods: A survey,” Oper. Res., vol. 14, no. 4, pp. 699–719, 1966.   
[151] M. Padberg and G. Rinaldi, “A branch-and-cut algorithm for the resolution of large-scale symmetric traveling salesman problems,” SIAM Rev., vol. 33, no. 1, pp. 60–100, 1991.   
[152] L. A. Wolsey and G. L. Nemhauser, Integer and Combinatorial Optimization. Hoboken, NJ, USA: John Wiley & Sons, 1999.   
[153] C. Lu, Y.-F. Liu, and J. Zhou, “An enhanced SDR based global algorithm for nonconvex complex quadratic programs with signal processing applications,” IEEE Open J. Signal Process., vol. 1, pp. 120–134, Aug. 2020.   
[154] C. Chen, A. Atamtu¨rk, and S. S. Oren, “A spatial branch-and-cut method for nonconvex QCQP with bounded complex variables,” Math. Program., vol. 165, pp. 549–577, 2017.   
[155] C. Lu and Y.-F. Liu, “An efficient global algorithm for single-group multicast beamforming,” IEEE Trans. Signal Process., vol. 65, no. 14, pp. 3761–3774, Jul. 2017.   
[156] C. Lu, Z. Deng, W.-Q. Zhang, and S.-C. Fang, “Argument division based branch-and-bound algorithm for unit-modulus constrained complex quadratic programming,” J. Glob. Optim., vol. 70, no. 1, pp. 171– 187, Aug. 2018.   
[157] C. Lu, Y.-F. Liu, W.-Q. Zhang, and S. Zhang, “Tightness of a new and enhanced semidefinite relaxation for MIMO detection,” SIAM J. Optim, vol. 29, no. 1, pp. 719–742, Mar. 2019.   
[158] Y. Xu, C. Lu, Z. Deng, and Y.-F. Liu, “New semidefinite relaxations for a class of complex quadratic programming problems,” J. Glob. Optim., pp. 1–21, 2023.   
[159] B. Matthiesen, C. Hellings, E. A. Jorswieck, and W. Utschick, “Mixed monotonic programming for fast global optimization,” IEEE Trans. Signal Process., vol. 68, pp. 2529–2544, 2020.   
[160] L. P. Qian, Y. J. Zhang, and J. Huang, “MAPEL: Achieving global optimality for a non-convex wireless power control problem,” IEEE Trans. Wireless Commun., vol. 8, no. 3, pp. 1553–1563, Mar. 2009.   
[161] H. Tuy, “Monotonic optimization: Problems and solution approaches,” SIAM J. Optim., vol. 11, no. 2, pp. 464–494, 2000.   
[162] R. E. Gomory, “Outline of an algorithm for integer solutions to linear programs,” Bull. Amer. Math. Soc., vol. 64, pp. 275–278, 1958.   
[163] H. Marchand, A. Martin, R. Weismantel, and L. Wolsey, “Cutting planes in integer and mixed integer programming,” Discrete Appl. Math., vol. 123, no. 1-3, pp. 397–446, 2002.   
[164] G. Cornu´ejols, “Valid inequalities for mixed integer linear programs,” Math. program., vol. 112, no. 1, pp. 3–44, 2008.   
[165] N. Zhang, Y.-F. Liu, H. Farmanbar, T.-H. Chang, M. Hong, and Z.- Q. Luo, “Network slicing for service-oriented networks under resource constraints,” IEEE J. Sel. Areas Commun., vol. 35, no. 11, pp. 2512– 2521, Oct. 2017.   
[166] G. Tychogiorgos, A. Gkelias, and K. K. Leung, “A non-convex distributed optimization framework and its application to wireless ad-hoc networks,” IEEE Trans. Wireless Commun., vol. 12, no. 9, pp. 4286– 4296, Sept. 2013.   
[167] R. Lin, Z. Zhou, S. Luo, Y. Xiao, X. Wang, S. Wang, and M. Zukerman, “Distributed optimization for computation offloading in edge computing,” IEEE Trans. Wireless Commun., vol. 19, no. 12, pp. 8179–8194, Dec. 2020.   
[168] I. Boukhedimi, A. Kammoun, and M.-S. Alouini, “Coordinated SLNR based precoding in large-scale heterogeneous networks,” IEEE J. Sel. Top. Signal Process., vol. 11, no. 3, pp. 534–548, Apr. 2017.   
[169] P. Komulainen, A. T¨olli, and M. Juntti, “Effective CSI signaling and decentralized beam coordination in TDD multi-cell MIMO systems,” IEEE Trans. Signal Process., vol. 61, no. 9, pp. 2204–2218, May 2013.   
[170] M. Maros and J. Jald´en, “ADMM for distributed dynamic beamforming,” IEEE Trans. Signal Inf. Process. Netw., vol. 4, no. 2, pp. 220–235, Jun. 2018.   
[171] A. Falsone, K. Margellos, S. Garatti, and M. Prandini, “Dual decomposition for multi-agent distributed optimization with coupling constraints,” Automatica, vol. 84, pp. 149–158, 2017.   
[172] S. Boyd, N. Parikh, E. Chu, B. Peleato, and J. Eckstein, “Distributed optimization and statistical learning via the alternating direction method of multipliers,” Found. Trends Mach. Learn., vol. 3, no. 1, pp. 1–122, 2011.   
[173] W. Deng, M.-J. Lai, Z. Peng, and W. Yin, “Parallel multi-block ADMM with $o ( 1 / k )$ convergence,” J. Sci. Comput., vol. 71, pp. 712–736, 2017.   
[174] J. Zhang and Z.-Q. Luo, “A proximal alternating direction method of multiplier for linearly constrained nonconvex minimization,” SIAM J. Optim., vol. 30, no. 3, pp. 2272–2302, 2020.   
[175] T.-H. Chang, M. Hong, W.-C. Liao, and X. Wang, “Asynchronous distributed ADMM for large-scale optimization–Part I: Algorithm and convergence analysis,” IEEE Trans. Signal Process., vol. 64, no. 12, pp. 3118–3130, Jun. 2016.   
[176] M. Hong, Z.-Q. Luo, and M. Razaviyayn, “Convergence analysis of alternating direction method of multipliers for a family of nonconvex problems,” SIAM J. Optim., vol. 26, no. 1, pp. 337–364, 2016.   
[177] Y. Shi, K. Yang, T. Jiang, J. Zhang, and K. B. Letaief, “Communicationefficient edge AI: Algorithms and systems,” IEEE Commun. Surv. Tutor., vol. 22, no. 4, pp. 2167–2191, 4th Quart. 2020.   
[178] Y. Wang, Q. Shi, and T.-H. Chang, “Why batch normalization damage federated learning on non-IID data?” IEEE Trans. Neural Netw. Learn. Syst. (early access), pp. 1–15, 2023.   
[179] Y. Wang, Y. Xu, Q. Shi, and T.-H. Chang, “Quantized federated learning under transmission delay and outage constraints,” IEEE J. Sel. Areas Commun., vol. 40, no. 1, pp. 323–341, Jan. 2022.   
[180] B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas, “Communication-efficient learning of deep networks from decentralized data,” in Proc. Int. Conf. Artif. Intell. Statist. (AISTATS), Fort Lauderdale, FL, USA, Apr. 2017, pp. 1273–1282.   
[181] X. Zhang, M. Hong, S. Dhople, W. Yin, and Y. Liu, “FedPD: A federated learning framework with adaptivity to non-IID data,” IEEE Trans. Signal Process., vol. 69, pp. 6055–6070, 2021.   
[182] S. Wang, Y. Xu, Z. Wang, T.-H. Chang, T. Q. Quek, and D. Sun, “Beyond ADMM: A unified client-variance-reduced adaptive federated learning framework,” in Proc. AAAI Conf. Artif. Intell., vol. 37, no. 8, Washington, DC, USA, Feb. 2023, pp. 10 175–10 183.   
[183] M. Hong, D. Hajinezhad, and M.-M. Zhao, “Prox-PDA: The proximal primal-dual algorithm for fast distributed nonconvex optimization and learning over networks,” in Proc. Int. Conf. Mach. Learn. (ICML), Sydney, Australia, Aug. 2017, pp. 1529–1538.   
[184] A. Tolli, H. Pennanen, and P. Komulainen, “Decentralized minimum power multi-cell beamforming with limited backhaul signaling,” IEEE Trans. Wireless Commun., vol. 10, no. 2, pp. 570–580, Feb. 2011.   
[185] C. Shen, T.-H. Chang, K.-Y. Wang, Z. Qiu, and C.-Y. Chi, “Distributed robust multicell coordinated beamforming with imperfect CSI: An ADMM approach,” IEEE Trans. Signal Process., vol. 60, no. 6, pp. 2988–3003, Jun. 2012.   
[186] C. Shen, T.-H. Chang, J. Gong, Y. Zeng, and R. Zhang, “Multi-UAV interference coordination via joint trajectory and power control,” IEEE Trans. Signal Process., vol. 68, pp. 843–858, 2020.   
[187] T.-H. Chang, M. Hong, H.-T. Wai, X. Zhang, and S. Lu, “Distributed learning in the nonconvex world: From batch data to streaming and beyond,” IEEE Signal Process. Mag., vol. 37, no. 3, pp. 26–38, May 2020.   
[188] X. Li, K. Huang, W. Yang, S. Wang, and Z. Zhang, “On the convergence of FedAvg on Non-IID data,” in Proc. ICLR, New Orleans, LA, USA, May 2019.   
[189] M. Chen, Z. Yang, W. Saad, C. Yin, H. V. Poor, and S. Cui, “A joint learning and communications framework for federated learning over wireless networks,” IEEE Trans. Wireless Commun., vol. 20, no. 1, pp. 269–283, Jan. 2021.   
[190] M. Salehi and E. Hossain, “Federated learning in unreliable and resource-constrained cellular wireless networks,” IEEE Trans. Commun., vol. 69, no. 8, pp. 5136–5151, Aug. 2021.   
[191] G. Zhu, Y. Du, D. Gunduz, and K. Huang, “One-bit over-the-air aggregation for communication-efficient federated edge learning: Design and convergence analysis,” IEEE Trans. Wireless Commun., vol. 20, no. 3, pp. 2120–2135, Mar. 2021.   
[192] A. Reisizadeh, A. Mokhtari, H. Hassani, A. Jadbabaie, and R. Pedarsani, “FedPAQ: A communication-efficient federated learning method with periodic averaging and quantization,” in Proc. Int. Conf. Artif. Intell. Statist. (AISTATS), Palermo, Italy, Aug. 2020, pp. 2021– 2031.   
[193] S. Zheng, C. Shen, and X. Chen, “Design and analysis of uplink and downlink communications for federated learning,” IEEE J. Sel. Areas Commun., vol. 39, no. 7, pp. 2150–2167, Jul. 2020.   
[194] J. Liu and C. Zhang, “Distributed learning systems with first-order methods,” Found. Trends Databases, vol. 9, no. 1, pp. 1–100, 2020.   
[195] J. Wang, Q. Liu, H. Liang, G. Joshi, and H. V. Poor, “Tackling the objective inconsistency problem in heterogeneous federated optimization,” in Proc. NeurIPS, vol. 33, Dec. 2020, pp. 7611–7623.   
[196] Y. Gong, Y. Li, and N. M. Freris, “FedADMM: A robust federated deep learning framework with adaptivity to system heterogeneity,” in Proc. Int. Conf. Data Eng. (ICDE), Kuala Lumpur, Malaysia, May 2022, pp. 2575–2587.   
[197] G. Hinton, L. Deng, D. Yu, G. E. Dahl, A.-R. Mohamed, N. Jaitly, A. Senior, V. Vanhoucke et al., “Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups,” IEEE Signal Process. Mag., vol. 29, no. 6, pp. 82–97, Nov. 2012.   
[198] A. Krizhevsky, I. Sutskever, and G. E. Hinton, “Imagenet classification with deep convolutional neural networks,” in Proc. NeurIPS, Lake Tahoe, Nevada, USA, Dec. 2012, pp. 1097–1105.   
[199] B. Liu, “Sentiment analysis and opinion mining,” Synth. Lect. Hum. Lang. Technol., vol. 5, no. 1, pp. 1–167, 2012.   
[200] J. Papandriopoulos and J. S. Evans, “SCALE: A low-complexity distributed protocol for spectrum balancing in multiuser DSL networks,” IEEE Trans. Inf. Theory, vol. 55, no. 8, pp. 3711–3724, Aug. 2009.   
[201] X. Wu, S. Tavildar, S. Shakkottai, T. Richardson, J. Li, R. Laroia, and A. Jovicic, “FlashLinQ: A synchronous distributed scheduler for peerto-peer ad hoc networks,” IEEE/ACM Trans. Netw., vol. 21, no. 4, pp. 1215–1228, Aug. 2013.   
[202] N. Naderializadeh and A. S. Avestimehr, “ITLinQ: A new approach for spectrum sharing in device-to-device communication systems,” IEEE J. Sel. Areas Commun., vol. 32, no. 6, pp. 1139–1151, Jun. 2014.   
[203] E. Bjornson and E. Jorswieck, “Optimal resource allocation in coordinated multi-cell systems,” Found. Trends Commun. Inf. Theory, vol. 9, 2013.   
[204] M. Razaviyayn, M. Sanjabi, and Z.-Q. Luo, “A stochastic successive minimization method for nonsmooth nonconvex optimization with applications to transceiver design in wireless communication networks,” Math. Program., no 2, pp. 515–545, 2017.   
[205] H. Sun, X. Chen, Q. Shi, M. Hong, X. Fu, and N. D. Sidiropoulos, “Learning to optimize: Training deep neural networks for interference management,” IEEE Trans. Signal Process., vol. 66, no. 20, pp. 5438– 5453, Oct. 2018.   
[206] K. Hornik, M. Stinchcombe, and H. White, “Multilayer feedforward networks are universal approximators,” Neural Netw., vol. 2, no. 5, pp. 359–366, 1989.   
[207] F. Liang, C. Shen, W. Yu, and F. Wu, “Towards optimal power control via ensembling deep neural networks,” IEEE Trans. Commun., vol. 68, no. 3, pp. 1760–1776, Mar. 2020.   
[208] M. Eisen and A. Ribeiro, “Optimal wireless resource allocation with random edge graph neural networks,” IEEE Trans. Signal Process., vol. 68, pp. 2977–2991, 2020.   
[209] S. Shrestha, X. Fu, and M. Hong, “Optimal solutions for joint beamforming and antenna selection: From branch and bound to graph neural imitation learning,” IEEE Trans. Signal Process., vol. 71, pp. 831–846, 2023.   
[210] J. Wu, Z. Wang, Y.-F. Liu, and F. Liu, “Efficient global algorithms for transmit beamforming design in ISAC systems,” 2014. [Online]. Available: http://arx org/abs/1408.5710   
[211] W. Xia, G. Zheng, Y. Zhu, J. Zhang, J. Wang, and A. P. Petropulu, “A deep learning framework for optimization of MISO downlink beamforming,” IEEE Trans. Commun., vol. 68, no. 3, pp. 1866–1880, Mar. 2020.   
[212] H. Sun, W. Pu, X. Fu, T.-H. Chang, and M. Hong, “Learning to continuously optimize wireless resource in a dynamic environment: A bilevel optimization perspective,” IEEE Trans. Signal Process., vol. 70, pp. 1900–1917, 2022.   
[213] Z. Zhang, M. Tao, and Y.-F. Liu, “Learning to beamform in joint multicast and unicast transmission with imperfect CSI,” IEEE Trans. Commun., vol. 71, no. 5, pp. 2711–2723, May 2023.   
[214] Y. Li and Y.-F. Liu, “HPE transformer: Learning to optimize multigroup multicast beamforming under nonconvex QoS constraints,” IEEE Trans. Commun., pp. 1–1, 2024.   
[215] N. Samuel, T. Diskin, and A. Wiesel, “Learning to detect,” IEEE Trans. Signal Process., vol. 67, no. 10, pp. 2554–2564, May 2019.   
[216] Q. Hu, Y. Cai, Q. Shi, K. Xu, G. Yu, and Z. Ding, “Iterative algorithm induced deep-unfolding neural networks: Precoding design for multiuser MIMO systems,” IEEE Trans. Wireless Commun., vol. 20, no. 2, pp. 1394–1410, Feb. 2021.   
[217] L. Pellaco, M. Bengtsson, and J. Jald´en, “Matrix-inverse-free deep unfolding of the weighted MMSE beamforming algorithm,” IEEE Open J. Commun. Soc., vol. 3, pp. 65–81, 2022.   
[218] M. Zhu, T.-H. Chang, and M. Hong, “Learning to beamform in heterogeneous massive MIMO networks,” IEEE Trans. Wireless Commun., vol. 22, no. 7, pp. 4901–4915, Jul. 2023.   
[219] W. Yu, F. Sohrabi, and T. Jiang, “Role of deep learning in wireless communications,” IEEE BITS Inf. Theory Mag., vol. 2, no. 2, pp. 56– 72, Nov. 2022.   
[220] W. Cui, K. Shen, and W. Yu, “Spatial deep learning for wireless scheduling,” IEEE J. Sel. Areas Commun., vol. 37, no. 6, pp. 1248– 1261, Jun. 2019.   
[221] M. Lee, G. Yu, and G. Y. Li, “Graph embedding-based wireless link scheduling with few training samples,” IEEE Trans. Wireless Commun., vol. 20, no. 4, pp. 2282–2294, Apr. 2021.   
[222] Y. Shen, Y. Shi, J. Zhang, and K. B. Letaief, “Graph neural networks for scalable radio resource management: Architecture design and theoretical analysis,” IEEE J. Sel. Areas Commun., vol. 39, no. 1, pp. 101–115, Jan. 2021.   
[223] R. Levie, C. Yapar, G. Kutyniok, and G. Caire, “RadioUNet: Fast radio map estimation with convolutional neural networks,” IEEE Trans. Wireless Commun., vol. 20, no. 6, pp. 4001–4015, Jun. 2021.   
[224] J. Chen, Y.-C. Liang, H. V. Cheng, and W. Yu, “Channel estimation for reconfigurable intelligent surface aided multi-user mmWave MIMO systems,” IEEE Trans. Wireless Commun., vol. 22, no. 10, pp. 6853– 6869, Oct. 2023.   
[225] T. Jiang, H. V. Cheng, and W. Yu, “Learning to reflect and to beamform for intelligent reflecting surface with implicit channel estimation,” IEEE J. Sel. Areas Commun., vol. 39, no. 7, pp. 1931–1945, Jul. 2021.   
[226] M. A. ElMossallamy, K. G. Seddik, W. Chen, L. Wang, G. Y. Li, and Z. Han, “RIS optimization on the complex circle manifold for interference mitigation in interference channels,” IEEE Trans. Veh. Technol., vol. 70, no. 6, pp. 6184–6189, Jun. 2021.   
[227] R. Li, B. Guo, M. Tao, Y.-F. Liu, and W. Yu, “Joint design of hybrid beamforming and reflection coefficients in RIS-aided mmWave MIMO systems,” IEEE Trans. Commun., vol. 70, no. 4, pp. 2404–2416, Apr.   
[228] Z. Zhang, T. Jiang, and W. Yu, “Learning based user scheduling in reconfigurable intelligent surface assisted multiuser downlink,” IEEE J. Sel. Top. Signal Process., vol. 16, no. 5, pp. 1026–1039, Aug. 2022.   
[229] F. Sohrabi, Z. Chen, and W. Yu, “Deep active learning approach to adaptive beamforming for mmWave initial alignment,” IEEE J. Sel. Areas Commun., vol. 39, no. 8, pp. 2347–2360, Aug. 2021.   
[230] F. Sohrabi, T. Jiang, W. Cui, and W. Yu, “Active sensing for communications by learning,” IEEE J. Sel. Areas Commun., vol. 40, no. 6, pp. 1780–1794, Jun. 2022.   
[231] T. Jiang, F. Sohrabi, and W. Yu, “Active sensing for two-sided beam alignment and reflection design using ping-pong pilots,” IEEE J. Sel. Areas Inf. Theory, vol. 4, pp. 24–39, 2023.   
[232] W. Xu, F. Gao, X. Tao, J. Zhang, and A. Alkhateeb, “Computer vision aided mmWave beam alignment in V2X communications,” IEEE Trans. Wireless Commun., vol. 22, no. 4, pp. 2699–2714, Apr. 2023.   
[233] S. Hochreiter and S. J., “Long short-term memory,” Neural Comput., vol. 9, no. 8, pp. 1735–1780, Nov. 1997.   
[234] Z. Zhang, T. Jiang, and W. Yu, “Active sensing for localization with reconfigurable intelligent surface,” in Proc. IEEE Int. Conf. Commun. (ICC), Rome, Italy, May 2023, pp. 1–6.   
[235] D. Han and N. Lee, “Distributed precoding using local CSIT for MU-MIMO heterogeneous cellular networks,” IEEE Trans. Commun., vol. 69, no. 3, pp. 1666–1678, Mar. 2021.   
[236] Z. Wang, M. Eisen, and A. Ribeiro, “Learning decentralized wireless resource allocations with graph neural networks,” IEEE Trans. Signal Process., vol. 70, pp. 1850–1863, 2022.   
[237] A. Chowdhury, G. Verma, C. Rao, A. Swami, and S. Segarra, “Unfolding WMMSE using graph neural networks for efficient power allocation,” IEEE Trans. Wireless Commun., vol. 20, no. 9, pp. 6004– 6017, Sept. 2021.   
[238] K. Li, R. R. Sharan, Y. Chen, T. Goldstein, J. R. Cavallaro, and C. Studer, “Decentralized baseband processing for massive MU-MIMO systems,” IEEE J. Emerg. Sel. Top. Circuits Syst., vol. 7, no. 4, pp. 491–507, Dec. 2017.   
[239] C. Jeon, K. Li, J. R. Cavallaro, and C. Studer, “Decentralized equalization with feedforward architectures for massive MU-MIMO,” IEEE Trans. Signal Process., vol. 67, no. 17, pp. 4418–4432, Sept. 2019.   
[240] J. R. Sa´nchez, F. Rusek, O. Edfors, M. Sarajli´c, and L. Liu, “Decentralized massive MIMO processing exploring daisy-chain architecture and recursive algorithms,” IEEE Trans. Signal Process., vol. 68, pp. 687–700, 2020.   
[241] M. Sarajli´c, F. Rusek, J. R. Sa´nchez, L. Liu, and O. Edfors, “Fully decentralized approximate zero-forcing precoding for massive MIMO systems,” IEEE Wireless Commun. Lett., vol. 8, no. 3, pp. 773–776, Jun. 2019.   
[242] Z. Zhang, Y. Dong, K. Long, X. Wang, and X. Dai, “Decentralized baseband processing with Gaussian message passing detection for uplink massive MU-MIMO systems,” IEEE Trans. Veh. Technol., vol. 71, no. 2, pp. 2152–2157, Feb. 2022.   
[243] J. V. Alegr´ıa, F. Rusek, and O. Edfors, “Trade-offs in decentralized multi-antenna architectures: The WAX decomposition,” IEEE Trans. Signal Process., vol. 69, pp. 3627–3641, 2021.   
[244] A. Zaib, M. Masood, A. Ali, W. Xu, and T. Y. Al-Naffouri, “Distributed channel estimation and pilot contamination analysis for massive MIMO-OFDM systems,” IEEE Trans. Commun., vol. 64, no. 11, pp. 4607–4621, Nov. 2016.   
[245] X. Zhao, M. Li, Y. Liu, T.-H. Chang, and Q. Shi, “Communicationefficient decentralized linear precoding for massive MU-MIMO systems,” IEEE Trans. Signal Process., vol. 71, pp. 4045–4059, 2023.   
[246] Y. Xu, B. Wang, E. Song, Q. Shi, and T.-H. Chang, “Low-complexity channel estimation for massive MIMO systems with decentralized baseband processing,” IEEE Trans. Signal Process., vol. 71, pp. 2728– 2743, 2023.   
[247] E. G. Larsson and J. Vieira, “Phase calibration of distributed antenna arrays,” IEEE Commun. Lett., vol. 27, no. 6, Jun. 2023.   
[248] M. Rashid and J. A. Nanzer, “Frequency and phase synchronization in distributed antenna arrays based on consensus averaging and Kalman filtering,” IEEE Trans. Wireless Commun., vol. 22, no. 4, pp. 2789– 2803, Apr. 2023.   
[249] G. Chen, Q. Wu, C. Wu, M. Jian, Y. Chen, and W. Chen, “Static IRS meets distributed MIMO: A new architecture for dynamic beamforming,” IEEE Wireless Commun. Lett., vol. 12, no. 11, pp. 1866–1870, Nov. 2023.   
[250] A. V. Oppenheim, “Algorithm kings: The birth of digital signal processing,” IEEE Solid-State Circ. Mag., vol. 4, no. 2, pp. 34–37, 2012.   
[251] M. Kim, S. Kasi, P. A. Lott, D. Venturelli, J. Kaewell, and K. Jamieson, “Heuristic quantum optimization for 6G wireless communications,” IEEE Netw., vol. 35, no. 4, pp. 8–15, Jul./Aug. 2021.   
[252] P. Botsinis, D. Alanis, Z. Babar, H. V. Nguyen, D. Chandra, S. X. Ng, and L. Hanzo, “Quantum search algorithms for wireless communications,” IEEE Commun. Surv. Tutor., vol. 21, no. 2, pp. 1209–1242, 2nd Quart. 2019.   
[253] S. J. Nawaz, S. K. Sharma, S. Wyne, M. N. Patwary, and M. Asaduzzaman, “Quantum machine learning for 6G communication networks: State-of-the-art and vision for the future,” IEEE Access, vol. 7, pp. 46 317–46 350, 2019.   
[254] B. Narottama, Z. Mohamed, and S. Aı¨ssa, “Quantum machine learning for next-G wireless communications: Fundamentals and the path ahead,” IEEE Open J. Commun. Soc., vol. 4, pp. 2204–2224, 2023.   
[255] L. Gyongyosi and S. Imre, “Advances in the quantum internet,” Commun. ACM, vol. 65, no. 8, pp. 52–63, Jul. 2022.   
[256] A. S. Holevo, Quantum Systems, Channels, Information: A Mathematical Introduction. Berlin, Boston: De Gruyter, 2013.  