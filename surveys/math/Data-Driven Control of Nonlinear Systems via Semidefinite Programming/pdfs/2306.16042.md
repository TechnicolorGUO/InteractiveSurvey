# Guarantees for data-driven control of nonlinear systems using semidefinite programming: A survey ⋆  

Tim Martina,∗, Thomas B. Scho¨nb, Frank Allgo¨wera  

aUniversity of Stuttgart, Institute for Systems Theory and Automatic Control, Germany bUppsala University, Department of Information Technology, Sweden  

# Abstract  

This survey presents recent research on determining control-theoretic properties and designing controllers with rigorous guarantees using semidefinite programming and for nonlinear systems for which no mathematical models but measured trajectories are available. Data-driven control techniques have been developed to circumvent a time-consuming modelling by first principles and because of the increasing availability of data. Recently, this research field has gained increased attention by the application of Willems’ fundamental lemma, which provides a fertile ground for the development of data-driven control schemes with guarantees for linear time-invariant systems. While the fundamental lemma can be generalized to further system classes, there does not exist a comparable data-based system representation for nonlinear systems. At the same time, nonlinear systems constitute the majority of practical systems. Moreover, they include additional challenges such as data-based surrogate models that prevent system analysis and controller design by convex optimization. Therefore, a variety of data-driven control approaches has been developed with different required prior insights into the system to ensure a guaranteed inference. In this survey, we will discuss developments in the context of data-driven control for nonlinear systems. In particular, we will focus on methods based on system representations providing guarantees from finite data, while the analysis and the controller design boil down to convex optimization problems given as semidefinite programming. Thus, these approaches achieve reasonable advances compared to the state-of-the-art system analysis and controller design by models from system identification. Specifically, the paper covers system representations based on extensions of Willems’ fundamental lemma, set membership, kernel techniques, the Koopman operator, and feedback linearization.  

Keywords: Data-driven control, Data-driven system analysis, Nonlinear systems, Semidefinite programming  

# 1. Introduction  

Model-based control techniques suppose the access to a mathematical model that describes the behavior of a system over time. The description of the dynamics can be given as difference equations in discrete time or as differential equations in continuous time of the system’s inputs and states or outputs. Besides the synthesis of a controller to influence the behavior of the system, system analysis aims to provide valuable insights into the system by the verification of control-theoretic properties such as dissipativity (Willems, 1972). Subsequently, these properties can be used for a controller design using feedback laws (Khalil, 2002), e.g., the small-gain theorem or the interconnection of passive systems.  

One possible derivation of models is based on first principles, for instance, Newton’s laws of motion, Kirchhoff’s circuit laws, and the first and second law of thermodynamics. However, their application often requires expert knowledge, calls for a priori simplifications to obtain suitable models for control, or is more time consuming than the controller design itself. At the same time, the goal intrinsically is the controller instead of a model.  

For these reasons, data-driven approaches (Hou and Wang, 2013) have gained in popularity. There system properties are verified and controllers designed from measured trajectories of the underlying system. System identification (Ljung, 1999; Nelles, 2021) represents a so-called indirect data-driven method because first a model is identified from data and then analyzed or a controller is derived by model-based techniques. However, here the mismatch between the identified model and the underlying system is often obscure. Indeed, the investigation of the model mismatch is even for the identification of linear time-invariant (LTI) systems an active research field (Oymak and Ozay, 2019). At the same time, if this mismatch is unknown, then the design of a controller with closed-loop stability and performance guarantees is jeopardized though inherent guarantees of the control design procedure.  

Investigations of direct data-driven techniques for LTI systems without an intermediate modelling step include PID control (Ziegler and Nichols, 1942), adaptive control (Åstro¨m and Wittenmark, 1989), iterative feedback tuning (Hjalmarsson et al., 1998), virtual reference feedback tuning (Campi et al., 2002), reinforcement learning (Bradtke, 1992), unfalsified control (Safonov and Tsao, 1997), and subspace-based LQG-control (Favoreel et al., 1999).  

Moreover, the renewed interest in the behavioral approach and the fundamental lemma from Willems et al. (2005) in the context of data-driven control has led to a framework (Markovsky and Do¨rfler, 2021) for data-driven system analysis and various control schemes. Furthermore, inspired by Willems’ fundamental lemma, De Persis and Tesi (2020) presents a parametrization of the closed loop of an LTI system and a state feedback based on data matrices. This result also has led to further data-driven control synthesis approaches (Markovsky and Do¨rfler, 2021).  

While the data for Willems’ fundamental lemma would allow the exact identification of the LTI system, the data-informativity framework of van Waarde et al. (2020, 2023) examines the question, when data are informative enough to draw conclusions concerning controllability, stabilizability, etc. Therefore, the amount of data that is needed to identify a system is in general larger than what is needed to control the system. The framework is based on the set of all LTI systems explaining the data. This resembles a set-membership approach (Fogel, 1979), which is, e.g., exploited in Cheng et al. (2015) to design a controller for superstability from noisy input-output data by linear programming.  

These recent developments have established for LTI systems a comprising framework for data-driven system analysis and control including, e.g., verification of various system properties, optimal control, robust control, and predictive control. However, analogous results are missing for nonlinear systems due to the manifold of additional challenges. Indeed, the identification of a nonlinear system only from a finite set of samples is not possible. Instead, additional a priori insights into the system are required. Moreover, although many controller design techniques have inherent closed-loop stability guarantees, they are jeopardized due to the not exactly known nonlinearities. Thus, no end-to-end guarantees for the closed loop can be recovered. Additionally, estimating a bound between the nonlinearity and its estimation from finite data is nontrivial. Lastly, a direct analysis of nonlinear systems leads in general to nonconvex optimization problems, for example, the estimation of the region of attraction.  

Data-driven approaches for nonlinear systems with guarantees include nonlinear adaptive control (Astolfi, 2014), learning-based model predictive control (MPC) (Hewing et al., 2020), reinforcement learning with safety guarantees (Berkenkamp et al., 2017), and stability verification (Lavaei et al., 2022) using scenario optimization (Campi et al., 2009). Furthermore, neural networks are exemplarily applied in Min et al. (2023) to simultaneously learn the dynamics, controller, and a Lyapunov function to provide stability guarantees under a known approximation error of the neural network. Under a known upper bound on the Lipschitz constant of the system’s dynamics, set membership (Novara et al., 2013) and Kinky inference (Calliess, 2014) provide a framework for nonlinear systems to design a controller, for instance, by online prediction (Tanaskovic et al., 2017) or online certificate function control (Taylor et al., 2021). Related to this framework, Montenbruck and Allgo¨wer (2016) presents a data-driven system analysis via the input-output mapping of a nonlinear system and Martin and Allgo¨wer (2020) examines an extension by an iterative sampling scheme.  

This article focuses on data-driven methods based on system representations providing rigorous guarantees and enabling verification of control-theoretic properties and the design of controllers via semidefinite programming (SDP). To circumvent nonconvex optimization though nonlinear system dynamics, convex relaxations and various linearization and polynomialization methods are employed. Due to noisy measurements or the approximation of the system dynamics, the underlying dynamics can not exactly be identified. Nevertheless, the presented approaches provide guarantees by first obtaining a set of systems consistent with the data and a bound on the approximation error. Combined with robust control techniques and a convex optimization via SDPs, rigorous end-to-end guarantees for the determined system properties and closed loop are ensured from finite data. The motivation for the development of these methods is explained in the following points (i)-(vi).  

(i) The presented methods derive system representations suitable for data-driven system analysis and the design of various controller schemes from data. Therefore, these methods strive to establish a framework for nonlinear data-driven system analysis and control, analogously to the frameworks for LTI systems by the fundamental lemma (Willems et al., 2005) and data informativity (van Waarde et al., 2020).  

(ii) System identification, e.g., based on neural networks or Gaussian processes, can result in precise but strong nonlinear, models. Whereas a system analysis or a state feedback design based on these models would be a nonconvex optimization problem, the presented system representations are tailored for solving many control-related problems by SDPs.  

(iii) As shown in Section 3, SDPs can be solved in practice often in a tractable way by relying on well-established algorithms and solvers.  

(iv) While system identification aims to approximate the dynamics as precise as possible, the system representations presented here are motivated to verify system properties or design a controller. As in the LTI case (van Waarde et al., 2020), one expect that the identification requires more data than the verification or controller synthesis problem.  

(v) System identification techniques for nonlinear systems not always provide error bounds to ensure guarantees.  

(vi) The presented system representations leverage, among others, a set of systems feasible with the observed data, similar to a set-membership approach (Novara et al., 2013). While the existing literature considers Lipschitz approximations for specific control structures and data-inefficient system analysis (Montenbruck and Allgo¨wer, 2016), the presented methods exploits more general robust control techniques to, e.g., include performance criteria for more general closed-loop structures.  

In contrast to set-membership identification (Milanese and Novara, 2004), where the feasible system set is leveraged to obtain a model and its mismatch, the methods here exploits the system set directly for control.  

The survey is organized as follows. We begin with the introduction of some notation and a motivation of SDPs in control in Section 3. Afterwards, we will briefly report the presented data-driven approaches in Section 4 and then provide a more detailed discussion of their key ideas. Therefore, we will focus on the data-based representation of the nonlinear system rather than their application to specific control problems. Section 10 shows further discussion of the presented methods and Section 11 concludes the article.  

# 2. Notation  

Throughout the article, we denote the set of natural numbers by $\mathbb { N }$ , the natural numbers including zero by $ { \mathbb { N } } _ { 0 }$ , and the set of real numbers by $\mathbb { R }$ . The Euclidean norm of a vector $\boldsymbol \nu \in \mathbb { R } ^ { n }$ is denoted by $\| \nu \| _ { 2 }$ . Furthermore, $I$ and 0 corresponds to the identity and the zero matrix of suitable dimensions, respectively. The Frobenius norm of a matrix $M \in \mathbb { R } ^ { n \times m }$ is denoted by $\| M \| _ { \mathrm { F r } }$ . The right inverse of a full-row-rank matrix $R \in \mathbb { R } ^ { n \times m }$ is denoted by $R ^ { \dag } ~ \in ~ \mathbb { R } ^ { m \times n }$ . For a symmetric matrix $A \ = \ A ^ { T }$ , $A \succ 0$ or $A \succeq 0$ denote that $A$ is positive definite or positive semidefinite, respectively. Analogously, $A \prec 0$ or $A \preceq 0$ if $A$ is negative definite or negative semidefinite, respectively.  

# 3. Semidefinite programming in control  

This section motivates the application of SDPs in system analysis and control. To this end, we first provide a brief introduction of SDPs following Vandenberghe and Boyd (1996). Second, we comment on the usefulness of SDPs in control.  

While SDPs are introduced in different forms, we remain on a control perspective. There an SDP minimizes a linear function subject to a constraint given by the definiteness of an affine function of symmetric matrices. More precisely,  

$$
\begin{array} { c } { \displaystyle \operatorname* { m i n } _ { x \in \mathbb { R } ^ { n } } ~ \boldsymbol { c } ^ { T } \boldsymbol { x } } \\ { \mathrm { s u b j e c t ~ t o ~ } \boldsymbol { F } ( \boldsymbol { x } ) = \boldsymbol { F } _ { 0 } + \displaystyle \sum _ { i = 1 } ^ { n } x _ { i } \boldsymbol { F } _ { i } \ge 0 , } \end{array}
$$  

with $c \in \mathbb { R } ^ { n }$ and symmetric matrices $F _ { i } \in \mathbb { R } ^ { m \times m } , i = 0 , \ldots , n .$ Since the objective function as well as $F ( x )$ are linear in the optimization variable $x$ , optimization problem (1) is convex. In this case, all local optima are globally optimal such that convex optimization problems are theoretically tractable.  

The optimization problem of SDP (1) can be illustrated as in Figure 1. To find its optimal solution, we need to push the dotted line as far as possible into the direction of $- c$ while not intersecting the feasible set $F ( x ) \succeq 0$ . As illustrated, the feasible set is convex and the optimal solution $x _ { \mathrm { o p t } }$ lies in general on its boundary, i.e., the matrix $F ( x _ { \mathrm { o p t } } )$ is singular.  

![](images/c1e14588721769007f241a006e14761f9c9ad86f1a3add25fa3cbfffc2f7f2d2.jpg)  
Figure 1: Graphical illustration of an SDP.  

Besides the theoretical tractability due to convexity, SDPs are attractive as many problems from combinatorial optimization and control theory can be recast as an SDP. Indeed, SDPs can handle constraints given by linear matrix inequalities (LMI) $F ( x ) \succeq 0$ , convex quadratic inequalities, lower bounds on matrix norms, lower bounds on determinants of positive semidefinite matrices, and polynomial inequalities via sum-of-squares (SOS) hierarchies (see Section 3.1).  

Furthermore, SDPs generalize linear programming with matrix inequalities instead of componentwise inequalities between vectors. By this connection, many results and algorithms from linear programming extend to SDPs even though the latter is more general. For instance, most interior-point methods for linear programming can be generalized to SDPs. To this end, barrier functions are introduced which tend to infinity as points approach the boundary of the feasible set. Thereby, the constraint optimization (1) can be reformulated into an unconstrained one, which can be solved efficiently by Newton iteration techniques. Similar to linear programming, these iterations have polynomial worst-case complexity and perform very well in practice. For instance, Vandenberghe and Boyd (1996) provides the ruleof-thumb that interior-point methods solve SDPs in 5−50 iterations, where each iteration corresponds to a least-squares problem of the same size as the original problem.  

We conclude this section by a simple application of SDPs in a control context. For that purpose, we want to check whether an LTI system ${ \dot { x } } ( t ) = A x ( t ) + B u ( t ) , y ( t ) = C x ( t ) + D u ( t )$ with state $\boldsymbol { x } ( t ) \in \mathbb { R } ^ { n _ { \boldsymbol { x } } }$ , input $u ( t ) \in \mathbb { R } ^ { m }$ , and output $\ b { y } ( t ) \in \mathbb { R } ^ { m }$ , is passive. According to Willems (1972), we need to search for a positive definite function $S \left( x \right)$ such that ${ \dot { S } } ( x ( t ) ) \leq y ( t ) ^ { T } u ( t )$ for all $\boldsymbol { x } ( t ) \in \mathbb { R } ^ { n _ { \boldsymbol { x } } }$ and $u ( t ) \in \mathbb { R } ^ { m }$ . For the quadratic ansatz $S ( x ) =$ $x ^ { T } P x , P \succeq 0$ , we obtain the condition  

$$
\begin{array} { r } { \bigg [ \boldsymbol { x } ^ { \top } \bigg ] ^ { T } \left[ \frac { - P A - A ^ { T } P \quad - P B + \frac { 1 } { 2 } C } { { D } ^ { T } P + \frac { 1 } { 2 } C } \right] \bigg [ \frac { \boldsymbol { x } } { \boldsymbol { u } } \bigg ] \geq 0 , } \end{array}
$$  

which is implied by $L ( P ) \succeq 0$ . By introducing each element of  

Table 1: Organization of presented methods and references.   


<html><body><table><tr><td>Section</td><td>Specific methods</td><td>Main references</td></tr><tr><td rowspan="2">Polynomial approximation</td><td>Polynomial interpolation</td><td>Martin and Allgöwer (2023b,2022a), Guo et al. (2022b), Martin et al. (2023a)</td></tr><tr><td>Polynomial subclass Data-based closed-loop description</td><td>see1 De Persis and Tesi (202O),Guo etal. (2022a), Cetinkaya andKishida (2O21),Luppi etal. (2022)</td></tr><tr><td>Kernel regression</td><td>Linear sector from GP Linearized kernel Polynomial kernel</td><td>Fiedler et al. (2021b) Berkenkamp and Schoellig (2015), Hu et al. (2023) Devonport et al. (2020)</td></tr><tr><td rowspan="2">LPV embedding</td><td>LPV system</td><td>Verhoek et al. (2021a), Verhoek et al. (2022a), Miller and Sznaier (2023), Mejari, et al. (2023)</td></tr><tr><td>LPV embedding Extended linearization</td><td>Verhoek et al. (2022b), Verhoek et al. (2023a) Dai and Sznaier (2021a)</td></tr><tr><td>State lifting Feedback linearization</td><td>Koopman Nonlinearity cancellation</td><td>Zhang et al. (2022), Strässer et al. (2023a) De Persis etal. (2022)</td></tr><tr><td></td><td>Flat system</td><td>Alsalti et al. (2021,2022,2023a.b,c)</td></tr></table></body></html>  

$P = { \binom { p _ { 1 1 } } { \vdots } } \quad \cdot \cdot \cdot \Biggr ] ,$ one can see that $L ( P ) \succeq 0$ is an LMI with the optimization variables $p _ { i j } , i = 1 , \ldots , n _ { x } , j = 1 , \ldots , n _ { x }$ . Hence, we can check for passivity of an LTI system by the SDP  

$$
\begin{array} { r l } { \underset { P \in \mathbb R ^ { n _ { x } \times n _ { x } } } { \mathrm { m i n } } } & { 0 } \\ { \mathrm { s u b j e c t ~ t o } } & { \left[ P \quad \begin{array} { c c } { 0 } \\ { 0 } & { L ( P ) } \end{array} \right] \succeq 0 . } \end{array}
$$  

When replacing the LTI dynamics by a nonlinear $\dot { \boldsymbol { x } } ( t ) \ =$ $f ( x ( t ) , u ( t ) ) , y ( t ) = h ( x ( t ) , u ( t ) )$ , then condition (2) results into a nonlinear matrix inequality. The resulting optimization problem is therefore not an SDP in general. To rely on the wellestablished solvers for SDPs, the methods presented here not only need to infer on the dynamics of the system but also derive a system description suitable for a system analysis and a controller design by SDPs.  

# 3.1. Sum-of-squares optimization  

Many control-related problems, e.g., the verification of Lyapunov stability of a polynomial system, include polynomial inequality constraints. To solve these NP-hard problems, polynomial inequalities can be relaxed by SOS decomposition leading to an SDP with LMI constraints. We will briefly introduce SOS optimization here as various presented methods rely on this relaxation.  

Consider a real polynomial in $x = \left[ x _ { 1 } \quad \cdot \cdot \cdot \quad x _ { n } \right] ^ { T } \in \mathbb { R } ^ { n }$ of degree $d$  

$$
p ( x ) = \sum _ { \alpha \in \mathbb { N } _ { 0 } ^ { n } , | \alpha | \leq d } a _ { \alpha } x ^ { \alpha } ,
$$  

with vectorial indices $\alpha ^ { T } \ = \ \ \left[ \alpha _ { 1 } \quad \cdot \cdot \alpha _ { n } \right] ^ { T } \ \in \ \mathbb { N } _ { 0 } ^ { n } , \ | \alpha | \ =$ $\alpha _ { 1 } + \cdots + \alpha _ { n }$ , real coefficients $\mathbf { \bar { \boldsymbol { a } } } _ { \alpha } \in \mathbb { R }$ , and monomials $x ^ { \alpha } =$ $x _ { 1 } ^ { \alpha _ { 1 } } \cdots x _ { n } ^ { \alpha _ { n } }$ . Let $\mathbb { R } [ x ] , \ \mathbb { R } [ x ] ^ { m }$ , and $\mathbb { R } [ x ] ^ { m \times n }$ denote the set of all real polynomials, all $m$ -dimensional polynomial vectors, and all $m \times n$ polynomial matrices, respectively. Then a matrix $P \in \mathbb { R } [ x ] ^ { n \times n }$ is an SOS matrix if there exists a matrix $Q \in \mathbb { R } [ x ] ^ { m \times n }$ such that $P ( x ) = Q ( x ) ^ { T } Q ( x )$ . According to the square matricial representation (Chesi et al., 2009), the search for $\boldsymbol { Q }$ boils down to checking the feasibility of an LMI.  

By the SOS decomposition $P ( x ) = Q ( x ) ^ { T } Q ( x )$ , all SOS matrices are positive semidefinite for all $x \in \mathbb { R } ^ { n }$ . However, not all polynomial positive semidefinite matrices are SOS. Thus, an SOS condition corresponds to a relaxation of a positive semidefiniteness condition of a polynomial matrix. Nevertheless, SOS optimization is widely used in control for the following two reasons. The Positivstellensatz from Putinar (1993) allows to check for non-negativity of a polynomial on a compact semialgebraic set. Together with a matrix-version of this result (Scherer and Hol, 2006), a regional analysis of control systems is possible. Moreover, the moment-SOS hierarchy (Lasserre, 2000) shows that the relaxation converges with increasing degree of polynomials.  

One drawback of SOS optimization is scalability. Indeed, for a polynomial $p ( x )$ with degree $2 d$ , the SOS relaxation of $p ( x ) \leq 0$ leads to $p ( x ) = z ( x ) Q z ( x )$ and $Q \succeq 0$ with $\boldsymbol { Q }$ of dimensions $\binom { n + d } { d } \times \binom { n + d } { d } \approx n ^ { d } \times n ^ { d }$ . If the scalability of standard SOS relaxation prevents the application to large problems, chordal sparsity (Zheng, 2019) for the obtained SOS problem might improve scalability issues. Furthermore, SOS relaxation could be replaced by $\mathbf { B }$ -spline relaxations, which shows less conservatism and less computational demand for, e.g., LPV controller design with polynomial parameter dependence (Hilhorst et al., 2016).  

# 4. Preview  

The purpose of this section is to provide a preview of the data-driven methods covered in this survey. They are organized  

by the derivation technique for their data-based system representation as given in Table 1.  

# 4.1. Data-based polynomial approximation  

In Section 5, we will take a closer look at characterizations of the unknown nonlinear dynamics by data-based polynomial approximation. Polynomial approximation has been widely used to deal with nonlinear systems in control theory (Abudia et al., 2022) and in application, e.g., by Taylor linearization of the system dynamics. Thus, this data-based system representation is intuitive from a control perspective. Furthermore, a polynomial representation allows for the verification of system properties and for the design of controllers by SOS optimization. Moreover, a polynomial approximation does not require knowledge of a function basis containing the system dynamics. At the same time, the literature on polynomial interpolation (Sauer and Xu, 1995) provides well-investigated approximation errors. These are essential to infer a tight set membership for the nonlinear system from data and to provide guarantees.  

For Taylor polynomials (TP), Martin and Allg¨ower (2022a) verifies dissipativity properties, Martin and Allgo¨wer (2023b) determines incremental dissipativity, Guo et al. (2022b) derives locally asymptotically stabilizing controllers, and Martin et al. (2023a) obtains state-feedback laws to render an equilibrium globally asymptotically stable while satisfying closed-loop performance criteria. Since TPs commonly provide local approximations, Martin and Allgo¨wer (2023b) combines multiple TPs to refine the data-driven inference.  

If the error of the polynomial approximation vanishes, then the special case of polynomial systems is obtained. Datadriven control for unknown polynomial systems using SOS relaxation include the verification of dissipativity (Martin and Allg¨ower, 2021) and integral quadratic constraints (IQC) (Martin and Allgo¨wer, 2022b) and the controller synthesis (Guo et al., 2022a; Bisoffi et al., 2022; Dai and Sznaier, 2021b; Luppi et al., 2021; Zheng et al., 2023). Related to the polynomial case, Stra¨sser et al. (2021) considers the controller synthesis for rational systems. Related to the polynomial approximation by TPs, Berberich et al. (2022a); Nguyen et al. (2023); Cheah et al. (2023) investigate Lur’e-type systems (Khalil, 2002) (Chapter 10.1) with a data-driven inference of the LTI part of the dynamics while assuming measurements and a known sector bound on the nonlinear part. Note that all these results excessively exploit techniques from robust control as linear fractional representation (LFR), Petersen’s lemma, a matrix S-lemma (van Waarde et al., 2022), or Farkas’ lemma to provide guarantees though the system dynamics is not precisely known.  

In contrast to the previous set-membership approaches, De Persis and Tesi (2020) uses Taylor linearization to provide a data-driven representation of the linear part of the closed loop. Thereby, an equilibrium point can be rendered locally asymptotically stable by solving an optimization problem with LMI constraints. Moreover, the closed-loop characterization is extended to polynomial systems (Guo et al., 2022a), periodic orbits (Cetinkaya and Kishida, 2021), and Lur’e-type systems (Luppi et al., 2022).  

# 4.2. Gaussian processes and kernel ridge regression  

Gaussian processes (GP) and kernel ridge regression constitute a flexible framework to approximate nonlinear functions in machine learning and nonlinear dynamics in system identification. Both regression methods provide the possibility to include prior knowledge and inherent uncertainty measures to derive guarantees for data-driven control. However, the obtained system representation is often strongly nonlinear due to nonlinear kernel functions. To deal with this nonlinearity, Umlauft et al. (2018) presents a controller design by feedback linearization and Capone et al. (2022) by backstepping. Nonetheless, both require a certain structure of the system dynamics. Therefore, we will study in Section 6 the following three approaches to achieve a controller synthesis by SDPs.  

Fiedler et al. (2021b) learns a linear sector for the nonlinear parts of the dynamics from a GP to apply linear robust control afterwards. To this end, Fiedler et al. (2021a) establishes a statistical bound between the underlying nonlinear dynamics and the mean function of the GP.  

Instead of bounding the mismatch of the kernel regression by a sector, Berkenkamp and Schoellig (2015) directly computes the Taylor linearization of the nonlinear GP-model around an equilibrium point for a linear robust controller design. Alternatively, Hu et al. (2023) suggests to stabilize the linear part of a kernel regression, while approximately cancelling its nonlinearity as in De Persis et al. (2022).  

Devonport et al. (2020) proposes to use polynomial kernels yielding a polynomial regression model and a polynomial sector for the approximation error. Thus, a system analysis and a controller design by SOS techniques are possible. Moreover, we will observe connections to the polynomial approximation approach shown in Section 5.1.  

# 4.3. Embedding into linear parameter-varying systems  

In Section 7, we will report data-driven system analysis and controller design for a nonlinear system by combining datadriven methods for linear parameter-varying (LPV) systems and embedding nonlinear systems into LPV systems. Thereby, this paradigm provides a data-driven system analysis and controller design by SDPs for nonlinear systems. In contrast to the local approximations by polynomials, LPV systems provide a global linearization of the nonlinear system. However, for the embedding, a known function basis of the scheduling map or the velocity-form of the underlying nonlinear system is required. The LPV representation of the nonlinear system is not tight as the scheduling parameter can change independently of the state and input.  

For LPV systems, Verhoek et al. (2021a) introduces a fundamental lemma for verifying dissipativity properties (Verhoek et al., 2023b) and predictive control (Verhoek et al., 2021b). Moreover, Verhoek et al. (2022a) provides a representation of open-loop and closed-loop LPV systems from noise-free trajectories. Miller and Sznaier (2023) and Mejari, et al. (2023) introduce a set-membership description for LPV systems from noisy data for the controller design with stability and performance guarantees based on SDPs.  

Under the assumption that a function basis of the scheduling map is known, the unknown nonlinear dynamics can be written as an LPV system. Since the nonlinear dynamics is contained within the solution of the LPV system, Verhoek et al. (2022b) obtains a data-driven LPV controller that stabilizes the underlying nonlinear system. Alternatively, if the function basis of the velocity-form of a nonlinear system is known, then the velocityform can be embedded into the data-driven framework of LPV systems (Verhoek et al., 2023a).  

Related to exploiting the extended linearization of a nonlinear system as in Verhoek et al. (2022b), the authors Dai and Sznaier (2021a) suggest to compute in each time instance a control policy for the frozen system matrices of the nonlinear extended linearization. Together with enforcing a decrease of the Lyapunov function along the closed-loop trajectory, the iterative scheme guarantees closed-loop stability by solving a finite set of LMIs in each time step. The inference on the extended linearization is obtained under a known function basis of the nonlinear dynamics and from data subject to noise.  

# 4.4. Koopman lifting  

The Koopman operator (Bevanda et al., 2021) provides an exact description of the nonlinear dynamics by a single, but infinite-dimensional, (bi-)linear system. To this end, the timeevolution of the states is observed through the lens of observables. By a finite dictionary of observables, a finite dimensional system representation is obtained from finite data using extended dynamics mode decomposition (EDMD). While the emerging estimation error is neglected in many existing results, we will focus in Section 8 on works incorporating this error. Thereby, a controller design with guarantees is achieved.  

Combined with the data-based validation of the estimation error, Zhang et al. (2022) provides a linear robust predictive control scheme with closed-loop guarantees. Stra¨sser et al. (2023a) considers a bilinear lifted system and determines a linear feedback of the lifted states that asymptotically stabilizes the nonlinear system. Moreover, a region of attraction w.r.t. the lifted state is guaranteed.  

Motivated by the bilinear model deduced from the lifting, we will shortly report the data-driven control approaches Bisoffi et al. (2020), Yuan and Corte´s (2022), and Stra¨sser et al. (2023b) for bilinear systems with unknown system matrices.  

# 4.5. Approximate nonlinearity cancellation and feedback linearization  

Whereas the previous approaches derive a suitable representation of the system dynamics itself, nonlinearity cancellation and feedback linearization modify the dynamics by a state feedback to obtain an approximately linear system description. Since the feedback linearization includes an input transformation, the dynamics of the original and the transformed linear system differs. Hence, a data-driven system analysis by feedback linearization or nonlinearity cancellation is intrinsically not possible. For more details, we refer to Section 9.  

De Persis et al. (2022) locally asymptotically stabilizes an equilibrium by approximately cancelling the nonlinearity of the closed-loop dynamics. To this end, the data-based closed-loop parametrization for LTI systems (De Persis and Tesi, 2020) is obtained for the linear part of the closed loop of a nonlinear system with known function basis. Subsequently, a controller that stabilizes the linear part of the closed-loop dynamics and minimizes the influence of the nonlinearity can be determined by an SDP.  

The global feedback linearization of a flat system serves as the basis for an extension of Willems’ fundamental lemma (Alsalti et al., 2021) under a known function basis for the input transformation. Alsalti et al. (2023a) relaxes this assumption by incorporating the error for an arbitrary choice of basis functions into data-driven simulation and output-matching control. Further, Alsalti et al. (2022) proposes a robust predictive control scheme for full-state feedback-linearizable nonlinear systems. However, all these results require nonlinear optimization.  

# 5. Data-driven control by polynomial approximation  

A polynomial system representation allows for a system analysis and controller design by SDPs via SOS techniques. Moreover, the well-elaborated error bounds for polynomial interpolation (Sauer and Xu, 1995) can be leveraged by robust control methods to ensure rigorous guarantees despite approximation of the nonlinear dynamics.  

After an elaboration of data-driven control based on polynomial interpolation techniques, works on polynomial, rational, and Lur’e-type systems will be reported. Lastly, we will review a data-based closed-loop representation, which will also be leveraged in some of the later presented frameworks.  

# 5.1. Data-driven control by polynomial interpolation  

In the sequel, we present the data-driven set-membership approach for system analysis and controller design from Martin and Allgo¨wer (2023b), Martin and Allgo¨wer (2022a), and Martin et al. (2023a). There the feasible system set for nonlinear systems is derived by combining noisy data and error bounds for polynomial interpolation. Since the feasible system set is characterized by polynomial inequalities, the subsequent system analysis and state-feedback design boil down to SOS optimization problems.  

We begin with some background on polynomial interpolation. By Taylor’s theorem (Apostol, 1974), a $k + 1$ times continuously differentiable function $f : \mathbb { R } ^ { n _ { x } }  \mathbb { R }$ can be written as $f ( x ) = T _ { k } ( \omega ) [ f ( x ) ] + R _ { k } ( \omega ) [ f ( x ) ]$ with the TP of order $k$ at $\boldsymbol { \omega } \in \mathbb { R } ^ { n _ { x } }$  

$$
T _ { k } ( \omega ) [ f ( x ) ] = \sum _ { | \alpha | = 0 } ^ { k } { \frac { 1 } { \alpha ! } } { \frac { \partial ^ { | \alpha | } f ( \omega ) } { \partial x ^ { \alpha } } } \left( x - \omega \right) ^ { \alpha } ,
$$  

with $\alpha ! = \alpha _ { 1 } ! \cdots \alpha _ { n _ { x } } !$ . Moreover, for all $x \in \mathbb { R } ^ { n _ { x } }$ there exists a $\nu \in [ 0 , 1 ]$ such that  

$$
R _ { k } ( \omega ) [ f ( x ) ] = \sum _ { | \alpha | = k + 1 } \frac { 1 } { \alpha ! } \frac { \partial ^ { k + 1 } f ( \omega + \nu ( x - \omega ) ) } { \partial x ^ { \alpha } } \left( x - \omega \right) ^ { \alpha } .
$$  

Since $\nu$ intrinsically depends on $x$ , it summarizes the nonpolynomial nonlinearity of $f$ . Furthermore, its value is typically unknown. Hence, Martin and Allgo¨wer (2022a) assumes an upper bound on the magnitude of the $( k + 1 )$ -th partial derivatives to avoid the computation of $\nu$ .  

Assumption 1 (Martin and Allgo¨wer (2022a)). Upper bounds $M _ { \alpha } \geq 0 , \alpha \in \mathbb { N } _ { 0 } ^ { n _ { x } } , | \alpha | = k + 1$ , on the magnitude of each $( k + 1 )$ -th order partial derivative of $f$ are known, i.e.,  

$$
\left\| \frac { \partial ^ { k + 1 } f ( x ) } { \partial x ^ { \alpha } } \right\| _ { 2 } \leq M _ { \alpha } , \quad \forall x \in \mathbb { R } ^ { n _ { x } } .
$$  

Under Assumption 1, the Lagrange remainder ${ R _ { k } } ( \omega ) [ f ( x ) ]$ can be bounded by  

$$
{ ( R _ { k } ( \omega ) [ f ( x ) ] ) } ^ { 2 } \le \sum _ { | \alpha | = k + 1 } \kappa \frac { M _ { \alpha } ^ { 2 } } { \alpha ! ^ { 2 } } { ( x - \omega ) } ^ { 2 \alpha } ,
$$  

where ${ \boldsymbol { \kappa } } \in  { \mathbb { N } } _ { 0 }$ is equal to the number of $M _ { \alpha } \neq 0$ . Since the right-hand side of (3) does not depend on $\nu$ , we conclude that $f$ is contained in the polynomial characterized sector  

$$
f ( x ) \in \left\{ T _ { k } ( \omega ) [ f ( x ) ] + R ( x ) : R ^ { 2 } ( x ) \leq \sum _ { | \alpha | = k + 1 } \kappa \frac { M _ { \alpha } ^ { 2 } } { \alpha ! ^ { 2 } } ( x - \omega ) ^ { 2 \alpha } \right\} .
$$  

While the investigation of the approximation error for polynomial interpolation is well-studied, Martin and Allgo¨wer (2022a) proposes their application to infer on the interpolation polynomial from noisy data. For that purpose, let noisy samples $\{ y _ { i } , x _ { i } \} _ { i = 1 } ^ { S }$ with $y _ { i } = f ( x _ { i } ) + d _ { i }$ be available. The unknown noise realizations $d _ { i }$ satisfy $d _ { i } ^ { 2 } \leq \epsilon ^ { 2 }$ . Furthermore, let the TP be written as $z ( x ) ^ { T } a ^ { * }$ , where $\boldsymbol { a } ^ { * } \in \mathbb { R } ^ { n _ { z } }$ summarizes the unknown coefficients of the interpolation polynomial and $z ( x ) \in \mathbb { R } [ x ] ^ { n _ { z } }$ is a vector of linear independent polynomials building a basis for all polynomials with degree less than or equal to $k$ . For instance, $z$ could contain all monomials up to degree $k$ . Following a set-membership procedure (Milanese and Novara, 2004), we characterize all coefficients $a \in \mathbb { R } ^ { n _ { z } }$ admissible with the data  

$$
y _ { i } = z ( x _ { i } ) ^ { T } a + R _ { k } ( \omega ) [ f ( x _ { i } ) ] + d _ { i } \} .
$$  

Note that (5) includes the coefficients of the true interpolation polynomial $a ^ { * }$ . Furthermore, since the remainder evaluated at the data are unknown, Martin and Allgo¨wer (2022a) (Lemma 2) calculates a superset of (5) based on the error bounds for TPs (3) , denoted by $\bar { R } ^ { \mathrm { p o l y } } [ f ( x _ { i } ) ]$ ,  

$$
\Sigma _ { a } = \left\{ a : ( y _ { i } - z ( x _ { i } ) ^ { T } a ) ^ { 2 } \leq q ( y _ { i } , x _ { i } ) , i = 1 , \ldots , S \right\}
$$  

with $q ( y _ { i } , x _ { i } ) = \bar { R } ^ { \mathrm { p o l y } } [ f ( x _ { i } ) ] + \epsilon ^ { 2 } + 2 \epsilon \sqrt { \bar { R } ^ { \mathrm { p o l y } } [ f ( x _ { i } ) ] }$ . Finally, combining the polynomial sector bound for TPs (4) with $\Sigma _ { a }$ leads to a set membership for the unknown nonlinear function  

$$
f ( x ) \in \left\{ z ( x ) ^ { T } a + R ( x ) : a \in \Sigma _ { a } , R ( x ) ^ { 2 } \leq \bar { R } ^ { \mathrm { p o l y } } [ f ( x ) ] \right\} .
$$  

By the latter, we obtain for the nonlinear function $f$ a representation that is based on noisy data, is polynomial, and does not require a function basis of $f$ .  

Before we continue with the application of the feasible system set (6) for data-driven system analysis and control, some comments are appropriate. By Assumption 1, the rate of variation of the nonlinear function $f$ is bounded. Therefore, we can infer the behavior of $f$ in the neighbourhood of a sample. A similar causality of the behavior of $f$ and samples is, e.g., also considered in set-membership identification (Milanese and Novara, 2004) by a known Lipschitz constant. Since the bounds $M _ { \alpha }$ are usually not known, we refer to Martin and Allgo¨wer (2023b) for their estimation by a validation procedure and the applicability for data from a real experiment.  

Moreover, Martin and Allgo¨wer (2023b) discusses the choice of $\omega$ and a combining of multiple local polynomial interpolations, i.e., a piecewise polynomial approximation, to reduce the approximation error. To reduce the computation burden, Martin and Allg¨ower (2022a) (Proposition 1) suggests to compute the ellipsoidal outer approximation  

$$
\left\{ a : { \left[ \begin{array} { l } { I } \\ { a ^ { T } } \end{array} \right] } ^ { T } Q { \left[ \begin{array} { l } { I } \\ { a ^ { T } } \end{array} \right] } \leq 0 \right\}
$$  

of $\Sigma _ { a }$ . Furthermore, Martin et al. (2023a) investigates a Frequentist and Bayesian treatment for Gaussian distributed $d _ { i }$ , following the lines of Umenberger et al. (2019).  

Next, we show how to verify system properties for a general nonlinear system by the derived set membership (6). For that purpose, Martin and Allgo¨wer (2022a) analyzes an unknown nonlinear continuous-time system  

$$
{ \dot { x } } ( t ) = f ( x ( t ) , u ( t ) )
$$  

with $k + 1$ times continuously differentiable function $\begin{array} { r l } { f } & { { } = } \end{array}$ $\begin{array} { r l } { \lceil f _ { 1 }  } & { { } \cdot \cdot \cdot } \quad f _ { n _ { x } } \rceil : \mathbb { R } ^ { n _ { x } + n _ { u } }  \mathbb { R } ^ { n _ { x } }  \end{array}$ and noisy data $\{ \dot { x } _ { i } , x _ { i } , u _ { i } \} _ { i = 1 } ^ { S }$ with $\dot { \bar { x } } _ { i } = f ( x _ { i } , u _ { i } ) \dot { + } d _ { i }$ . Note that $d _ { i }$ might include estimation errors of the time-derivatives of the states. Applying a polynomial interpolation for each element of $f$ yields  

$$
\begin{array} { r l } & { f ( x , u ) = \left[ \begin{array} { c } { z _ { 1 } ( x , u ) ^ { T } a _ { 1 } ^ { * } + R [ f _ { 1 } ( x , u ) ] } \\ { \vdots } \\ { z _ { n _ { x } ( x , u ) ^ { T } } a _ { n _ { x } } ^ { * } + R [ f _ { n _ { x } } ( x , u ) ] } \end{array} \right] } \\ & { \quad \quad = \left[ \begin{array} { c } { z _ { 1 } ( x , u ) ^ { T } S _ { 1 } } \\ { \vdots } \\ { z _ { n _ { x } ( x , u ) ^ { T } } S _ { n _ { x } } } \end{array} \right] a ^ { * } + \left[ \begin{array} { c } { R [ f _ { 1 } ( x , u ) ] } \\ { \vdots } \\ { R [ f _ { n } ( x , u ) ] } \end{array} \right] , } \\ & { \quad \quad \quad = \underbrace { z _ { n } ( x , u ) ^ { T } S _ { n _ { x } } } _ { = : Z ( x , u ) } \quad \underbrace { \quad } \underbrace { \quad } \mathrm { } } \end{array}
$$  

with $a _ { i } ^ { * } = S _ { i } a ^ { * }$ , and $\begin{array} { r } { R [ f ( x , u ) ] ^ { T } R [ f ( x , u ) ] \leq \sum _ { i = 1 } ^ { n _ { x } } \bar { R } ^ { \mathrm { p o l y } } [ f _ { i } ( x , u ) ] } \end{array}$ . As shown in Martin and Allgo¨wer (2023b) (Remark 2) and  

Martin et al. (2023a), summarizing all unknown coefficients of the polynomial interpolations into $a ^ { * }$ and considering $z _ { i }$ for each row of $f$ can be leveraged to include interpolation polynomials of different orders and prior knowledge on the structure of $f$ .  

For the available data $\{ \dot { x } _ { i } , x _ { i } , u _ { i } \} _ { i = 1 } ^ { S }$ , we pursue the described derivation of $\Sigma _ { a }$ to conclude that $f ( x , u )$ is contained in the feasible system set  

$$
\begin{array} { r l r } {  { \{ Z ( x , u ) ^ { T } a + R ( x , u ) : a \in \Sigma _ { a } ,  } } \\ & { } & {  \ R ( x , u ) ^ { T } R ( x , u ) \le \sum _ { i = 1 } ^ { n _ { x } } \bar { R } ^ { \mathrm { p o l y } } [ f _ { i } ( x , u ) ] \} . } \end{array}
$$  

Given the quadratic description (7) for $\Sigma _ { a }$ , the feasible system set can also be written as an LFR (Scherer and Weiland, 2000)  

$$
\begin{array} { r } { \bigg [ \dot { x } ( t ) \bigg ] = \left[ \begin{array} { c c c } { 0 } & { 0 } & { I } \\ { \left[ I \right] } & { \left[ 0 \right] } & { 0 } \\ { 0 } \end{array} \right] \left[ \begin{array} { c c c } { x ( t ) } \\ { u ( t ) } \\ { w _ { 1 } ( t ) } \\ { w _ { 2 } ( t ) } \end{array} \right] , } \\ { w _ { 1 } ( t ) = Z ( q ( t ) ) ^ { T } a , w _ { 2 } ( t ) = R ( q ( t ) ) , } \end{array}
$$  

with $\begin{array} { r } { w _ { 2 } ( t ) ^ { T } w _ { 2 } ( t ) \leq \sum _ { i = 1 } ^ { n _ { x } } \bar { R } ^ { \mathrm { p o l y } } [ f _ { i } ( q ( t ) ) ] } \end{array}$ and  

$$
\begin{array} { r } { \left[ S _ { i } ^ { T } z _ { i } ( { q } ( t ) ) \right] ^ { T } Q \left[ S _ { i } ^ { T } z _ { i } ( { q } ( t ) ) \right] \leq 0 , } \end{array}
$$  

for $w _ { 1 } = \left[ w _ { 1 , 1 } \quad \cdots \quad w _ { 1 , n _ { x } } \right] ^ { T }$  

Although the uncertainty descriptions of $w _ { 1 }$ and $w _ { 2 }$ are polynomial in $q$ , we can apply the LMI-based robust control framework of Scherer and Weiland (2000) to verify system properties for all systems within the set membership (8). If all systems satisfy a certain property, then also the ground-truth system fulfils the property as it is contained within (8). Due to the polynomial bounds on the uncertainties $w _ { 1 }$ and $w _ { 2 }$ , the verification boils down to an SOS condition. By an additional S-procedure, Martin and Allgo¨wer (2022a) and Martin and Allgo¨wer (2023b) verify dissipativity and incremental dissipativity properties, respectively, for all trajectories of the unknown nonlinear system staying within a compact set. A regional analysis is meaningful due to the non-global inferences on the dynamics from data. Moreover, the results from Martin and Allgo¨wer (2022b) (arXiv:2103.10306v3, Section 5.B) can be applied here to determine optimal IQCs to gather tighter system properties than by simple dissipativity properties.  

Martin et al. (2023a) elaborates the set membership (8) with a TP at $\omega = 0$ for each row of an input-affine nonlinear system. Following the robust control framework of Scherer and Weiland (2000), Theorem 8 of Martin et al. (2023a) formulates the conditions for data-driven dissipativity verification in the dual space. Thereby, a state-feedback design by SOS optimization with quadratic performance guarantees is possible. In contrast to the TP approach from Guo et al. (2022b), the authors Martin et al. (2023a) incorporate the remainder of polynomial interpolation into the controller synthesis to obtain globally asymptotically stabilizing controllers.  

![](images/a330c615cc3b60d4ffde3a9246b42ae508a0b6b46cc30dbd09a17a744633a1b3.jpg)  
Figure 2: Graphical illustration of data-driven system analysis and control using polynomial interpolation.  

![](images/687a324dfe828b73a01abcd9b64ec5627c15fd554934a6829f0d32453bb56317.jpg)  
Figure 3: Relation of polynomial interpolation approach from Section 5.1 and approaches for subclasses from Section 5.2.  

Figure 2 summarizes the data-driven system analysis and control by polynomial interpolation. While this framework seems to be flexible, we also identify some open questions and problems. Among others, the impact of the chosen polynomial basis for $z _ { 1 } , \ldots , z _ { n _ { x } }$ should be analysed. Here, the basis should be optimized for the controller design. Hence, the basis is ideally optimized during the controller synthesis. Since the the presented procedure can also be applied for more general polynomial interpolations, e.g., Hermite polynomials (Sauer and Xu, 1995), this investigation might reduce the conservatism by means of more regional polynomial approximations.  

# 5.2. Polynomial, rational, and Lur’e-type systems  

We summarize in the following the data-driven setmembership approaches for polynomial, rational, and Lur’etype systems. These classes of nonlinear systems are strongly related to the system representation by polynomial interpolation as shown in Figure 3. Polynomial systems comprises, for example, fluid dynamics (Chernyshenko et al., 2014) and robotics (Majumdar, 2013), whereas rational dynamics, e.g., biochemical reactors (Strogatz, 2014). Lur’e systems (Khalil, 2002) (Chapter 10.1) are LTI systems including a sector bounded nonlinearity, and thus can comprise exemplarily Lipschitz bounded nonlinearities and recurrent neural networks (Luppi et al., 2022).  

The literature on data-driven system analysis and control for polynomial systems mostly studies a continuous-time system with polynomial dynamics ${ \dot { x } } ( t ) = A z ( x ( t ) , u ( t ) )$ or input-affine polynomial dynamics $\dot { x } ( t ) = A \bar { z } ( x ( t ) ) + B W ( x ( t ) ) u ( t )$ , respectively. While the coefficient matrices $A \in \mathbb { R } ^ { n _ { x } \times n _ { z } }$ and $B \in \mathbb { R } ^ { n _ { x } \times n _ { B } }$ are unknown, a set of data $\{ \dot { x } _ { i } , x _ { i } , u _ { i } \} _ { i = 1 } ^ { S }$ is available and a vector $z \in \mathbb { R } [ x , u ] ^ { n _ { z } }$ or a vector $\bar { z } \in \mathbb { R } [ x ] ^ { n _ { z } }$ and a polynomial matrix $W \in \mathbb { R } [ x ] ^ { n _ { B } \times n _ { u } }$ , respectively, are known. The latter can be satisfied from knowledge of an upper bound on the degree of the polynomial dynamics.  

Clearly, considering polynomial systems generalizes the results for LTI systems (van Waarde et al., 2022; Koch et al., 2022). On the other hand, the polynomial problem setup is included in the data-driven framework of polynomial interpolation in Section 5.1: For vanishing approximation error $\bar { R } ^ { \mathrm { p o l y } } [ f ( x , u ) ] = 0$ , we can proceed as in Section 5.1 to derive a set membership for the unidentified coefficients and, subsequently, to verify system properties and to design a state feedback. Hence, we directly report the examined data-driven control problems for polynomial systems.  

Based on SOS optimization, Martin and Allg¨ower (2021) and Martin and Allgo¨wer (2022b) investigate the verification of dissipativity and more general time domain hard IQCs with optimized linear filter, respectively. Whereas most model-based and data-driven results, which are based on SOS optimization, consider continuous-time systems, Martin and Allgo¨wer (2021) and Martin and Allgo¨wer (2022b) investigate discrete-time polynomial systems. Thereby, the data of the time-derivative of the states are avoided. This advantage comes at the cost of being restricted to quadratic storage functions (Martin and Allg¨ower, 2022b) or polynomials of higher degree due to the function decomposition $V ( f ( x , u ) )$ with a polynomial storage function $V ( x )$ . Moreover, polynomial discrete-time systems often require a regional analysis because a time discretization of a globally asymptotically stable system can lead to a locally asymptotically stable discrete-time system. For instance, the Euler time discretization with time step $T > 0$ of $\dot { x } = - x ^ { 3 }$ yields $x ( t + 1 ) = x ( t ) - T x ( t ) ^ { 3 }$ . However, the state of the discretized system tends to infinity for any initial condition $| | x ( 0 ) | | _ { 2 } > \sqrt { 2 / T }$ .  

Furthermore, data-driven controller design for global stabilization for continuous-time polynomial systems is examined: Guo et al. (2022a) derives a polynomial state feedback from data solving a single SOS condition. To this end, an energybounded noise of the data immediately leads to a set membership for the unknown coefficient matrices, which can be exploited by means of the non-conservative S-lemma from van Waarde et al. (2022). The same control problem for pointwisein-time-bounded noise is solved in Bisoffi et al. (2022) by the non-conservative Petersen’s lemma and an ellipsoidal outer approximation of the set of coefficients consistent with the data. However, the controller design requires alternating SOS optimization due to the bilinearity of optimization variables. Dai and Sznaier (2021b) proposes a rational state feedback by relating the feasible system set with the set of systems with converging trajectories via Farkas’ lemma. Therefore, the weaker stability of Rantzer’s dual Lyapunov theory (Rantzer, 2001) is considered. Farkas’ lemma leads to a condition that can be relaxed to an SDP by SOS relaxation and the nuclear norm relaxation for rank conditions. Summarized, the literature on data-driven state-feedback design considers a variety of robust control techniques to stabilize all systems consistent with the data. However, we assess the robust control framework by  

LFRs (Scherer and Weiland, 2000) to constitute one of the most appealing ones. In particular, it can also be applied for polynomial problems and leads to SDPs despite multiple uncertainty channels and performance criteria.  

In contrast to global stabilization, Luppi et al. (2021) and Zheng et al. (2023) investigate the control of unknown polynomial systems including safety conditions rather than stability conditions. To this end, Luppi et al. (2021) optimizes over a polynomial state-feedback law to enlarge the size of an invariant set. The feasible system set is incorporated into the invariance condition by Young’s relation (Caverly and Forbes, 2019). But in fact, as in the model-based case, the derived invariance conditions are bilinear, and thus have to be solved by alternating SOS optimization. To circumvent the nonconvexity, Zheng et al. (2023) proposes a density function formulation based on the dual Lyapunov method (Rantzer, 2001) and to proceed along the lines of Dai and Sznaier (2021b). The obtained rational state feedback keeps the closed-loop trajectories of all polynomial systems admissible with the data outside of an unsafe set.  

Instead of polynomial systems, Stra¨sser et al. (2021) presents a data-driven feedback design for continuous-time rational systems. Multiplication of the rational dynamics by all denominators of the dynamics yields a problem formulation akin to that in the polynomial case. However, the problem emerges that the additive noise does not affect the data through the original rational dynamics but the polynomial reformulation. The remaining procedure follows a set-membership approach combined with robust control techniques from Scherer and Weiland (2000). Thereby, a state feedback is designed with stability and performance guarantees by solving an SOS problem.  

Related to a linear TP with bounded Lagrange remainder, the Lur’e problem considers an LTI system with a sector bounded nonlinearity. In a data-driven context, Berberich et al. (2022a) proposes a flexible multiplier LMI-framework to combine data, prior information on the LTI system, and bounded and measurable nonlinearities. To obtain a feasible system set for the LTI system with sector bounded and measurable nonlinearity, Nguyen et al. (2023) solves an optimal control problem from MPC with state and input constraints by application of the Slemma from van Waarde et al. (2022). Cheah et al. (2023) solves a similar problem by Young’s relation.  

# 5.3. A data-driven closed-loop characterization  

De Persis and Tesi (2020) examines besides the data-driven stabilization of LTI systems also the nonlinear case. In contrast to the set-membership approaches of Section 5.1 and 5.2, De Persis and Tesi (2020) proposes to directly characterize the closed loop by data matrices. This result has also inspired further works reported, among others, in this section.  

De Persis and Tesi (2020) (Section 5.2) considers the stabilization of an unknown nonlinear discrete-time system $x ( t { + } 1 ) =$ $f ( x ( t ) , u ( t ) )$ . To apply their results from LTI systems, the authors propose a Taylor linearization around the known equilibrium point $( x _ { \mathrm { e } } , u _ { \mathrm { e } } ) = ( 0 , 0 )$ . This leads to the linearized system dynamics  

$$
x ( t + 1 ) = A x ( t ) + B u ( t ) + d ( t ) ,
$$  

with $\begin{array} { r } { A \ = \ \frac { \partial f ( 0 , 0 ) } { \partial x } } \end{array}$ , $\begin{array} { r } { B \ = \ \frac { \partial f ( 0 , 0 ) } { \partial u } } \end{array}$ ∂ f (0u,0) , and remainder d. Clearly, (9) corresponds to the TP approximation from Section 5.1 for $k = 1$ and $\omega = 0$ . For data $\left\{ x _ { i } , u _ { i } \right\} _ { i = 1 } ^ { S }$ satisfying $x _ { i + 1 } = A x _ { i } + B u _ { i } + d _ { i }$ , De Persis and Tesi (2020) defines the data-dependent matrices $X =$ $\Big [ x _ { 1 } \quad \cdots \quad x _ { S - 1 } \Big ] , U = \Big [ u _ { 1 } \quad \cdots \quad u _ { S - 1 } \Big ] , \mathbf { \hat { X } } ^ { + } = \Big [ x _ { 2 } \quad \cdots \quad x _ { S } \Big ] ,$ and $D = \left[ d _ { 1 } \quad \cdots \quad d _ { S - 1 } \right]$ .  

Assumption 2 (De Persis and Tesi (2020) (Assumption 5)).   
Let a constant $M > 0$ with $D D ^ { T } \preceq M X ^ { + } X ^ { + } { } ^ { T }$ be known.  

Assumption 2 cumulatively bounds the whole sequence of the remainder $d _ { 1 } , \ldots , d _ { S - 1 }$ by a single constraint, rather than for each realization $d _ { i }$ separately as in Section 5.1. Furthermore, in contrast to the quadratically increasing bound of the Lagrange remainder (3), Assumption 2 supposes a bound on the remainder that increases linearly. Nevertheless, $M$ of Assumption 2 corresponds to similar insights as $M _ { \alpha }$ in Assumption 1.  

For deriving a stabilizing linear state feedback $u = K x$ , observe that the data matrices satisfy $X ^ { + } = A X + B U + D$ . Hence, the linear part of the closed-loop dynamics can be characterized based on the data matrices  

$$
\begin{array} { r l } { A + B K = \left[ A \ } & { { } B \right] \left[ \begin{array} { l } { I } \\ { K } \end{array} \right] = \left[ A \quad B \right] \left[ \begin{array} { l } { X } \\ { U } \end{array} \right] G = ( X ^ { + } - D ) G , } \end{array}
$$  

with $G$ satisfying  

$$
{ \Bigg [ } { I } { \Bigg ] } = { \binom { X } { U } } G .
$$  

De Persis and Tesi (2020) describes the uncertainty from the unknown remainder directly by the matrix $D$ . Thereby, De Persis and Tesi (2020) obtains a parametrization $G$ of the to-be-optimized controller that increases with the number of data. In contrast, the set-membership approach in Section 5.1 translates the uncertain remainder into an uncertainty of the coefficients of the TP. This leads to a controller design that does not scale with the number of samples. Moreover, incorporating the remainder of the TP approximation into the controller synthesis (Martin et al., 2023a) enables a global stabilization. Throughout this article, we will see further results based on a set-membership procedure or the closed-loop characterization from De Persis and Tesi (2020) exhibiting similar properties.  

Some of the data-based results for nonlinear systems inspired by De Persis and Tesi (2020) are mentioned next. Guo et al. (2022a) includes an extension for polynomial systems. De Persis and Tesi (2021) proposes an experiment design by scaled input sequences to ensure Assumption 2 and the PE condition for the data from a nonlinear system. Furthermore, Cetinkaya and Kishida (2021) stabilizes a periodic orbit using a Pyragastype control law and a system representation for the periodic time-evolution of the states. While the to-be-stabilized orbit becomes an equilibrium of the periodic system description, Cetinkaya and Kishida (2021) also solves the problem when the orbit is not precisely known. Luppi et al. (2022) stabilizes Lur’e-type systems $x ( t + 1 ) \ = \ A x ( t ) + B ( u ( t ) ) + f ( t , x ( t ) )$ using SDPs with LMI constraints. To this end, a quadratic constraint and samples of the nonlinearity $f$ need to be known, analogously to the approaches for Lur’e systems mentioned in Section 5.2.  

The persistence of excitation (PE) condition that $\begin{array} { r } { \left[ \begin{array} { l } { X } \\ { U } \end{array} \right] } \end{array}$ has full row rank (De Persis and Tesi, 2020) (Assumption 4) guarantees that $G$ always exists. Note that a data-based description of the closed-loop dynamics can also be retrieved by the relationship ${ \Big [ } A \quad B { \Big ] } = ( X ^ { + } - D ) { \Bigg [ } { \frac { X } { U } } { \Bigg ] } ^ { \dagger }$ which corresponds to $G = { \left[ \begin{array} { l } { X } \\ { U } \end{array} \right] } ^ { \dagger } { \left[ \begin{array} { l } { I } \\ { K } \end{array} \right] } .$ Instead of one specific $G$ , the closed-loop description (10) with consistency condition (11) provides for a fixed $K$ a whole subspace in terms of $G$ . Hence, optimizing over $G$ typically results in non-unique solutions. As shown in Do¨rfler et al. (2022), it is advantageous to regularize $G$ to single out solutions that are robust regarding noise.  

Along Theorem 6 of De Persis and Tesi (2020), the origin of the nonlinear system is asymptotically stable if the linear part of the closed loop (10) is asymptotically stable, i.e., if there exists a Lyapunov matrix $P \succ 0$ and matrix $G$ such that  

$$
\left( A + B K \right) P ( A + B K ) ^ { T } - P = \left( ( X ^ { + } - D ) G \right) P ( ( X ^ { + } - D ) G ) ^ { T } - P \prec 0 .
$$  

Since the remainder matrix $D$ is unknown, Theorem 5 of De Persis and Tesi (2020) uses Young’s relation (Caverly and Forbes, 2019) to ensure by an SDP that this stability condition holds for all $D$ satisfying Assumption 2. By optimizing over $P$ and $G$ , the state-feedback matrix $K$ can be recovered from (11).  

Although not directly related to the presented closed-loop representation of De Persis and Tesi (2020), we would also like to mention Berberich et al. (2022b). The authors also use a data-based inference on the behavior of the affine Taylor linearization, but in the context of predictive control. To this end, online updated data is combined with the fundamental lemma of Willems et al. (2005) to obtain a data-driven system parametrization of the nonlinear system in the neighbourhood of the current state. Thereby, the MPC scheme boils down to solving a convex quadratic program in each time instance.  

# 6. GP and kernel ridge regression for data-driven control  

GP and kernel ridge regression constitute well-established techniques in machine learning to approximate a nonlinear function from data and to predict its outputs for unseen inputs (Rasmussen and Williams, 2006) and (Bishop, 2006) (Section 6). Both regression methods are equipped with an uncertainty measure given by an upper bound for their approximation error. However, the regression solution and its error bound are usually nonlinear due to the nonlinear kernel functions. For that reason, the research direction, reported in this section, tackles the challenge to identify a representation of the regression that is suitable for system analysis and controller synthesis using SDPs. Thereby, these data-based methods can be leveraged for a wide range of control problems compared to the specific control schemes, e.g., using GP models with feedback linearization (Helwa et al., 2019) and (Lederer et al., 2019).  

# 6.1. Kernel ridge regression  

For kernel ridge regression, we first introduce the notion of kernel functions and their reproducing kernel Hilbert space (RKHS) to efficiently solve the following infinite-dimensional regression problem: For an unknown nonlinear function $f :$ $\mathbb { X } \subseteq \mathbb { R } ^ { n _ { x } } \to \mathbb { R }$ , let the data points $\{ y _ { i } , x _ { i } \} _ { i = 1 } ^ { S }$ with $y _ { i } = f ( x _ { i } )$ be available. Then, we want to find the solution of  

$$
\operatorname* { m i n } _ { \mu \in \mathcal H } \sum _ { i = 1 } ^ { S } ( y _ { i } - \mu ( x _ { i } ) ) ^ { 2 } + \lambda \| \mu \| _ { \mathcal H } ^ { 2 } ,
$$  

where $\lambda > 0$ is a regularization parameter, $\mathcal { H }$ a real Hilbert space of functions $\mu : \mathbb { X } \to \mathbb { R }$ , and $\| \cdot \| _ { \mathcal { H } }$ the associated function norm, i.e., $\| \mu \| _ { \mathcal { H } } = \sqrt { \langle \mu , \mu \rangle _ { \mathcal { H } } }$ .  

To solve this least-squares-error (LSE) problem, let a function $k ~ : ~ \mathbb { X } \times \mathbb { X } \to \mathbb { R }$ be a kernel if it is symmetric $k ( x , x ^ { \prime } ) = k ( x ^ { \prime } , x )$ for all $x , x ^ { \prime } \in \mathbb { X }$ and positive definite, i.e., $\textstyle \sum _ { i , j = 1 } ^ { n } \alpha _ { i } \alpha _ { j } k ( x _ { i } , x _ { j } ) ~ \geq ~ 0$ for all $n \in \mathbb { N }$ , $x _ { 1 } , \ldots , x _ { n } \ \in \ \mathbb { X }$ , and $\ L _ { \alpha _ { 1 } , \dots , \alpha _ { n } } \in \mathbb { R }$ (Steinwart and Christmann, 2008) (Theorem 4.16). Kernels naturally emerge in finite dimensional linear regression problems and allow a computationally efficient evaluation. Indeed, the solution of a linear regression includes the evaluation of the scalar product of the feature mapping $Z ( x ) : \mathbb { X } \to \mathbb { R } ^ { n _ { f } }$ , with often large $n _ { f }$ . At the same time, there exists for many $Z ( x )$ a kernel $k$ such that $k ( x , x ^ { \prime } ) = Z ( x ) ^ { T } Z ( x ^ { \prime } )$ (Steinwart and Christmann, 2008) (Definition 4.1).  

The special class of reproducing kernels and their associated RKHS will be crucial to solve (12). According to Steinwart and Christmann (2008) (Def. 4.18), a kernel $k : \mathbb { X } \times \mathbb { X } \to \mathbb { R }$ is a reproducing kernel of a real Hilbert space $\mathcal { H }$ of functions $f : \mathbb { X } \to \mathbb { R }$ if $k ( x , \cdot ) \in \mathcal { H }$ and $f ( x ) = \langle f , k ( x , \cdot ) \rangle _ { \mathcal { H } }$ for all $x \in \mathbb { X }$ and $f \in { \mathcal { H } }$ . The Hilbert space $\mathcal { H }$ is called RKHS of kernel $k$ .  

In the sequel, let a kernel $k$ and its RKHS $\mathcal { H }$ be given and the following assumption be satisfied.  

Assumption 3 (Maddalena et al. (2021)). Let $f \in \mathcal H$ and let an upper bound M on $| | f | | _ { \mathcal { H } }$ be known.  

Under Assumption 3, the regression problem (12) is called kernel ridge regression and the representer theorem (Kanagawa et al., 2018) (Theorem 3.4) provides its explicit solution  

$$
\mu ( x ) = y _ { X } ( \lambda I + K _ { X } ) ^ { - 1 } K ( x ) \in \mathcal { H } ,
$$  

with $y _ { X } = \Big [ y _ { 1 } \quad \cdots \quad y _ { S } \Big ] , K ( x ) = \Big [ k ( x , x _ { 1 } ) \quad \cdots \quad k ( x , x _ { S } ) \Big ] ^ { T } ,$ and Gram matrix $K _ { X }$ , i.e., its $( i , j )$ -th element corresponds to $k ( x _ { i } , x _ { j } )$ . Furthermore, Hu et al. (2023) derives the following approximation error  

$$
\| f ( x ) - \mu ( x ) \| _ { 2 } \leq M \sqrt { k ( x , x ) - K ( x ) ^ { T } \hat { K } _ { X } ^ { - 1 } K ( x ) } ,
$$  

for all $x \in \mathbb { X }$ and with $\hat { K } _ { X } = ( \lambda I + K _ { X } ) ( 2 \lambda I + K _ { X } ) ^ { - 1 } ( \lambda I + K _ { X } ) .$ . Thus, we obtain the set membership  

$$
\begin{array} { r l r } & { } & { f ( x ) \in \Sigma _ { \mathrm { k e r } } = \left\{ \mu ( x ) + R ( x ) : \mu ( x ) = y _ { X } ( \lambda I + K _ { X } ) ^ { - 1 } K ( x ) \right. } \\ & { } & { \left. \mathrm { a n d } \ R ( x ) ^ { 2 } \leq M ^ { 2 } ( k ( x , x ) - K ( x ) ^ { T } \hat { K } _ { X } ^ { - 1 } K ( x ) ) \right\} . } \end{array}
$$  

By (14), we can conclude that the unknown function $f$ is contained within a sector with centre $\mu ( x )$ and width $M \sqrt { k ( x , x ) - K ( x ) ^ { T } \hat { K } _ { X } ^ { - 1 } K ( x ) }$ . In contrast to the set membership (6) from polynomial approximation, the description of $\Sigma _ { \mathrm { k e r } }$ is usually nonlinear as the kernel $k$ is typically nonlinear, for example, compare the list of kernels in Section 2.1 of Kanagawa et al. (2018). Hence, a direct application of $\Sigma _ { \mathrm { k e r } }$ for a system analysis or a controller design by SDPs is not possible. Furthermore, Assumption 3 requires a bound on the norm associated to the kernel of the nonlinear function, while Assumption 1 a bound on high order partial derivatives. Both insights enable one to bound the difference between the nonlinear function and the approximation by the kernel regression or the polynomial interpolation. With the approximation error for $f \notin { \mathcal { H } }$ from Fiedler et al. (2021a), both approaches do not require knowledge of a function basis of the underlying nonlinear function. A data-driven inference on Assumption 3 is examined in Scharnhorst et al. (2023). Moreover, an approximation error for noisy data is investigated in Maddalena et al. (2021). Finally, since the kernel and the functions of its RKHS can share desired properties (Jidling et al., 2017), prior knowledge on $f$ can be included to reduce conservatism and improve the data efficiency.  

# 6.2. GP regression  

GP regression is another non-parametric regression method to infer an unknown nonlinear function by refining a prior belief by a set of noisy data. Hence, GP regression is a Bayesian method, where the underlying data generation is not drawn from a fixed function (Frequentist statistics) but from a stochastic process $\mathcal { F }$ , i.e., a distribution over functions.  

In the sequel, let a random vector $X$ that is Gaussian distributed with mean $\mu$ and covariance matrix $\Xi \succ 0$ be denoted by $X \sim { \mathcal { N } } ( \mu , \Xi )$ . A GP is a collection of random variables such that any finite subset is Gaussian distributed (Rasmussen and Williams, 2006). This specific stochastic process is uniquely defined by its mean function $m : \mathbb { X } \to \mathbb { R }$ and its covariance kernel $k ( x , x ^ { \prime } )$ . If the prior distribution $\mathcal { F }$ is a GP with zero mean and covariance $k$ and the data $\{ y _ { i } , x _ { i } \} _ { i = 1 } ^ { S }$ with $y _ { i } = { \mathcal { F } } ( x _ { i } ) + d _ { i }$ and independently identically distributed (iid) $d _ { i } \sim { \cal N } ( 0 , \sigma ^ { 2 } )$ is available, then the posterior $\mathcal { F } _ { \mathrm { p o s t } }$ is again a GP with mean  

$$
\mu _ { \mathrm { p o s t } } ( x ) = y _ { X } ( \sigma ^ { 2 } I + K _ { X } ) ^ { - 1 } K ( x )
$$  

and covariance  

$$
k _ { \mathrm { p o s t } } ( x , x ^ { \prime } ) = k ( x , x ^ { \prime } ) - y _ { X } ( \sigma ^ { 2 } I + K _ { X } ) ^ { - 1 } K ( x )
$$  

(Rasmussen and Williams, 2006). Here $y _ { X } , K _ { X }$ , and $K ( x )$ are defined as for the kernel ridge regression. Thus, the kernel ridge regression solution (13) is the same as the posterior mean. Intuitively, for large regularization parameters $\lambda$ or large noise variance $\sigma ^ { 2 }$ , the regression loosely fits the samples or does not trust the data, respectively. For more details on the connections between GP and kernel ridge regression, we refer to Kanagawa et al. (2018). Moreover, the posterior variance $k _ { \mathrm { p o s t } } ( \boldsymbol { x } , \boldsymbol { x } )$ measures the uncertainty of the inference on the data-generating distribution $\mathcal { F }$ .  

In the context of robust control, the ground truth dynamics might not be a stochastic process $\mathcal { F }$ but a function $f : \mathbb { X } \to \mathbb { R }$ . Since the posterior mean and covariance are obtained from Bayesian methods, a Frequentist bound on $f$ can not be derived directly from the previous Bayesian treatment. To infer a Frequentist bound, let data $\{ y _ { i } , x _ { i } \} _ { i = 1 } ^ { S }$ with $y _ { i } = f ( x _ { i } ) + d _ { i }$ and iid $d _ { i } \sim { \cal N } ( 0 , \sigma ^ { 2 } )$ be given. Then we can rely on Assumption 3 to compute a bound on the approximation error of the form  

$$
\begin{array} { r } { \operatorname* { P r } \Big ( \vert \vert f ( x ) - \mu _ { \mathrm { p o s t } } ( x ) \vert \vert _ { 2 } \le \beta \sqrt { k _ { \mathrm { p o s t } } ( x , x ) } , \forall x \in \mathbb { X } \Big ) \ge 1 - \delta , } \end{array}
$$  

with confidence $\delta \in ( 0 , 1 )$ , posterior mean $\mu _ { \mathrm { p o s t } }$ (15), posterior variance $k _ { \mathrm { p o s t } }$ (16), and where $\Pr ( E )$ denotes the probability of an event $E$ . For the scalar $\beta$ , Fiedler et al. (2021a) (Theorem 1) proposes $\beta = M + \dot { R } \sqrt { \log ( \operatorname * { d e t } ( \sigma ^ { 2 } I + K _ { X } ) ) - 2 \mathrm { l o g } ( \delta ) }$ and Chowdhury and Gopalan (2017) (Theorem 2) $\beta = M +$ $R \sqrt { 2 ( \gamma + 1 + \ln ( 1 / \delta ) ) }$ . However, the latter requires the rather difficult calculation of the maximum information gain $\gamma$ , and thus often calls for heuristic upper bounds. The error bound in (17) yields the following stochastic set membership  

$$
\begin{array} { r l r } & { } & { f ( x ) \in \Sigma _ { \mathrm { G P } } = \{ \mu ( x ) + R ( x ) : \mu ( x ) = \mu _ { \mathrm { p o s t } } ( x ) \mathrm { ~ a n d ~ } } \\ & { } & { \quad R ( x ) ^ { 2 } \le \beta ^ { 2 } k _ { \mathrm { p o s t } } ( x , x ) \} , } \end{array}
$$  

with probability $1 - \delta$ .  

Due to the nonlinear kernel function $k$ , the set membership $\scriptstyle \sum _ { \mathrm { G P } }$ includes nonlinear functions as in $\Sigma _ { \mathrm { k e r } }$ . For that reason, Umlauft et al. (2018) proposes a feedback linearization to stabilize the input-affine system ${ \dot { x } } = f ( x ) + G ( x ) u$ with a GP model for $f ( x )$ . The controller design requires a perfectly known and invertible input matrix $G ( x )$ . Moreover, a control Lyapunov function musts be calculated to establish stability guarantees, which requires the computationally complex solution of a dynamic program. Similarly, Capone et al. (2022) calls for perfect knowledge of $G ( x )$ and specific structure of the nonlinear dynamics $f ( x )$ as common for backstepping control (Khalil, 2002) (Section 13.2). Following a robust backstepping procedure, stability of the closed loop can be guaranteed from the GP inference on $f ( x )$ . Furthermore, Berkenkamp et al. (2016) proposes to directly study the time-derivative of a Lyapunov function for analysing the region of attraction of a stable closed loop. Indeed, the time-derivative of a Lyapunov function for a GP model of the dynamics is again a GP. Due to the impossible evaluation of the confidence intervals of this GP, a discretization of the state space and an over-estimation by Lipschitz continuity are required, which prevent an extension to a controller synthesis. Lastly, Romer et al. (2019) verifies a bound on the $\mathcal { L } _ { 2 }$ -gain and passivity properties via optimizing over a confidence region inferred from a GP.  

Since all these approaches require nonlinear optimization or a specific system dynamics, we present three approaches to tackle the nonlinearity of the kernel such that a system analysis and controller design by SDPs are possible.  

# 6.3. Learning linear sectors from GPs  

Fiedler et al. (2021b) suggests to linearly bound the Frequentist approximation error (17). Thereby, the nonlinear dynamics  

is represented by a linear system with linearly bounded uncertainty as common for system analysis and controller design by linear robust control techniques.  

For a nonlinear unknown part $\phi : [ a , b ] \to \mathbb { R }$ of a dynamics, Fiedler et al. (2021b) considers the sector  

$$
\kappa _ { 1 } x ^ { 2 } \leq x \phi ( x ) \leq \kappa _ { 2 } x ^ { 2 } ,
$$  

as common, for instance, for Lure’s problem. According to the set membership $\Sigma _ { \mathrm { G P } }$ for $\phi ( x )$ and Fiedler et al. (2021b) (Lemma 2), $\phi ( x )$ belongs with probability at least $1 - \delta$ to the sector (19) with  

$$
\kappa _ { 1 } = \operatorname* { m i n } _ { x \in [ a , b ] \backslash 0 } \frac { \xi } { x ^ { 2 } } , \kappa _ { 2 } = \operatorname* { m a x } _ { x \in [ a , b ] \backslash 0 } \frac { \xi } { x ^ { 2 } } ,
$$  

$\xi = \operatorname* { m i n } \left\{ x ( \mu _ { \mathrm { p o s t } } ( x ) + \beta \sqrt { k _ { \mathrm { p o s t } } ( x , x ) } ) , x ( \mu _ { \mathrm { p o s t } } ( x ) - \beta \sqrt { k _ { \mathrm { p o s t } } ( x , x ) } ) \right\}$ . Intuitively, Lemma 2 of Fiedler et al. (2021b) determines two linear functions $\kappa _ { 1 } x$ and $\kappa _ { 2 } x$ that under and over approximate the nonlinear boundaries $\mu _ { \mathrm { p o s t } } ( x ) \ : - \ : \beta \sqrt { k _ { \mathrm { p o s t } } ( x , x ) }$ and $\mu _ { \mathrm { p o s t } } ( x ) + \beta \sqrt { k _ { \mathrm { p o s t } } ( x , x ) } .$ , respectively. Thereby, $\phi ( x )$ is contained within the set $\{ \kappa x : \kappa _ { 1 } \leq \kappa \leq \kappa _ { 2 } \}$ . Note that this result requires $\phi$ to satisfy Assumption 3, i.e., $\phi$ is an element of the RKHS of the kernel of the GP and an upper bound of the norm of $\phi$ associated to the RKHS is known. Moreover, the computation of $\mathbf { \Psi } _ { K _ { 1 } , K _ { 2 } }$ includes a nonlinear optimization problem, which might be complex for multivariate $\phi : \mathbb { R } ^ { n } \to \mathbb { R }$ .  

We refer to Fiedler et al. (2021b) for the application of the linear sector (19) for a linear state-feedback design with quadratic performance using LFRs and SDPs. Note that also other control problems can be solved based on this LFR description.  

The presented concept is comparable with the polynomial representation from Section 5.1 because both determine a suitable sector around the nonlinearity. However, Martin and Allg¨ower (2022a) directly determines a polynomial sector of the dynamics instead of the inference of a learning method. Therefore, depending on the nonlinearity of the learning method, the linear sector (19) might be more conservative than actually necessary for the nonlinear dynamics. For instance, the shape of $\mu _ { \mathrm { p o s t } } ( x ) \pm \beta \sqrt { k _ { \mathrm { p o s t } } ( x , x ) }$ strongly depends on the chosen kernel function and its hyperparameters. Moreover, whereas Martin and Allgo¨wer (2023b) computes the sector by an SDP, (20) requires to solve a nonlinear optimization problem.  

# 6.4. Data-driven control by linearized kernels  

Berkenkamp and Schoellig (2015) linearizes the posterior mean (15) and covariance (16) around an equilibrium for a linear robust controller design. Therefore, Berkenkamp and Schoellig (2015) considers a Bayesian rather than a Frequentist treatment as in Fiedler et al. (2021b). Furthermore, we analyze the stabilization of an unknown nonlinear system by nonlinearity cancellation as proposed by Hu et al. (2023).  

Similar to Section 6.3, Berkenkamp and Schoellig (2015) presents a robust controller design by an LFR, but of the linearized nonlinear dynamics of $x ( t + 1 ) \ = \ f ( x ( t ) , u ( t ) )$ , deduced from a GP. Since the derivative of a GP is again a GP, Berkenkamp and Schoellig (2015) infers the Jacobian matrix of $f ( x , u ) = \left[ f _ { 1 } ( x , u ) \quad \cdots \quad f _ { n _ { x } } ( x , u ) \right] ^ { T }$ around an equilibrium point $\xi _ { \mathrm { e } } = \left[ x _ { \mathrm { e } } ^ { T } \quad u _ { \mathrm { e } } ^ { T } \right] ^ { T }$ by  

$$
\left. \frac { \partial f _ { i } } { \partial \xi } \right| _ { \xi _ { \mathrm { e } } } \sim N \left( \mu _ { i } ^ { \prime } ( \xi _ { \mathrm { e } } ) , \Xi _ { i } ^ { \prime } ( \xi _ { \mathrm { e } } ) \right) .
$$  

The posterior mean function $\mu _ { i } ^ { \prime } ( \xi _ { \mathrm { e } } )$ and the covariance matrix $\Xi _ { i } ^ { \prime } ( \xi _ { \mathrm { e } } )$ can be found in Berkenkamp and Schoellig (2015) (equation (10) and (11)). Thus, Berkenkamp and Schoellig (2015) can conclude on a probabilistic set membership for the Jacobian matrix $\left. \frac { \partial f } { \partial \xi } \right| _ { \xi _ { \mathrm { c } } }$ . We refer to equations (17)-(21) in Berkenkamp and Schoellig (2015) for an LFR for the linearized dynamics and to Theorem 1 in Berkenkamp and Schoellig (2015) for a robust linear state-feedback synthesis with $\mathcal { H } _ { 2 }$ performance by solving an SDP with LMI constraints. Moreover, Berkenkamp and Schoellig (2015) suggests possible extensions by learning the operating point $\xi _ { \mathrm { e } }$ from the learned GP of $\Phi$ , updating the GP by additional data to improve the control performance, not full state measurements, and tracking control.  

We emphasize that Berkenkamp and Schoellig (2015) elaborates a Bayesian inference on the system dynamics, and therefore the data-generating $f ( x , u )$ is a sample from a GP. Since the controller from Berkenkamp and Schoellig (2015) (Theorem 1) robustly asymptotically stabilizes the set membership of the Jacobian matrix, the controller asymptotically stabilizes the nonlinear system if its Jacobian matrix sampled from (21) is contained within this set. But in fact, no guarantees regarding the region of attraction and the performance of the closed loop can be deduced because the high order nonlinearities are neglected for the synthesis. Contrary, Fiedler et al. (2021b) incorporates the nonlinearity within the synthesis, and thereby can, e.g., guarantee closed-loop performance and a region of attraction. For that reason, the procedure of Berkenkamp and Schoellig (2015) is not suitable for determining dissipativity properties. Furthermore, instead of deriving an inference on the Jacobian linearization by first learning a GP, one could also directly receive the Jacobian from data following the polynomial approximation in Section 5.1 for a TP with $\omega = \xi _ { \mathrm { e } }$ and $k = 1$ .  

Hu et al. (2023) presents a second approach to stabilize a nonlinear system by mainly focusing on the linear part of a kernel ridge regression. More specifically, Hu et al. (2023) considers the nonlinear dynamics  

$$
\boldsymbol { x } ( t + 1 ) = \boldsymbol { f } ( \boldsymbol { x } ( t ) ) + \boldsymbol { B } \boldsymbol { u } ( t ) ,
$$  

with unknown nonlinear drift $f ( x )$ and unknown input matrix $B$ . To infer on the drift, data $\{ y _ { i } , x _ { i } \} _ { i = 1 } ^ { S }$ with $y _ { i } = f ( x _ { i } )$ of the system without exciting input $u = 0$ have to be measured. Applying (14) for each row implies under Assumption 3 the uncertain system representation  

$$
x ( t + 1 ) = A K ( x ( t ) ) + B u ( t ) + R ( x ( t ) ) ,
$$  

with data-dependent matrix $A = \left[ y _ { 1 } \quad \cdots \quad y _ { S } \right] ( \lambda I + K _ { X } ) ^ { - 1 }$ and $\| R ( x ) \| _ { 2 } ^ { 2 } \leq n _ { x } M ^ { 2 } ( k ( x , x ) - K ( x ) ^ { T } \dot { \hat { K } } _ { X } ^ { - 1 } K ( x ) )$ .  

To conclude on the unknown input matrix $B$ , additional data $\{ \tilde { y } _ { i } , \tilde { x } _ { i } , \tilde { u } _ { i } \} _ { i = 1 } ^ { \tilde { S } }$ with $\begin{array} { r } { \tilde { y } _ { i } ~ = ~ f ( \tilde { x } _ { i } ) + B \tilde { u } _ { i } } \end{array}$ is measured. Alternatively to the cumulative uncertainty bound (Hu et al., 2023) (equation (31) and (32)), we suggest to compute a tighter ellipsoidal outer approximation $\Sigma _ { B }$ for $\lVert \tilde { y } _ { i } - A K ( \tilde { x } _ { i } ) - B \tilde { u } _ { i } \rVert _ { 2 } ^ { 2 } \ \leq$ $n _ { x } M ^ { 2 } ( k ( \tilde { x } _ { i } , \tilde { x } _ { i } ) - K ( \tilde { x } _ { i } ) ^ { T } \hat { K } _ { X } ^ { - 1 } K ( \tilde { x } _ { i } ) ) , i = 1 , \ldots , \tilde { S }$ , as in Martin and Allgo¨wer (2022a).  

To stabilize the nonlinear closed loop, Hu et al. (2023) separates the known kernel approximation $A K ( x ( t ) )$ into its linear and nonlinear components and uses the control structure $u = \bar { F } x + \tilde { F } \tilde { K } ( x )$ . Then, Hu et al. (2023) follows the nonlinearity cancellation approach of De Persis et al. (2022). Hence, the linear feedback $\bar { F } x$ aims to stabilize the linear closed-loop dynamics, whereas the nonlinear feedback $\tilde { F } \tilde { K } ( x )$ tries to minimize the influence of the nonlinearity of the closed loop. Both can be formulated as an SDP (Hu et al., 2023).  

Following the discussion of Berkenkamp and Schoellig (2015), the approach of Hu et al. (2023) can only guarantee asymptotic stability if the choice of kernels satisfies $\mathrm { l i m } _ { \| x \| _ { 2 } \to 0 } \ \sqrt { k ( x , x ) - K ( x ) ^ { T } \hat { K } _ { X } ^ { - 1 } K ( x ) } / \| x \| _ { 2 } \ = \ 0$ . Since $R ( x )$ is neglected for stabilization, weaker closed-loop guarantees are achieved compared to Fiedler et al. (2021b). Moreover, since the system representation and the closed-loop representation include the nonlinear term $R ( x )$ , the verification of dissipativity or a region of attraction would require nonlinear optimization ( $\mathrm { \Delta H u }$ et al., 2023) (Theorem 2).  

# 6.5. Polynomial kernel for data-driven control  

In contrast to Section 6.3 and Section 6.4, Devonport et al. (2020) does not reduce the nonlinear kernel to a linear representation but to a polynomial. To this end, the nonlinearity of kernels is handled by polynomial kernels together with an uniform bound for the approximation error of the nonlinear dynamics by polynomials. Due to the polynomial system representation, SOS optimization can be applied for verifying system properties and controller synthesis.  

As in Section 5.2, the application of SOS relaxation motivates the investigation of continuous-time systems  

$$
\dot { x } ( t ) = f ( x ( t ) ) + G ( x ( t ) ) u ( t ) + \Phi ( x ( t ) ) ,
$$  

where $f : \mathbb { X } \to \mathbb { R } ^ { n _ { x } }$ and $G : \mathbb { X } \to \mathbb { R } ^ { n _ { x } \times n _ { u } }$ correspond to polynomial prior knowledge on the dynamics and $\Phi : \mathbb { X } \to \mathbb { R } ^ { n _ { x } }$ to an unknown and potentially nonlinear term. Furthermore, let $f ( 0 ) = \Phi ( 0 ) = 0$ . To infer the unknown nonlinear function $\Phi$ , let data $\{ y _ { i } , x _ { i } , u _ { i } \} _ { i = 1 } ^ { S }$ with $y _ { i } = f ( x _ { i } ) + G ( x _ { i } ) u _ { i } + \Phi ( x _ { i } ) + d _ { i }$ and uniformly bounded noise $\| d _ { i } \| _ { \infty } \leq \sigma$ be given. Then Devonport et al. (2020) suggests to approximate each element of $\Phi = \left[ \Phi _ { 1 } ( x ) \quad \cdot \cdot \cdot \quad \Phi _ { n _ { x } } ( x ) \right] ^ { T }$ by polynomial kernels  

$$
k ( x , x ^ { \prime } ) = \sum _ { i = 1 } ^ { \ell } \alpha _ { i } ^ { 2 } ( x ^ { T } x ^ { \prime } ) ^ { i } ,
$$  

with scaling factors $\alpha _ { i } \in \mathbb { R }$ . Since the corresponding RKHS $\mathcal { H } _ { \mathrm { p o l y } }$ is the set of all polynomials of degree less than or equal to $\ell$ and zero at zero, $\Phi \notin \mathcal { H } _ { \mathrm { p o l y } }$ . Thus, Assumption 3 is violated.  

To this end, Devonport et al. (2020) supposes the following assumption.  

Assumption 4 (Devonport et al. (2020) (Assumption 3)). For a known $\epsilon > 0$ , there exists a polynomial vector $q ( x )$ of degree less or equal to $\ell$ such that $\| \Phi ( x ) - q ( x ) \| _ { \infty } \leq \epsilon$ for all $x \in \mathbb { X }$ .  

By Assumption 4, the data satisfy  

$$
y _ { i } = f ( x _ { i } ) + G ( x _ { i } ) u _ { i } + q ( x _ { i } ) + \tilde { d } _ { i } ,
$$  

with $\| \tilde { d } _ { i } \| _ { \infty } \quad \le \quad \sigma + \epsilon .$ . Since each element of $\begin{array} { r l } { q ( x ) } & { { } = } \end{array}$ $\big [ q _ { 1 } ( x ) \quad \cdots \quad q _ { n _ { x } } ( x ) \big ] ^ { T }$ is an element of ${ \mathcal { H } } _ { \mathrm { p o l y } }$ , we can derive for each $q _ { i } ( x )$ the set membership (18) from data (22) and known $\| q _ { i } \| _ { \mathcal { H } _ { \mathrm { p o l y } } }$ according to Assumption 3. This in turn results in a set membership  

$$
\{ \mu ( x ) + R ( x ) : \mu ( x ) = \mu _ { \mathrm { p o s t } } ( x ) \mathrm { a n d } R ( x ) ^ { 2 } \leq \beta ^ { 2 } k _ { \mathrm { p o s t } } ( x , x ) + \epsilon ^ { 2 } \} .
$$  

for each $\Phi _ { i } ( x )$ .  

Devonport et al. (2020) shows that the posterior mean $\mu _ { \mathrm { p o s t } } ( x )$ and variance $k _ { \mathrm { p o s t } } ( \boldsymbol { x } , \boldsymbol { x } )$ are polynomial for a polynomial kernel. Hence, the set membership (23) is characterized by polynomials analogously to the set membership from TPs (6). Thus, the system analysis and controller synthesis from Section 5.1 by solving an SOS optimization problem is also possible for the set membership from polynomial kernels (23). Indeed, the uncertain TP in (6) reduces to the known $\mu _ { \mathrm { p o s t } } ( x )$ in (23), while the square of the remainder in (6) and (23) is upper bounded by a polynomial. Furthermore, Section 5.1 considers a row-wise inference on the dynamics by TPs compatible to the kernel inference for each $\Phi _ { i }$ by (23). Nevertheless, Devonport et al. (2020) shows an alternating optimization over the state feedback and Lyapunov function.  

Originally, Devonport et al. (2020) (Proposition 3 and Section 4) does not explicitly account for the uncertainty $\epsilon$ in (23) and in the subsequent controller synthesis. If we include this uniform bounded uncertainty, then (23) is non-zero for $x = 0$ . Thus, an inference on stability of the origin is prevented. To circumvent this issue, we suggest to derive a polynomial bound $\epsilon ( x ) \geq 0$ with $\epsilon ( 0 ) = 0$ . For instance, a suitable $\epsilon ( x )$ can be calculated from the remainder formula for TPs (3) or Hermite polynomials (Sauer and $\mathrm { { X u } }$ , 1995) under Assumption 1.  

Following the idea of computing $\epsilon ( x )$ from the remainder formula for TPs, then $q _ { i } ( x )$ corresponds to the TP of $\Phi _ { i } ( x )$ in Assumption 4. In this case, the set membership from TPs (6) and from polynomial kernels (23) include the bound for the remainder (3). Further, (6) computes the smallest ellipse containing the set of polynomials consistent with (22). The centre of the ellipse can be interpret as an LSE estimation. On the other hand, the posterior mean $\mu _ { \mathrm { p o s t } } ( x )$ corresponds to the LSE estimation for the $\mathrm { T P } q _ { i }$ from data (22).  

# 7. Data-driven control by LPV embedding  

An LPV system is a linear system with system matrices that depend on a time-varying independent variable. This variable is called scheduling variable and can describe nonlinearities, time-varying system parameters, or exogenous effects. In contrast to linear time-varying systems, the scheduling variable is unknown a priori but measurable. Hence, gain scheduling control is possible where the control law depends on the state and the scheduling variable. While LPV systems establish an interesting extension of LTI systems in itself, To´th (2010) shows their potential of capturing the behavior of nonlinear systems.  

For that reason, we review the data-driven treatment of a nonlinear system by combining data-driven control of LPV systems and the embedding of the nonlinear system into an LPV system. To this end, we first provide an overview on the extension of data-driven results for LTI systems to LPV systems. Afterwards, the embedding of nonlinear systems into LPV systems is discussed from a data-based perspective.  

# 7.1. Data-driven control for LPV systems  

This section introduces three data-driven representations for unknown LPV systems: (i) an extension of Willems’ fundamental lemma, (ii) an extension of De Persis and Tesi (2020), and (iii) a set-membership approach. All three data-driven system representations ensure rigorous guarantees and system analysis and control based on SDPs. Notice that specific data-driven control schemes for LPV systems has been already investigated previously, for instance, by virtual reference feedback tuning (Formentin and Savaresi, 2011). See also the survey by Bachnas et al. (2014).  

(i) In the behavioral framework, the dynamics of a system is characterized by its behavior that spans all possible inputoutput trajectories that can be observed from the system. Since the framework is trajectory-based, it is appealing for representations of dynamical systems from measured trajectories. One particular result is the fundamental lemma by Willems et al. (2005) that characterizes any trajectory of an LTI system based on a single measured trajectory. Therefore, this non-parametric parametrization can directly be exploited for data-driven simulation and output matching control (Markovsky and Rapisarda, 2008), predictive control (Coulson et al., 2019; Berberich et al., 2021; Yin et al., 2021), system level synthesis (Xue and Matni, 2021), and the verification of dissipativity (Maupong et. al., 2017; Romer et al., 2019) and more general inputoutput properties (Koch et al., 2021) over a data-dependent time horizon. Moreover, various extensions of the fundamental lemma, among others, linear time-varying systems (Nortmann and Mylvaganam, 2020) and Wiener or Hammerstein systems (Berberich and Allgo¨wer, 2020) are investigated.  

Based on a behavioral formulation, Verhoek et al. (2021a) (Theorem 2) presents a fundamental lemma for general LPV systems. For the sake of simplicity, we only present the fundamental lemma for LPV systems with IO-representation  

$$
y ( t ) = \sum _ { i = 1 } ^ { n _ { a } } a _ { i } ( p ( t - i ) ) y ( k - i ) + \sum _ { i = 1 } ^ { n _ { b } } b _ { i } ( p ( t - i ) ) u ( t - i ) ,
$$  

with output $\boldsymbol { y } ( t ) \in \mathbb { R } ^ { n _ { \mathrm { y } } }$ , input $u ( t ) \in \mathbb { R } ^ { n _ { u } }$ , scheduling parameter $p ( t ) = \left[ p _ { 1 } ( t ) \quad \cdots \quad p _ { n _ { p } } ( t ) \right] ^ { T } \in \mathbb { P }$ , and $n _ { a } \ge 1 , n _ { b } \ge 0$ . The  

functions $a _ { i }$ and $b _ { i }$ depend affine on the time-shifted scheduling parameter, i.e.,  

$$
\begin{array} { l } { \displaystyle a _ { i } ( p ( t - i ) ) = \sum _ { j = 0 } ^ { n _ { p } } a _ { i , j } p _ { j } ( t - i ) , } \\ { \displaystyle b _ { i } ( p ( k - i ) ) = \sum _ { j = 0 } ^ { n _ { p } } b _ { i , j } p _ { j } ( t - i ) , } \end{array}
$$  

with unknown coefficients $a _ { i , j } \in \mathbb { R } ^ { n _ { y } \times n _ { y } }$ and $b _ { i , j } \in \mathbb { R } ^ { n _ { y } \times n _ { u } }$ . Now let a trajectory $( y , p , u )$ from (24) of length $N$ be given, i.e., $y ~ = ~ \left[ y ( 1 ) ~ \cdots ~ y ( N ) \right]$ , $p ~ = ~ \Big [ p ( 1 ) ~ \cdots ~ p ( N ) \Big ] .$ , and $u \ =$ $\Big [ u ( 1 ) \quad \cdots \quad u ( N ) \Big ]$ satisfying (24). Furthermore, let $( u , p )$ be PE of a sufficiently large degree (Verhoek et al., 2021a). Then the fundamental lemma for LTI systems implies that for any trajectory (y¯, p¯, u¯) from (24) of length L, there exists a g ∈ RN−L+1 such that  

$$
\begin{array} { r } { \mathcal { H } _ { L } ( u ) \qquad } \\ { \left[ \mathcal { H } _ { L } ( p \otimes u ) - \bar { P } _ { n _ { u } } \mathcal { H } _ { L } ( u ) \right] g = \left[ \begin{array} { c } { \mathrm { v e c } ( \bar { u } ) } \\ { 0 } \\ { \mathcal { H } _ { L } ( y ) } \\ { 0 } \end{array} \right] , } \end{array}
$$  

where $\otimes$ is the Kronecker product of two matrices, ${ \bar { P } } _ { n }$ is a block-diagonal matrix with diagonal blocks $\bar { p } ( t ) \otimes I _ { n }$ , $\mathrm { v e c } ( \bar { u } ) =$ $\left\lceil \bar { u } ( 1 ) ^ { T } \quad \cdots \quad \bar { u } ( L ) ^ { T } \right\rceil ^ { T }$ , and $\mathcal { H } _ { L }$ the Hankel matrix of depth $L$ (Verhoek et al., 2021a).  

By the simple algebraic relation (25), a single trajectory $( y , p , u )$ is sufficient to generate any trajectory $( \bar { y } , \bar { p } , \bar { u } )$ of an LPV system. Thus, it can be leveraged to predict the behavior of an LPV system for a data-driven predictive control scheme (Verhoek et al., 2021b). Following the ideas for LTI systems (Romer et al., 2019), Verhoek et al. (2023b) determines finitehorizon dissipativity properties from one recorded noisefree trajectory.  

(ii) While the fundamental lemma (25) allows for an easy treatment of input-output data under rather mild controllability assumptions on the system, it only allows for system properties to be inferred over finite horizon. For arbitrary time horizons, Verhoek et al. (2022a) extends De Persis and Tesi (2020) to a representation of open- and closed-loop LPV systems from input-scheduling-parameter-state data. For that purpose, let the system matrices $A : \mathbb { P } \to \mathbb { R } ^ { n _ { x } \times n _ { x } }$ and $B : \mathbb { P }  \mathbb { R } ^ { n _ { x } \times n _ { u } }$ be affine w.r.t. the scheduling parameter $p$ , i.e.,  

$$
A ( p ) = A _ { 0 } + \sum _ { i = 1 } ^ { n _ { p } } p _ { i } A _ { i } , B ( p ) = B _ { 0 } + \sum _ { i = 1 } ^ { n _ { p } } p _ { i } B _ { i } , 
$$  

with unknown matrices $A _ { i } , B _ { i } , i \ = \ 1 , \ldots , n _ { p }$ . Then Verhoek et al. (2022a) studies an LPV system in SS-representation  

$$
\begin{array} { r l } & { \boldsymbol { x } ( t + 1 ) = \boldsymbol { A } ( p ( t ) ) \boldsymbol { x } ( t ) + \boldsymbol { B } ( p ( t ) ) \boldsymbol { u } ( t ) } \\ & { \qquad = \mathcal { A } \left[ \begin{array} { c } { \boldsymbol { x } ( t ) } \\ { p ( t ) \otimes \boldsymbol { x } ( t ) } \end{array} \right] + \mathcal { B } \left[ \begin{array} { c } { \boldsymbol { u } ( t ) } \\ { p ( t ) \otimes \boldsymbol { u } ( t ) } \end{array} \right] , } \end{array}
$$  

with state $\boldsymbol { x } ( t ) \in \mathbb { R } ^ { n _ { \boldsymbol { x } } }$ , input $u ( t ) \in \mathbb { R } ^ { n _ { u } }$ , and unknown matrices $\mathcal { A } = \left[ A _ { 0 } \quad A _ { 1 } \quad \cdots \quad A _ { n _ { p } } \right]$ and $\mathcal { B } = \Big [ B _ { 0 } \quad B _ { 1 } \quad \cdots \quad B _ { n _ { p } } \Big ] .$  

To find $\mathcal { A }$ and $\mathcal { B }$ , let the noise-free data $\{ x _ { i } , p _ { i } , u _ { i } \} _ { i = 1 } ^ { S }$ from (27) be available and let the data-depended matrix  

$$
\mathscr { G } = \left[ \begin{array} { c c c } { x _ { 1 } } & { \cdot \cdot \cdot } & { x _ { S - 1 } } \\ { p _ { 1 } \otimes x _ { 1 } } & { \cdot \cdot \cdot } & { p _ { S - 1 } \otimes x _ { S - 1 } } \\ { u _ { 1 } } & { \cdot \cdot \cdot } & { u _ { S - 1 } } \\ { p _ { 1 } \otimes u _ { 1 } } & { \cdot \cdot \cdot } & { p _ { S - 1 } \otimes u _ { S - 1 } } \end{array} \right]
$$  

have full row rank. The latter condition corresponds to a PE condition that generalizes the corresponding condition for LTI systems (De Persis and Tesi, 2020). Since  

$$
X ^ { + } = \left[ x _ { 2 } \quad \cdots \quad x _ { S } \right] = \left[ { \mathcal { A } } \quad { \mathcal { B } } \right] { \mathcal { G } }
$$  

and $\mathcal { G }$ has full row rank, we obtain the unknown matrices $\mathcal { A }$ and $\mathcal { B }$ by $\left[ \begin{array} { l l } { \mathcal { R } } & { \mathcal { B } } \end{array} \right] = \boldsymbol { X } ^ { + } \boldsymbol { \mathcal { G } } ^ { \dagger }$ and the following data-based representation of (27)  

$$
x ( t + 1 ) = X ^ { + } { \pmb \mathcal { G } } ^ { \dagger } \left[ { \pmb x } ( t ) \otimes { \pmb x } ( t ) \right] .
$$  

By this data-based representation and the model-based conditions for stability and quadratic performance for LPV systems (Verhoek et al., 2022a) (Lemma 1-4), we can analyze an LPV system directly from data.  

For the data-driven controller synthesis for (27), Verhoek et al. (2022a) extends the data-based closed-loop representation of LTI systems (De Persis and Tesi, 2020) (Theorem 2), as shown in Section 5.3, for a state feedback $u ( t ) = K ( p ( t ) ) x ( t )$ . For a polytopic and convex $\mathbb { P }$ , the design of a stabilizing feedback boils down to a finite number of LMI constraints by the full-block S-procedure (Scherer, 2001). Verhoek et al. (2022a) (Theorem 4-6) presents further statements for a data-driven controller synthesis with performance guarantees. Thereby, it is possible to design a controller for LPV systems with stability and performance guarantees from data by solving an SDP with a finite number of LMIs constraints.  

(iii) Miller and Sznaier (2023) considers a set-membership approach for LPV systems, and thus ensures rigorous guarantees despite noise-corrupted data. Moreover, the controller synthesis does not scale with the number of data as in Verhoek et al. (2022a). To this end, noisy samples $\{ x _ { i } , p _ { i } , u _ { i } \} _ { i = 1 } ^ { S }$ from the LPV systems in SS-representation (27) with $B ( p ) \ = \ B$ are drawn, i.e.,  

$$
x _ { i + 1 } = \mathcal { A } { \left[ \begin{array} { l } { ~ x _ { i } } \\ { p _ { i } \otimes x _ { i } } \end{array} \right] } + B u _ { i } + d _ { i } .
$$  

The actual noise realizations $\begin{array} { r l r } { d _ { i } , i } & { { } \ } & { = \ } & { { } 1 , \ldots , S } \end{array}$ are unknown. Collecting the data into matrices $\begin{array} { r l } { X } & { { } = \quad \left[ x _ { 1 } \quad \cdots \quad x _ { S - 1 } \right] , U \quad { \mathrm { ~ = ~ } } \quad \left[ u _ { 1 } \quad \cdots \quad u _ { S - 1 } \right] , X ^ { + } \quad = } \\ { \left[ x _ { 2 } \quad \cdots \quad x _ { S } \right] , P _ { X } } & { { } = \quad \left[ p _ { 1 } \otimes x _ { 1 } \quad \cdots \quad p _ { S - 1 } \otimes x _ { S - 1 } \right] , { \mathrm { ~ a n d ~ } } } \\ { D = \left[ d _ { 1 } \quad \cdots \quad d _ { S - 1 } \right] { \mathrm { a m o u n t s ~ t o ~ t h e ~ r e l a t i o n } } } \end{array}$  

$$
X ^ { + } = \left[ \mathcal { R } \quad B \right] \left[ { \begin{array} { l } { X } \\ { P _ { X } } \\ { U } \end{array} } \right] + D .
$$  

For simplicity and analogously to the LTI result (van Waarde et al., 2022), let the noise be cumulatively bounded  

$$
\left[ \begin{array} { c } { I } \\ { D ^ { T } } \end{array} \right] ^ { T } \left[ \Delta _ { 1 } \quad \Delta _ { 2 } ^ { T } \right] \left[ \begin{array} { c } { I } \\ { D ^ { T } } \end{array} \right] \succeq 0 ,
$$  

with $\Delta _ { 3 } \preceq 0$ . See Martin and Allgo¨wer (2022b) for a comparison of this cumulative and pointwise-in-time noise bound. Substituting the unknown noise matrix $D$ from (28) immediately yields the set membership for the unknown coefficient matrices $\mathcal { A }$ and $B$  

$$
\begin{array} { r l } { \Sigma _ { \mathcal { R } , B } = \{ [ \tilde { \mathcal { R } } \quad \tilde { B } ] : } & { } \\ { \star ^ { T } [ \Delta _ { 1 } \quad \Delta _ { 2 } ^ { T } ] : } \\ { \star ^ { T } [ \Delta _ { 2 } \quad \Delta _ { 3 } ] ^ { T } [ \boldsymbol { X } ^ { + ^ { T } } } & { - [ \begin{array} { c } { \boldsymbol { X } } \\ { \boldsymbol { D } \boldsymbol { X } } \\ { \boldsymbol { U } } \end{array} ] ^ { T } [ [ \boldsymbol { \tilde { \mathcal { R } } } \boldsymbol { \tilde { \mathcal { R } } } ] ^ { T } ] \succeq 0 \} . } \end{array}
$$  

By “ $\star ^ { \prime \prime }$ , the matrices on the right-hand side of “ ” are abbreviated.  

Since $\Sigma _ { \mathcal { A } , B }$ characterizes the set of all LPV systems consistent with the noisy data, the ground-truth LPV system (27) is contained within the set. Therefore, finding a control policy, that stabilizes all LPV systems within $\Sigma _ { \mathcal { A } , B }$ , also stabilizes the ground-truth system. In contrast to the previous LPV approaches, here the data is corrupted by noise, and thereby the true system can not be exactly identified from data. This uncertainty adds conservatism to the controller design but can be handled by robust control techniques.  

By Lemma 1 from Miller and Sznaier (2023), the controller synthesis for LPV systems with convex polytopic scheduling space $\mathbb { P }$ boils down to the robust stabilization of the LTI systems with system matrices contained in the set membership (29) and scheduling parameters at the vertices $\mathbb { P }$ . This can be solved by a non-conservative S-Lemma (van Waarde et al., 2022). Thereby, also a controller design with performance guarantees is conceivable. In contrast to Verhoek et al. (2022a), the setmembership approach has the advantage that the number of optimization variables does not increase with the number of samples.  

Following a similar procedure, Mejari, et al. (2023) presents a set-membership approach for LPV systems using pointwisein-time bounded noise. Moreover, the synthesis of a gainscheduling feedback controller that ensures a robust invariant set w.r.t. bounded disturbance is investigated.  

# 7.2. Data-driven LPV embedding of nonlinear systems  

While the data-driven LPV methods from the previous section are also of independent interest, we clarify next their applicability for checking system properties and controller design for nonlinear systems. To this end, we consider the two conversions of a nonlinear system into an LPV system as proposed by Verhoek et al. (2022b) and Verhoek et al. (2023a) in a datadriven control context.  

Verhoek et al. (2022b) studies a general nonlinear discretetime system  

$$
x ( t + 1 ) = f ( x ( t ) , u ( t ) ) ,
$$  

with continuously differentiable function $f : \mathbb { X } \times \mathbb { U } \to \mathbb { X }$ and $f ( 0 , 0 ) = 0$ . As shown in C¸ imen (2010) (Proposition 1) and the references therein, the nonlinear system can be embedded into the LPV system (27) with scheduling parameter $p ( t ) = \psi ( x ( t ) , u ( t ) ) \in \mathbb { P }$ . Thus, $f ( x , u ) \in \{ A ( p ) x + B ( p ) u : p \in \mathbb { P } \}$ .  

Assumption 5 (Verhoek et al. (2022b)). Let the scheduling map $\psi ( x , u )$ be known and chosen such that the matrices $A ( p )$ and $B ( p )$ of (27) are affine in p as in (26).  

Under Assumption 5, input-scheduling-parameter-state data can be obtained from recorded input-state trajectories of the nonlinear system (30) as required for the three data-driven representations for LPV from Section 7.1. Thus, a set membership for the nonlinear system (30) is given by the set of all LPV systems consistent with the data, i.e.,  

$$
\Sigma _ { \mathrm { L P V } } = \left\{ \mathcal { R } { \left[ \begin{array} { l } { x } \\ { p \otimes x } \end{array} \right] } + \mathcal { B } { \left[ \begin{array} { l } { u } \\ { p \otimes u } \end{array} \right] } : p \in \mathbb { P } , \left[ \mathcal { R } \quad \mathcal { B } \right] = X ^ { + } { \mathcal { G } } ^ { \dagger } \right\} .
$$  

or  

$$
\tilde { \Sigma } _ { \mathrm { L P V } } = \left\{ \tilde { \mathcal { A } } \left[ \mathstrut _ { p \otimes x } ^ { x } \right] + \tilde { \mathcal { B } } \left[ \mathstrut _ { p \otimes u } ^ { u } \right] : p \in \mathbb { P } , \left[ \tilde { \mathcal { A } } \quad \tilde { \mathcal { B } } \right] \in \Sigma _ { \mathcal { A } , B } \right\} .
$$  

Moreover, Assumption 5 allows the scheduling parameter to be constructed from input-state measurements of the nonlinear system to realize the feedback law $u ( t ) = K ( p ( t ) ) x ( t )$ . Hence, we can conclude that all three data-driven LPV approaches from Section 7.1 are conceivable for a data-driven system analysis or controller design for nonlinear systems under Assumption 5. Note that Verhoek et al. (2022b) focuses on the LPV representation (ii) from Verhoek et al. (2022a).  

As shown in Koelewijn et al. (2020), the previous direct LPV embedding comes with the shortcoming that stability from the LPV system (27) implies stability for the nonlinear system (30) only at the origin but not for potential non-zero equilibria. This phenomenon emerges as the LPV stability analysis supposes that the scheduling parameter is an exogenous variable independent of state and input. Therefore, Verhoek et al. (2023a) considers an LPV embedding of the so-called velocity-form of a nonlinear system. Thereby, global stability and performance guarantees are possible.  

The velocity-form of a nonlinear system describes the dynamics of $\Delta x ( t ) = x ( t ) - x ( t - 1 )$ and naturally exhibits a state-depended form. Similar to Assumption 5, Verhoek et al. (2023a) requires additional insights into the nonlinearities of its dynamics to infer a suitable scheduling variable. As for the direct LPV embedding, the data-driven control methods for LPV systems (i)-(iii) from the previous section are applicable for analysing and designing controllers for the embedded velocity-form LPV system using SDPs with a finite number of LMI constraints. Also note the similarities of the analysis of the velocity-form and incremental system analysis of nonlinear system (30) (Forni et al., 2013).  

![](images/d5fef38dd149d922644aa93f3e76eb1a646316373d14e7e3b467bf514c270999.jpg)  
Figure 4: Combining data-driven control techniques for LPV systems and LPV embedding of nonlinear systems.  

As summarized in Figure 4, combining an embedding of an unknown nonlinear dynamics into an LPV system and datadriven control techniques for LPV systems enables a data-based system analysis and control of nonlinear systems. The key idea to analyze systems and design controllers by SDPs despite nonlinear dynamics is the linearization by embedding the nonlinear system into an LPV system. Thereby, the nonlinearity is relaxed as the free scheduling variable. The LPV embedding comes at the cost of additional conservatism due to the independence of the scheduling variable regarding states and inputs. Thus, the LPV representation allows for more possible trajectories than the ground-truth nonlinear system. Nevertheless, To´th (2010) indicates the successful application of an LPV embedding for a large subset of nonlinear systems. We also refer to Markovsky (2023) for an embedding of a nonlinear system into an LTI system by introducing additional inputs and for its application for data-driven simulation.  

In contrast to the previously presented approaches by polynomial approximation (Section 5) and kernel regression (Section 6), the LPV approach requires knowledge of a function basis containing the nonlinearity of the dynamics (Assumption 5) or of its velocity-form. This insight might be reasonable for mechanical or electrical systems, however, is often not known. The latter scenario is tackled in the polynomial approximation and kernel regression approach. We assess the latter problem more difficult as the data only provide local insights into the nonlinear dynamics. Hence, the number of required data samples, e.g., in Verhoek et al. (2022b), can be significantly smaller. Further advantages of the LPV approach are the design of a potentially more flexible nonlinear feedback law and it does not rely on the scalability of an SOS relaxation.  

We conclude with some possible extensions and open questions. As commented in Verhoek et al. (2023a) (Remark 1), Assumption 5 could be relaxed by using a monomial basis instead of a true function basis. This motivates the question whether an upper bound on the remainder for TPs and the insight from Assumption 1 can be incorporated into the data-based LPV representations and the subsequent analysis. For a monomial basis, a second question is whether a direct SOS treatment of the polynomial approximation is beneficial compared to an LPV relaxation by embedding the polynomial dynamics into an LPV system. Furthermore, we point out that an LPV embedding under Assumption 5 might be non-unique. For instance, given $p _ { 1 } = x _ { 1 } x _ { 2 }$ and $p _ { 2 } = x _ { 2 } ^ { 2 }$ , then  

$$
\left[ \begin{array} { c } { x _ { 1 } ^ { + } } \\ { x _ { 2 } ^ { + } } \end{array} \right] = \left[ \begin{array} { c c } { x _ { 1 } x _ { 2 } ^ { 2 } } \\ { x _ { 1 } ^ { 2 } x _ { 2 } + x _ { 2 } ^ { 3 } } \end{array} \right] = \left[ \begin{array} { c c } { \alpha p _ { 2 } } & { ( 1 - \alpha ) p _ { 1 } } \\ { p _ { 1 } } & { p _ { 2 } } \end{array} \right] \left[ \begin{array} { c } { x _ { 1 } } \\ { x _ { 2 } } \end{array} \right] \forall \alpha \in \mathbb { R } .
$$  

Hence, the problem arises that the set of matrices $A _ { 1 }$ and $A _ { 2 }$ from (26) compatible with the data is always a linear subspace, and thus unbounded. At the same time, many robust control techniques require a bounded uncertainty set.  

# 7.3. Iterative control scheme by extended linearization  

Related to the problem setup in Verhoek et al. (2022b), we briefly report the data-driven iterative control scheme of Dai and Sznaier (2021a). There the controller design for an unknown nonlinear system $x ( t + 1 ) = f ( x ( t ) ) + g ( x ( t ) ) u ( t )$ is solved by the extended linearization (C¸ imen, 2010) and under a known function basis that spans the dynamics.  

Assumption 6 (Dai and Sznaier (2021a) (Assumption 1)). Let basis functions $F : \mathbb { R } ^ { n _ { x } }  \mathbb { R } ^ { n _ { f } }$ and $G : \mathbb { R } ^ { n _ { x } }  \mathbb { R } ^ { n _ { g } \times n _ { u } }$ be known such that there exist matrices $A \ \in \ \mathbb { R } ^ { n _ { x } \times n _ { f } } , B \ \in \ \mathbb { R } ^ { n _ { x } \times n _ { g } }$ with $f ( x ) = A F ( x )$ and $g ( x ) = B G ( x )$ .  

Assumption 6 calls for a dictionary of basis functions for the nonlinear system dynamics. This insight might by accessible from first principles, e.g., for mechanical or electrical systems.  

Proceeding as in Miller and Sznaier (2023) or Mejari, et al. (2023) yields a set membership $\Sigma _ { A , B }$ for the unknown matrices $A$ and $B$ from noisy data $\left\{ x _ { i } , u _ { i } \right\} _ { i = 1 } ^ { S }$ . Thus, Dai and Sznaier (2021a) concludes on the nonlinear data-based system representation  

$$
f ( x ) + g ( x ) u \in \left\{ \tilde { A } Z ( x ) x + \tilde { B } G ( x ) u : \left[ \tilde { A } \quad \tilde { B } \right] \in \Sigma _ { A , B } \right\} ,
$$  

with extended linearization $F ( x ) = Z ( x ) x$ .  

Instead of exploiting an LPV embedding to linearize the nonlinearity of (33) as in Verhoek et al. (2022b), Dai and Sznaier (2021a) suggests an online scheme. There the optimization problem  

$$
\begin{array} { r l r } {  { \operatorname* { m i n } _ { u ( t ) , u ( t + 1 ) , \dots } \sum _ { i = t } ^ { \infty } x ( i ) ^ { T } Q x ( i ) + u ( i ) ^ { T } R u ( i ) } } \\ & { } & { \mathrm { s . t . ~ } x ( i + 1 ) = \tilde { A } Z ( x ( t ) ) x ( i ) + \tilde { B } G ( x ( t ) ) u ( i ) } \end{array}
$$  

is solved in each time instant $t$ and the first part of the optimal control policy $u ( t )$ is applied to the system. Hence, the key idea to circumvent the nonlinearity of (33) is to freeze $Z ( x )$ and $G ( x )$ at time $t$ and to treat the nonlinear dynamics as an LTI system. Hence, the optimal control problem (34) can be solved for all $\left[ \tilde { A } \quad \tilde { B } \right] \in \Sigma _ { A , B }$ by an SDP with LMI constraints using datadriven control for LTI systems (van Waarde et al., 2022). To guarantee that the equilibrium at the origin is globally asymptotically stable, the optimal control problem is extended by a decrease of a control Lyapunov function along the closed-loop trajectory.  

On the one hand, this procedure constitutes an alternative to an LPV embedding as similar assumptions on prior insights and data are required. On the other hand, the optimal control problem (34) has to be solved iteratively online and the closed loop does not necessarily satisfy a specified control performance. An open question is whether the non-unique extended linearization might lead to performance or feasibility issues although not observed in the numerical example of Dai and Sznaier (2021a). Moreover, the feasibility of the optimal control problem is not guaranteed during runtime, which is typically ensured in MPC. We highlight the connection to the datadriven predictive control approach for nonlinear systems from Berberich et al. (2022b). There also an online updated local linear approximation of the nonlinear system is exploited but by using the fundamental lemma by Willems et al. (2005) rather than a set-membership representation.  

# 8. Data-driven control by state lifting  

The nonlinearity of a dynamical system usually prevents a system analysis and controller design by convex optimization. The literature on the Koopman operator presents a solution by lifting the states to higher, potentially infinite, dimensions. Thereby, the nonlinear dynamics is exactly described by a (bi-)linear system, and thus can be handled by control techniques for (bi-)linear systems. Due to its success in application, we review the Koopman operator with a focus on results providing rigorous guarantees.  

# 8.1. Koopman operator paradigm  

The Koopman operator paradigm was first introduced by Koopman (1931) and it has been increasingly used over the last decades because it provides a global (bi-)linear system description in contrast to a local Jacobian linearization. Its applications cover prediction (Mezic´, 2005), global stability analysis (Mauroy et al., 2020), MPC (Korda and Mezic´, 2018a), linear-quadratic regulation (Brunton et al., 2016), and robotics (Bruder et al., 2019). Further control-oriented applications can be found in Section 5.2 of Bevanda et al. (2021).  

The notion of the Koopman operator is originally introduced for an autonomous system $x ( t + 1 ) = f ( x ( t ) )$ with state $x ( t ) \in$ $\mathbb { X } \subseteq \mathbb { R } ^ { n }$ . Instead of observing the time evolution of the states, the Koopman operator considers the system dynamics through the lens of scalar functions $\psi : \mathbb { X } \to \mathbb { C }$ from a function space $\mathcal { H }$ . Thereby, the Koopman operator $\mathcal { K } : \mathcal { H }  \mathcal { H }$ is given by $\mathcal { K } \psi = \psi \circ f$ , with function composition ◦. Thus, the operator characterizes the propagation of a whole hypersurface over one time-step rather than of a single state. Due to the linearity of the function composition, $\mathcal { K }$ is linear, although the underlying dynamics is nonlinear. Moreover, $\mathcal { K }$ operates globally for all $x \in \mathbb { X }$ with $\mathcal { K } \psi ( x ) = \psi \circ f ( x ) = \psi ( x ( t + 1 ) )$ .  

Besides providing a global linearization, the Koopman theory can be useful in system analysis: The particular choice of observables by the eigenfunctions $\phi$ of $\mathcal { K }$ , with $\mathcal { K } \phi = \lambda \phi$ and eigenvalue $\lambda$ , enables a spectral analysis of nonlinear systems. Furthermore, Yi and Manchester (2021) investigates the equivalence of Koopman theory and contraction theory and Mauroy et al. (2013) shows the connection of Koopman and Lyapunov theory by interpreting Lyapunov functions as special case of observable. We refer to the survey by Bevanda et al. (2021) and the references therein for more details including data-based inferences on eigenfunctions (Section 3.4).  

The linearity of the system representation comes at the cost that the Koopman operator is infinite-dimensional. Therefore, a finite dimensional truncation is necessary for an efficient analysis and controller design. For that purpose, a dictionary of finitely many observables $\left\{ \psi _ { i } \right\} _ { i = 1 } ^ { n _ { D } }$ is chosen, which leads to the lifted finite-dimensional dynamics $z ( t + 1 ) = A z ( t )$ with $\boldsymbol { z } = \left[ \psi _ { 1 } ( \boldsymbol { x } ) \quad \cdots \quad \psi _ { n _ { D } } ( \boldsymbol { x } ) \right] ^ { T } = \dot { \Psi } ( \boldsymbol { x } )$ . However, since the dictionary generally does not span an invariant space w.r.t. the Koopman operator, the lifted dynamics involves a truncation error. Since this error depends on the system dynamics and the chosen observables, its structure and size is in general unclear. The literature examines, besides specific choices of observables as time-delay coordinates (Kamb et al., 2020), learning of suitable observables from data, e.g., learning the eigenfunctions (Kaiser et al., 2021), deep learning (Lusch et al., 2018), and by SDPs (Sznaier, 2021). While the observables are mostly chosen to achieve a small prediction error, optimizing the dictionary together with a controller is interesting to find observables achieving good control performance.  

While the Koopman operator is linear for autonomous systems, the Koopman paradigm leads for input-affine systems and state-dependent lifting functions to a bilinear system description in continuous-time and to an LPV description in discretetime (Bevanda et al., 2021) (Corollary 5.1.1). Nevertheless, most works restrict the finite-dimensional truncation model to an LTI system (Korda and Mezic´, 2018a; Zhang et al., 2022) $z ( t + 1 ) = A z ( t ) + B u ( t )$ or a bilinear system (Sinha et al., 2022; Stra¨sser et al., 2023a) $z ( t + 1 ) = A z ( t ) + u ( t ) ( B _ { 0 } + B _ { 1 } z ( t ) )$ (here $u ( t ) \in \mathbb { R } )$ .  

Extended dynamic mode decomposition (EDMD) constitutes a common estimation of the finite-dimensional system matrices of the truncation models from data: For a given set of statedependent observables $\left\{ \psi _ { i } \right\} _ { i = 1 } ^ { n _ { D } }$ , input-state samples $\{ x _ { i } , u _ { i } \} _ { i = 1 } ^ { S }$ are collected from the underlying nonlinear system $x ( t + 1 ) \ =$ $f ( x ( t ) ) + g ( x ( t ) ) u ( t )$ . Then, for a bilinear system representation, the LSE problem  

$$
\operatorname* { m i n } _ { A , B _ { 0 } , B _ { 1 } } \Big \| Z ^ { + } - \big [ A B _ { 0 } B _ { 1 } \big ] Y \Big \| _ { \mathrm { F r } }
$$  

is solved with data-dependent matrices $\begin{array} { r l r l } { Z ^ { + } } & { { } } & { = } & { } \end{array}$ $\left[ \Psi ( x _ { 2 } ) \quad \cdot \cdot \cdot \quad \Psi ( x _ { S } ) \right]$ and  

$$
Y = \left[ \begin{array} { c c c } { { \Psi ( x _ { 1 } ) } } & { { \ldots } } & { { \Psi ( x _ { S - 1 } ) } } \\ { { u _ { 1 } } } & { { \ldots } } & { { u _ { S - 1 } } } \\ { { \Psi ( x _ { 1 } ) u _ { 1 } } } & { { \ldots } } & { { \Psi ( x _ { S - 1 } ) u _ { S - 1 } } } \end{array} \right] .
$$  

As shown in Korda and Mezic´ (2018b), EDMD is asymptotically consistent, i.e., converges to the Koopman operator for $n _ { D }  \infty$ and $s  \infty$ under some additional assumptions. In the non-asymptotic case, Nu¨ske et al. (2023) provides statistical bounds on the estimation error due to finite data.  

# 8.2. Data-driven control by state lifting with guarantees  

In the following, we take a closer look at two articles because they incorporate an estimation error into the controller design by a Koopman-lifted system representation. Thereby, guarantees for the closed loop of the original nonlinear system can be recovered if the estimation error satisfies the assumed error characterization.  

Zhang et al. (2022) proposes to lift the nonlinear system $x ( t + 1 ) \ = \ f ( x ( t ) , u ( t ) ) , x \in \ \mathbb { X } , u \in \ \mathbb { U }$ , for a suitable choice of observables to the LTI system  

$$
\begin{array} { c } { { z ( t + 1 ) = A z ( t ) + B u ( t ) + w ( t ) , } } \\ { { x ( t ) = C z ( t ) + \nu ( t ) . } } \end{array}
$$  

The matrices $A$ and $B$ are calculated from EDMD, analogously to (35) with an additional regularization, and the output matrix $C$ from  

$$
\operatorname* { m i n } _ { C } \sum _ { i = 1 } ^ { S } \| C \Psi ( x _ { i } ) - x _ { i } \| _ { 2 } ^ { 2 } + \beta \| C \| _ { \mathrm { F r } } ^ { 2 } ,
$$  

with regularization parameter $\beta > 0$ . Thereby, the transformation from $z$ to the predicted state $x$ is also linearized for general observables. To account for the truncation error, EDMD for finite data, and the simplified LTI representation of the infinite dimensional Koopman model, Zhang et al. (2022) extends the lifted system by bounded uncertainties $w$ and $\nu$ .  

Assumption 7 (Zhang et al. (2022)). For (36), $w \in \mathcal { W }$ and $\nu \in \mathcal { V }$ with known bounded sets $\mathcal { W }$ and $\mathcal { V }$ .  

Under reasonable assumptions on the observables, Zhang et al. (2022) (Proposition 2) proves that the uncertainty sets $\mathcal { W }$ and $\mathcal { V }$ are bounded. Further, since the knowledge of $\mathcal { W }$ and $\mathcal { V }$ is non-trivial, Zhang et al. (2022) suggests to validate a choice of $\mathcal { W }$ and $\mathcal { V }$ using statistical learning theory.  

Under Assumption 7, the nonlinear dynamics is captured by  

$$
f ( x , u ) \in \{ C ( A \Psi ( x ) + B u + w ) + \nu : w \in \mathcal W , \nu \in \mathcal V \} ,
$$  

with $A , B$ , and $C$ from EDMD. The nonlinearity of this set membership by $\Psi ( x )$ can be circumvented by analysing the lifted system (36) with lifted state vector $z = \Psi ( x )$ .  

Since the error characterization of Assumption 7 does not vanish at the origin, this uncertainty description is not suitable for verifying dissipativity or a state-feedback design. Instead, Zhang et al. (2022) follows a robust tube-based MPC approach (Mayne et al., 2005). Thereby, Zhang et al. (2022) proves closed-loop robustness w.r.t. the estimation error and point-wise convergence (Theorem 3). Furthermore, an MPC scheme with nonconvex optimization is circumvented by the linear Koopman prediction model.  

In contrast to a linear MPC, Stra¨sser et al. (2023a) designs a state feedback from a lifted state model including a finitegain bounded estimation error. Since a lifting of an input-affine nonlinear system does not lead to an LTI system (Bevanda et al., 2021), Sinha et al. (2022) and Stra¨sser et al. (2023a) consider a discrete-time bilinear representation  

$$
z ( t + 1 ) = A z ( t ) + u ( t ) ( B _ { 0 } + B _ { 1 } z ( t ) )
$$  

of a finite-dimensional lifted system with scalar input $u ( t ) \in \mathbb { R }$ . Thus, a higher accuracy and better control performance can be achieved. Sinha et al. (2022) does not account for the error by estimating the Koopman operator. Contrary, Stra¨sser et al. (2023a) supposes a finite-gain bound for an additive estimation error during closed-loop operation with $u ( t ) = k ^ { T } z ( t )$ .  

Assumption 8 (Str¨asser et al. (2023a) (Assumption 2)). An additive estimation error $\epsilon ( z ) \ \in \ \mathbb { R } ^ { n _ { D } }$ satisfies a finite-gain bound $\begin{array} { r } { \| \epsilon ( z ) \| _ { 2 } \le L \| z \| _ { 2 } } \end{array}$ with known $L \geq 0$ .  

Stra¨sser et al. (2023a) proposes to estimate $L$ by first approximating the Lipschitz constant of the nonlinear dynamics from data. Together with the matrices $A , B _ { 0 } , B _ { 1 }$ from EDMD, this results in a Lipschitz constant of $\epsilon ( z )$ satisfying the finite-gain bound in Assumption 8. Alternatively, a validation procedure by Hoeffding’s inequality or learning a kernel approximation for $\epsilon ( z )$ to obtain a linear sector by Fiedler et al. (2021b) are conceivable. However, since the gain $L$ is required for the closed loop and the controller gain $k$ is undetermined at first, closed-loop data is not available. Therefore, the estimation of $L$ is non-trivial and might require an iteration between controller synthesis and estimation of $L$ .  

Under Assumption 8, the nonlinear dynamics of the closed loop $f ( x ) + g ( x ) k ^ { T } \Psi ( x )$ is contained in  

$$
\begin{array} { r l } & { \{ \Psi ^ { - 1 } ( A \Psi ( x ) + k ^ { T } \Psi ( x ) ( B _ { 0 } + B _ { 1 } \Psi ( x ) ) + \epsilon ( \Psi ( x ) ) ) : } \\ & { \qquad \quad \| \epsilon ( \Psi ( x ) ) \| _ { 2 } \leq L \| \Psi ( x ) \| _ { 2 } \} . } \end{array}
$$  

For the lifted state $z = \Psi ( x )$ , the nonlinearity of the set membership boils down to a bilinear system with finite-gain bounded uncertainty. Moreover, the inverse mapping $x = \Psi ^ { - 1 } ( z )$ might be a simple matrix multiplication for certain lifting, e.g., delay or monomial coordinates (Stra¨sser et al., 2023a). Thereby, a stabilizing linear feedback of the lifted states can be received by LMI robust control techniques for bilinear systems that also stabilizes the nonlinear system.  

Motivated by the bilinear model deduced from lifting techniques, we summarize in the following remark three data-driven control techniques for bilinear systems.  

Remark 1 (Data-driven control of bilinear systems). For bilinear systems with unknown system matrices, Yuan and Corte´s (2022) presents an extension of Willems’ fundamental lemma by interpreting the bilinearity as an independent input. Similar to De Persis and Tesi (2020), Bisoffi et al. (2020) presents a data-based closed-loop parametrization in order to design a state feedback by LMIs. Since the bilinearity is actually known and available for feedback, Str¨asser et al. (2023b) presents a gain-scheduling controller to achieve a better control performance than Stra¨sser et al. (2023a).  

Zhang et al. (2022) and Stra¨sser et al. (2023a) consider a closed-loop analysis in the lifted states without ensuring that the lifted states actually have a preimage in the original state space. By incorporating a projection of the lifted states back on the original space together with the error bounds from Nu¨ske et al. (2023), Bold et al. (2023) presents a nonlinear predictive controller with practical asymptotic stability guarantees. For that purpose, a similar error bound as in Assumption 8 is deduced from Nu¨ske et al. (2023) but in the original state space under the assumption of a finite and invariant dictionary of observables.  

In contrast to the Koopman operator, Carleman lifting (Carleman, 1932) provides by monomial observables a systematic approach to bound its estimation error from finite data. For instance, Amini et al. (2021) and Abudia et al. (2022) derive a guaranteed, but potentially conservative, error bound between trajectories of an autonomous nonlinear system and the data-driven inference of a truncated lifted linear system. Hence, further examinations on these error bounds are necessary for the application, e.g., for a linear MPC design (Hashemian and Armaou, 2019). Furthermore, Rotondo et al. (2022) investigates the connection of Carleman lifting and TP approximation but neglects the error regarding the vector field of the truncated Carleman lifting. Similarly, Bramburger et al. (2023) exploits a combination of Koopman lifting with polynomial observables and SOS optimization but also neglects the error due to finite data and truncation. However, due to the polynomial dictionary, an investigation of the estimation error might be possible.  

Related to the state lifting by the Koopman operator, a nonlinear system ${ \dot { x } } = f ( x ) + g ( x ) u$ can be polynomialized if the dynamics contain only certain nonlinearities. More specifically, the time derivatives of the nonlinear functions in $f$ and $g$ have to be written as terms of the same functions. See Table 2 in Str¨asser et al. (2021) for a collection of such functions. In this case, the nonlinear dynamics can be formulated as a finitedimensional polynomial system $\dot { z } ( t ) = A Z ( z ( t ) ) + B H ( z ( t ) ) u ( t )$ by introducing a lifted state $z$ together with some conservatism (Stra¨sser et al., 2021) (Remark 9). In a data-driven context, Stra¨sser et al. (2021) examines polynomialization of nonlinear systems with known function basis of $f$ and $g$ . Hence, the data-driven system analysis and controller design boils to the problem of polynomial systems with unknown coefficient matrices $A$ and $B$ as in Section 5.2.  

The Koopman operator constitutes a powerful tool to analyze general nonlinear system by methods from linear or bilinear control theory. While the operator is infinite-dimensional, the literature asks for finite-dimensional estimations retrieved from a finite set of data. Recent works take the error by truncation and simplified lifted model into account and handle it by robust control techniques. Thus, a system analysis and a controller design with rigorous guarantees and using SDPs are possible. But in fact, the characterization of this error is so far rather vague, and therefore potentially conservative. Concurrent, deriving insights into the error for arbitrary observables is non-trivial and still an open problem. Moreover, while the controller performance is optimized regarding the lifted states, the resulting performance of the underlying system might be unclear.  

# 9. Data-driven control by approximate nonlinearity cancellation and feedback linearization  

Approximate nonlinearity cancellation aims to find a feedback law that stabilizes the systems while reducing the influence of the nonlinearity of the closed-loop dynamics. Whereas the presented nonlinearity cancellation technique works in the original states, feedback linearization transforms a nonlinear system via a certain change of coordinates and a feedback law (Isidori, 1995). For flat systems, the transformed system dynamics becomes linear as the nonlinear internal dynamics vanishes. Systems of that kind emerges in practice, e.g., in robotics and in automatic flight control (Levine, 2009). Due to the feedback law in both paradigms, the dynamics is changed in order to obtain a closed-loop description suitable for linear control design techniques. In contrast, the previously presented approaches aim to obtain a suitable characterisation of the openloop dynamics itself instead of modifying it.  

We report the data-driven control literature exploiting SDPs within these control frameworks. We begin with the data-driven nonlinearity cancellation because this result will be required to obtain a linear system description via feedback linearization.  

# 9.1. Data-driven approximate nonlinearity cancellation  

In this section, we review exact and approximate nonlinearity cancellation for a data-driven controller design of nonlinear systems by SDPs. More specifically, De Persis et al. (2022) aims to stabilize and cancel the nonlinearity of the discrete-time nonlinear system  

$$
x ( t + 1 ) = f ( x ) + B u ,
$$  

with unknown drift $f : \mathbb { R } ^ { n _ { x } }  \mathbb { R } ^ { n _ { x } }$ and unknown input matrix $B \in \mathbb { R } ^ { n _ { x } \times n _ { u } }$ . To infer on the nonlinear function $f$ from data, the knowledge of a function basis is supposed.  

Assumption 9 (De Persis et al. (2022) (Assumption 1)). Let a continuous function $z \ : \ \mathbb { R } ^ { n _ { x } } \ \to \ \mathbb { R } ^ { n _ { z } }$ be known such that $f ( x ) = A z ( x )$ for some matrix $A \in \mathbb { R } ^ { n _ { x } \times n _ { z } }$ .  

A similar assumption is already introduced and clarified in Section 7.2 and Section 7.3. For that reason, a suitable basis $z$ might be available from first principles, while only the system parameters $A$ are unknown. Since one key idea will be to separate the linear and nonlinear dynamics, De Persis et al. (2022) writes $z$ without loss of generality as  

$$
z ( x ) = { \binom { x } { q ( x ) } } ,
$$  

where $q$ only contains nonlinear functions.  

After the stage is set, De Persis et al. (2022) extends De Persis and Tesi (2020) by determining a data-driven representation of the closed loop with system (37) and the nonlinear state feedback $u ( t ) = K z ( t )$ . To this end, the data $\{ x _ { i } , u _ { i } \} _ { i = 1 } ^ { S }$ from system (37) is collected into the matrices $U = \left[ u _ { 1 } \quad \cdots \quad u _ { S - 1 } \right] , X ^ { + } =$ $\begin{array} { r l } { \Big [ x _ { 2 } } & { \cdots \quad x _ { S } \Big ] , Z = \left[ \begin{array} { l l l } { x _ { 1 } } & { \cdots } & { \cdots } \\ { q ( x _ { 1 } ) } & { \cdots } & { q ( x _ { S - 1 } ) } \end{array} \right] . } \end{array}$ Then, the closed loop can be characterized by the following data-dependent matrices  

$$
\begin{array} { r l } { x ( t + 1 ) = \left[ A } & { B \right] \bigg [ \underset { K } { I } \bigg ] z ( x ) } \\ { = \left[ A } & { B \right] \bigg [ \underset { U } { Z } \bigg ] G z ( x ) = X ^ { + } G z ( x ) , } \end{array}
$$  

where the last equality follows from $X ^ { + } = A Z + B U$ . The second equality holds for a matrix $G$ satisfying  

$$
{ \Bigg [ } { I } { \Bigg ] } = { \Bigg [ } { Z } { \Bigg ] } G ,
$$  

as already shown in De Persis and Tesi (2020) and Section 5.3. Proceeding the idea of separating the linear and nonlinear terms, De Persis et al. (2022) (Lemma 1) derives the data-based closed-loop description $x ( t + 1 ) = L x + N q ( x )$ with $L = X ^ { + } G _ { 1 }$ , $N = X ^ { + } G _ { 2 }$ , $G = \left[ \bar { G } _ { 1 } \quad G _ { 2 } \right]$ .  

Given this description of the closed loop, it is globally asymptotically stabilized for a $G$ satisfying $X ^ { + } G _ { 2 } = 0$ and that renders $L = X ^ { + } G _ { 1 }$ to be Schur. Indeed, by cancelling the input matrix $X ^ { + } G _ { 2 }$ of the nonlinearity, only the linear system matrix $X ^ { + } G _ { 1 }$ needs to become stable. De Persis et al. (2022) (Theorem 1 and Theorem 3) formulates this problem as an SDP. Furthermore, De Persis et al. (2022) (Theorem 4) investigates the case when the nonlinearity $X ^ { + } G _ { 2 }$ can not be cancelled out exactly. Instead, its influence $\| X ^ { + } G _ { 2 } \| _ { \mathrm { F r } }$ is minimized. Therefore, the nonlinearity is only approximately cancelled and the origin is only asymptotically stable, if the linear part dominates the nonlinear, i.e.,  

$$
\operatorname* { l i m } _ { \| \boldsymbol { x } \| _ { 2 } \to 0 } \frac { \| \boldsymbol { q } ( \boldsymbol { x } ) \| _ { 2 } } { \| \boldsymbol { x } \| _ { 2 } } = 0 .
$$  

This procedure can also be adapted for noisy data and bounded neglected nonlinearities (De Persis et al., 2022)(Theorem 6 and 8). To this end, the controller again musts render the linear closed-loop dynamics stable. However, since the dynamics can not exactly be identified from data, a set of systems matrices has to be stabilized.  

While De Persis and Tesi (2020) neglects the nonlinearity and elaborates a linear feedback design, De Persis et al. (2022) achieves a more flexible nonlinear feedback law. Moreover, the effect of the nonlinearity is minimized to increase the region of attraction. However, since the stabilization criterion in De Persis and Tesi (2020) and De Persis et al. (2022) contains only the linear part of the dynamics, only an asymptotically stable equilibrium can be ensured without guarantees for the size of the region of attraction. Moreover, the refinement of the latter is unclear because the nonlinearity might actually be useful for stabilization. Thus, a cancellation might even decrease the region of attraction or might render the system non-robust regarding small disturbances (Freeman and Kokotovic´, 1996). Instead of cancelling the nonlinearity, it is bounded and incorporated into the controller synthesis in Martin et al. (2023a) to achieve performance criteria and global stability.  

To impose further guarantees, De Persis et al. (2022) proposes to analyze the region of attraction (Proposition 1) or robust invariant sets (Theorem 7) for the obtained closed loop.  

Nonetheless, here the problem arises that the closed-loop dynamics contains nonlinear terms, and thus estimating these sets calls for solving a nonconvex optimization problem. Furthermore, the complexity of the closed-loop parametrization (38) increases with the number of samples as in De Persis and Tesi (2020). Thus, a set membership for the uncertain system matrices $A$ and $B$ might be preferable. Finally, note that nonlinearity cancellation conceptually does not allow for analyzing the underlying system regarding, e.g., dissipativity.  

# 9.2. Data-driven feedback linearization  

Before studying the data-based case, we begin with a general recap of feedback linearization of flat single-input single-output discrete-time systems and refer to Monaco and Normand-Cyrot (1987) for the multiple-input multiple-output case. Consider the nonlinear system  

$$
\begin{array} { c } { { x ( t + 1 ) = f ( x ( t ) , u ( t ) ) , } } \\ { { y ( t ) = h ( x ( t ) ) , } } \end{array}
$$  

with smooth functions $f : \mathbb { R } ^ { n _ { x } } \times \mathbb { R } \to \mathbb { R } ^ { n _ { x } }$ and $h : \mathbb { R } ^ { n _ { x } }  \mathbb { R }$ . Further, we assume that system (39) satisfies  

$$
\begin{array} { r l } & { \displaystyle \frac { \partial } { \partial u } ( h \circ f _ { 0 } ^ { i } \circ f ( x , u ) ) = 0 , \quad \forall ( x , u ) \in \mathbb { R } ^ { n _ { x } } \times \mathbb { R } , 0 \leq i \leq n _ { x } - 2 , } \\ & { \displaystyle \frac { \partial } { \partial u } ( h \circ f _ { 0 } ^ { n _ { x } - 1 } \circ f ( x , u ) ) \neq 0 , \quad \forall ( x , u ) \in \mathbb { R } ^ { n _ { x } } \times \mathbb { R } , } \end{array}
$$  

with $f _ { 0 } ^ { i }$ denoting the $i$ times composition of $f ( x , 0 )$ . Therefore, system (39) has a well-defined relative degree $n _ { x }$ , and hence is called flat. Following Diwold et al. (2022), one can define the state transformation  

$$
\begin{array} { r } { z ( t ) = \Psi ( x ( t ) ) = \left[ \begin{array} { c } { h ( x ( t ) ) } \\ { h \circ f _ { 0 } ( x ( t ) ) } \\ { \vdots } \\ { h \circ f _ { 0 } ^ { n _ { x } - 1 } ( x ( t ) ) } \end{array} \right] = \left[ \begin{array} { c } { y ( t ) } \\ { y ( t + 1 ) } \\ { \vdots } \\ { y ( t + n _ { x } - 1 ) } \end{array} \right] , } \end{array}
$$  

which yields the transformed system dynamics of (39)  

$$
\begin{array} { r } { z ( t + 1 ) = \left[ \begin{array} { c } { z _ { 2 } ( t ) } \\ { \vdots } \\ { z _ { n _ { x } } ( t ) } \\ { h \circ f _ { 0 } ^ { n _ { x } - 1 } \circ f ( x ( t ) , u ( t ) ) } \end{array} \right] , } \\ { y ( t ) = z _ { 1 } ( t ) . } \end{array}
$$  

Thus, a flat system can be fully linearized by the state transformation $z = \Psi ( x )$ , containing only forward time-shifted outputs, and the input transformation $\begin{array} { r } { \nu ( \dot { t } ) = h \circ f _ { 0 } ^ { n _ { x } - 1 } \circ f ( x ( t ) , u ( \dot { t } ) ) = } \end{array}$ $\Psi _ { \nu } ( x ( t ) , u ( t ) ) = \Psi _ { \nu } ( \Psi ^ { - 1 } ( z ( t ) ) , u ( t ) ) = \Psi _ { \nu } ( { \tilde { Y ( t ) } } , u ( t ) )$ with $Y ( t ) =$ $\left| y ( t ) \quad \cdots \quad y ( t + n _ { x } - 1 ) \right|$ .  

After this introduction to feedback linearization, we can proceed to the data-driven control of flat systems. To this end, let the flat system (39) be unknown, and thus the input transformation $\Psi _ { \nu }$ as well. Note that the unknown system can be perturbed to check for flatness (Alsalti et al., 2023a). Then Alsalti et al. (2021) suggests to assume that $\Psi _ { \nu }$ admits a linear combination of known functions.  

Assumption 10 (Alsalti et al. (2021)). Suppose that the input transformation takes the form $\Psi _ { \nu } ( Y ( t ) , u ( t ) ) = a ^ { T } \tilde { \Psi } _ { \nu } ( Y ( t ) , u ( t ) )$ with known vector of functions $\tilde { \Psi } _ { \nu } : \mathbb { R } ^ { n _ { x } } \times \mathbb { R } \to \mathbb { R } ^ { n _ { \tilde { \Psi } } }$ and unknown coefficient vector $a \in \mathbb { R } ^ { n _ { \tilde { \Psi } } }$ .  

In general, finding a suitable choice of $\tilde { \Psi } _ { \nu }$ can be challenging, in particular for discrete-time systems. Indeed, the function composition $\Psi _ { \nu } ~ = ~ h \circ f _ { 0 } ^ { n _ { x } - 1 } \circ { \overset { \cdot } { f } } ( x , u )$ prevents the derivation of $\tilde { \Psi } _ { \nu }$ from a function basis of the system dynamics $f$ , which might be available from first principles. In contrast, this is possible for continuous-time systems as the function composition is replaced by Lie derivatives. For instance, consider the flat discrete-/continuous-time system  

$$
\begin{array} { r } { x _ { 1 } ( t + 1 ) | \dot { x } _ { 1 } ( t ) = \alpha _ { 1 } \sin ( x _ { 2 } ( t ) ) , \qquad } \\ { x _ { 2 } ( t + 1 ) | \dot { x } _ { 2 } ( t ) = \alpha _ { 2 } \cos ( x _ { 1 } ( t ) ) + u ( t ) , \qquad } \\ { y ( t ) = x _ { 1 } ( t ) , \qquad } \end{array}
$$  

with unknown coefficients $\alpha _ { 1 }$ and $\alpha _ { 2 }$ and basis functions $\sin ( x _ { 2 } ) , \cos ( x _ { 1 } )$ , and $u$ . For the discrete-time case, the input transformation corresponds to $\Psi _ { \nu } ( x , u ) = \alpha _ { 1 } \sin ( \alpha _ { 2 } \cos ( x _ { 1 } ) + u )$ . Hence, $\tilde { \Psi } _ { \nu } ( x , u ) \ = \ \sin ( \alpha _ { 2 } \cos ( x _ { 1 } ) + u )$ which is however unknown due to the unknown coefficient $\alpha _ { 2 }$ . Contrary, in continuous time, $\nu ( t ) = \ddot { y } ( t ) = \alpha _ { 1 } \alpha _ { 2 } \cos ( x _ { 1 } ) \cos ( x _ { 2 } ) + \alpha _ { 1 } \cos ( x _ { 2 } ) u$ with known basis functions $\cos ( x _ { 1 } ) \cos ( x _ { 2 } )$ and $\cos ( x _ { 2 } ) u$ .  

In case a function basis $\tilde { \Psi } _ { \nu }$ is not available and only the scalar product of $\tilde { \Psi } _ { \nu }$ is required, then Alsalti et al. (2021) proposes to consider an infinite number of basis functions and to compute the scalar product by kernel methods. However, this comes with the drawback that an infinitely long PE input sequence is required to span the whole input-output trajectories of the system. Alternatively, Alsalti et al. (2023a) (Assumption 5) relaxes Assumption 10 by incorporating an uniformly bounded uncertainty $\epsilon$  

$$
\Psi _ { \nu } ( Y ( t ) , u ( t ) ) = a ^ { T } \tilde { \Psi } _ { \nu } ( Y ( t ) , u ( t ) ) + \epsilon ( Y ( t ) , u ( t ) ) .
$$  

Thereby, $\tilde { \Psi } _ { \nu }$ does not necessarily have to span a function basis for $\Psi _ { \nu }$ .  

Under Assumption 10, the feedback linearization (40) of nonlinear system (39) yields  

$$
z ( t + 1 ) = \underbrace { \left[ \begin{array} { l l l l } { 0 } & { 1 } & { \cdots } & { 0 } \\ { \vdots } & { \ddots } & { \ddots } & { \vdots } \\ { \vdots } & & { \ddots } & { \ddots } \\ { 0 } & { \underbrace { \dots } _ { \begin{array} { l l l l } { 0 } & { \cdots } & { \cdots } & { 0 } \end{array} } } _ { = : D } \right] z ( t ) } _ { y ( t ) } + \left[ \begin{array} { l } { 0 } \\ { \vdots } \\ { 0 } \\ { a ^ { T } } \end{array} \right] \tilde { \Psi } _ { \nu } ( Y ( t ) , u ( t ) ) , \end{array}
$$  

Therefore, the behavior $\tilde { \Psi } _ { \nu }  y$ is linear with unknown input matrix $\left[ 0 \quad \cdots \quad 0 \quad a \right] ^ { T }$ . Thus, Alsalti et al. (2021) (Proposition 1) can apply Willems’ fundamental lemma for LTI systems here. Note that the PE condition is more difficult to be fulfilled for a larger function basis. Moreover, the PE condition includes input and output data instead of only input data as in the LTI case. Therefore, the PE condition can only be checked after an experiment is carried out. We refer to Alsalti et al. (2023b) (Theorem 5) for the design of inputs to guarantee PE of a sequence of monomial basis functions.  

By means of the extension of Willems’ fundamental lemma for flat systems, Alsalti et al. (2021) solves the data-driven simulation and output-matching control problem for feedback linearizable systems. Alsalti et al. (2023a) generalises these results for the relaxed version (41) of Assumption 10. Specifically, the effect of uniformly bounded uncertainty $\epsilon$ and output measurement noise on the data-driven simulation and outputmatching control problem is analyzed by providing output error bounds. Bounding this error together with the extended fundamental lemma can be leveraged for robust data-driven predictive control with rigorous stability guarantees (Alsalti et al., 2022, 2023c).  

While the feedback linearization leads to a linear behavior from the new input $\nu$ to $y$ , the system dynamics $u  y$ in (42) is nonetheless nonlinear. Therefore, the extended fundamental lemma results in nonlinear optimization problems for the data-driven simulation, output-matching control, and predictive control. Thus, solving these optimization problems might be difficult or computationally expensive, in particular, if a large prediction horizon or number of basis functions are considered. Furthermore, for data $\left\{ x _ { i } , u _ { i } \right\} _ { i = 1 } ^ { S }$ satisfying $x _ { i + 1 } = f ( x _ { i } , u _ { i } )$ and error (41), we can determine a set membership containing $f ( x , u )$  

$$
\begin{array} { r l } & { \left. \Psi ^ { - 1 } ( D \Psi ( x ) + \left[ 0 \right] ( \tilde { a } ^ { T } \tilde { \Psi } _ { \nu } ( x , u ) + \epsilon ( x , u ) ) ) : \| \epsilon ( x , u ) \| _ { 2 } \leq \epsilon ^ { * } , } \\ & { \left\| \Psi ( x _ { i + 1 } ) - D \Psi ( x _ { i } ) - \left[ 0 \right] \tilde { a } ^ { T } \tilde { \Psi } _ { \nu } ( x _ { i } , u _ { i } ) \right\| _ { 2 } \leq \epsilon ^ { * } , i = 1 , \ldots , S - 1 \right. . } \end{array}
$$  

Note that $\left\| \Psi ( x _ { i + 1 } ) - D \Psi ( x _ { i } ) - \left[ 0 \right] { \tilde { a } } ^ { T } \tilde { \Psi } _ { \nu } ( x _ { i } , u _ { i } ) \right\| _ { 2 } ~ \leq ~ \epsilon ^ { * } , i ~ =$ $1 , \ldots , S \ - \ 1$ , imply the set of all coefficients $\tilde { a }$ feasible with that data, and thus contains the true unknown coefficients $a$ . While the nonlinearity from $\Psi$ and $\Psi ^ { - 1 }$ can be circumvented by considering the set membership w.r.t. $z$ , the nonlinearity from $\tilde { \Psi } _ { \nu } ( x , u )$ remains.  

To circumvent a controller design by a nonlinear optimization problem, De Persis et al. (2022) (Assumption 6) restricts Assumption 10 to a linear input transformation concerning the input  

$$
\Psi _ { \nu } ( Y ( t ) , u ( t ) ) = a ^ { T } \tilde { \Psi } _ { \nu } ( Y ( t ) ) + b u ( t ) .
$$  

While this condition might only be possible for special cases, e.g., the polynomial system in De Persis et al. (2022) (Example 10), it is always satisfied for an input-affine continuous-time system with linear input matrix. For a purely linear system description, De Persis et al. (2022) (Corollary 2) requires in addition to (43) that the nonlinearity $a ^ { T } \tilde { \Psi } _ { \nu } ( Y ( t ) )$ can be exactly cancelled. The remaining data-driven inference of the unknowns $a$ and $b$ and the nonlinearity cancellation using SDPs corresponds to the procedure described in Section 9.1.  

The main advantage of a feedback linearization is that a flat system can exactly be linearized in some coordinates. Thereby, for instance, global asymptotic stability can be ensured. On the other hand, the approximate nonlinearity cancellation from Section 9.1 stays in the original coordinates. Thus, it allows a controller design and closed-loop analysis in the original coordinates. Moreover, the latter does not require flatness of the system.  

Under the more restrictive assumption that complete dictionaries for the state transformation $\Psi$ and the input transformation $\Psi _ { \nu }$ are available, De Persis et al. (2023) learns both transformations from data. To this end, the null space of a data-dependent matrix has to be computed, which is even for large matrices possible. Based on the obtained state and input transformation, an explicit control law to locally stabilize the nonlinear system around an equilibrium can be deduced.  

In summary, data-driven feedback linearization requires knowledge of a function basis for the input transformation and leads to a nonlinear system description. Hence, it does not allow for a system analysis or state-feedback design by SDPs. A linear description of the system dynamics can only be obtained together with a nonlinearity cancellation. Contrary, Koopman linearization does not require an input transformation. Thus, a (bi-)linear characterization of the system itself is deduced, which is suitable for a system analysis by SDPs. We refer to Kaiser et al. (2021) for a more thorough discussion of advantages of the Koopman paradigm compared to feedback linearization. Moreover, the question rises whether the overhead of SDPs is necessary as practicable and rigorous learning-based approaches based on feedback linearization already exist, e.g., see Helwa et al. (2019) and Lederer et al. (2019).  

# 10. Discussion  

After the presentation of the various data-based system representations, we consider in this section a more general and embraced discussion. Specifically, we discuss the derivation of the system representations and the required prior model knowledge. Moreover, we compare the implementability of the presented approaches with similar data-driven methods from the literature. We review how the different methods incorporate noisy data. Finally, we give some general comments on the advantages of data-based discrete- and continuous-time system representations. Table 2 partially summarizes the discussion.  

# 10.1. Derivation of data-driven system representations  

We can identify a common procedure for the derivation of the presented data-driven system representations. Using techniques from model-based control theory, the nonlinear dynamics $f ( x , u )$ is first embedded into a set of surrogate systems $\Sigma _ { \mathrm { s u r } }$ , which are suitable for a system analysis or a controller synthesis via SDP. However, for unknown nonlinear systems, these surrogate systems include unknown coefficients. Therefore, $\Sigma _ { \mathrm { s u r } }$ is embedded into the set of systems $\Sigma _ { \mathrm { s u r - d d } }$ with data-driven inference on the unknown coefficients. For the polynomial interpolation approach, $\Sigma _ { \mathrm { s u r } }$ corresponds to the polynomial sector (4)  

![](images/1e20e9426059aaaa03e2e2033a6b17f57263545e09d7d606743dadf92b94f808.jpg)  
Figure 5: Illustration for the derivation of data-driven system representations for nonlinear systems suitable for system analysis and control by SDPs. Right figure for GP/kernel regression and left figure for the remaining approaches.  

from TPs and $\Sigma _ { \mathrm { s u r - d d } }$ corresponds to (6) with the inference on the TP from data. Analogously, for data-driven LPV embedding, $\Sigma _ { \mathrm { s u r } }$ is the standard LPV embedding $\{ A ( p ) x + B ( p ) u : p \in \mathbb { P } \}$ such that $\Sigma _ { \mathrm { s u r - d d } }$ corresponds to (32). Indeed, we can proceed this for all set membership introduced here except for the ones obtained by GP and kernel ridge regression. There first a datadriven set membership $\Sigma _ { \mathrm { d d } }$ including nonlinear functions is obtained, e.g., (18). Then a set of linear surrogate systems $\Sigma _ { \mathrm { d d - s u r } }$ , e.g., from (20) is obtained. We illustrate both procedures in Figure 5.  

# 10.2. Data-driven system analysis, predictive control, and state-feedback design  

The presented system representations can be applied for data-driven system analysis and control. We provide a brief summary in Table 2. Note that the extension of the state feedback with input-state measurements to output feedback with input-output data is possible for a discrete-time setup by considering the extended state of past outputs (De Persis and Tesi, 2020; Berberich et al., 2022a; Koch et al., 2022). However, the extended state might lead to conservative requirements on the system and data.  

# 10.3. Prior system knowledge  

All presented system representations require some prior system knowledge to infer guarantees on the dynamics from data. We divide these into two categories.  

The first type of assumption asks for an upper bound on a Lipschitz constant, higher order partial derivatives, or the complexity of the dynamics. While these assumptions are easier to satisfy than the second type, they only allow an accurate inference on the dynamics in the neighbourhood of samples. Indeed, this information typically implies only a correlation of the nonlinear behaviour at a data point and its neighbourhood. Due to the multitude of local models from polynomial approximation or the non-parametric model from kernel regression, these approaches are computational more demanding. This drawback might be circumvented in an online control scheme, where only the local behaviour of the system is relevant at one time step.  

Table 2: Properties of the presented data-driven system representations. Abbreviations: system analysis (SA), predictive control (PC), state feedback (SF), Willems’ fundamental lemma (WFL), Data-driven closed-loop characterization (DDCLC).   


<html><body><table><tr><td>System representation</td><td>Data-driven method type</td><td>Application</td><td>Prior knowledge</td><td>Noisy data</td></tr><tr><td>Polynomial interpolation Polynomial subclass</td><td>Set membership WFL, DDCLC, set membership</td><td>SA,SF SA,SF</td><td>First type Second type</td><td>Yes Partially</td></tr><tr><td>Data-based closed-loop description Linear sector from GP</td><td>DDCLC Kernel</td><td>SF SA,SF</td><td>First type First type</td><td>Yes Yes</td></tr><tr><td>Linearized kernel</td><td>Kernel</td><td>SA,SF</td><td>First type</td><td>Yes</td></tr><tr><td>Polynomial kernel</td><td>Kernel</td><td>SA,SF</td><td>First type</td><td>Yes</td></tr><tr><td>LPV system</td><td>WFL,DDCLC,set membership</td><td>SA,PC,SF</td><td>Second type</td><td>Partially</td></tr><tr><td>LPV embedding</td><td>WFL,DDCLC, set membership</td><td>SA,PC,SF</td><td>Second type</td><td>Partially</td></tr><tr><td>Extended linearization</td><td>Set membership</td><td>PC</td><td>Second type</td><td>Yes</td></tr><tr><td>Koopman</td><td>EDMD</td><td>PC,SF</td><td>First type</td><td></td></tr><tr><td>Nonlinearity cancellation</td><td>DDCLC</td><td>SF</td><td></td><td>Partially</td></tr><tr><td>Flat system</td><td>WFL</td><td>PC</td><td>Second type Second type</td><td>Yes Partially</td></tr></table></body></html>  

The second type of assumptions calls for a function basis that captures the nonlinearity of the dynamics, the scheduling parameter, a state transformation, etc. Thereby, these assumptions reduce the problem to unknown coefficients. We saw inferences on these coefficients by a set-membership procedure or Willem’s fundamental lemma. Due to the prior information on the actual nonlinearity, we will observe in Section 10.4 that the number of samples are lower than for the approaches based on the first type of assumption and some machine learning approximation methods, e.g., using neural networks.  

# 10.4. Implementability  

For the discussion of implementability of the presented approaches, we rely on the examples provided in the reported works. We first observe that numerical examples of a nonlinear system with two states are mostly considered. This is in line with the system complexity of examples of other datadriven control approaches with comparable focus on theoretical guarantees, e.g., backstepping for GPs (Capone et al., 2022), estimation of the region of attraction from GPs (Berkenkamp et al., 2016), control certificate functions based on Lipschitz estimation (Taylor et al., 2021), safe reinforcement learning (Berkenkamp et al., 2017), neural Lyapunov function (Min et al., 2023), and learning deep neural networks for Koopman models (Tiwari et al., 2023). These works study the same inverted pendulum example as in Martin et al. (2023a), Verhoek et al. (2022b), Devonport et al. (2020), De Persis et al. (2022), and Zhang et al. (2022).  

For the inference on a Koopman model, Zhang et al. (2022) and Stra¨sser et al. (2023a) require $5 \cdot 1 0 ^ { 4 }$ samples for the inverted pendulum with 5 lifted states and 2000 for a Van der Pol oscillator with 32 lifted states, respectively. For learning a neural Lyapunov function or a deep neural network for a Koopman model, Min et al. (2023) and Tiwari et al. (2023) call for even $1 0 ^ { 5 }$ and $1 . 6 \cdot 1 0 ^ { 6 }$ samples, respectively. Contrary, Martin et al. (2023a), Verhoek et al. (2022b), Devonport et al. (2020),  

De Persis et al. (2022), and Zhang et al. (2022) require only between 10 and 100 samples from the inverted pendulum. As expected, approaches with a priori known nonlinear dictionary call for less data. The computation time to solve the resulting SDPs are reported in Martin et al. (2023a) with 8 s, Devonport et al. (2020) with 5 minutes, and Stra¨sser et al. (2023a) with less than one second.  

This brief comparison shows that the presented data-driven control methods perform in numerical examples comparable with the existing literature, while providing additional advantages as discussed in the introduction. While Martin and Allgo¨wer (2023b), Verhoek et al. (2022b), and Berberich et al. (2022b) present initial applications on experimental examples, a broader application of the presented system representations for real data and a more detailed comparison using benchmark examples should be part of future research.  

# 10.5. Noisy data  

As summarized in Table 2, except for the fundamental lemma, most presented system representations provide guarantees though noise-corrupted data. The noise is mostly characterized by deterministic bounds as commonly supposed in datadriven control (van Waarde et al., 2022), data-driven system analysis (Koch et al., 2022), set-membership identification (Novara et al., 2013), adaptive control (Narendra and Annaswamy, 1986), and robust model predictive control (Mayne et al., 2005). However, such a noise description might be conservative if the noise is, e.g., Gaussian distributed as often assumed in system identification. Nevertheless, one can obtain for the presented set memberships, which are linear in the unknown parameters, analogous results with probabilistic guarantees for Gaussian distributed noise following Umenberger et al. (2019) and Martin et al. (2023a).  

Furthermore, an additive measurement noise $d _ { \mathrm { m e a s } }$ on the true states $x _ { \mathrm { { t r u e } } }$ , i.e., $x _ { \mathrm { { m e a s } } } = x _ { \mathrm { { t r u e } } } + d _ { \mathrm { { m e a s } } }$ , yields a more challenging errors-in-variables problem than the presented simplified noise models. To refine these models, one could  

extend the SOS approach for LTI systems from Miller et al.   
(2022).  

# 10.6. Discrete- and continuous-time models from data  

Throughout the presentation of the different data-based methods, we have seen continuous-time as well as discrete-time setups. While the approaches from Section 5, 6, 7.1 (ii) and (iii), 8, and Section 9.1 can be considered for both setups, the question rises what are the advantages compared to each other?  

The main advantage of a discrete-time system representation is that only measurements of state or output trajectories are required instead of their time derivatives in addition. The latter can usually only be obtained under weak noise and fast sampling, which allows for signal smoothing with subsequent approximation of the time derivatives by finite differences.  

Advantages of continuous-time system representations are that the learned parameters have a physical meaning as they do not depend on the sampling interval. Moreover, non-uniformly sampled data can be handled. Furthermore, the choice of the sampling interval is less critical than in discrete time. Indeed, if the sampling interval is too low compared to the system dynamics, then the eigenvalues of the discrete-time model are close to the unit circle leading to inaccurate stability inferences. We refer for more details to Garnier and Young (2014). Lastly, we mention that, e.g., the condition for Lyapunov stability is always linear w.r.t. the dynamics in continuous time while quadratic only for quadratic Lyapunov functions in discrete time. At the same time, transferring these conditions into an SDP by LMI robust control techniques is easier if these conditions are linear or quadratic regarding the nonlinear dynamics.  

# 10.7. A new paradigm of data-driven control methods?  

According to Definition 4 for data-driven control in the survey of Hou and Wang (2013), the approaches presented here would not be classified as data-driven. Indeed, the definition requires the controller design to be based on input-output data and does not allow for exploiting any model information. Moreover, instead of a direct method from data to control input, here first a data-based representation of the system is obtained, which is then explicitly included in the controller synthesis by SDPs. Furthermore, in view of Hou and Wang (2013), data-driven control methods are applicable independent of the class of systems. Thereby, the paradigm of data-driven control has changed over the last decade to a much broader collection of control techniques.  

# 11. Conclusion  

In this survey, we provided an overview on data-driven control approaches for nonlinear systems. In particular, the focus lay on data-based system representations, which are tailored for verifying system properties and designing controllers by SDPs.  

Thereby, these methods strive to establish a framework for nonlinear data-driven system analysis and control rather than providing specific control schemes. More specifically, we discussed data-driven control by polynomial approximation, GP and kernel regression, LPV embedding, state lifting, and nonlinearity cancellation and feedback linearization.  

Except for GP and kernel regression, these data-driven system representations are inspired by the model-based control literature. There the same techniques are leveraged to derive a verification of system properties and a controller synthesis by SDPs despite nonlinear system dynamics. Since the goal of these control methods is to derive a linear-like representation, data-driven techniques for LTI, bilinear, LPV, and polynomial systems are still relevant in the nonlinear case. Moreover, most of the data-based system characterizations for nonlinear systems that we have presented are combined with LMIbased robust techniques to achieve rigorous guarantees. In contrast, many system representations from system identification and machine learning are tailored to provide a precise surrogate model of the underlying system, and thus aim to approximate its dynamics as precise as possible. However, this typically leads to complex surrogate models preventing a convex system analysis and controller synthesis.  

Guarantees for data-driven inference on nonlinear system regardless of the framework require a priori insights into the dynamics. Hence, the performance of the data-driven approaches not only rely on the informativity of the data but also on the accuracy of the prior information. This is an additional challenge compared to the LTI case, where this kind of assumptions is not required.  

To conclude this survey, we provide further open challenges and questions beside the ones mentioned in the individual sections: (i) While the characterization of errors for a polynomial approximation is well-established, the proposed error characterizations, e.g., for the estimation of the Koopman operator, are tailored for control, and thus might be conservative. (ii) How to justify assumptions with prior insights in a data-based setup? (iii) Input-output data are investigated mainly using the extended state (Berberich et al., 2022a) resulting in restrictive assumptions on the data. Moreover, Montenbruck and Allgo¨wer (2016) and Martin and Allg¨ower (2020) consider the inputoutput system behaviour directly by its input-output mapping. However, this requires a large number of measured trajectories. (iv) Closing the gap between representations from a control and a data perspective. While the former is tailored for system analysis and control, the latter for explaining the data and providing a precise surrogate model. However, we search rather for a data-motivated representation suitable for controller design. (v) For a comprising comparison of data-driven control schemes, benchmark systems and data would be required. (vi) The extension of the data-informativity framework (van Waarde et al., 2023) to nonlinear systems is missing, i.e., when is the data informative to infer observability, controllability, stabilizability, etc., for a nonlinear system.  

# References  

Abudia, M., Rosenfeld, J.A., and Kamalapurkar, R. (2022). Carleman Lifting for Nonlinear System Identification with Guaranteed Error Bounds. arXiv preprint arXiv:2205.15009.   
Alsalti, M., Berberich, J., Lopez, V.G., Allg ¨ower, F., and Mu¨ ller, M.A. (2021). Data-Based System Analysis and Control of Flat Nonlinear Systems. In Proc. 60th Conf. Decision and Control (CDC), pp. 1484-1489.   
Alsalti, M., Lopez, V.G., Berberich, J., Allg ¨ower, F., and Mu¨ ller, M.A. (2022). Practical exponential stability of a robust data-driven nonlinear predictive control scheme. arXiv preprint arXiv:2204.01150.   
Alsalti, M., Lopez, V.G., Berberich, J., Allgo¨ wer, F., and M ¨uller, M.A. (2023a). Data-based Control of Feedback Linearizable Systems. IEEE Trans. Automat. Control, doi: 10.1109/TAC.2023.3249289.   
Alsalti, M., Lopez, V.G., and M¨uller, M.A. (2023b). On the design of persistently exciting inputs for data-driven control of linear and nonlinear systems. arXiv preprint arXiv:2303.08707.   
Alsalti, M., Lopez, V.G., Berberich, J., Allgo¨ wer, F., and M ¨uller, M.A. (2023c). Data-driven nonlinear predictive control for feedback linearizable systems. In Proc. 22nd IFAC World Congress, arXiv preprint, arXiv:2211.06339.   
Amini, A., Sun, Q., and Motee, N. (2021). Error Bounds for Carleman Linearization of General Nonlinear Systems. In Proc. Conf. Control and its Applications, pp. 1-8.   
Apostol, T.M. (1974). Mathematical Analysis. 2nd Edition, Addison-Wesley, Boston, pp. 492.   
Astolfi, A. (2014). Nonlinear Adaptive Control. Encyclopedia of Systems and Control. Springer, London.   
Åstr¨om, K.J. and Wittenmark, B. (1989). Adaptive Control (2nd ed.). AddisonWesley.   
Bachnas, A.A., T´oth, R., Mesbah, A., and Ludlage, J.H.A. (2014). A review on data-driven linear parameter-varying modeling approaches: A high-purity distillation column case study. Journal of Process Control, 24(4):272-285.   
Berberich, J. and Allg¨ower, F. (2020). A trajectory-based framework for datadriven system analysis and control. In Proc. European Control Conf. (ECC), pp. 1365–1370.   
Berberich, J., Ko¨ hler, J., M¨uller, M.A., and Allgo¨ wer, F. (2021). Data-driven model predictive control with stability and robustness guarantees. IEEE Trans. Automat. Control, 66(4):1702-1717.   
Berberich, J., Scherer, C.W., and Allgo¨wer, F. (2022a). Combining Prior Knowledge and Data for Robust Controller Design. IEEE Trans. Automat. Control, 68(8):4618-4633.   
Berberich, J., Ko¨ hler, J., Mu¨ ller, M.A., and Allgo¨ wer, F. (2022b). Linear Tracking MPC for Nonlinear Systems—Part II: The Data-Driven Case. IEEE Trans. Automat. Control, 67(9):4406-4421.   
Berkenkamp, F. and Schoellig, A.P. (2015). Safe and Robust Learning Control with Gaussian Processes. In Proc. European Control Conf. (ECC), pp. 2496–2501.   
Berkenkamp, F., Moriconi, R., Schoellig, A.P., and Krause, A. (2016). Safe Learning of Regions of Attraction for Uncertain, Nonlinear Systems with Gaussian Processes. In Proc. 55th Conf. Decision and Control (CDC), pp. 4661-4666.   
Berkenkamp, F., Turchetta, M., Schoellig, A.P., and Krause, A. (2017). Safe Model-Based Reinforcement Learning with Stability Guarantees. In Proc. Advances in Neural Information Processing Systems, vol. 30.   
Bevanda, P., Sosnowski, S., and Hirche, S. (2021). Koopman operator dynamical models: Learning, analysis and control. Annual Reviews in Control, vol. 52, pp. 197-212.   
Bishop, C.M. (2006). Pattern Recognition and Machine Learning. Springer, New York.   
Bisoffi, A., De Persis, C., and Tesi, P. (2020). Data-based stabilization of unknown bilinear systems with guaranteed basin of attraction. Systems & Control Letters, vol. 145, pp. 104788.   
Bisoffi, A., De Persis, C., and Tesi, P. (2022). Data-driven control via Petersen’s lemma. Automatica, vol. 145, pp. 110537.   
Bold, L., Gr¨une, L., Schaller, M., and Worthmann, K. (2023). Practical asymptotic stability of data-driven model predictive control using extended DMD. arXiv preprint arXiv:2308.00296.   
Bradtke, S.J. (1992). Reinforcement learning applied to linear quadratic regulation. In Proc. Advances in Neural Information Processing Systems, vol.   
Bramburger, J.J., Dahdah, S., and Forbes, J:R. (2023). Synthesizing Conro print arXiv:2307.01089.   
Bruder, D., Remy, C.D., and Vasudevan, R. (2019). Nonlinear system identification of soft robot dynamics using Koopman operator theory. In Proc. Int. Conf. on Robotics and Automation (ICRA), pp. 6244–6250.   
Brunton, S.L., Brunton, B.W., Proctor, J.L., and Kutz, J.N. (2016). Koopman Invariant Subspaces and Finite Linear Representations of Nonlinear Dynamical Systems for Control. PloS one, 11(2): e0150171.   
Calliess, J.P. (2014). Conservative decision-making and inference in uncertain dynamical systems. PhD thesis, University of Oxford.   
Campi, M.C., Lecchini, A., and Savaresi, S.M. (2002). Virtual reference feedback tuning: a direct method for the design of feedback controllers. Automatica, 38(8):1337-1346.   
Campi, M.C., Garatti, S., and Prandini, M. (2009). The scenario approach for systems and control design. Annual Reviews in Control, 33(2):149–157.   
Capone, A., Lederer, A., and Hirche, S. (2022). Gaussian Process Uniform Error Bounds with Unknown Hyperparameters for Safety-Critical Applications. In Proc. Conf. Machine Learning.   
Carleman, T. (1932). Application de la the´orie des ´equations int´egrales lin´eaires aux syst´emes d’e´quations diff´erentielles non lin´eaires. Acta Mathematica, vol. 59, pp. 63–87.   
Caverly, R.J. and Forbes, J.R. (2019). LMI Properties and Applications in Systems, Stability, and Control Theory. arXiv preprint arXiv:1903.08599.   
Cetinkaya, A., and Kishida, M. (2021). Nonlinear Data-Driven Control for Stabilizing Periodic Orbits. In Proc. 60th Conf. Decision and Control (CDC), pp. 4326-4331.   
Cheah, S.K., Bhattacharjee, D., Hemati, M.S., and Caverly, R.J. (2023). Robust Local Stabilization of Nonlinear Systems With Controller-Dependent Norm Bounds: A Convex Approach With Input-Output Sampling. IEEE Control Systems Lett., vol. 7, pp. 931-936.   
Cheng, Y., Sznaier, M., and Lagoa, C. (2015). Robust Superstabilizing Controller Design from Open-Loop Experimental. In Proc. IFAC Symposium on Sys. Id., 48(28):1337–1342.   
Chernyshenko, S.I., Goulart, P., Huang, D., and Papachristodoulou, A. (2014). Polynomial sum of squares in fluid dynamics: a review with a look ahead. Phil. Trans. R. Soc. A., 372:20130350.   
Chesi, G., Garulli, A., Tesi, A., and Vicino, A. (2009). Homogeneous Polynomial Forms for Robustness Analysis of Uncertain Systems. Springer, London.   
Chowdhury, S.R. and Gopalan, A. (2017). On Kernelized Multi-armed Bandits. In Proc. Conf. Machine Learning.   
C¸ imen, T. (2010). Systematic and effective design of nonlinear feedback controllers via the state-dependent Riccati equation (SDRE) method. Annual Reviews in Control, 34(1):32–51.   
Coulson, J., Lygeros, J., and Do¨rfler, F. (2019). Data-enabled predictive control: In the shallows of the DeePC. In Proc. European Control Conf. (ECC), pp. 307–312.   
Dai, T. and Sznaier, M. (2021a). Nonlinear Data-Driven Control via StateDependent Representations. In Proc. 60th Conf. Decision and Control (CDC), pp. 5765–5770.   
Dai, T. and Sznaier, M. (2021b). A Semi-Algebraic Optimization Approach to Data-Driven Control of Continuous-Time Nonlinear Systems. IEEE Control Systems Lett., 5(2):487-492.   
De Persis, C. and Tesi, P. (2020). Formulas for Data-Driven Control: Stabilization, Optimality and Robustness. IEEE Trans. Automat. Control, 65(3):909–924.   
De Persis, C. and Tesi, P. (2021). Designing Experiments for Data-Driven Control of Nonlinear Systems. In Proc. Symposium on Mathematical Theory of Networks and Systems, 54(9):285–290.   
De Persis, C., Rotulo, M., and Tesi, P. (2022). Learning Controllers from Data via Approximate Nonlinearity Cancellation. IEEE Trans. Automat. Control, 68(10):6082-6097.   
De Persis, C., Gadginmath, D., Pasqualetti, F., and Tesi, P. (2023). DataDriven Feedback Linearization with Complete Dictionaries. arXiv preprint arXiv:2308.11229.   
Devonport, A., Yin, H., and Arcak, M. (2020). Bayesian Safe Learning and Control with Sum-of-Squares Analysis and Polynomial Kernels. In Proc. 59th Conf. Decision and Control (CDC), pp. 3159-3165.   
Diwold, J., Kolar, B., and Scho¨berl, M. (2022). A Trajectory-Based Approach to Discrete-Time Flatness. IEEE Control Systems Lett., vol. 6, pp. 289-294.   
D¨orfler, F., Tesi, P., and De Persis, C. (2022). On the Role of Regularization in Direct Data-Driven LQR Control. In Proc. 61st Conf. Decision and Control (CDC), pp. 1091-1098.   
Favoreel, W., De Moor, B., Van Overschee, P., and Gevers, M. (1999). Modelfree subspace-based LQG-design. In Proc. American Control Conf. (ACC), pp. 3372–3376.   
Fiedler, C., Scherer, C.W., and Trimpe, S. (2021a). Practical and Rigorous Uncertainty Bounds for Gaussian Process Regression. In Proc. AAAI Conf. Artificial Intelligence, 35(8):7439-7447.   
Fiedler, C., Scherer, C.W., and Trimpe, S. (2021b). Learning-enhanced robust controller synthesis with rigorous statistical and control-theoretic guarantees. In Proc. 60th Conf. Decision and Control (CDC), pp. 5122-5129.   
Fogel, E. (1979). System Identification via Membership Set Constraints with Energy Constrained Noise. IEEE Trans. Automat. Control, 24(5):752-758.   
Formentin, S. and Savaresi, S.M. (2011). Virtual reference feedback tuning for linear parameter-varying systems. In Proc. 18th IFAC World Congress, pp. 10219–10224.   
Forni, F., Sepulchre, R., and van der Schaft, A.J. (2013). On differential passivity of physical systems. In Proc. 52nd Conf. Decision and Control (CDC), pp. 6580-6585.   
Freeman, R.A. and Kokotovi´c, P. (1996). Robust Nonlinear Control Design. Birkh¨auser, Boston.   
Garnier, H. and Young, P.C. (2014). The advantages of directly identifying continuous-time transfer function models in practical applications. International Journal of Control, 87(7):1319–1338.   
Guo, M., De Persis, C., and Tesi, P. (2022a). Data-Driven Stabilization of Nonlinear Polynomial Systems With Noisy Data. IEEE Trans. Automat. Control, 67(8):4210-4217.   
Guo, M., De Persis, C., and Tesi, P. (2022b). Data-driven stabilizer design and closed-loop analysis of general nonlinear systems via Taylor’s expansion. arXiv preprint arXiv:2209.01071.   
Hashemian, N. and Armaou, A. (2019). Feedback control design using model predictive control formulation and Carleman approximation method. AIChE J. 65(9): e16666.   
Helwa, M.K., Heins, A., and Schoellig, A.P. (2019). Provably Robust LearningBased Approach for High-Accuracy Tracking Control of Lagrangian Systems. IEEE Robotics and Automation Letters, 4(2):1587-1594.   
Hewing, L., Wabersich, K.P., Menner, M., and Zeilinger, M.N. (2020). Learning-Based Model Predictive Control: Toward Safe Learning in Control. Annual Review of Control, Robotics, and Autonomous Systems, vol. 3, pp. 269-296.   
Hilhorst, G., Lambrechts, E., and Pipeleers, G. (2016). Control of linear parameter-varying systems using B-splines. In Proc. 55th Conf. Decision and Control (CDC), pp. 3246-3251.   
Hjalmarsson, H., Gevers, M., Gunnarsson, S., and Lequin, O. (1998). Iterative feedback tuning: theory and applications. IEEE Control Systems Magazine, 18(4):26-41   
Hou, Z.S. and Wang, Z. (2013). From model-based control to data-driven control: Survey, classification and perspective. Information Sciences, vol. 235, pp. 3-35.   
Hu, Z., De Persis, C., and Tesi, P. (2023). Learning controllers from data via kernel-based interpolation. arXiv preprint arXiv:2304.09577.   
Isidori, A. (1995). Nonlinear Control Systems (3rd ed.). Springer, London.   
Jidling, C., Wahlstr¨om, N., Wills, A., and Scho¨n, T.B. (2017). Linearly constrained gaussian processes. In Proc. Advances in Neural Information Processing Systems, vol. 30.   
Kaiser, E., Kutz, J.N., and Brunton, S.L. (2021). Data-driven discovery of Koopman eigenfunctions for control. Mach. Learn.: Sci. Technol., 2(3): 035023.   
Kamb, M., Kaiser, E., Brunton, S.L., and Kutz, L.N. (2020). Time-Delay Observables for Koopman: Theory and Applications. SIAM Journal on Applied Dynamical Systems, 19(2):886-917.   
Kanagawa, M., Hennig, P., Sejdinovic, D., and Sriperumbudur, B.K. (2018). Gaussian Processes and Kernel Methods: A Review on Connections and Equivalences. arXiv preprint arXiv:1807.02582.   
Khalil, H.K.(2002). Nonlinear Systems (3rd ed.). Prentice Hall.   
Koch, A., Berberich, J., Ko¨ hler, J., and Allgo¨ wer, F. (2021). Determining optimal input-output properties: A data-driven approach. Automatica, vol. 134, pp. 109906.   
Koch, A., Berberich, J., and Allgo¨wer, F. (2022). Provably Robust Verification of Dissipativity Properties from Data. IEEE Trans. Automat. Control, 67(8):4248–4255. Koelewijn, P.J.W., , and Weiland, (2020). Pitfalls of Guaranteeing Asymptotic Stability in LPV Control of Nonlinear Systems. In Proc. European Control Conf. (ECC), pp. 1573–1578.   
Koopman, B.O. (1931). Hamiltonian systems and transformation in Hilbert space. In Proc. National Academy of Sciences, 17(5):315-318.   
Korda, M. and Mezi´c, I. (2018a). Linear predictors for nonlinear dynamical systems: Koopman operator meets model predictive control. Automatica, vol. 93, pp. 149–160.   
Korda, M. and Mezi´c, I. (2018b). On convergence of extended dynamic mode decomposition to the Koopman operator. J. of Nonlinear Science, vol. 28, pp. 687–710.   
Lasserre, J.B. (2000). Optimisation globale et th´eorie des moments. C.R. Acad. Sci. Paris, S´er I, 331(11):929–934.   
Lavaei, A., Esfahani, P.M., and Zamani, M. (2022). Data-Driven Stability Verification of Homogeneous Nonlinear Systems with Unknown Dynamics. In Proc. 61st Conf. Decision and Control (CDC), pp. 7296-7301.   
Lederer, A., Umlauf J., and Hirche, S. (2019). Uniform Error Bounds for Gaussian Process Regression with Application to Safe Control. In Proc. Advances in Neural Information Processing Systems.   
Levine, J. (2009). Analysis and Control of Nonlinear Systems: A FlatnessBased Approach. Springer, Berlin Heidelberg.   
Ljung, L. (1999). System Identification: Theory for the User (2nd ed.). Prentice Hall information and system sciences series. Prentice Hall PTR.   
Luppi, A., Bisoffi, A., De Persis, C., and Tesi, P. (2021). Data-driven design of safe control for polynomial systems. arXiv preprint arXiv:2112.12664.   
Luppi, A., De Persis, C., and Tesi, P. (2022). On data-driven stabilization of systems with nonlinearities satisfying quadratic constraints. Systems & Control Lett., vol. 163, pp. 105206.   
Lusch, B., Kutz, J.N., and Brunton, S.L. (2018). Deep learning for universal linear embeddings of nonlinear dynamics. Nature Communications, 9: 4950.   
Maddalena, E.T., Scharnhorst, P., and Jones, C.N. (2021). Deterministic error bounds for kernel-based learning techniques under bounded noise. Automatica, vol. 134, pp. 109896.   
Majumdar, A., Ahmadi, A.A., and Tedrake, R. (2013). Control design along trajectories with sums of squares programming. In Proc. IEEE Conf. Robotics and Automation, pp. 4054-4061.   
Maupong, T.M., Mayo-Maldonado, J.C., and Rapisarda, P. (2017). On Lyapunov functions and data-driven dissipativity. In Proc. 20th IFAC World Congress, pp. 7783-7788.   
Mauroy, A., Mezic´, I., and Moehlis, J. (2013). Isostables, isochrons, and Koopman spectrum for the action-angle representation of stable fixed point dynamics. Physica D: Nonlinear Phenomena, vol. 261, pp. 19- 30.   
Mauroy, A., Mezi´c, I., and Susuki, Y. (2020). The Koopman operator in systems and control. Springer, Switzerland.   
Markovsky, I. and Rapisarda, P. (2008). Data-driven simulation and control. Int. J. of Control, 81(12):1946–1959.   
Markovsky, I. and D¨orfler, F. (2021). Behavioral systems theory in data-driven analysis, signal processing, and control. Annual Reviews in Control, vol. 52, pp. 42-64.   
Markovsky, I. (2023). Data-Driven Simulation of Generalized Bilinear Systems via Linear Time-Invariant Embedding. IEEE Trans. Automat. Control, 68(2):1101-1106.   
Martin, T. and Allgo¨wer, F. (2020). Iterative data-driven inference of nonlinearity measures via successive graph approximation. In Proc. 59th Conf. on Decision and Control. (CDC), pp. 4760-4765.   
Martin, T. and Allg¨ower, F. (2021). Dissipativity Verification with Guarantees for Polynomial Systems From Noisy Input-State Data. IEEE Control Systems Lett., 5(4):1399-1404.   
Martin, T. and Allg¨ower, F. (2023b). Data-driven system analysis of nonlinear systems using polynomial approximation. IEEE Trans. Automat. Control (Early Access), DOI: 10.1109/TAC.2023.3321212.   
Martin, T. and Allgo¨wer, F. (2022a). Determining dissipativity for nonlinear systems from noisy data using Taylor polynomial approximation. In Proc. American Control Conf. (ACC), pp. 1432-1437.   
Martin, T. and Allgo¨wer, F. (2022b). Data-driven inference on optimal inputoutput properties of polynomial systems with focus on nonlinearity measures. IEEE Trans. Automat. Control, 68(5):2832-2847.   
Martin, T., Sch¨on, T.B., and Allgo¨wer, F. (2023a). Gaussian inference for data-driven state-feedback design of nonlinear systems. In Proc. 22nd IFAC World Congress, arXiv preprint, arXiv:2211.05639.   
Mayne, D.Q., Seron, M.M., and Rakovi´c, S.V. (2005). Robust model predictive control of constrained linear systems with bounded disturbances. Automatica, 41(2):219–224.   
Mejari,, M., Gupta, A., and Piga, D. (2023). Data-Driven Computation of Robust Invariant Sets and Gain-Scheduled Controllers for Linear ParameterVarying Systems. arXiv preprint arXiv:2309.0181.   
Mezi´c, I. (2005). Spectral properties of dynamical systems, model reduction and decompositions. Nonlinear Dynamics, vol. 41, pp. 309–325.   
Milanese, M. and Novara, C. (2004). Set Membership identification of nonlinar systems. Automatica, 40(6):957-975.   
Miller, J., Dai, T., and Sznaier, M. (2022). Data-Driven Stabilizing and Robust Control of Discrete-Time Linear Systems with Error in Variables. arXiv preprint arXiv:2210.13430.   
Miller, J. and Sznaier, M. (2023). Data-Driven Gain Scheduling Control of Linear Parameter-Varying Systems Using Quadratic Matrix Inequalities. IEEE Control Systems Lett., vol. 7, pp. 835-840.   
Min, Y., Richards, S.M., and Azizan, N. (2023). Data-Driven Control with Inherent Lyapunov Stability. arXiv preprint arXiv:2303.03157.   
Monaco, S. and Normand-Cyrot, D. (1987). Minimum-phase nonlinear discrete-time systems and feedback stabilization. In Proc. 26th Conf. Decision and Control (CDC), pp. 979–986.   
Montenbruck, J.M. and Allgo¨wer, F. (2016). Some Problems Arising in Controller Design from Big Data via Input-Output Methods. In Proc. 55th Conf. Decision and Control (CDC), pp. 6525-6530.   
Narendra, K., and Annaswamy, A. (1986). Robust adaptive control in the presence of bounded disturbances. IEEE Trans. Automat. Control, 31(4):306- 315.   
Nelles, O. (2021). Nonlinear System Identification: From Classical Approaches to Neural Networks Fuzzy Models, and Gaussian Processes (2nd ed.). Springer, Cham.   
Nguyen, H.H., Friedel, M., and Findeisen, R. (2023). LMI-based Data-Driven Robust Model Predictive Control. arXiv preprint arXiv:2303.04777.   
Nortmann, B. and Mylvaganam, T. (2020). Data-Driven Control of Linear Time-Varying Systems. In Proc. 59th Conf. Decision and Control (CDC), pp. 3939–3944.   
Novara, C., Fagiano, L., and Milanese, M. (2013). Direct feedback control design for nonlinear systems. Automatica, 49(4):849–860.   
Nu¨ ske, F., Peitz, S., Philipp, F., Schaller, M., and Worthmann, K. (2023). Finitedata error bounds for Koopman-based prediction and control. Journal of Nonlinear Science, 33:14.   
Oymak, S. and Ozay, N. (2019). Non-asymptotic Identification of LTI Systems from a Single Trajectory. In Proc. American Control Conf. (ACC), 5655–5661.   
Putinar, M. (1993). Positive polynomials on compact semi-algebraic sets. Indiana Univ. Math. J. 42, pp. 969–984.   
Rantzer, A. (2001). A dual to Lyapunov’s stability theorem. Systems & Control Lett., 42(3):161–168.   
Rasmussen, C.E. and Williams, C.K.I. (2006). Gaussian Processes for Machine Learning. The MIT Pres   
Romer, A., Trimpe, S., and Allgo¨wer, F. (2019). Data-driven inference of passivity properties via Gaussian process optimization. In Proc. European Control Conf. (ECC), pp. 29–35.   
Romer, A., Berberich, J., K¨ohler, J., and Allg¨ower, F. (2019). One-shot verification of dissipativity properties from input-output data. IEEE Control Systems Lett., 3(3):709–714.   
Rotondo, D., Luta, G., and Aarvåg, J.H.U. (2022). Towards a Taylor-Carleman bilinearization approach for the design of nonlinear state-feedback controllers. European Journal of Control, vol. 68, pp. 100670.   
Safonov, M.G. and Tsao, T.C. (1997). The unfalsified control concept and learning. IEEE Trans. Automat. Control, 42(6):843-847.   
Sauer, T. and Xu, Y. (1995). On multivariate Hermite interpolation. Advances in Computational Mathematics, vol. 4, pp. 207–259.   
Scharnhorst, P., Maddalena, E.T., Jiang, Y., and Jones, C.N. (2023). Robust uncertainty bounds in reproducing kernel hilbert spaces: A convex optimization approach. IEEE Trans. Automat. Control, 68(5):2848-2861.   
Scherer, C.W. and Weiland, S. (2000). Linear matrix inequalities in control, Lecture Notes (Compilation: 2015). Available: https://www.imng.unistuttgart.de/mst/files/LectureNotes.pdf   
Scherer, C.W. (2001). LPV control and full block multipliers. Automatica, 37(3):361–375.   
Scherer, C.W. and Hol, C. (2006). Matrix Sum-of-Squares Relaxations for Robust Semi-Definite Programs. Math. Programming, 107, pp. 189–211.   
Sinha, S., Nandanoori, S.P., Drgona, J., and Vrabie, D. (2022). Data-driven stabilization of discrete-time control-affine nonlinear systems: A Koopman operator approach. In Proc. European Control Conf. (ECC), pp. 552-559.   
Steinwart, I. and Christmann, A. (2008). Support Vector Machines. Springer, New York.   
Stra¨sser, R., Berberich, J., and Allgo¨wer, F. (2021). Data-Driven Control of Nonlinear Systems: Beyond Polynomial Dynamics. In Proc. 60th Conf. Decision and Control (CDC), pp. 4344-4351.   
Stra¨sser, R., Berberich, J., and Allgo¨wer, F. (2023a). Robust data-driven control for nonlinear systems using the Koopman operator. In Proc. 22nd IFAC World Congress, arXiv preprint arXiv:2304.03519.   
Stra¨sser, R., Berberich, J., and Allg¨ower, F. (2023b). Control of bilinear systems using gain-scheduling: Stability and performance guarantees. arXiv preprint arXiv:2304.04486.   
Strogatz, S.H. (2014). Nonlinear dynamics and chaos: With applications to physics, biology, chemistry, and engineering (2nd ed.). CRC press.   
Sznaier, M. (2021). A Data Driven, Convex Optimization Approach to Learning Koopman Operators. In Proc. Machine Learning Research, vol. 144, pp. 1–11.   
Tanaskovic, M., Fagiano, L., Novara, C., and Morari, M. (2017). Data-driven control of nonlinear systems: An on-line direct approach. Automatica, vol. 75, pp. 1–10.   
Taylor, A.J., Dorobantu, V.D., Dean, S., Recht, B., Yue, Y, and Ames, A.D. (2021). Towards Robust Data-Driven Control Synthesis for Nonlinear Systems with Actuation Uncertainty. In Proc. 60th Conf. Decision and Control (CDC), pp. 6469-6476.   
Tiwari, M., Nehma, G., and Lusch, B. (2023). Computationally Efficient DataDriven Discovery and Linear Representation of Nonlinear Systems For Control. arXiv preprint arXiv:2309.04074.   
To´th, R. (2010). Modeling and Identification of Linear Parameter-Varying Systems. Springer Berlin, Heidelberg.   
Umenberger, J., Ferizbegovic, M., Sch¨on, T.B., and Hjalmarsson, H. (2019). Robust exploration in linear quadratic reinforcement learning. In Proc. Advances in Neural Information Processing Systems, vol. 32.   
Umlauft, J., Po¨hler, L., and Hirche, S. (2018). An Uncertainty-Based Control Lyapunov Approach for Control-Affine Systems Modeled by Gaussian Process. IEEE Control Systems Lett., 2(3):483-488.   
Vandenberghe, L. and Boyd, S. (1996). Semidefinite Programming. SIAM Review, 38(1):49-95.   
van Waarde, H.J., Eising, J., Trentelman, H.L., and Camlibel, M.K. (2020). Data Informativity: A new perspective on Data-Driven Analysis and Control. IEEE Trans. Automat. Control, 65(11):4753-4768.   
van Waarde, H.J., Camlibel, M.K., and Mesbahi, M. (2022). From Noisy Data to Feedback Controllers: Nonconservative Design via a Matrix S-Lemma. IEEE Trans. Automat. Control, 67(1):162-175.   
van Waarde, H.J., Eising, J., Camlibel, M.K., and Trentelman, H.L. (2023). The informativity approach : To Data-driven Analysis and Control. arXiv preprint arXiv:2302.10488.   
Verhoek, C., To´th, R., Haesaert, S., and Koch, A. (2021a). Fundamental Lemma for Data-Driven Analysis of Linear Parameter-Varying Systems. In Proc. 60th Conf. Decision and Control (CDC), pp. 5040-5046.   
Verhoek, C., Abbas, H.S., To´th, R., and Haesaert, S. (2021b). Data-Driven Predictive Control for Linear Parameter-Varying Systems. In Proc. 4th IFAC Workshop on LPV Systems, 54(8):101-108.   
Verhoek, C., To´th, R., and Abbas, H.S. (2022). Direct Data-Driven StateFeedback Control of Linear Parameter-Varying Systems. arXiv preprint arXiv:2211.17182.   
Verhoek, C., Abbas, H.S., To´th, R. (2022). Direct data-driven LPV control of nonlinear systems: An experimental result. arXiv preprint arXiv:2211.17191.   
Verhoek, C., Koelewijn, P.J.W., Haesaert, S., and T´oth, R. (2023a). Direct datadriven state-feedback control of general nonlinear systems. arXiv preprint arXiv:2303.10648.   
Verhoek, C., Berberich, J., Haesaert, S., Allg¨ower, F., and To´th, R. (2023b). Data-driven Dissipativity Analysis of Linear Parameter-Varying Systems. arXiv preprint arXiv:2303.10648.   
Willems, J.C. (1972). Dissipative dynamical systems part I: General theory. Arch. Rational Mech. Anal., vol. 45, pp. 321–351.   
Willems, J.C., Rapisarda, P., Markovsky, I., and De Moor, B.L.M. (2005). A note on persistency of excitation. Systems & Control Lett., 54(4):325–329.   
Yi, B. and Manchester, I.R. (2021). On the Equivalence of Contraction and Koopman Approaches for Nonlinear Stability and Control. In Proc. 60th Conf. Decision and Control (CDC), pp. 4609-4614.   
Yin, M., Iannelli, A., and Smith, R.S. (2021). Maximum Likelihood Estimation in Data-Driven Modeling and Control. IEEE Trans. Automat. Control, 68(1):317-328.   
Yuan, Z. and Corte´s, J. (2022). Data-Driven Optimal Control of Bilinear Systems. IEEE Control Systems Lett., vol. 6, pp. 2479–2484.   
Xue, A. and Matni, N. (2021). Data-Driven System Level Synthesis. In Proc. Machine Learning Research, vol. 144, pp. 1–12.   
Zhang, X., Pan, W., Scattolini, R., Yu, S., and Xu, X. (2022). Robust tubebased model predictive control with Koopman operators. Automatica, vol. 137, pp. 110114.   
Zheng, Y. (2019). Chordal Sparsity in Control and Optimization of Large-scale Systems. PhD thesis, University of Oxford.   
Zheng, J., Dai, T., Miller, J., and Sznaier, M. (2023). Robust Data-Driven Safe Control using Density Functions. arXiv preprint arXiv:2303.09004.   
Ziegler, J.G. and Nichols, N.B. (1942). Optimum settings for automatic controllers. Trans. ASME, vol. 64, pp. 759–768.  