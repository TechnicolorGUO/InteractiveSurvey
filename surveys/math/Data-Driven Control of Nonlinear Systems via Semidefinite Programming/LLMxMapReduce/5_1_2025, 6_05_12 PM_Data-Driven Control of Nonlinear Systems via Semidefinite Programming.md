# 5/1/2025, 6:05:12 PM_Data-Driven Control of Nonlinear Systems via Semidefinite Programming  

# 0. Data-Driven Control of Nonlinear Systems via Semidefinite Programming  

# 1. Introduction  

Control theory has undergone a significant evolution, shifting from traditional model-based approaches that rely heavily on precise mathematical descriptions of system dynamics to increasingly data-driven methodologies [1]. This paradigm shift has been catalyzed by the rapid advancements in artificial intelligence and the proliferation of data availability across various engineering domains [1,20]. While traditional methods have proven effective for systems where accurate models are readily available, they encounter substantial limitations when applied to complex, high-dimensional, time-varying, and uncertain systems [1,7,21].  

Nonlinear systems, in particular, present unique and profound challenges compared to their linear counterparts [1,7,22]. Their dynamics are often highly complex, exhibiting phenomena such as multiple equilibria, limit cycles, bifurcations, and sensitivity to initial conditions, which complicate analysis and prediction [25]. Furthermore, obtaining accurate mathematical models for nonlinear systems is frequently difficult due to inherent uncertainties, external disturbances, measurement noise, and the complex physical or chemical processes involved, as seen in examples like robot manipulators or hydrometallurgical processes [7,11,12,16]. These factors render traditional model-based control design, which often relies on linearized approximations or extensive system identification efforts, less effective or even intractable [1,12,16].  

![](images/8ea6caefd373ec8be6676cc58ab6d5d1ebc3635337d4868ae4b599ec82873c2c.jpg)  

Data-driven methods emerge as a powerful alternative by directly leveraging system data—collected from sensors, experiments, or simulations—to design controllers or derive models for prediction and analysis, thereby circumventing the need for a first-principles mathematical model [1,2,4]. Techniques such as neural networks, fuzzy logic, reinforcement  

learning, and various model-free adaptive control strategies utilize system input-output data to identify system behavior, learn optimal control policies, or adapt controller parameters online, proving effective for complex and uncertain nonlinear dynamics [7,10,11,12,16,25]. This data-centric approach directly addresses the challenges posed by unknown or difficult-tomodel dynamics [1,2,6,12,16].​  

Simultaneously, Semidefinite Programming (SDP) has established itself as a powerful framework within convex optimization, finding extensive applications across diverse scientific and engineering disciplines, including control theory [3,17,18,27]. SDP problems involve optimizing a linear function subject to linear matrix inequality (LMI) constraints. The significance of SDP in control stems from its ability to provide computationally tractable methods for analyzing system properties like stability—often through Lyapunov functions formulated as LMIs—and synthesizing controllers while rigorously handling various system constraints [3]. Furthermore, techniques exist to address more complex scenarios involving nonlinear SDP [18].​  

The confluence of these two areas—data-driven control and Semidefinite Programming—offers a compelling approach to tackle the challenges of nonlinear systems. The primary motivations for combining these fields are rooted in leveraging the strengths of each: data-driven methods effectively handle the inherent uncertainties and modeling difficulties of nonlinear systems by extracting information directly from operational data, while SDP provides a robust mathematical framework for formulating control objectives and constraints as convex optimization problems, enabling formal analysis and synthesis with guarantees, particularly concerning stability and safety [6]. This combination allows for the development of controllers that can adapt to unknown or changing dynamics based on data, while simultaneously ensuring desired performance characteristics and constraint satisfaction through the structured optimization capabilities offered by SDP.  

This survey aims to provide a structured overview of the research landscape at the intersection of data-driven control, nonlinear systems, and Semidefinite Programming. It synthesizes existing literature to delineate the key problem formulations, methodologies, theoretical guarantees, and applications in this interdisciplinary field, thereby contributing to a clearer understanding of its current status and future directions.  

# 2. Background on Nonlinear Systems and Data-Driven Control Concepts  

Nonlinear systems constitute a broad class of dynamical systems whose evolution cannot be described by linear equations. Unlike linear systems, they often exhibit complex behaviors such as bifurcations, multiple equilibria, limit cycles, and chaotic dynamics, making their analysis and control significantly more challenging [15]. Mathematically, a continuous-time nonlinear system can often be represented in the form $\dot { \vec { y } } = \vec { A } \vec { y } + \vec { f } ( \vec { y } )$ , where $\vec { f } ( \vec { y } )$ denotes the nonlinear terms, or more generally, $\dot { \vec { x } } = f ( \vec { x } , \vec { u } )$ , while discrete-time systems might take the form $y ( k ) = f ( u , y , k )$ [7,8]. Common sources of nonlinearity in engineering systems include physical constraints like saturation, dead zones, and hysteresis in actuators and sensors, as well as inherent physical phenomena such as aerodynamic forces, gravitational effects in varying configurations, or chemical reaction kinetics [13,15].  

Examples of nonlinear systems abound across various engineering domains. In robotics, multi-link manipulators are inherently nonlinear due to the complex interplay of inertia, Coriolis, and gravitational forces, described by equations like $M ( q ) \ddot { q } + B ( q , \dot { q } ) \dot { q } + G ( q ) = \tau$ [11,23]. Flexible-joint manipulators introduce further nonlinearity through joint elasticity [16]. Aerospace systems like quadrotor UAVs exhibit complex nonlinear dynamics derived from Newton-Euler formulations [22]. Chemical processes, such as batch polymerization reactors, present nonlinearities arising from exothermic reactions and mass transfer phenomena [22]. Other examples include cascade leaching processes in mining [12], energy systems involving permanent magnet synchronous motors [21], and even high-dimensional quantum optical circuits where scattering loss and mode mixing are significant imperfections [9].  

Analyzing and controlling nonlinear systems poses significant difficulties [15]. Unlike linear systems where powerful tools like superposition, frequency response, and well-established stability criteria (e.g., Routh-Hurwitz, Nyquist) are readily available, these methods are generally not applicable directly to nonlinear systems. Traditional model-based control design for nonlinear systems often requires precise analytical models, which can be challenging or impossible to obtain due to system complexity, unknown parameters, or time-varying characteristics [1,6]. Techniques like linearization are only valid locally around an operating point, limiting their applicability across the system's full operating range. Furthermore, traditional analysis concepts like controllability rely on known dynamic models, making their application to systems where only input-output data is available problematic, particularly due to the discrete nature of the data points [1].  

This inherent difficulty in obtaining and utilizing accurate analytical models for complex nonlinear systems highlights a key distinction between traditional model-based control and data-driven control paradigms [1,15]. Traditional model-based control emphasizes deriving a mathematical model from first principles or system identification, followed by controller design based on this model [1]. In contrast, data-driven control leverages system input-output data directly, either to design a controller without an explicit model or to construct a data-driven model approximation [15,25].​  

Data-driven approaches offer significant advantages, particularly when obtaining an accurate analytical model is difficult or impossible [1,6]. They bypass the need for detailed system physics, relying instead on observed system behavior captured in data [12,25]. This shift in focus moves away from precise model parameterization towards using data directly for control or for approximating the system dynamics [2,16]. Data-driven model approximation techniques include using Neuro-Fuzzy models which combine local ARX models with activation functions [7], approximating nonlinear systems as Linear Parameter-Varying (LPV) systems from data [6], constructing multiple local models to handle complexity [5], or employing methods like the Koopman operator for system identification from data [2]. Direct data-driven control methods like ModelFree Adaptive Control (MFAC) rely solely on input-output data and principles like dynamic linearization, adjusting parameters based on real-time system response [10,12]. Intelligent controllers, such as those based on Neural Networks and Fuzzy Logic, also fall under this umbrella as they can learn or be adapted using data to handle nonlinearities and uncertainties [13,16,23].  

Despite their promise, data-driven control methods for nonlinear systems face several key challenges [15]. A primary concern is ensuring closed-loop stability, which is often more difficult to guarantee rigorously compared to model-based designs [15]. Data quality is crucial; noisy, insufficient, or non-representative data can lead to poor model approximations or control performance [15]. Computational tractability is another challenge, especially for complex systems or online learning, where the computational burden of processing large datasets or optimizing controllers in real-time can be significant [5]. Furthermore, ensuring robustness against system uncertainties, external disturbances, and variations not captured in the training data remains an active area of research [10,21]. The application of traditional system analysis concepts, such as controllability or reachability, using only discrete data points also presents unique challenges [1].  

# 3. Background on Semidefinite Programming (SDP)  

Semidefinite programming (SDP) constitutes a fundamental subfield of convex programming, characterized by the optimization of a linear objective function subject to the constraint that an affine combination of symmetric matrices remains positive semidefinite [27]. This structure positions SDP as a powerful tool for problems that can be cast in this form. The standard primal form of an SDP is typically expressed as:​  

$$
{ \begin{array} { r l } & { \qquad \operatorname* { m i n } \operatorname { t r a c e } ( C X ) } \\ & { \qquad \operatorname { s u b j e c t \ t o \ t r a c e } ( A _ { i } X ) = b _ { i } , \quad i = 1 , \dots , m } \\ & { \qquad X \succeq 0 } \end{array} }
$$  

Here, $X$ is the symmetric decision variable matrix, $C$ and $A _ { i }$ ​ are given symmetric matrices of appropriate dimensions, and $b _ { i }$ are given scalars. The constraint $X \succeq 0$ signifies that $X$ is a positive semidefinite matrix [27]. This condition on positive semidefiniteness, potentially applied to an affine matrix expression  

$$
\mathcal { A } ( X ) = A _ { 0 } + \sum _ { i = 1 } ^ { n } x _ { i } A _ { i } ,
$$  

is known as a Linear Matrix Inequality (LMI) when the expression must be positive semidefinite, or a set of LMIs if there are multiple such constraints. LMIs are a key tool in formulating problems as SDPs [3]. The properties of positive semidefinite matrices are fundamental to formulating and solving these problems, even in contexts like robust optimization where uncertainty is considered [17].​  

The inherent convexity of SDPs, stemming from the fact that the feasible set defined by LMIs and the positive semidefinite cone is convex [27], offers significant advantages. Specifically, any local optimum is also a global optimum, eliminating the complexities of non-convex landscapes. Furthermore, in theory, SDPs are solvable in polynomial time, which is a desirable computational property for large-scale problems.  

The state of the art in SDP solvers reflects significant advancements, enabling the practical application of this theoretical framework. Efficient algorithms and methods for solving SDP problems have been developed, including interior-point methods and decomposition techniques [14,15]. Numerous software packages are available, providing the practical means to implement SDP-based solutions [3]. Some solvers offer features such as providing optimality certificates, which are valuable in applications requiring guarantees on the quality of the solution [19]. Comprehensive resources, such as the "Handbook of Semidefinite Programming," detail the theoretical foundations and computational methods for tackling SDPs [14]. While the focus is primarily on standard linear SDPs, iterative approaches involving linearized constraints demonstrate how linear SDPs can underpin methods for more complex nonlinear semidefinite problems [18].​  

![](images/22891dfe7dc79d699e778121d492641a64907c745f6fd8acffb4aaa13730a10f.jpg)  

In control theory, SDP plays a crucial role, primarily facilitated through the use of LMIs. Fundamental applications include stability analysis, where system stability can be verified by finding a positive definite Lyapunov matrix satisfying certain LMIs, and controller synthesis, where controller parameters are determined by solving LMIs derived from stability or performance criteria [3,15]. The ability of SDP to effectively handle LMI constraints makes it particularly well-suited for these types of control problems, providing a robust mathematical framework for design and analysis.​  

# 4. Data-Driven Modeling Techniques for Nonlinear Systems  

Developing accurate mathematical models for complex nonlinear systems based solely on first principles can be prohibitively challenging or impossible. Data-driven modeling offers a powerful alternative, constructing models directly from observed system input–output data or state trajectories [2,15].  

<html><body><table><tr><td>Category</td><td>Description</td><td>Examples / Key Concepts</td><td>Trade-offs</td></tr><tr><td>System Identification</td><td>Build models from data (Input/Output). Parametric vs Non-</td><td>ARX, RGLS (Parametric); NN, Kernel methods</td><td>Interpretability vs Flexibility, Structure Selection</td></tr><tr><td>Approximators</td><td>approximators learning I/O maps.</td><td>(RBF, RNN, Deep Learning), Neuro- Fuzzy</td><td>Data Requirements, Computation Cost, Overfitting, Interpretability</td></tr></table></body></html>  

<html><body><table><tr><td>Multiple Model Approaches</td><td>Partition operating space and use simpler local models, combine outputs.</td><td>Partitioning Input/State Space, Local Linear/ARX models</td><td>Complexity of Management/Transit ions, Curse of Dim.</td></tr><tr><td>Reduced-Order Modeling (ROM)</td><td>Approximate dynamics in lower dimension while preserving key features.</td><td>SVD, POD,DMD, Koopman Operator (EDMD)</td><td>Accuracy (observable selection), Computational Efficiency</td></tr></table></body></html>  

This section surveys prominent data-driven modeling techniques for nonlinear systems, categorizing and comparing them based on their ability to capture complex nonlinear dynamics, computational cost, data requirements, and model interpretability. We discuss the underlying principles of system identification, analyze reduced-order modeling techniques, detail the application of universal approximators like Neural Networks and Neuro-Fuzzy models, and elaborate on multiple model approaches. A central theme throughout these techniques is the analysis of trade-offs inherent in model accuracy, complexity, computational efficiency, and the crucial aspects of model validation and generalization in a data-driven context.​  

The foundation of data-driven modeling often lies in system identification, which aims to build mathematical models from experimental data. Methodologies are broadly categorized into parametric and non-parametric approaches. Parametric methods assume a predefined model structure, such as Auto-Regressive with eXogenous (ARX) models used in some NeuroFuzzy frameworks, and estimate the parameters of this structure from data, often using techniques like recursive generalized least squares [7]. While potentially offering model interpretability and predictability within the assumed structure, selecting an appropriate nonlinear structure is challenging [5,7]. Non-parametric methods, conversely, learn system behavior directly from data without a rigid structure, employing flexible function approximators like Neural Networks or Kernel-based methods [15,23]. These methods offer greater flexibility in capturing complex nonlinearities but often result in less interpretable "black-box" models. Hybrid approaches, such as Neuro-Fuzzy models combining local parametric models with data-driven structural components, attempt to balance these trade-offs [7]. Convex optimization techniques provide a framework for addressing challenges in both parametric and non-parametric identification, including handling missing data through methods like nuclear norm minimization [14]. The process inherently involves selecting a model structure and estimating parameters, navigating the fundamental trade-off between model accuracy, which improves with complexity, and the risk of overfitting or increased computational burden [24].​  

Universal approximators, notably Neural Networks (NNs), are widely used for data-driven nonlinear modeling due to their capacity to approximate arbitrary continuous functions. NNs, with their layered architectures and nonlinear activation functions, can learn complex input–output mappings directly from data [9,11,15,23]. Training involves adjusting network parameters through algorithms like gradient descent or recursive least squares variants [16]. Different architectures like Radial Basis Function (RBF) NNs, Recurrent Neural Networks (RNNs), and deep learning models (including physics-informed variants like PINNs) are employed depending on the system characteristics and data availability [11,19]. A critical challenge is preventing overfitting, where the model performs well on training data but poorly on unseen data, necessitating careful consideration of model complexity and regularization techniques [24]. Neuro-Fuzzy (NF) models represent a hybrid approach, merging the learning power of NNs with the interpretability of fuzzy logic [7]. These models often employ architectures with local parametric models (e.g., ARX) combined via data-driven fuzzy activation functions, enabling online adaptation of parameters [7]. The output of an NF model can often be expressed as a weighted sum of local model contributions, where the weights are determined by fuzzy membership functions, for example, using normalized Gaussian functions [7]:​  

$$
\psi _ { j } ( k ) = \frac { \mu _ { j } \left( \tilde { \varphi } ( k ) \right) } { \sum _ { i = 1 } ^ { N } \mu _ { i } \left( \tilde { \varphi } ( k ) \right) }
$$  

where  

$$
\mu _ { j } \left( \tilde { \varphi } ( k ) \right) = \exp \left( \sum _ { i = 1 } ^ { \tilde { r } } - \frac { 1 } { 2 } \left( \frac { \tilde { \varphi } _ { i } ( k ) - c _ { j , i } } { \lambda _ { j , i } } \right) ^ { 2 } \right) ,
$$  

with $\psi _ { j } ( k )$ representing the activation, $\tilde { \varphi } ( k )$ the regressor, $\boldsymbol { c } _ { j , i }$ ​ the centers, and $\lambda _ { j , i }$ the standard deviations. Online learning is vital for these models to track dynamic system changes [7].  

Multiple model approaches provide a strategy to handle complex nonlinearities by decomposing the problem into identifying simpler local models within different operating regimes of the system [5,7]. This typically involves partitioning the state or input space based on data. Strategies include partitioning the entire input space or, more specifically, the range of the control input to mitigate the curse of dimensionality [5]. Within each partition, local models are identified, which can be simple linear models, local ARX structures, or models linear in the control input [5,7]. The overall system behavior is then approximated by combining these local models, often using smooth weighting functions derived from fuzzy logic or based on the system's current operating point [7]. These methods are effective for systems with piecewise nonlinearities but introduce complexity in managing multiple models and ensuring smooth transitions, although theoretical analysis can provide insights into approximation errors [5].​  

For high-dimensional nonlinear systems, direct full-order modeling can be computationally prohibitive. Reduced-order modeling (ROM) techniques seek to approximate system dynamics in a lower-dimensional subspace while preserving essential characteristics. Techniques like Singular Value Decomposition (SVD) and Proper Orthogonal Decomposition (POD) are used to identify dominant modes from data, while Dynamic Mode Decomposition (DMD) can extract spatio-temporal patterns and serve as a transient predictor [8,15,24]. A powerful framework for nonlinear ROM is the Koopman operator theory, which lifts finite-dimensional nonlinear dynamics to a potentially infinite-dimensional linear space of observables, enabling linear analysis and control techniques in this lifted space [2,15]. Data-driven approximation of the Koopman operator is often achieved through methods like Extended Dynamic Mode Decomposition (EDMD), utilizing a dictionary of observable functions and linear regression on snapshot data [2]. Subspace identification methods, combined with sparse approximation, can also relate to Koopman-based models [2]. Techniques for sparse regularization and greedy algorithms can further aid model simplification and dimensionality reduction [14,24].  

Comparing these techniques highlights various trade-offs. Universal approximators and multiple model approaches excel at capturing complex nonlinearities but can suffer from high data requirements, computational cost during training, and challenges with interpretability (especially for large NNs). ROM techniques, particularly Koopman-based methods, offer the potential for linear representations in a lifted space, which can be computationally efficient for analysis and control, but their accuracy depends heavily on the selection of observable functions [2]. Parametric identification, when feasible, can offer interpretability but is limited by the assumed structure. Overarching challenges include dealing with noisy data, which can degrade model performance and training convergence [7], handling missing data [14], and ensuring model generalization to unseen operating conditions, which requires rigorous model validation [5]. Ultimately, the choice of a datadriven modeling technique depends on the specific system, data characteristics, computational resources, and the desired balance between model accuracy, complexity, interpretability, and efficiency, particularly in the context of subsequent control design using methods like Semidefinite Programming.  

# 4.1 System Identification and Reduced Order Modeling  

System identification constitutes a fundamental process in data-driven control, focusing on the creation of mathematical models for dynamical systems based on observed input–output data. This contrasts with model‐free approaches, where control strategies operate directly on data without forming an explicit system representation [6]. For nonlinear systems, system identification methodologies are broadly categorized into parametric and non‐parametric approaches. Parametric methods assume a predefined model structure and aim to estimate the parameters of this structure from data. Examples include using parameter estimation techniques on input/output data to determine the constants of a nonlinear model for systems like a batch reactor or verifying system parameters for a quadrotor using optimization methods like particle swarm optimization [22]. Auto-Regressive with eXogenous (ARX) models, often used as local models within more complex frameworks like Neuro-Fuzzy systems, represent a parametric structure whose parameters can be updated online using methods such as recursive generalized least squares (RGLS) [7]. A structured parametric approach involves partitioning the input space and identifying local models within each partition, as seen in methods that identify local linear models based on the range of the control input [5]. Advantages of parametric identification for nonlinear systems can include model interpretability and potential for extrapolation beyond training data, provided the assumed structure adequately captures the underlying dynamics. However, selecting an appropriate nonlinear model structure is often challenging and can lead to poor performance if mismatched.​  

Non-parametric methods, in contrast, do not assume a rigid, fixed-parameter model structure beforehand but rather learn the system’s behavior directly from data, often using flexible function approximators. The application of neural networks and fuzzy logic can be interpreted as non-parametric system identification, where the model structure is flexible and adapted or learned entirely from the data [23]. Neuro-Fuzzy models combine aspects of both, employing an incremental tree-construction algorithm to split the input space and generate local models with associated parameters, where the structure (number and location of local models) is data-driven [7]. Kernel-based system identification with manifold regularization also falls under this umbrella, utilizing data-driven kernels to define model complexity and smoothness from a Bayesian perspective [15]. Recursive least squares algorithms used to estimate parameters like PID gains within a neural network structure can also be viewed in this light, facilitating rapid learning of effective controller parameters from data [16]. Non-parametric methods offer greater flexibility and can potentially capture complex nonlinearities without strong prior assumptions about the system structure. However, they often result in less interpretable “black-box” models and may struggle with extrapolation outside the training data distribution. Hybrid approaches, like the Neuro-Fuzzy model with local ARX structures, attempt to balance the flexibility of non-parametric methods with the structure of parametric ones [7]. Convex optimization techniques provide a powerful framework for both parametric and non-parametric identification tasks, including handling challenges like missing data through techniques such as nuclear norm minimization [14].​  

For high-dimensional or complex nonlinear systems, obtaining a full-order model can be computationally prohibitive for analysis and control. Reduced-order modeling (ROM) techniques aim to approximate the system dynamics within a lowerdimensional subspace while retaining essential behavioral characteristics. Linear system identification techniques like singular value decomposition (SVD) and canonical correlation analysis (CCA) are valuable tools for identifying linear statespace models and inherent dimensionality reduction [14]. Truncated SVD is specifically utilized for data purification by mitigating the impact of disturbances and noise, effectively reducing the effective dimension of the data [25]. In the context of nonlinear systems, techniques like Proper Orthogonal Decomposition (POD), which is fundamentally based on SVD of snapshot data, and Dynamic Mode Decomposition (DMD) are widely used to extract dominant spatial-temporal patterns and modes. For instance, a “fast” method for model reduction approximates the tangent space using a $d$ -dimensional truncated SVD on a snapshot matrix  

$$
\mathbf { Y } \in \mathbb { R } ^ { p \times N } : \quad \mathbf { Y } \approx \mathbf { U } _ { d } \mathbf { S } _ { d } \hat { \mathbf { V } } _ { d } ^ { \top } .
$$  

The tangent space approximation is defined as  

$$
\begin{array} { r } { { \bf V } = { \bf U } _ { d } { \bf S } _ { d } ^ { - 1 } . } \end{array}
$$  

Trajectories are then projected onto this subspace to obtain reduced coordinates  

$$
\pmb { \xi } = \mathbf { V } ^ { \top } \mathbf { y } .
$$  

The dynamics in the reduced space are subsequently approximated, often via polynomial regression [8]. DMD is also explored as a transient predictor [15]. Other ROM techniques include methods for sparse regularization, which can be viewed as dimensionality reduction especially for high-dimensional data, and greedy algorithms for model simplification [24]. The selection of regularization parameters, such as in nuclear norm minimization problems, is crucial for balancing model complexity and performance in reduced-order models [24]. Specific tools like SSMTool and SSMLearn are being developed to facilitate equation-based and data-driven computation of reduced models on spectral submanifolds (SSMs) [26].​  

A powerful ROM technique for nonlinear systems is based on the Koopman operator theory. The Koopman operator is an infinite-dimensional linear operator that describes the evolution of scalar observation functions defined on the state space of a dynamical system. By lifting the finite-dimensional nonlinear dynamics to a potentially infinite-dimensional linear space of observables, the Koopman operator framework allows the use of linear system theory tools for analysis and control [2,15]. Approximating the Koopman operator from data is often achieved using methods like Extended Dynamic Mode Decomposition (EDMD) or related techniques. These methods construct a finite-dimensional approximation of the operator by selecting a dictionary of observable functions and performing a linear regression on snapshot data to find the matrix representation of the operator in the span of these observables. Subspace identification methods, combined with sparse approximation, can be used to identify models related to the Koopman operator, connecting it to higher-order state transition matrices (STMs) [2]. Nonparametric approaches and policy gradient methods are also employed for estimating Koopman operators [15]. These Koopman-based models can then be utilized for prediction of system behavior and  

synthesis of linear controllers in the lifted space. The effectiveness of these methods is validated on systems like the Lorenz oscillator and high-dimensional finite-element models [2].  

Comparing the computational efficiency and accuracy of these techniques reveals trade-offs. Parametric methods, when the model structure is known and simple, can be computationally efficient for parameter estimation, but accuracy is heavily dependent on the structure assumption. Non-parametric methods, such as large neural networks, can be computationally intensive during training but offer flexibility for complex systems. ROM techniques like SVD/POD and DMD provide computationally efficient linear representations of high-dimensional data, effective for capturing dominant linear or nearlinear dynamics and modes. The “fast” model reduction method relying on truncated SVD and polynomial regression aims for efficiency in constructing the reduced model and dynamics [8,24]. Koopman operator approximation via methods like EDMD involves computationally manageable linear regressions if the observable dictionary size is kept finite, offering a linear framework even for nonlinear systems, but the choice of observables significantly impacts accuracy [2,15]. The balance between model complexity (and thus computational cost) and accuracy is a recurring theme, addressed in methods like selecting regularization parameters [24]. Overall, the selection of a suitable identification or ROM technique is driven by the specific characteristics of the nonlinear system, the available data, computational resources, and the desired trade-off between model complexity, interpretability, efficiency, and accuracy.​  

# 4.2 Neural Network and Neuro-Fuzzy Modeling  

Neural Networks (NNs) serve as powerful universal approximators capable of learning complex nonlinear functions directly from data. Their architecture, typically comprising interconnected layers of neurons with nonlinear activation functions, allows them to capture intricate input–output relationships characteristic of nonlinear system dynamics [5,9,11,14,15,16,19,23,25]. Training algorithms, such as gradient descent variants or specialized methods like modified recursive least squares [16], adjust network parameters (weights and biases) to minimize the difference between the network's output and the observed system output, thereby learning the underlying dynamics. Radial Basis Function (RBF) NNs, for instance, have been employed for modeling unknown robot manipulator dynamics based on inputs including position, velocity, and integrated error signals [11]. Recurrent Neural Networks (RNNs) have also been used in cooperative architectures for system identification, employing techniques like particle swarm optimization to mitigate convergence to local optima [25]. Deep learning architectures, characterized by multiple hidden layers, have demonstrated success in complex mapping tasks, such as modeling light propagation in multimode fibers [9] and leveraging physical laws for modeling high-speed flows (Physics-Informed Neural Networks or PINNs) [19]. The effectiveness of NNs in diverse applications, including image processing and signal recovery [24], underscores their versatility. A critical aspect of NN modeling involves navigating the trade-off between model complexity and generalization performance; overly complex models may overfit the training data, leading to poor performance on unseen data.  

![](images/ab167d87da4ccbfd072a7a0d5e2976628fa9da684b0455c72bcd42985461e87d.jpg)  

Neuro-Fuzzy (NF) models represent a hybrid approach that combines the powerful learning capabilities of NNs with the transparent, rule-based structure of fuzzy logic [7,10]. This fusion aims to achieve both accurate function approximation and interpretable knowledge representation. A typical NF model architecture includes input channels processing delayed system inputs and outputs, a regressor formed from these signals, neurons representing fuzzy rules or local models, and a weighted sum of neuron outputs to produce the estimated system output [7]. For example, in one structure, each neuron can contain a local linear model (e.g., ARX structure) whose contribution to the overall output is determined by a fuzzy activation function [7]. Fuzzy logic systems (FLSs), serving as a basis for NF models, use a knowledge base of If–Then rules to map inputs to outputs [13]. Using techniques like singleton fuzzification and center average defuzzification, FLSs can be expressed in a linear-in-parameters form  

$$
y ( x ) = \theta ^ { T } \varphi ( x ) ,
$$  

where $\theta$ is a vector of parameters and $\varphi ( x )$ is a vector of fuzzy basis functions [13]. NF models often use normalized activation functions, such as normalized Gaussian functions, where the degree of activation depends on how closely the  

input matches the center and spread of the Gaussian associated with each rule or neuron [7]:  

$$
\psi _ { j } ( k ) = \frac { \mu _ { j } \left( \tilde { \varphi } ( k ) \right) } { \sum _ { i = 1 } ^ { N } \mu _ { i } \left( \tilde { \varphi } ( k ) \right) }
$$  

with  

$$
\mu _ { j } \left( \tilde { \varphi } ( k ) \right) = \exp \left( \sum _ { i = 1 } ^ { \tilde { r } } - \frac { 1 } { 2 } \left( \frac { \tilde { \varphi } _ { i } ( k ) - c _ { j , i } } { \lambda _ { j , i } } \right) ^ { 2 } \right) ,
$$  

where $\psi _ { j } ( k )$ is the activation of the $j$ -th neuron, $\mu _ { j } \left( \tilde { \varphi } ( k ) \right)$ is the membership value, $\tilde { \varphi } ( k )$ is the regressor input, $\boldsymbol { c } _ { j , i }$ ​ are centers, and $\lambda _ { j , i }$ are standard deviations [7]. The interpretability arises from the fuzzy rules, while the learning capability stems from adapting the parameters of the local models $( \theta _ { j } )$ and potentially the parameters of the activation functions ( $c _ { j , i } , \lambda _ { j , i } )$ [7].  

Online learning approaches are crucial for adapting NF model parameters in real time, allowing the model to track changes in dynamic systems [7]. This involves continuously updating parameters based on incoming data samples.  

A significant challenge in training nonlinear models like NNs and NF systems is the presence of noisy data. Noise can corrupt the input–output measurements, potentially leading to inaccurate parameter estimates and reduced model performance or convergence to suboptimal solutions [25]. Potential solutions to mitigate the impact of noise and improve model training include regularization techniques, which add constraints or penalties to the training objective to prevent overfitting, and data purification or filtering methods, which attempt to reduce the noise level in the training data before it is used for model learning [25]. While regularization or data purification methods are not explicitly detailed in the context of the specific cooperative RNN approach [25], the challenge of achieving optimal training in complex nonlinear models remains pertinent.  

# 4.3 Multiple Model Approaches  

Multiple model approaches offer a pragmatic strategy for approximating complex nonlinear systems by employing a "divide and conquer" principle [5,7]. The core idea involves partitioning the system's operating regime, typically defined by regions in the input or state space, and approximating the system behavior within each local region using a simpler model [7]. This approach is particularly adept at handling systems exhibiting varying dynamics or piecewise nonlinearities across different operating points.  

Partitioning strategies based on data are crucial for defining these local regions. One method involves splitting the input space into several distinct regions [7]. Alternatively, as demonstrated in one approach, the partitioning can be applied specifically to the range of the control input $\mathsf { \backslash } ( \mathsf { u } ( \mathsf { k } ) \backslash )$ rather than the entire state or input space [5]. This latter technique aims to reduce the dimensionality of the problem, differentiating it from methods that partition the state space, such as traditional Piecewise Affine (PWA) models [5].  

Within each defined region, a local model is identified to capture the system dynamics. The structure of these local models can vary. For instance, Neuro-Fuzzy (NF) models often employ local AutoRegressive with eXogenous input (ARX) models within each region [7]. Another approach utilizes local models that are linear with respect to the control input $\mathsf { \backslash } ( \mathsf { u } ( \mathsf { k } ) \backslash ) .$ , identified within specific intervals of the input range [5].  

The overall approximation of the global nonlinear system is formed by combining the outputs of these local models. This combination can be achieved through various mechanisms. A common method in NF models is the use of fuzzy activation functions, which provide a smooth transition between the local models as the system's operating point moves from one region to another [7]. This smooth transition helps ensure continuity and avoids abrupt switching behaviors. For models partitioning the control input range, the combination effectively selects the appropriate local model based on the current control signal value [5]. The theoretical underpinnings of these models can include analyses of approximation error; for example, a theoretical upper bound for the approximation error of models partitioning the control input range has been derived based on Taylor's theorem [5].​  

Comparing multiple model approaches with global modeling techniques reveals distinct advantages and disadvantages. Multiple models excel at representing complex, piecewise nonlinearities that are challenging for single global models. By breaking down the problem, they can potentially simplify the identification task within each local region. However, these approaches can introduce computational overhead associated with managing multiple models and determining the active region or weighting scheme. The complexity of switching or achieving smooth transitions between local models also needs careful consideration [7]. Despite these potential challenges, the ability to specifically partition relevant spaces, such as only the input range, can offer a favorable trade-off by mitigating the "curse of dimensionality" while effectively approximating complex nonlinearities [5].  

# 5. SDP in Nonlinear Control Theory (Model-Based Foundations)  

This section explores the foundational role of Semidefinite Programming (SDP) as a convex optimization framework for addressing challenging problems in the control of nonlinear systems. While nonlinear control problems are often nonconvex, SDP enables their analysis and solution through various techniques, including relaxations and the exploitation of specific model structures, such as polynomial systems.  

![](images/4083dafeedcda584115c361fdae2e06701b4732f41dc6bf116be76451fb32708.jpg)  

The application of SDP in this domain primarily focuses on three interconnected areas: Lyapunov stability analysis, controller synthesis, and robust control design, leveraging the tractability offered by casting these problems as SDPs or the related Linear Matrix Inequalities (LMIs) [3,14,17,27].  

Lyapunov stability analysis, a cornerstone for nonlinear systems, traditionally faces the challenge of finding a suitable Lyapunov function. For systems with polynomial dynamics, this search can be significantly facilitated by Sum-of-Squares (SOS) programming. SOS programming provides a computational method to verify if a polynomial is a sum of squares of other polynomials, a property directly linked to stability conditions (e.g., ensuring the Lie derivative of a candidate Lyapunov function is non-positive). Crucially, the problem of determining if a polynomial is SOS can be exactly formulated as an SDP [27]. This transformation allows the search for polynomial Lyapunov functions or the verification of stability conditions to be cast as computationally tractable SDP feasibility or optimization problems [14,17].  

Beyond stability analysis, SDP provides a powerful framework for Controller Synthesis. The design of controllers for nonlinear systems, aiming to achieve desired performance and stability, can be reformulated as an SDP or LMI problem for certain system classes or via suitable approximations and transformations [14,17,27]. This approach allows researchers to determine controller parameters by solving a convex optimization problem, efficiently solvable using interior-point methods. Various control objectives and constraints, such as H-infinity performance or bounds on control inputs, can be systematically incorporated into the optimization formulation through LMI constraints [17].​  

A particularly significant application of SDP is in Robust Control Design, where the goal is to guarantee system performance and stability in the presence of uncertainties, a common challenge in practical and data-driven scenarios [3,17]. Robust optimization techniques, heavily reliant on SDP and LMI formulations, provide a systematic methodology to handle different types of uncertainties, ensuring desired properties hold across an entire set of possible system variations [14,17,27]. While many robust control problems directly yield LMI forms, more complex formulations involving nonlinear matrix equality constraints can be addressed using advanced techniques like Sequential Semidefinite Programming (SSDP) [3]. This allows SDP-based methods to tackle a broader range of robust control synthesis problems, including those arising in strategies like robust gain-scheduling.​  

In summary, SDP provides a unifying convex framework that underpins significant advancements in model-based nonlinear control theory by enabling the systematic analysis of stability, the synthesis of controllers, and the design of robust control strategies through computationally tractable optimization problems [3,14,17,27]. These applications leverage the ability of SDP and LMI to represent complex system properties and control objectives as convex constraints.  

# 5.1 SDP-Based Stability Analysis  

Lyapunov stability analysis constitutes a cornerstone technique for guaranteeing the stability of dynamic systems, particularly nonlinear ones. The core principle involves finding a scalar function, known as a Lyapunov function, whose properties along the system trajectories indicate stability. A fundamental challenge in applying this method to nonlinear systems lies in the difficulty of constructing or finding a suitable Lyapunov function.  

![](images/27bc2c5dff8d04e50480a2704b22bc0bac0c9e4b7e19c4c08b65fe386c96f0cf.jpg)  

For systems described by polynomial dynamics, the search for polynomial Lyapunov functions can be significantly streamlined and automated through the application of Sum-of-Squares (SOS) programming [27].  

SOS programming provides a computational method to determine if a given polynomial is a sum of squares of other polynomials. This capability is directly applicable to verifying stability conditions derived from Lyapunov theory. Specifically, conditions like the decrease of the Lyapunov function along system trajectories ( $\dot { V } ( x ) \leq 0$ ) can be formulated as a requirement that certain polynomials (derived from the Lie derivative of the candidate Lyapunov function) are SOS. A key advantage of the SOS approach is its tractability: determining if a polynomial is an SOS can be exactly formulated as a Semidefinite Program (SDP) [27]. This transformation allows the problem of finding polynomial Lyapunov functions to be cast as an SDP feasibility problem or an optimization problem over the coefficients of the Lyapunov function candidate and the SOS decomposition polynomials.​  

The power of SDP extends beyond finding Lyapunov functions to directly formulating and solving stability conditions for dynamic systems. Stability criteria can often be expressed as Linear Matrix Inequalities (LMIs), which are a specific class of convex optimization problems efficiently solvable using SDP techniques, particularly interior-point methods [14]. This approach enables rigorous stability analysis, including for uncertain dynamic systems, by formulating conditions that guarantee stability under parameter variations as SDP problems [17]. By transforming the stability analysis problem into an SDP, researchers can leverage powerful convex optimization solvers to obtain verifiable stability certificates.  

Integrating data-driven models into this framework is possible when these models exhibit certain structural properties amenable to SOS/SDP analysis. If a data-driven model results in polynomial dynamics or can be bounded by polynomial inequalities, the SOS/SDP methodology can be applied directly to analyze the stability of the data-driven model itself or the stability of the closed-loop system when this model is used within a control scheme. While the application to purely nonpolynomial or highly complex data-driven models may require approximations or alternative techniques, the SOS/SDP framework provides a robust method for stability analysis when the dynamics can be represented or bounded in a polynomial form, formulating these analyses as solvable SDP problems [17].​  

# 5.2 SDP-Based Controller Synthesis  

Designing a controller for a dynamic system fundamentally involves determining controller parameters such that the closedloop system achieves desired performance characteristics while maintaining stability. For certain classes of nonlinear systems, or through appropriate system transformations and relaxations, the problem of synthesizing controllers can be reformulated as a convex optimization problem, specifically a Semidefinite Program (SDP) or a problem involving Linear Matrix Inequalities (LMIs) [14,17]. The tractability of solving SDPs numerically via efficient interior-point methods makes this approach attractive for controller design.  

Research has explored the application of SDPs for controller synthesis, particularly for systems subject to uncertainty [17]. In this context, SDP formulations are employed to design controllers that can guarantee stability and performance not just for nominal parameters, but across a range of possible system parameter variations [17]. This robust control design is a key area where the convex nature of SDPs provides a powerful framework. The structure of SDP allows for the systematic incorporation of various control objectives, such as H-infinity performance for disturbance rejection or H2 performance for noise attenuation, as well as constraints on system inputs or states, directly into the optimization problem [17]. By formulating these requirements as LMI constraints, the problem becomes finding controller gains or parameters within the convex set defined by these constraints.​  

Furthermore, convex optimization techniques, including convex relaxations, have been explored in related control design problems such as mixed-integer predictive control, which is a form of controller synthesis, and the design of robust global power and ground networks, which can be viewed as an optimization problem with control implications [14]. These applications underscore the versatility of convex optimization in addressing complex design challenges in control and related engineering domains.​  

A significant consideration in controller synthesis is the complexity of the controller structure itself, such as comparing static feedback (constant gain) versus dynamic feedback (involving internal dynamics). The choice of controller structure directly influences the complexity of the resulting SDP formulation. More complex dynamic controllers typically lead to larger and potentially more intricate SDPs. Analyzing the specific trade-offs between the structural complexity of the controller and the computational complexity of solving the corresponding SDP is crucial for practical implementation, although detailed analyses of these trade-offs were not explicitly covered in the provided digests. The ability to encode control objectives and constraints as LMI/SDP conditions remains a central advantage of this approach for robust and performance-oriented controller synthesis.​  

# 5.3 SDP-Based Robust Control Design  

In the realm of data-driven control, the imperative to design controllers robust to uncertainties and disturbances is particularly pronounced. These uncertainties are often inherent, arising from modeling errors or noise within the data used for system identification or control design [6]. Robust control methodologies address this challenge by aiming to guarantee stability and performance not just for a nominal system, but for all possible systems within a defined set representing the uncertainties.​  

A common approach to formulating such robust control objectives is through convex optimization, particularly utilizing Semidefinite Programming (SDP) or Linear Matrix Inequalities (LMIs) [3,17]. Robust optimization techniques provide a systematic framework for handling various types of uncertainties, including parametric and unstructured forms. By casting the control design problem as an SDP or LMI, it becomes possible to ensure desired system properties hold across the entire uncertainty set [17]. Foundational work in applying robust linear programming and optimal control, leveraging techniques like SDP, has provided essential frameworks for designing controllers resilient to model uncertainties [14]. Furthermore, tools like generalized Chebyshev bounds derived via SDP offer valuable means for quantifying and managing uncertainty, complementing the design process [14].​  

While many robust control problems can be directly transcribed into LMI form, complexities such as nonlinear constraints may necessitate more advanced techniques. Sequential Semidefinite Programming (SSDP) is one such method designed to tackle robust control design problems that involve optimizing a linear objective function subject to a combination of LMI constraints and nonlinear matrix equality constraints [3]. This sequential approach broadens the class of problems amenable to SDP-based solutions and is particularly relevant in advanced control strategies like robust gain-scheduling, where such constraint structures frequently arise [3].  

# 6. Integrated Data-Driven Control Architectures using SDP  

Addressing the challenges of controlling complex, often nonlinear systems where precise analytical models are unavailable necessitates novel approaches. Data-driven methods leverage empirical data to inform control decisions, while Semidefinite Programming (SDP) provides a powerful framework for solving convex optimization problems that arise in control synthesis and analysis, particularly for guaranteeing properties like stability and performance. Integrated data-driven control architectures combine these paradigms to harness the strengths of each, aiming to overcome their individual limitations— such as the lack of formal guarantees in purely data-driven approaches or the reliance on accurate models in traditional SDP-based methods.  

![](images/0407858d92787c4641ea2b5a85cd14ac350acdd2e523735ba495ee7d9428dd75.jpg)  

his section explores various architectural paradigms where data-driven techniques are synergistically combined with SDP.  

One prevalent architecture involves a two-step process: first, identifying a data-driven model of the nonlinear system from observed data, and subsequently designing a controller for this identified model using SDP. Data-driven models, such as those based on system realization techniques or lifted linear representations like the Koopman operator [14], can provide tractable approximations of complex dynamics. Control synthesis for these models can then be formulated as convex optimization problems, frequently solvable via SDP or Linear Matrix Inequalities (LMIs). A critical aspect of this approach is managing the inherent uncertainty in data-driven models. Robust SDP techniques offer a mechanism to design controllers that provide performance or stability guarantees despite bounded modeling errors, although the explicit integration of datadriven uncertainty characterization with robust SDP remains an active area of research, distinct from some direct data-tocontrol or data-driven parameter tuning strategies observed in the literature [6,16,22].​  

A second major architectural theme integrates SDP directly within data-driven learning algorithms, such as Adaptive Dynamic Programming or Reinforcement Learning, or utilizes SDP as a tool for post-learning analysis and certification. In this context, SDP is employed to enforce desirable properties during the learning process or to formally verify them afterward. For instance, SDP can be used to search for Lyapunov functions to certify stability or to check conditions related to safety certificates derived from learned value functions or policies [6]. Furthermore, constraints related to stability, safety [6], or performance can be formulated as SDP constraints embedded within the learning objective [6]. This approach is particularly powerful for providing theoretical guarantees, including probabilistic safety assurances for stochastic systems, potentially leveraging chance-constrained SDP formulations [6]. SDP has also been applied as a tool for certifying properties in other data-driven estimation or manipulation tasks [9,19].  

A third category encompasses direct data-to-SDP approaches, where control decisions are made by solving SDPs formulated directly based on measured data, potentially bypassing explicit system dynamics modeling. This paradigm often aligns with data-driven optimal control methods, such as data-driven extensions of LQR or Model Predictive Control. SDP can be used to directly compute optimal feedback gains or solve finite-horizon optimization problems based on system data, ensuring constraint satisfaction and optimality criteria are met in a data-driven fashion.  

These integrated architectures offer distinct advantages. Model-first approaches provide a structured design framework and leverage established robust control theory but depend on the quality and suitability of the data-driven model for SDP synthesis. Integrating SDP within learning offers strong theoretical guarantees but can add computational complexity to the learning process. Direct data-to-SDP methods offer model-free advantages but may face challenges in generalization and interpretability. Comparing the strengths, weaknesses, and applicability of these architectures—along with addressing key challenges such as scalability, real-time implementation, and the explicit incorporation of data uncertainty into SDP formulations—is crucial for advancing the field of data-driven control for nonlinear systems.​  

# 6.1 Controller Synthesis with Data-Driven Models and SDP  

A significant approach in controlling complex nonlinear systems involves first leveraging system data to construct a tractable model and subsequently synthesizing a controller for this model using powerful convex optimization techniques such as Semidefinite Programming (SDP). This paradigm offers a structured path to control design, particularly when analytical models are challenging to obtain. The efficacy of this method hinges on selecting data-driven model structures that inherently lend themselves to control synthesis formulations solvable via SDP, typically by transforming the problem into Linear Matrix Inequalities (LMIs). For instance, representing nonlinear systems locally or globally through Linear Fractional Transformations (LFTs) is a classic technique that facilitates the direct application of LMI-based control design methods, as LFTs allow embedding system uncertainties or nonlinearities within a structured linear framework. Similarly, advancements in Koopman operator theory have enabled the lifting of nonlinear system dynamics to higher-dimensional spaces where they evolve linearly [2,15]. These lifted linear models can then potentially be used within an LMI/SDP framework for designing linear controllers in the lifted space, which translate to nonlinear controllers in the original space.  

A critical challenge in this approach is the inevitable inaccuracy of data-driven models, which are only approximations of the true nonlinear system. Controllers designed based on these approximate models may perform poorly or even destabilize the actual system. To mitigate this, techniques are employed to ensure robust performance on the original nonlinear system. Robust SDP methods, which can explicitly account for bounded uncertainties in the system model, are conceptually well-suited for designing controllers that are resilient to modeling errors derived from data. By formulating the control synthesis problem as a robust LMI/SDP, it is possible to guarantee performance or stability margins for a range of possible models encompassing the uncertainty introduced during the data-driven identification phase.​  

While the concept of combining data-driven system modeling with SDP-based controller synthesis is theoretically compelling and supported by the structure of models like LFTs and Koopman representations [2,15], the provided literature digests illustrate related but often distinct data-driven control strategies. Some approaches bypass explicit system model identification altogether, designing controllers directly from data through optimization. For example, one method uses data to derive a closed-loop representation and designs a controller by solving an optimization problem to minimize state variance subject to safety constraints, crucially achieving this without identifying an explicit system model [6]. This contrasts with the process of first modeling the system dynamics and then designing a controller for that model. Other methods focus on data-driven tuning or learning of controller parameters rather than modeling system dynamics for subsequent SDP design. A neural network, for instance, can be used to learn dynamic PID gains that are directly applied in the control law, potentially augmented by fuzzy logic, without involving SDP in the synthesis process from a system model [16]. Furthermore, while optimization algorithms like Bi-objective SQP for nonlinear SDP could be utilized in data-driven control pipelines, their description in available digests focuses on the algorithmic solution rather than the integrated data-driven modeling and control synthesis process [18]. Similarly, techniques like LyNMPC optimize control inputs by minimizing cost functions, sometimes using general optimization solvers like "fmincon" in MATLAB and employing dynamic gains, but the descriptions do not indicate the use of SDP based on an identified data-driven system model [22]. This suggests that while data plays a crucial role in various modern control techniques for nonlinear systems, the specific pathway of fitting a datadriven system dynamics model suitable for SDP synthesis and explicitly addressing the resulting model uncertainty via robust SDP is a particular specialization within the broader field, distinct from direct data-to-control or data-driven tuning methods presented in some literature.​  

# 6.2 SDP for Stability/Safety Guarantees in Data-Driven Learning  

Providing theoretical guarantees, such as stability and safety, for controllers learned from data presents a significant challenge. These controllers often lack explicit model structures, making traditional formal analysis difficult.  

![](images/9c538fcbe1720af96e6071a1ff9d5cc41cfe792fcd4bd3ef152f7e9506cf7bc0.jpg)  

Semidefinite programming (SDP) offers a powerful framework to address this challenge, serving both as a certification too and as a method for embedding guarantees directly into the learning process.  

SDP can be utilized as a certification tool to formally verify desired properties of a learned controller or system behavior. A common approach involves searching for Lyapunov functions, which are central to certifying stability. While Lyapunovbased methods are established for stability analysis [22], in a data-driven context SDPs can be formulated to search for quadratic or polynomial Lyapunov functions based on observed data. Similarly, SDPs can be used to certify properties of learned value functions or control policies by checking certain positive definiteness conditions related to performance or safety certificates [6].​  

Furthermore, SDPs can be integrated into the data-driven learning process itself. This involves formulating the learning objective or updates as optimization problems with SDP constraints. These constraints are designed to enforce stability, safety, or other desired closed-loop properties during both the training phase and subsequent deployment. This ensures that the learned controller adheres to critical performance boundaries [6].  

A crucial application area for SDP in data-driven control is providing probabilistic safety guarantees, particularly relevant for stochastic nonlinear systems. Methods incorporating probabilistic safety constraints often leverage chance-constrained SDP formulations [6]. For instance, a minimum-variance approach can be employed to minimize the risk of violating safety constraints by reducing the variance of the closed-loop system's state relative to a defined safe set [6]. This type of approach, potentially formulated via SDP, can achieve probabilistic properties such as $\lambda$ -contractivity, which guarantees stability and state confinement within a given safe set, for example, a polyhedral region [6]. By embedding these probabilistic guarantees directly through SDP constraints, data-driven controllers can operate reliably in uncertain environments.​  

# 6.3 Data-Driven LQR and Optimal Control via SDP  

Extending classical optimal control techniques, such as the Linear Quadratic Regulator (LQR), to a data-driven setting is a significant area of research for systems where a precise parametric model is unavailable. Traditional LQR design relies on known system matrices (A and B), whereas data-driven approaches leverage observed system behavior directly. Research in this domain focuses on adapting LQR principles to utilize data for control synthesis. For example, approaches include direct adaptive learning methods for LQR controllers [15]. Furthermore, studies explore regularization techniques specifically tailored for covariance parameterization within direct data-driven LQR control frameworks [15]. These direct methods aim to synthesize optimal feedback gains using system data, potentially bypassing explicit model estimation.​  

Semidefinite Programming (SDP) serves as a convex optimization tool widely used in optimal control synthesis. In the context of data-driven LQR and optimal control, SDP can be employed to derive feedback gains that satisfy optimality conditions or stability guarantees informed by data. Moreover, SDP formulations are particularly well-suited for solving finite-horizon optimal control problems, such as those encountered in Model Predictive Control (MPC). When applied to data-driven models or directly to control synthesis, SDP can be utilized within the MPC optimization loop to determine optimal control actions over a prediction horizon, inherently handling state and input constraints. The convex nature of SDP problems allows for efficient and reliable computation of solutions, which is advantageous for real-time control implementation, ensuring constraint satisfaction and achieving performance objectives in data-driven settings.​  

# 7. Robustness and Uncertainty Handling in Data-Driven SDP Control  

The design of robust controllers is critically important in data-driven control of nonlinear systems due to the inherent challenges posed by model approximations derived from finite data, as well as the presence of noisy or incomplete measurements [4,21]. Data-driven models are inevitably subject to errors, and real-world data is often corrupted by disturbances and noise, necessitating control strategies that can maintain desired performance and stability despite these uncertainties.​  

![](images/b2fc7a4f0a268e3ae92ba162d0a193cddc2177b9810faf2a86e3c02ab349c9a5.jpg)  

Different types of uncertainties are represented mathematically depending on their nature. Bounded uncertainties, such as bounded parameter errors in identified models, are typically modeled within specified uncertainty sets. For instance, robust optimization techniques, including robust semidefinite programming (SDP), are specifically designed to handle such uncertainties by seeking solutions that remain feasible or optimal for all possible realizations of the uncertain parameters within a defined set [17]. This approach guarantees performance in the worst-case scenario within the uncertainty set [17]. Control synthesis methods employing LMI constraints and sequential SDP also contribute to achieving robust control solutions against system uncertainties [3].​  

Probabilistic uncertainties, such as stochastic noise distributions in data or process disturbances, require different techniques. Chance-constrained SDP is a powerful tool for handling uncertainties with known or estimated probability distributions [6]. This method ensures that system constraints are satisfied with a high probability, rather than guaranteeing satisfaction for all possible uncertainty realizations. For example, a probabilistic safe controller can be designed to guarantee a certain level of safety despite the presence of noise and uncertainties in the system, often by minimizing metrics like the variance of system states [6].​  

Beyond robust SDP and chance-constrained approaches, other data-driven methods enhance robustness by directly addressing specific uncertainty sources. Measurement noise, which can be non-stationary and heteroscedastic, can be handled by embedding a noise model within recursive identification algorithms. For instance, a recursive generalized least squares (RGLS) algorithm can be used, where the noisy output  

$$
\backslash ( y \_ { \mathrm { { t e x t } } \{ \mathsf { n o i s e } \} ( \mathsf { k } ) \setminus \big ) }
$$  

is related to the true output $\backslash ( \mathsf { f } ( \mathsf { u } , \mathsf { y } , \mathsf { k } ) \backslash )$ and noise $\backslash ( w ( \boldsymbol { \mu } ) \backslash )$ by  

$$
\begin{array} { r } { \backslash ( \mathsf { y } _ { - } \backslash \mathsf { t e x t } \{ \mathsf { n o i s e } \} ( \mathsf { k } ) = \mathsf { f } ( \mathsf { u } , \mathsf { y } , \mathsf { k } ) + \mathsf { w } ( \mathsf { k } ) \backslash ) , } \end{array}
$$  

and the noise itself is modeled, e.g., as an AR process  

$$
\langle ( \langle h a t \{ w \} ( k ) = - \langle s \mathsf { u m \_ } \{ i = 1 \} \wedge \{ \mathsf { n \_ c } \} \mathsf { c \_ i } \backslash \mathsf { h a t } \{ w \} ( k \mathrm { - i } ) \vee \mathsf { [ 7 ] } .
$$  

Another strategy involves using adaptive elements to compensate for uncertainties or unmeasured states. Adaptive highgain observers can estimate unmeasured states and relax requirements like known Lipschitz constants on nonlinear  

dynamics, with the adaptive gain providing robustness to uncertainties [13]. The observer dynamics might be given by a set of equations such as:​  

$$
\begin{array} { r l } & { \dot { \hat { x } } _ { 1 } = \hat { \theta } _ { 1 } ^ { T } \varphi _ { 1 } ( x _ { 1 } ) + \hat { x } _ { 2 } + l _ { 1 } r ( t ) \left( y - \hat { x } _ { 1 } \right) } \\ & { \dot { \hat { x } } _ { i } = \hat { \theta } _ { i } ^ { T } \varphi _ { i } ( \hat { \bar { x } } _ { i } ) + \hat { x } _ { i + 1 } + l _ { i } r ^ { i } ( t ) \left( y - \hat { x } _ { 1 } \right) , \quad i = 2 , \dots , n - 1 } \\ & { \dot { \hat { x } } _ { n } = \hat { \theta } _ { n } ^ { T } \varphi _ { n } ( \hat { \bar { x } } _ { n } ) + g ( u ( t ) ) + l _ { n } r ^ { n } ( t ) \left( y - \hat { x } _ { 1 } \right) } \\ & { \dot { r } = \phi ( r , y ) } \end{array}
$$  

where $\mathsf { \backslash } ( \mathsf { r } ( \mathsf { t } ) \backslash )$ is the adaptive high-gain [13]. Similarly, using neural networks to approximate unknown system dynamics is a common approach to handle model uncertainty, where the adaptation of neural weights, governed by update laws like $\backslash ( \backslash \mathsf { d o t } \{ \backslash \mathsf { t i l d e } \{ \mathsf { W } \} \} = \backslash \mathsf { G a m m a } \backslash , \mathsf { S } ( \mathbb { Z } ) \backslash , \mathsf { z \_ 2 - } \backslash \mathsf { s i g m a } \backslash , \backslash \mathsf { G a m m a } \backslash , \backslash \mathsf { h a t } \{ \mathsf { W } \} \backslash ) ,$  

contributes to robustness [11]. Model-free adaptive control techniques also incorporate robustness mechanisms, such as parametric gain (PG) estimation that changes with input/output to reduce disturbance impact [12], or using time-varying pseudo-partial derivatives (PPD) to guarantee robustness against external disturbances [10]. Data pre-processing techniques like truncated singular value decomposition can also be applied to handle external disturbances and measurement noise, improving the robustness of subsequent model identification [25]. Uncertainty quantification methods based on moment propagation equations offer ways to estimate uncertainty associated with system states [2].​  

Comparing the effectiveness and computational complexity of robust SDP and chance-constrained SDP in a data-driven context reveals distinct trade-offs. Robust SDP provides strong, worst-case guarantees for bounded uncertainties, ensuring feasibility and performance for al uncertainties within a specified set [17]. This level of guarantee can sometimes lead to conservative control designs. Chance-constrained methods, on the other hand, offer probabilistic guarantees, which can be less conservative but require knowledge or estimation of probability distributions [6]. The computational complexity of both approaches depends heavily on the size of the system, the complexity of the uncertainty description (set structure or probability distribution), and the specific SDP solver used. While robust optimization formulations can increase the size of the resulting SDP, chance constraints often require approximations or sample-based methods to convert the probabilistic constraints into deterministic equivalents (like convex constraints or a series of deterministic constraints), which can also impact computational burden. Detailed comparisons of their effectiveness and computational cost in the context of datadriven nonlinear control synthesis via SDP are areas of ongoing research, and explicit comparative studies on these specific data-driven SDP-based robustness methods are not extensively detailed in the provided digests. Other robustnessenhancing methods, like adaptive observers, neural network approximation, or model-free adaptive control techniques, offer alternative ways to handle uncertainties and disturbances, often tailored to specific system structures or types of uncertainty, with varying computational profiles and performance characteristics.​  

# 8. Computational Aspects and Scalability  

A primary challenge in applying data-driven control methods, particularly those formulated as Semidefinite Programs (SDPs), lies in their significant computational cost and scalability limitations. Solving SDPs is inherently computationally intensive, with the complexity typically increasing polynomially with the dimension of the matrix variables and the number of constraints. This becomes a critical bottleneck when dealing with high-dimensional nonlinear systems or problems requiring real-time implementation. The scalability challenge is pronounced when applying these methods to complex scenarios, such as high-dimensional quantum optical circuit inverse design, where computation times vary with the dimension and depth of the circuit [9]. For instance, acquiring a transfer matrix in one study took approximately 1 minute on a specific GPU setup, and finding optimal phase patterns for higher-dimensional circuits required up to 1 minute, illustrating the dependency on problem size. Similarly, in other data-driven nonlinear control contexts, such as Nonlinear Model Predictive Control (NMPC) using general optimization solvers like "fmincon," computational complexity can be a significant limitation, especially for high-dimensional systems [22]. Determining parameters for complex models like neural networks and fuzzy logic can also be computationally expensive [10].  

<html><body><table><tr><td>Challenge</td><td>Description</td><td>Tractability Techniques</td></tr><tr><td>High Computational Cost</td><td>SDP solving is intensive (polynomial complexity)</td><td>Exploit structure (sparsity), Decomposition methods</td></tr><tr><td></td><td></td><td></td></tr></table></body></html>  

<html><body><table><tr><td>Scalability Limitations</td><td>Inefficient for high- dimensional systems, real- time needs</td><td>Sparse regularization, Logarithmic barriers, ROM</td></tr><tr><td>Curse of Dimensionality</td><td>State/Input space grows exponentially</td><td>Multiple model approaches (partitioning relevant spaces)</td></tr><tr><td>Real-Time Implementation</td><td>Requires fast computation</td><td>Sequential SDP (SSDP) with good convergence, Efficient solvers</td></tr><tr><td>Numerical Stability</td><td>Potential for issues (e.g., non-positive definite covariance)</td><td>Use stable algorithms (e.g., RGLS), Low-order models</td></tr><tr><td>Optimization Complexity</td><td>Non-convexities,local optima in training</td><td>Sequential solving (SQP for Nonlinear SDP), Efficient updates</td></tr></table></body></html>  

To enhance the tractability of data-driven SDP control for larger systems, researchers explore various techniques aimed at reducing computational burden. One approach involves exploiting problem structure, such as sparsity. Methods for sparse regularization have been investigated to improve computational efficiency in related optimization problems [24]. Techniques utilizing logarithmic barriers for sparse matrix cones have been proposed to improve the scalability of SDP solvers [14]. Decomposition methods, such as those for sparse matrix nearness problems, can also contribute to reducing the computational cost of large-scale SDPs [14].  

Approximations and relaxations constitute another category of methods to improve scalability. While not always directly applied to the final SDP formulation itself, techniques that reduce the complexity of the underlying system representation or control problem can significantly reduce the size and complexity of the subsequent optimization. Model-order reduction, focusing on achieving accurate low-complexity models [2], is a relevant strategy, with fast methods being developed for this purpose [8]. Similarly, employing multiple model approaches that partition input ranges to reduce the number and complexity of local models can decrease computational complexity compared to methods like Piecewise Affine (PWA) models [5]. Control design techniques like Dynamic Surface Control (DSC) avoid the "explosion of complexity" by using filters to bypass repeated differentiation, reducing computational load in backstepping-like methods [13]. Within the optimization domain, computationally tractable robust counterparts can be obtained or well-approximated for certain problem classes like linear, conic quadratic, and semidefinite programming, aiding practical application [17].​  

Sequential solving techniques are particularly relevant for optimizing performance or achieving specific control objectives iteratively via SDPs. Sequential Semidefinite Programming (SSDP) is a method that offers global and fast local convergence properties akin to sequential quadratic programming (SQP) [3]. The implementation of SSDP is facilitated by readily available SDP solvers, suggesting a reasonable level of computational feasibility for this approach [3]. While some sequential methods like the bi-objective SQP method focus on convergence properties through numerical experiments [18], SSDP is explicitly highlighted for its utility in robust control design via sequential SDPs [3]. Standard interior-point methods are known efficient algorithms for solving SDPs in general [27], and specialized solvers are being developed that can provide high-accuracy optimality certificates for large-scale problems [19].​  

Other computational considerations include the stability of numerical algorithms, such as using low-order models to avoid non-positive definite covariance matrices that can cause unstable predictions [7]. Efficient parameter update rules, such as the RGLS algorithm which updates only relevant parameters [7], and modified recursive least squares for faster learning [16], also contribute to computational efficiency.  

Despite advancements, computational complexity remains a significant concern. While some methods acknowledge this as a limitation [1,16,25], detailed analyses of computational complexity or specific techniques for improvement are not always provided [1,16,25]. Future research efforts are specifically directed towards reducing the computational complexity of algorithms used in data-driven control, such as those for controllability verification [1]. Addressing these computational and scalability challenges is crucial for expanding the applicability of data-driven SDP control to more complex and realistic nonlinear systems, especially those requiring real-time performance.​  

# 9. Applications and Case Studies  

The practical relevance and effectiveness of data‐driven methods and semidefinite programming (SDP) in controlling nonlinear systems are demonstrated across a diverse array of engineering and scientific domains. These approaches are particularly well‐suited for scenarios involving complex nonlinearities, uncertainties, and critical safety or performance constraints [6].​  

<html><body><table><tr><td>Domain</td><td>Examples / Key Applications</td></tr><tr><td>Robotics/Autonomous Systems</td><td>Robotic Needle Interventions (IMFAC), Manipulator Control (FLM, RLM, PID-Fuzzy)</td></tr><tr><td>Chemical/Process Control</td><td>Batch Polymerization Reactor (LyNMPC), Cascade Gold Leaching (ICFDL-MFAC)</td></tr><tr><td>Aerospace</td><td>Quadrotor UAV (LyNMPC), Model Reduction (Aerothermoelasticity, Von Karman Beam)</td></tr><tr><td>Power Systems</td><td>Optimal Power Flow (SDP Relaxations), PMSM Control (Intelligent Control)</td></tr><tr><td>Brain Network Control</td><td>Optimal Input Node Selection, Effective Connectivity Estimation, DCM</td></tr><tr><td>Vehicle Networks</td><td>Connected/Autonomous Vehicles (Data- driven ADP), Car-Following(∈- controllability)</td></tr><tr><td>Imaging/Quantum Systems</td><td>Medical Image Processing(Al/Optimization), Computational Imaging, Quantum Control/Certification</td></tr><tr><td>Other Engineering</td><td>Filter Design, Circuit Optimization, Robust Optimization (Truss, Antenna)</td></tr></table></body></html>  

Applications are observed in domains including Robotics and Autonomous Systems, Chemical and Process Control, Aerospace, Power Systems, Brain Network Control, Vehicle Networks, and emerging areas like advanced imaging and quantum systems.​  

Robotics and Autonomous Systems: Data‐driven and optimization‐based methods address challenging control problems in robotics. A case study on robotic needle interventions demonstrates the use of the Incremental Model‐Free Adaptive Control (IMFAC) algorithm integrated with event prediction to prevent adverse events like needle buckling and tissue displacement [10]. Tested on simulated nonlinear systems and real‐world insertions in gelatin and biological tissues, this approach achieved a $9 5 \%$ success rate in preventing adverse events through adaptive and reactive control [6]. For manipulators, both flexible‐link (FLMs) and rigid‐link (RLMs), various control techniques reviewed in literature implicitly cover numerous applications [23]. Specifically, simulation results for a flexible‐joint manipulator show that an integrated PID‐type learning and fuzzy control approach can satisfy stringent transient and steady‐state performance requirements [16]. Certifiable outlier‐robust geometric perception, relevant for autonomous robotics, has been showcased in applications like scan matching, satellite pose estimation, and vehicle pose and shape estimation [19].  

Chemical and Process Control: Data‐driven control techniques are applied to complex industrial processes. The LYNMPC‐ based nonlinear three‐mode controller has been used in case studies involving a batch polymerization reactor and a quadrotor UAV (also relevant to Aerospace) [22]. For the batch reactor, the objective was maintaining temperature along a desired profile [22]. Another example is the application of a pure data‐driven Incremental Characteristic Model Following Adaptive Control with Dynamic Linearization (ICFDL‐MFAC) algorithm to a cascade gold leaching process [12]. This approach, verified through practical industrial process tests, demonstrated effectiveness and advantages, and is noted for its applicability to other multi‐input multi‐output industrial processes. Data‐driven modeling methods have also been verified through experiments on systems like a sloshing tank [8].  

Aerospace: Beyond the quadrotor example [22], applications in aerospace include model‐order reduction for complex dynamics such as hypersonic aerothermoelasticity and reduced‐order dynamics for high‐dimensional finite‐element models like the Von Kármán Beam [2,8]. Robust optimization, often leveraging SDP, is applicable to aerospace structures like truss topology design [17].  

Power Systems: SDP finds specific applications in power systems. Reduced‐complexity semidefinite relaxations have been explored for optimal power flow problems [14]. Intelligent control methods, which can be data‐driven, are applied to Permanent Magnet Synchronous Motors (PMSM) for tasks such as reference tracking, servo control, and energy loss minimization [21].  

Brain Network Control: Applications in brain network analysis leverage data‐driven approaches for understanding and potentially controlling neural activity. This includes the optimal selection of input nodes to control target brain regions, estimation of effective connectivity using brain partitioning, and sparse Dynamic Causal Modeling (DCM) for whole‐brain effective connectivity from resting‐state fMRI data [15]. Research also investigates dynamic brain networks with prescribed functional connectivity [15]. While SDP is not explicitly mentioned in relation to brain control in the provided digest, optimization techniques are fundamental to these problems.​  

Vehicle Networks: Data‐driven robust adaptive dynamic programming has been specifically applied to the adaptive optimal control of connected autonomous and human‐operated vehicles [4]. In scenarios involving V2V communication, control objectives include minimizing distance and velocity errors and optimizing fuel usage, considering constraints like range‐limited communication and input saturation. Online learning control in traffic micro‐simulations (e.g., Paramics) demonstrates the effectiveness of this data‐driven approach. Data‐driven methods are also used for system analysis, such as examining the ε‐controllability of states in a car‐following system using the MECS algorithm [1]. This analysis showed that the degree of controllability increases with ε.  

Imaging and Quantum Systems (Emerging Fields): Although not always framed as control, data‐driven and advanced computational techniques are transformative in fields like imaging and quantum information. Workshops have highlighted applications in medical image processing, including the use of AI algorithms and weakly supervised segmentation methods [24]. Computational imaging techniques, including computational optical imaging, non‐line‐of‐sight imaging, optical synthetic aperture imaging, and synchrotron radiation scanning imaging, demonstrate significant performance breakthroughs compared to traditional methods by leveraging advanced data processing and modeling. In quantum systems, programmable optical circuits are used for manipulating and certifying high‐dimensional spatially entangled two‐photon states, implementing various quantum gates [9].​  

Other Engineering and Optimization Domains: SDP's versatility is evident in other areas, such as filter design and circuit optimization, including optimizing the dominant time constant in RC circuits [14]. Robust optimization methodologies, often employing SDP, find applications in antenna design and stability analysis and synthesis in uncertain dynamic systems [17]. A case study on linear programs from the NETLIB collection demonstrated how robust optimization mitigates the impact of small data perturbations on solution feasibility. Sequential SDP (SSDP) is utilized for robust control design, validated with test examples that compare its performance against alternative optimization methods [3]. Furthermore, data‐driven methods contribute to modeling benchmark chaotic systems like the Lorenz oscillator [2] and general NARMAX systems [25], demonstrating effectiveness and superiority in system identification. Experimental validation of online neuro‐ fuzzy modeling has been performed on a commercial automotive engine and via numerical examples, including a nonlinear system described by  

$\begin{array} { r } { \operatorname { y } [ \bigotimes | \bigotimes | \bigotimes | \bigotimes | \bigotimes ( | \mathrm { k } + 1 ) = 0 . 7 2 \operatorname { y } ( \mathrm { k } ) + 0 . 0 2 5 \operatorname { y } ( | \mathrm { k } - 1 ) \mathrm { u } ( | \mathrm { k } - 1 ) + 0 . 0 1 \mathrm { u } ^ { 2 } ( | \mathrm { k } - 2 ) + 0 . 2 \mathrm { u } ( | \mathrm { k } - 1 ) + \mathrm { w } ( | \mathrm { k } ) , } \end{array}$ where  

$$
\mathsf { w } ( \mathsf { k } ) = ( \boldsymbol { 1 } / ( 1 + 0 . 1 1 \boldsymbol { z } ^ { \wedge } ( - 1 ) ) ) \cdot \mathsf { v } ( \mathsf { k } )
$$  

and ${ \mathsf v } ( { \mathsf k } )$ is random noise [7]. This demonstrates the ability to capture new operational conditions under noise.  

These diverse case studies and applications underscore the broad applicability and proven effectiveness of data‐driven and SDP‐based techniques in tackling the complexities of nonlinear systems across numerous scientific and engineering disciplines. The use of simulations and physical experiments across many studies further validates their practicality [5,6,7,10,11,12].​  

# 10. Challenges and Future Directions  

Applying data-driven control methodologies coupled with Semidefinite Programming (SDP) for complex nonlinear systems presents several significant challenges for researchers and practitioners. A primary obstacle lies in the inherent limitations related to data. The quality, quantity, and representativeness of the available data directly impact the accuracy of the identified models and, consequently, the performance and robustness of the resulting controllers [2,7]. Dealing with noisy data requires the development of novel algorithms that do not necessitate extensive prior knowledge or complex noise handling mechanisms [2,7]. Furthermore, addressing plant-model mismatch, which arises when the real system dynamics deviate from the data-derived model, remains a critical issue, often requiring extensive experimental tuning to achieve satisfactory performance [12,22]. Challenges also extend to scenarios involving cross-domain data, where statistical distribution shifts between training and deployment environments complicate analysis and require robust adaptation techniques [24].​  

Another major impediment is the computational burden associated with solving large-scale SDPs, particularly when dealing with high-dimensional systems [9,18,27]. The curse of dimensionality can render standard SDP solvers inefficient or intractable for complex problems [5]. Developing efficient algorithms for solving nonlinear SDPs is essential to make these methods practical for real-time control applications [18]. Computational complexity is also a challenge in tasks like datadriven controllability verification, where reducing the algorithm's computational load is a recognized necessity [1]. Furthermore, some data-driven modeling techniques, such as those based on Recurrent Neural Networks, can suffer from local convergence issues during training, necessitating computationally intensive global optimization strategies [25].  

Providing rigorous theoretical guarantees for data-driven controllers remains challenging compared to traditional modelbased designs [1]. While model-based methods often leverage established frameworks for stability, robustness, and performance analysis, data-driven approaches derived solely from observational data frequently lack such formal guarantees. This is compounded by the challenges of handling disturbances and observation noise within the theoretical framework [1]. Non-convexities introduced by specific problem formulations, such as nonlinear matrix equality constraints in robust control design, further complicate theoretical analysis and algorithm design [3].  

<html><body><table><tr><td>Category</td><td>Key Challenges</td><td>Future Directions</td></tr><tr><td>Data Limitations</td><td>Quality, Quantity, Representativeness, Noise, Cross-domain shifts,</td><td>Novel noise handling, Address plant-model mismatch,Robust</td></tr><tr><td>Computational Burden</td><td>High cost of large SDPs, Scalability for high-dim/real- time, Curse of Dim.</td><td>Efficient/specialized SDP solvers, Exploit structure/sparsity, ML</td></tr><tr><td>Theoretical Guarantees</td><td>Rigorous guarantees (stability, robustness, performance) from data, Noise effects</td><td>Develop formal frameworks (stability, robustness, controllability from data)</td></tr><tr><td>Problem Complexity</td><td>Non-convexity, Handling various constraints, Complex system properties</td><td>Address non-convexities (SSDP), Integrate constraints, Extend to complex systems</td></tr><tr><td>Practical Aspects</td><td>Experimental tuning, Hardware implementation</td><td>Optimize implementation (platforms, circuits), Close simulation-reality gap</td></tr></table></body></html>  

Based on these challenges, several promising future research avenues emerge. A critical area involves developing novel, more efficient, or specialized SDP solvers tailored for the structures arising in data-driven control problems [18]. This could involve exploiting sparsity, developing decomposition methods, or integrating machine learning for warm-starting or constraint handling. Exploring deeper integrations with machine learning techniques offers significant potential, such as using deep learning for advanced data representation, feature extraction, or even generating structured constraints for SDPs [24]. Hybrid approaches that strategically combine data-driven insights with partial model knowledge could leverage the strengths of both paradigms, potentially leading to more robust and interpretable controllers while reducing reliance solely on data or potentially inaccurate models [3,23]. Further research is needed to develop adaptive strategies that enhance robustness and performance in the face of uncertainties [16]. Extending the theoretical framework to provide rigorous guarantees for stability, robustness, and performance for data-driven systems, including analysis of canonical forms, is crucial [1,20]. This includes developing methods to explicitly account for disturbances and noise [1,2,7]. Extending the applicability of data-driven SDP methods to a wider range of complex nonlinear system properties, such as switched systems, time delays, distributed systems, and systems operating under varied conditions or requiring prediction of adverse events, represents another vital direction [3,10,21]. Addressing stronger nonlinearities in data-driven model reduction and finding optimal complexity bounds are also important for practical implementation [8]. Finally, addressing practical implementation challenges, such as finding suitable physical platforms and optimizing specific circuit designs, remains essential for translating theoretical advancements into real-world applications [9].  

# 11. Conclusion  

This survey has explored the significant advancements at the intersection of data-driven methodologies and Semidefinite Programming (SDP) for the control of complex nonlinear systems. The core finding is the synergistic benefit derived from combining the data-exploiting capabilities of the former with the rigorous analytical and synthesis power of the latter, offering a compelling approach to overcome the inherent challenges of controlling systems where explicit dynamic models are unavailable or intractable. The field demonstrates substantial progress across several key areas.​  

In the domain of data-driven modeling, researchers have developed various techniques to identify and represent nonlinear system dynamics directly from data. Approaches include unsupervised identification frameworks leveraging concepts like the time-varying Koopman operator and subspace identification methods [2]. Neuro-fuzzy models have been advanced for learning dynamic systems, including methods for online parameter updating to adapt to time-varying conditions [7]. Neural network-based methods, such as duplex neurodynamic learning, have shown effectiveness in identifying discrete-time nonlinear systems subject to disturbances and noise [25]. Furthermore, data-driven model reduction techniques using spectral submanifolds enable efficient analysis of high-dimensional nonlinear systems [8]. Multiple model approaches have also been proposed to handle the complexity of nonlinear system identification by partitioning input ranges [5].  

SDP, recognized for its broad applicability in convex programming and control theory [27], provides a powerful framework for system analysis and controller synthesis, particularly for problems that can be cast as Linear Matrix Inequalities (LMIs). Techniques like Sequential Semidefinite Programming (SSDP) have been developed to tackle robust control synthesis problems involving both LMI and nonlinear matrix equality constraints, offering favorable convergence properties [3]. While standard SDP focuses on convex problems, methods like SQP for nonlinear semidefinite programming address more general optimization challenges relevant to control design [18]. Robust Optimization (RO), closely related to SDP in handling uncertainty, has also been effectively applied to overcome feasibility issues in real-world optimization problems [17].​  

The integration of data-driven techniques and optimization, often involving principles amenable to SDP-based analysis, has led to sophisticated control strategies for nonlinear systems. Data-driven adaptive control schemes, including neuro-fuzzy approaches, have been designed to address complex issues like asymmetric output constraints and input saturation in strict-feedback systems, demonstrating semi-global uniformly ultimately bounded performance [13]. Model-free adaptive control strategies have been successfully applied to challenging processes with constraints, such as cascade gold leaching [12]. Data-driven robust adaptive dynamic programming shows promise for real-world applications like connected vehicles, operating without explicit models [4]. Risk-informed data-driven safe control designs have been proposed for stochastic uncertain nonlinear systems, minimizing state variance for safety assurance with high confidence [6]. Novel controllers like those derived from LyNMPC frameworks or neural PID based on deterministic learning leverage data-driven insights for adaptation and compensation of nonlinearities, simplifying tuning and improving performance [11,22]. Model-free approaches integrating learning and fuzzy control have also proven effective for complex systems like flexible-joint manipulators [16]. The development of theoretical tools, such as ​ϵ -controllability concepts and algorithms for data-driven systems, further supports the rigorous design of controllers [1].  

Despite significant progress, several challenges persist, requiring continued research. These include ensuring robustness and safety guarantees in the presence of uncertainties and disturbances, particularly in safety-critical applications [6,10]. Handling various constraints (input, output, state) within data-driven, optimization-based frameworks remains a key  

challenge [12,13]. The theoretical foundation for analyzing fundamental properties like controllability and stability directly from data or within data-driven closed-loop systems needs further development [1]. Scalability to high-dimensional systems and the computational efficiency of real-time implementation, especially for optimization-based methods, also present ongoing hurdles.  

The synergistic field of data-driven control enhanced by Semidefinite Programming and related optimization techniques is poised for significant future impact. As data availability increases and computational power grows, these methods will become increasingly vital for controlling the complex, interconnected systems characteristic of modern automation, artificial intelligence, and diverse engineering applications. Continued research addressing the identified challenges will be crucial for unlocking the full potential of this powerful paradigm.  

References​   
[1] 数据驱动控制系统可控性检验：微域可控性理论与MECS算法 https://blog.csdn.net/TongLiu1/article/details/143928703​   
[2] Data-Driven Modeling for Dynamical Systems: Analys https://etda.libraries.psu.edu/catalog/29967djg76​   
[3] Robust Control Design via Sequential Semidefinite  http://dx.doi.org/10.1137/s0363012900373483​   
[4] 数据驱动的鲁棒自适应动态规划及其在车联网中的应用 https://math.ecnu.edu.cn/seminardetail.html?xqid $\mathbf { \tau } = \mathbf { \dot { \tau } }$ 2399   
[5] Data-Driven Nonlinear System Identification and Co http://lsc.amss.cas.cn/xsbg/201507/t20150721_300320.html   
[6] Risk-Informed Data-Driven Safe Control for Stochas https://www.sciengine.com/doi/10.1109/JAS.2024.124479   
[7] Online Neuro-Fuzzy Modeling for Dynamic Systems wi https://link.springer.com/article/10.1007/s11071-024-09360-x   
[8] Fast Data-Driven Model Reduction for Nonlinear Dyn https://link.springer.com/article/10.1007/s11071-022-08014-0​   
[9] 高维量子光路逆向设计：复杂介质中的可编程纠缠操控 https://www.nature.com/articles/s41567-023-02319-6​   
[10] Model-Free Control for Autonomous Prevention of Ad https://www.frontiersin.org/journals/robotics-and  
ai/articles/10.3389/frobt.2023.1271748​   
[11] Deterministic Learning-Based Neural PID Control fo http://ieee-jas.net/article/doi/10.1109/JAS.2024.124224​   
[12] Model-Free Adaptive Control for Constrained Gold L https://pubs.acs.org/doi/10.1021/acsomega.2c06830?   
articleRef=test​   
[13] Output-Constrained Adaptive Control for Nonlinear  https://www.ieee-jas.net/article/doi/10.1109/JAS.2020.1003524​   
[14] Lieven Vandenberghe - Publications http://www.seas.ucla.edu/\~vandenbe/publications​   
[15] Alessandro Chiuso's Publications https://dblp.uni-trier.de/pid/79/4515.html​   
[16] Integrated PID-Fuzzy Control for Flexible-Joint Ma https://link.springer.com/article/10.1023/A:1007942528058​   
[17] Robust Optimization: Methodology and Applications https://link.springer.com/article/10.1007/s101070100286​   
[18] Bi-Objective SQP Method for Nonlinear Semidefinite   
https://www.applmath.com.cn/jweb_yysxxb_en/CN/10.1007/s10255-022-1081-9​   
[19] Tsinghua-BIMSA Applied Mathematics Seminars https://ymsc.tsinghua.edu.cn/info/1053/1723.htm​   
[20] 西安成功举办数据驱动的非线性与随机动力学及控制国际研讨会 https://math.nwpu.edu.cn/info/1129/15577.htm   
[21] Intelligent Control for PMSM-Based Energy Systems https://sites.ji.sjtu.edu.cn/ido/advanced-control2017/   
[22] LyNMPC-Based Nonlinear Three-Mode Controller for N https://pubs.acs.org/doi/10.1021/acsomega.2c05542​   
[23] Control Techniques for Flexible and Rigid Link Man http://dx.doi.org/10.1017/S0263574720000223​   
[24] 计算调和分析与超分辨率成像研讨会 http://tianyuan.amss.ac.cn/ztyt/info/2024/145119.html   
[25] 黄翔博士成果：基于双重神经动力学学习的非线性系统建模方法被IEEE TSMC录用   
http://imds.aia.hust.edu.cn/info/1041/2953.htm​   
[26] Haller Group: Data-Driven Nonlinear Dynamics Resea http://www.georgehaller.com/​   
[27] Semidefinite Programming: A Preview https://link.springer.com/article/10.1007/BF02614431​   
[28] 验证：你是机器人吗？ https://www.sciencedirect.com/science/article/pii/S0005109809002179​  