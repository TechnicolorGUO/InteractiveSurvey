# A Survey of All-in-One Image Restoration

# 1 Abstract


The field of image restoration has seen significant advancements, driven by the increasing demand for high-quality images in various applications such as digital photography, medical imaging, and video processing. This survey paper focuses on recent developments in all-in-one image restoration, particularly emphasizing multi-expert adaptive selection, non-parametric and contextualized multi-task learning, and degradation-aware models. The main findings include the effectiveness of adapter modules in multi-task tuning, the benefits of localized structured prediction and content-boundary contexts in multi-task learning, and the role of hierarchical and feature-transform models in handling diverse degradations. The paper also highlights the importance of contrastive and degradation-driven learning techniques in enhancing the discriminative power of prompts and improving model adaptability. Finally, the survey identifies the most promising directions for future research, aiming to provide a valuable resource for researchers and practitioners in the field of image restoration and multi-task learning.

# 2 Introduction
The field of image restoration has seen significant advancements in recent years, driven by the increasing demand for high-quality images in various applications such as digital photography, medical imaging, and video processing [1]. Traditional single-task models, which are designed to handle specific types of image degradations, often struggle to generalize across a wide range of tasks and degradation types [2]. This limitation has led to the development of all-in-one image restoration models, which aim to address multiple tasks and degradation types within a unified framework [3]. These models leverage advanced techniques such as multi-task learning, self-supervised pre-training, and adapter modules to improve their performance and adaptability. The integration of these techniques not only enhances the model's ability to handle diverse and complex degradation scenarios but also reduces the computational and storage costs associated with maintaining multiple single-task models [4].

This survey paper focuses on the recent advancements in all-in-one image restoration, with a particular emphasis on multi-expert adaptive selection, non-parametric and contextualized multi-task learning, and degradation-aware models [5]. The paper aims to provide a comprehensive overview of the current state of the art, highlighting the key techniques and methodologies that have been developed to address the challenges of multi-task image restoration [4]. By synthesizing insights from various studies and experimental results, the paper seeks to identify the most effective approaches and highlight areas for future research.

The survey begins by exploring the role of adapter modules in multi-task image restoration [4]. These modules are designed to introduce task-specific parameters that can be efficiently tuned without significantly increasing the overall model size. The paper discusses the design of adapter modules, including the classification of parameters based on gradient variations and the modular and interpretable nature of these adapters. It also delves into the integration of self-supervised pre-training and fine-tuning, which enable models to handle multiple tasks efficiently. The pre-training phase initializes the model with a strong understanding of image structures and degradation patterns, while the fine-tuning phase adapts the model to specific tasks using task-specific components. The paper further examines lightweight adapters, which facilitate rapid task adaptation and reduce computational overhead.

Next, the survey explores non-parametric and contextualized multi-task learning approaches. These methods leverage localized structured prediction and the integration of content and boundary contexts to enhance the model's ability to generalize across different tasks. Localized structured prediction focuses on the localized nature of image degradation and the structured relationships within image patches, while multi-task learning with content and boundary contexts captures both high-level semantic information and fine-grained structural details [6]. The paper also discusses gradient-guided parameter masking, which dynamically adjusts parameters to handle different weather conditions efficiently [7].

The survey then shifts to degradation-aware all-in-one restoration models, which include hierarchical and feature-transform models, as well as contrastive and degradation-driven learning techniques [5]. Hierarchical models, such as tree-structured representations, capture the intrinsic relationships between different degradation types, facilitating a more robust and adaptable restoration process. Feature transform blocks and degradation-related gating mechanisms are introduced to address domain gaps and align feature distributions across different degradation domains. Contrastive learning and degradation-aware prompt state space models are also discussed, highlighting their role in enhancing the discriminative power of prompts and improving the model's ability to handle multiple degradations.

Finally, the survey examines unified multi-task networks for specific degradations, such as spatial and frequency domain processing and multi-branch recurrent networks. These networks incorporate large receptive field spatial attention and frequency attention mechanisms to capture long-range dependencies and contextual information, which are crucial for tasks like deraining and low-light enhancement. Efficient and lightweight network designs, such as the Cross-stitched Multi-task Unified Dual Recursive Network (CMUDRN), are also discussed, emphasizing their ability to achieve state-of-the-art results while maintaining a small space and time footprint [8].

The contributions of this survey paper include a comprehensive overview of the key techniques and methodologies in all-in-one image restoration, a detailed analysis of the strengths and limitations of these approaches, and insights into the most promising directions for future research [9]. By synthesizing the latest advancements in the field, this survey aims to provide a valuable resource for researchers and practitioners working on image restoration and multi-task learning [10].

# 3 Multi-Expert Adaptive Selection for Image Restoration

## 3.1 Parameter-Efficient Tuning and Generalizability

### 3.1.1 Adapter Modules for Multi-Task Tuning
Adapter modules have emerged as a critical component in the design of multi-task learning frameworks, particularly in the context of image restoration. These modules are designed to introduce task-specific parameters that can be efficiently tuned without significantly increasing the overall model size. By leveraging a small set of additional parameters, adapter modules enable the model to adapt to the unique characteristics of each task while maintaining the benefits of shared knowledge across tasks. This approach not only enhances the model's performance on a diverse set of tasks but also ensures that the model remains computationally efficient and deployable in real-world scenarios.

The design of adapter modules involves a careful balance between the common parameters that capture general features and the task-specific parameters that address the unique requirements of each task. In the context of multi-task image restoration, this is achieved by classifying parameters based on the magnitude of gradient variations induced by the training data for each task [4]. Common parameters, which capture general features consistent across all tasks, are shared and updated during training, while task-specific parameters are adapted to the unique characteristics of each task. This dual-parameter approach helps mitigate the risk of overfitting, especially in scenarios with limited data, by leveraging the complementary information provided by the common parameters.

Furthermore, the integration of adapter modules into the multi-task learning framework facilitates a modular and interpretable approach to image restoration [4]. The modular nature of these adapters allows for the flexible incorporation of new tasks or the adaptation of the model to unseen degradations without the need for retraining the entire model from scratch. This adaptability is particularly valuable in dynamic environments where the types of image degradations may vary over time. By enabling efficient fine-tuning, adapter modules not only enhance the model's performance but also reduce the computational and storage costs associated with maintaining multiple single-task models, thereby advancing the state of the art in multi-task image restoration [4].

### 3.1.2 Self-Supervised Pre-Training and Fine-Tuning
Self-Supervised Pre-Training and Fine-Tuning is a pivotal approach in the development of All-in-One frameworks for image restoration, enabling models to handle multiple tasks efficiently without significant retraining [3]. In the pre-training phase, the model is trained on a large, unlabeled dataset using self-supervised learning techniques. These techniques often involve generating synthetic degradations and their corresponding clean images, allowing the model to learn robust and generalizable features that are applicable across various restoration tasks [11]. The pre-training phase is crucial as it initializes the model with a strong understanding of the underlying image structures and degradation patterns, which serves as a solid foundation for subsequent fine-tuning.

During the fine-tuning phase, the pre-trained model is adapted to specific restoration tasks by introducing task-specific components, such as lightweight adapters or specialized layers [4]. These components are designed to capture the unique characteristics of each task while leveraging the shared knowledge acquired during pre-training. This approach significantly reduces the amount of labeled data required for fine-tuning and accelerates the convergence of the model to optimal performance on each task [12]. The use of task-specific components also helps in mitigating the risk of catastrophic forgetting, where the model might lose previously learned knowledge when trained on new tasks.

The effectiveness of self-supervised pre-training and fine-tuning lies in its ability to balance the trade-off between generalization and specialization. By pre-training on a diverse set of synthetic degradations, the model develops a broad understanding of image restoration principles [11]. Subsequent fine-tuning with task-specific components allows the model to specialize in particular tasks without losing its generalization capabilities. This dual-phase training strategy not only enhances the model's performance on individual tasks but also improves its adaptability to new, unseen degradations, making it a versatile solution for multi-task image restoration [4].

### 3.1.3 Lightweight Adapters for Task Adaptation
Lightweight adapters have emerged as a promising solution for task adaptation in deep learning models, particularly in scenarios where the deployment of large, pre-trained models is constrained by computational resources. These adapters are small, task-specific modules that are inserted into the pre-trained model to enable rapid adaptation to new tasks without the need for extensive retraining. By focusing on a subset of parameters, adapters can efficiently capture the nuances of new tasks while leveraging the robust, general features learned by the pre-trained model. This approach not only reduces the computational overhead associated with fine-tuning large models but also mitigates the risk of catastrophic forgetting, where the model unlearns previously acquired knowledge.

The architecture of lightweight adapters typically involves adding a few additional layers, such as linear transformations or feed-forward networks, at strategic points within the pre-trained model. These layers are designed to modulate the activations of the pre-trained model, allowing it to adapt to the specific characteristics of the new task. For instance, in image restoration tasks, adapters can be placed after convolutional layers to adjust the feature maps according to the type of degradation present in the input images. The training process for these adapters is streamlined, as only the adapter parameters are updated, while the pre-trained model's weights remain fixed. This results in a significant reduction in training time and resource consumption, making the approach highly scalable and practical for real-world applications.

Furthermore, the use of lightweight adapters facilitates a modular and flexible approach to multi-task learning. By inserting different adapters for various tasks, a single pre-trained model can be effectively repurposed to handle a wide range of tasks without the need for retraining the entire model from scratch [4]. This is particularly advantageous in scenarios where the tasks are related but have distinct requirements, such as different types of image restoration tasks (e.g., denoising, deblurring, and super-resolution). The ability to dynamically switch between adapters allows the model to maintain high performance across multiple tasks, thereby enhancing its versatility and adaptability. Additionally, the modular nature of adapters simplifies the integration of new tasks, as only the relevant adapter needs to be trained, further reducing the complexity and cost of model maintenance.

## 3.2 Non-Parametric and Contextualized Multi-Task Learning

### 3.2.1 Localized Structured Prediction for Image Restoration
Localized Structured Prediction (LSP) for image restoration represents a significant advancement in addressing the challenges of multi-task image restoration [6]. This approach leverages the localized nature of image degradation and the structured relationships within image patches to enhance the restoration process [1]. By focusing on local patches, LSP can effectively capture the intricate details and textures that are often lost in traditional, more global approaches. The key innovation lies in the ability to define a learnable prior on these patches, which guides the restoration process by incorporating domain-specific knowledge and constraints. This localized and structured approach not only improves the quality of the restored images but also enhances the generalization capabilities of the model across different types of degradations [13].

In the context of LSP, the restoration process is formulated as an energy minimization problem, where the energy function is designed to balance the fidelity to the observed degraded image and the adherence to the learned prior. The prior is typically learned from a large dataset of high-quality images and is tailored to capture the statistical properties of natural images. This energy function is convex, allowing for exact minimization, which is a significant advantage over non-convex methods that may get stuck in local optima. The use of a convex energy function ensures that the restoration process is both stable and efficient, making it suitable for real-time applications. Moreover, the localized nature of the prior allows the model to adapt to the specific characteristics of different image regions, thereby improving the restoration quality in areas with complex textures or fine details [12].

The integration of non-linear multi-task learning with LSP further enhances the model's ability to handle multiple restoration tasks simultaneously [14]. By sharing a common backbone network and incorporating task-specific modules, the model can efficiently learn the shared representations across different tasks while also adapting to the unique characteristics of each task. This hybrid approach not only reduces the computational and storage overhead but also improves the overall performance by leveraging the synergies between tasks. Extensive experiments on benchmark datasets have shown that this framework outperforms traditional single-task models in terms of both visual quality and quantitative metrics, making it a promising direction for future research in image restoration [10].

### 3.2.2 Multi-Task Learning with Content and Boundary Contexts
Multi-Task Learning (MTL) with Content and Boundary Contexts represents a significant advancement in the field of image restoration, particularly in addressing the limitations of single-task models [15]. This approach leverages the synergistic benefits of learning multiple tasks simultaneously, thereby enhancing the model's ability to generalize across a variety of image restoration tasks [10]. By integrating content and boundary contexts, the model can capture both the high-level semantic information and the fine-grained structural details of images, which are crucial for tasks such as super-resolution, denoising, and deblurring. The key innovation lies in the design of a shared feature extraction module that captures common features across different tasks, while task-specific sub-networks handle the unique aspects of each task. This dual architecture ensures that the model can effectively learn from a diverse set of tasks without compromising the performance on individual tasks [14].

The integration of content and boundary contexts in MTL is achieved through a deep joint contextualized learning framework. This framework incorporates three types of image components: the base image content, the boundary map, and the residual map. The base image content captures the overall structure and semantic information, while the boundary map focuses on the edges and contours that define the boundaries between different regions in the image. The residual map, on the other hand, captures the fine details and discrepancies between the input and the desired output, which are essential for high-fidelity restoration. By jointly learning these components, the model can better understand the relationships between different tasks and leverage the shared knowledge to improve the restoration quality. For instance, the boundary map can provide valuable guidance for tasks that require precise edge preservation, such as deblurring, while the residual map can help in refining the details in super-resolution tasks.

Despite the benefits of MTL with content and boundary contexts, the approach introduces additional complexity in terms of model architecture and training. The introduction of multiple task-specific sub-networks and the need to balance the learning of common and task-specific features can lead to increased computational costs and the risk of overfitting. To mitigate these challenges, the model employs a two-phase transfer learning mechanism, where pre-training on a diverse set of tasks helps in learning shareable components, and fine-tuning on specific tasks ensures that the model can adapt to the unique characteristics of each task. This strategy not only improves the model's generalization ability but also reduces the storage costs associated with maintaining multiple single-task models [4]. Overall, the MTL approach with content and boundary contexts represents a promising direction in multi-task image restoration, offering a balance between performance and efficiency.

### 3.2.3 Gradient-Guided Parameter Masking for Weather Restoration
Gradient-Guided Parameter Masking (GGPM) represents a significant advancement in the realm of multi-scenario image restoration under adverse weather conditions [7]. This method leverages the dynamic nature of gradients during the training process to dynamically adjust the parameters used for different restoration tasks. By doing so, GGPM effectively decouples task-specific parameters from shared parameters, thereby reducing the interference that often occurs when a single model is trained to handle multiple types of image degradations simultaneously. The core mechanism of GGPM involves the creation of a mask that selectively activates or deactivates certain parameters based on the gradient flow, allowing the model to focus on the most relevant features for each specific weather condition.

The effectiveness of GGPM lies in its ability to adapt to varying weather conditions without the need for extensive retraining or additional parameters. This is achieved through a sophisticated analysis of the gradient changes during the training phase, which helps in identifying the parameters that are most crucial for specific tasks such as rain removal, snow clearing, or haze reduction [7]. By partitioning the model parameters into shared and task-specific components, GGPM ensures that the model can generalize well across different weather scenarios while maintaining high restoration quality. This approach not only enhances the model's performance but also significantly reduces the computational overhead, making it suitable for real-time applications where rapid and accurate image restoration is essential.

Moreover, GGPM addresses the limitations of existing methods that are typically optimized for single weather conditions, leading to suboptimal performance when applied to diverse weather scenarios. By integrating the insights gained from gradient analysis with the flexibility of parameter masking, GGPM provides a robust solution that can handle a wide range of image degradations efficiently. The experimental results demonstrate that GGPM outperforms traditional methods in terms of both restoration quality and computational efficiency, paving the way for more advanced and versatile image restoration systems capable of handling complex real-world scenarios.

# 4 Degradation-Aware All-in-One Restoration Models

## 4.1 Hierarchical and Feature-Transform Models

### 4.1.1 Tree-Structured Representation for Multi-Degradation
In the realm of all-in-one image restoration, one of the primary challenges is the effective representation and integration of multiple degradation types within a single model [9]. Traditional approaches often struggle with the complexity and variability of real-world degradations, leading to suboptimal performance when dealing with unseen or mixed degradations [12]. To address this issue, a tree-structured representation has emerged as a promising solution. This hierarchical approach aims to capture the intrinsic relationships between different degradation types, thereby facilitating a more robust and adaptable restoration process [1]. By organizing degradations into a tree-like structure, where nodes represent clusters of similar degradations, the model can progressively refine its understanding of the degradation landscape, starting from broad categories and moving towards finer distinctions [1].

The tree-structured representation leverages clustering algorithms to group degradations based on their visual and statistical characteristics [1]. Each level of the tree corresponds to a varying degree of granularity, allowing the model to first identify the general category of degradation and then focus on specific subtypes. This hierarchical clustering not only simplifies the learning process but also enhances the model's ability to generalize across different degradation scenarios. For instance, at the top level, the tree might distinguish between blurring and noise, while lower levels could further differentiate between Gaussian blur and motion blur, or between salt-and-pepper noise and Gaussian noise. This structured approach ensures that the model can effectively manage the trade-offs between task-specific and shared representations, thereby improving its overall performance and adaptability.

Moreover, the tree-structured representation facilitates the integration of fine-grained degradation features into the restoration process. By encoding the hierarchical relationships between degradations, the model can dynamically adjust its restoration strategy based on the specific degradation present in the input image [13]. This dynamic adjustment is crucial for handling the diverse and often overlapping nature of real-world degradations. Additionally, the tree structure can be used to guide the training process, ensuring that the model learns to prioritize the most relevant features for each degradation type. Experimental results on mixed datasets containing multiple degradation types have demonstrated the effectiveness of this approach, showing significant improvements in both quantitative metrics (such as PSNR and SSIM) and qualitative visual outcomes. Overall, the tree-structured representation provides a powerful framework for advancing the field of all-in-one image restoration.

### 4.1.2 Feature Transform Block for Domain Alignment
The Feature Transform Block (FTB) plays a crucial role in addressing the domain gaps caused by various image degradations in the context of Universal Image Restoration (UIR) [1]. These domain gaps often arise due to the diverse and complex nature of image distortions, which can significantly differ from the clean images used during training. To mitigate this issue, the FTB is designed to integrate the image features extracted from the corrupted input with the corresponding degradation representation, thereby aligning the feature distributions of similar degradations and making them more distinguishable from dissimilar ones. This alignment is essential for the network to effectively generalize across different types of degradations and maintain robust performance.

To achieve this alignment, the FTB incorporates degradation-related layer normalization, which helps in normalizing the feature maps based on the specific degradation type [1]. This normalization process ensures that the feature distributions remain consistent across different degradation domains, thus reducing the domain gap. Additionally, the FTB introduces a degradation-related gating mechanism that dynamically controls the information flow within the restoration network. This gating mechanism allows the network to selectively focus on relevant features while suppressing noise or irrelevant information, leading to more refined and high-quality restored images. The combination of these techniques ensures that the FTB can effectively adapt to various degraded images, enhancing the overall performance of the UIR model.

Extensive experiments have been conducted to validate the effectiveness of the FTB in addressing domain alignment issues. These experiments demonstrate that the FTB not only improves the performance of the UIR model on multi-degradation datasets but also achieves state-of-the-art results. The FTB's ability to refine image features and align them with the corresponding degradation representations is particularly beneficial in scenarios where the degradation types are complex and varied [1]. By integrating the FTB into the UIR framework, the model can better handle the challenges posed by diverse and composite degradations, ultimately leading to more robust and versatile image restoration capabilities.

### 4.1.3 Degradation-Related Gating Mechanisms
Degradation-related gating mechanisms represent a significant advancement in the field of image restoration, particularly in handling multiple degradation types within a unified framework [2]. These mechanisms dynamically adjust the network's behavior based on the specific degradation present in the input image, allowing for more flexible and effective restoration [16]. By incorporating gating units, the model can selectively activate or deactivate certain pathways or parameters, thereby optimizing the restoration process for the detected degradation. This adaptability is crucial in real-world applications where images may suffer from a combination of degradations, such as noise, blur, and low-light conditions, which are often unknown or vary in severity.

Recent approaches have explored various gating mechanisms to enhance the model's ability to handle diverse degradations. For instance, some methods utilize attention mechanisms to focus on specific regions of the image that are most affected by the degradation, allowing the model to allocate more resources to these areas. Other approaches employ conditional normalization techniques, where the normalization parameters are conditioned on the estimated degradation type, enabling the model to adapt its internal representations accordingly. These gating mechanisms not only improve the model's robustness but also reduce the need for extensive retraining or fine-tuning for each new degradation type, making them highly scalable and practical for real-world scenarios.

Despite the advancements, challenges remain in designing gating mechanisms that can accurately and efficiently identify and respond to a wide range of degradation types. One key challenge is the need for robust degradation estimation, which is often a non-trivial task, especially when dealing with complex and mixed degradations. Additionally, the computational overhead associated with these mechanisms can be significant, particularly in real-time applications. Future research is likely to focus on developing more efficient and accurate gating mechanisms, as well as integrating them with other advanced techniques, such as transformer-based models and contrastive learning, to further enhance the performance and generalizability of image restoration systems.

## 4.2 Contrastive and Degradation-Driven Learning

### 4.2.1 Sparse Prompt Module for Disentangled Representations
The Sparse Prompt Module (SPM) is a critical component in our proposed framework, designed to address the challenges of prompt redundancy and misalignment in all-in-one image restoration models [10]. By leveraging a sparse selection mechanism, the SPM ensures that only the most relevant prompts are activated for a given degradation, thereby reducing computational overhead and enhancing the model's efficiency. This approach contrasts with traditional dense prompt mechanisms, which often lead to overfitting and increased inference complexity. The SPM operates by dynamically selecting a subset of prompts that best represent the degradation characteristics of the input image, thus enabling the model to focus on the most salient features and ignore irrelevant information.

To achieve disentangled representations, the SPM employs a novel sparsification technique that encourages the model to learn distinct and orthogonal prompt embeddings for different degradation types. This is crucial for handling composite degradations, where multiple types of distortions are present in a single image. By disentangling the representations, the SPM ensures that the model can effectively isolate and address each degradation component, leading to more accurate and robust restoration results. The sparsification process is guided by a regularization term that penalizes the activation of non-relevant prompts, thereby promoting a sparse and task-specific activation pattern.

Furthermore, the SPM is integrated with a contrastive learning framework to enhance the discriminative power of the prompts. This contrastive learning mechanism explicitly incorporates negative samples during training, ensuring that the model can distinguish between similar but distinct degradation types. By strengthening the boundaries between different degradation representations, the SPM not only improves the model's ability to generalize to unseen degradations but also enhances its overall robustness. This combination of sparse prompt selection and contrastive regularization results in a more efficient and effective all-in-one image restoration model, capable of handling a wide range of degradation scenarios with high accuracy and low computational cost [10].

### 4.2.2 Contrastive Prompt Regularization for Discriminative Power
Contrastive Prompt Regularization (CPR) is a technique designed to enhance the discriminative power of prompts in multi-task image restoration frameworks [10]. Traditional prompt-based methods often suffer from limitations such as coarse prompt design and static input handling, which can lead to suboptimal performance when dealing with diverse and complex degradations [9]. CPR addresses these issues by introducing a mechanism that dynamically adjusts prompts to better align with the specific degradation characteristics of the input images. This dynamic adjustment is achieved through the use of contrastive learning, where the model is trained to distinguish between positive and negative prompt samples. Positive samples are those that accurately represent the degradation, while negative samples are designed to be misleading or irrelevant. By optimizing the model to maximize the distance between positive and negative samples, CPR ensures that the prompts are finely tuned to the task at hand, thereby improving the overall restoration quality.

The core idea behind CPR is to leverage the contrastive learning paradigm to create a robust and adaptive prompt generation process. During training, the model is presented with pairs of images and their corresponding prompts. These prompts are generated based on the degradation characteristics of the images, and the model learns to associate specific prompts with the correct degradation types. The contrastive loss function encourages the model to produce embeddings for positive prompt-image pairs that are closer together in the feature space, while pushing apart the embeddings of negative pairs. This not only enhances the discriminative power of the prompts but also improves the model's ability to generalize to unseen degradations. The result is a more flexible and accurate restoration system that can handle a wide range of degradation scenarios without the need for extensive retraining or manual intervention.

In practice, CPR can be integrated into existing multi-task image restoration frameworks by modifying the prompt generation and embedding modules [10]. The degradation extractor, which is responsible for identifying the type and severity of the degradation, plays a crucial role in this process. By feeding the extracted degradation features into the contrastive learning module, the system can generate prompts that are highly specific to the input image's degradation profile. This fine-grained control over the prompts leads to more precise and effective restoration outcomes. Additionally, CPR helps mitigate the issue of prompt misalignment, which is common in static prompt-based methods. By continuously refining the prompts through contrastive learning, the model can adapt to new and complex degradations, making it a powerful tool for universal image restoration tasks [11].

### 4.2.3 Degradation-Aware Prompt State Space Model
In the realm of image restoration, the Degradation-Aware Prompt State Space Model (DP-SSM) represents a significant advancement in handling multiple degradations within a unified framework [9]. Traditional methods often struggle with the exponential increase in degradation types, necessitating the training of models on a vast number of specific degradation combinations. DP-SSM addresses this challenge by introducing a novel degradation extractor that captures fine-grained degradation features from complex degraded images [9]. These features serve as critical priors, enhancing the model's ability to perform effective restoration across a wide range of degradation types. By integrating these features into the state space modeling process, DP-SSM enables a more nuanced and adaptive approach to degradation modeling, which is essential for improving restoration quality in scenarios with multiple, unknown degradations.

The core of DP-SSM lies in its ability to dynamically adjust the state transition, input, and output matrices of the state space equations based on the extracted degradation features. This dynamic adjustment is crucial for maintaining the integrity of high-frequency details, which are often lost due to task competition among different restoration tasks. The model's hierarchical embedding block (HEB) plays a pivotal role in this process by mitigating the loss of these details and ensuring that the restoration process remains robust and effective. Additionally, DP-SSM incorporates a sparse gated router that aligns prompts with target degradations via contrastive learning, bridging the gap between adaptive and explicit learning paradigms [10]. This mechanism not only enhances the model's ability to capture nuanced degradation characteristics but also ensures that the prompts are accurately and efficiently assigned to the corresponding degradation types, leading to more precise and visually appealing restoration results [10].

Compared to existing methods that rely on coarse prompts or predefined degradation categories, DP-SSM offers a more flexible and comprehensive approach. Traditional methods often fail to capture the full spectrum of degradation characteristics, leading to suboptimal restoration performance, especially in scenarios with multiple, overlapping degradations [1]. DP-SSM, on the other hand, leverages a tree-structured representation to capture the hierarchical relationships between different degradation types, progressively constructing a rich and detailed representation from coarse to fine. This hierarchical approach ensures that the model can effectively handle a wide range of degradation scenarios, from simple to complex, without the need for extensive retraining or manual intervention. Extensive experiments on mixed datasets containing multiple degradation types have demonstrated the superior performance of DP-SSM, making it a promising direction for future research in the field of image restoration [11].

# 5 Unified Multi-Task Networks for Specific Degradations

## 5.1 Spatial and Frequency Domain Processing

### 5.1.1 Large Receptive Field Spatial Attention
Large Receptive Field Spatial Attention (LRFSA) is a critical component in modern convolutional neural networks (CNNs) designed for image restoration and enhancement tasks. Unlike traditional CNNs that rely on local receptive fields, LRFSA mechanisms enable the network to capture long-range dependencies and contextual information across the entire image. This is particularly important for tasks such as deraining, desnowing, and deblurring, where the degradation effects often span large regions of the image [3]. By incorporating LRFSA, the network can effectively model and mitigate these effects, leading to more accurate and visually pleasing results.

The implementation of LRFSA typically involves the use of dilated convolutions or deformable convolutions, which allow the receptive field to be expanded without increasing the number of parameters significantly. Dilated convolutions introduce gaps between the kernel elements, effectively increasing the receptive field size while maintaining a manageable computational cost. Deformable convolutions, on the other hand, allow the sampling locations to be adjusted dynamically based on the input, providing a more flexible and adaptive way to capture spatial dependencies. Both techniques are crucial for enhancing the network's ability to handle complex and varied degradation patterns.

In addition to these architectural enhancements, LRFSA can be further refined through the integration of attention mechanisms. These mechanisms compute attention weights based on the spatial derivatives of the activation maps, which helps the network focus on the most relevant regions for the restoration task. For instance, the amplitude of spatial derivatives (|Ix(c)| and |Iy(c)|) can be used to guide the attention mechanism, ensuring that the network pays more attention to areas with high-frequency details or significant degradation. This not only improves the overall performance but also reduces the computational overhead, making the network more efficient and suitable for real-time applications.

### 5.1.2 Frequency Attention for Low-Light Enhancement
Frequency Attention for Low-Light Enhancement focuses on leveraging the frequency domain to address the challenges associated with low-light image restoration. Traditional methods often struggle with enhancing low-light images due to the presence of noise and the loss of fine details. By operating in the frequency domain, the proposed method can effectively separate the low-frequency components, which carry the overall structure and brightness of the image, from the high-frequency components, which contain the fine details and textures. This separation allows for targeted enhancement of the low-frequency components to boost the overall brightness and contrast of the image, while carefully preserving or enhancing the high-frequency components to maintain or improve the sharpness and clarity of the details.

The core of this approach involves the integration of a frequency attention mechanism within a convolutional neural network (CNN). This mechanism dynamically adjusts the importance of different frequency bands based on the content of the input image. Specifically, the attention mechanism computes attention weights using the amplitude of spatial derivatives of the activation maps, which helps in identifying regions that require more enhancement. By focusing on these regions, the model can apply more aggressive enhancement where needed, while avoiding over-amplification of noise in less critical areas. This adaptive approach ensures that the enhanced image retains a natural appearance and avoids artifacts such as color distortion or excessive noise amplification.

To further improve the performance and efficiency of the model, the frequency attention mechanism is combined with large receptive field attention in the spatial domain. This dual-domain approach allows the model to capture both global and local features effectively. The large receptive field attention helps in addressing issues like non-uniform blur and noise, which are common in low-light images. By integrating these two attention mechanisms, the proposed model, referred to as DarkIR, achieves state-of-the-art results on benchmark datasets for low-light image enhancement. The lightweight design of DarkIR also ensures that it can be efficiently deployed on resource-constrained devices, making it suitable for real-world applications in mobile and embedded systems.

### 5.1.3 Efficient and Lightweight Network Design
Efficient and Lightweight Network Design is a critical aspect of developing unified models for deraining and desnowing tasks, particularly when dealing with large-scale image inputs. Traditional approaches often suffer from high computational costs and large memory footprints, primarily due to the extensive number of parameters required to handle multiple degradation factors effectively. To address these challenges, the Cross-stitched Multi-task Unified Dual Recursive Network (CMUDRN) introduces a novel architecture that balances complexity and performance [8]. By leveraging basic, task-specific, recursive convolutional feature transformations, CMUDRN ensures that the network remains lightweight while maintaining sufficient representational power to tackle the intricate patterns of rain and snow artifacts [8].

The core of CMUDRN lies in its efficient use of dual residual networks, which are designed to enhance the network's ability to learn and generalize across different degradation types. Despite the presence of multiple input and output branches, the shared main body of the network, known as the stem, is optimized to minimize parameter redundancy. This design choice not only reduces the overall computational load but also ensures that the network can be trained efficiently on diverse datasets. The recursive nature of the feature transformations further contributes to the model's efficiency by allowing the network to iteratively refine its outputs, leading to improved performance with minimal additional computational overhead.

Moreover, the CMUDRN architecture is complemented by a series of lightweight components that focus on enhancing specific aspects of the image processing pipeline. For instance, the integration of frequency attention mechanisms and large receptive field attention helps the network to capture both fine-grained details and broader contextual information, crucial for effective deraining and desnowing. These components are designed to work synergistically, ensuring that the network can achieve state-of-the-art results while maintaining a small space and time footprint. This approach stands in contrast to cascaded network designs, which, although potentially powerful, often result in higher memory consumption and computational costs. By focusing on a unified and efficient design, CMUDRN sets a new benchmark for lightweight and high-performance image restoration models.

## 5.2 Multi-Branch Recurrent Networks

### 5.2.1 Recurrent Multi-Task Learning for Progressive Improvement
Recurrent Multi-Task Learning (RMTL) represents a significant advancement in the field of multi-task deep learning, particularly in the context of image restoration tasks such as deraining and desnowing. The core idea behind RMTL is to leverage the shared representations across multiple related tasks to progressively improve the performance of each task. In the CMUDRN architecture, this is achieved through a network that is designed to handle multiple degradation factors simultaneously, such as rain and snow, by integrating task-specific recursive convolutional feature transformations. The network is structured to allow for the cascading application of these transformations, where each iteration refines the output from the previous step, thereby enhancing the overall quality of the restored image.

The training process of the CMUDRN model is divided into two distinct phases to optimize the network's ability to perform multi-task learning effectively. In the first phase, the network is trained in a multitask learning (MTL) framework, where it learns to simultaneously address multiple degradation factors [16]. This initial training phase ensures that the network can capture the shared features and patterns across different tasks, which is crucial for the subsequent fine-tuning phase. During the second phase, the network is fine-tuned to operate in a recurrent manner, allowing it to iteratively refine its output. This recurrent application of the network enables a progressive improvement in the restoration quality, as each iteration builds upon the results of the previous one, gradually reducing the visual artifacts caused by rain and snow.

To further enhance the effectiveness of the RMTL approach, the CMUDRN model incorporates several design innovations. One key innovation is the use of frequency and spatial attention mechanisms, which help the network to focus on the most relevant features for each task. The frequency attention mechanism allows the network to better handle low-frequency components, which are often crucial for removing large-scale artifacts like rain streaks. Meanwhile, the spatial attention mechanism enables the network to adaptively emphasize important regions in the image, such as areas with high levels of noise or blur. These attention mechanisms, combined with the recurrent multi-task learning framework, contribute to the model's ability to achieve high-quality restoration results while maintaining a lightweight and efficient architecture.

### 5.2.2 Enhanced Attention Mechanisms and DuRB-M
In the realm of unified deraining and desnowing tasks, the Cross-stitched Multi-task Unified Dual Recursive Network (CMUDRN) introduces significant advancements through its enhanced attention mechanisms and the novel Dual Recursive Block with Merged operations (DuRB-M) [8]. The attention mechanism in CMUDRN leverages the amplitude of spatial derivatives of activation, denoted as |Ix(c)| and |Iy(c)|, to compute attention weights. This approach allows the network to dynamically focus on regions of the image where the spatial gradients are most pronounced, thereby enhancing the model's ability to capture and process fine details and edges, which are crucial for tasks such as deraining and desnowing.

The introduction of DuRB-M further optimizes the network's efficiency and performance. Unlike the previous designs, DuRB-M fuses the two operations employed in the Dual Recursive Block (DuRB-U) and the Dual Recursive Block with Skip connections (DuRB-US). This fusion not only reduces the computational overhead but also enhances the flow of information across the network layers. By merging these operations, DuRB-M achieves a more streamlined and effective recursive processing of features, which is essential for handling the complex and varied nature of image degradations such as rain and snow. The streamlined architecture of DuRB-M also contributes to the overall lightweight and fast nature of CMUDRN, making it suitable for real-time applications.

Experimental results demonstrate that these enhancements in attention mechanisms and the DuRB-M design significantly contribute to the effectiveness of CMUDRN in unified deraining and desnowing tasks. The attention mechanism's ability to focus on high-gradient regions and the DuRB-M's efficient feature processing enable CMUDRN to achieve state-of-the-art performance while maintaining a lightweight and computationally efficient structure. These improvements address the common drawbacks of existing models, such as excessive memory usage and slow processing times, making CMUDRN a promising solution for real-world applications in computer vision.

### 5.2.3 Efficient Training and Fine-Tuning
Efficient training and fine-tuning are critical aspects of developing lightweight and versatile models for unified deraining and desnowing tasks. In the context of the Cross-stitched Multi-task Unified Dual Recursive Network (CMUDRN), a two-step training methodology is employed to enhance both the efficiency and effectiveness of the model [8]. The first step involves training the network in a multitask learning (MTL) framework, where the model is simultaneously optimized for multiple tasks such as deraining and desnowing [16]. This initial phase leverages the shared feature representations across tasks, enabling the network to learn more generalized and robust features. By employing a multitask loss function, the model can effectively balance the contributions from different tasks, ensuring that the learned features are beneficial for all targeted degradations [14].

In the second step, the network undergoes fine-tuning to adapt to specific use cases or to improve performance on particular tasks. This fine-tuning process is crucial for enhancing the model's ability to handle recurrent operations, where the same network is applied iteratively to refine the output. During fine-tuning, the model is exposed to task-specific data, allowing it to specialize and optimize its performance for the intended application. This approach not only improves the model's accuracy but also ensures that it remains lightweight and computationally efficient, making it suitable for real-time applications. The fine-tuning phase is particularly important for scenarios where the degradation factors are complex or vary significantly, as it allows the model to adapt to these variations without requiring extensive retraining.

To further enhance the efficiency of training and fine-tuning, the CMUDRN incorporates several architectural improvements. For instance, the use of frequency attention and large receptive field attention mechanisms helps the model to capture both spatial and frequency information effectively. These attention mechanisms enable the network to focus on relevant features while reducing the computational load. Additionally, the improved attention mechanism that utilizes the amplitude of spatial derivatives of activation (|Ix(c)| and |Iy(c)|) helps in refining the model's sensitivity to different degradation factors [16]. By integrating these advanced techniques, the CMUDRN achieves state-of-the-art results on benchmark datasets while maintaining a low computational cost, making it a promising solution for real-world deraining and desnowing tasks.

# 6 Future Directions


The current advancements in all-in-one image restoration, while significant, are not without limitations. One of the primary challenges is the model's ability to generalize across a wide range of degradation types and conditions, particularly in scenarios where the training data is limited or the degradation patterns are highly varied. Despite the use of advanced techniques such as multi-task learning, self-supervised pre-training, and adapter modules, models still struggle to maintain robust performance when encountering new or composite degradations. Additionally, the computational and memory efficiency of these models remains a concern, especially when deploying them in real-time applications or on devices with limited resources. The integration of large-scale datasets and the dynamic adjustment of model parameters to handle specific degradation types are areas that require further exploration.

To address these limitations, several directions for future research can be proposed. First, the development of more sophisticated and data-efficient training strategies is essential. This could involve the creation of synthetic datasets that more accurately reflect real-world degradation patterns, as well as the use of semi-supervised and unsupervised learning techniques to leverage unlabeled data. Another promising direction is the exploration of meta-learning approaches, which could enable models to quickly adapt to new tasks with minimal fine-tuning. Meta-learning could be particularly useful in scenarios where the degradation types are diverse and the training data is limited.

Second, the design of more efficient and lightweight architectures is crucial for enhancing the practicality of all-in-one image restoration models. This could involve the development of novel adapter modules that are even more parameter-efficient, as well as the exploration of pruning and quantization techniques to reduce the computational and memory overhead. Additionally, the integration of hardware-specific optimizations, such as those tailored for edge devices, could further improve the efficiency and deployability of these models.

Finally, the potential impact of the proposed future work is significant. By developing more robust, efficient, and adaptable all-in-one image restoration models, researchers can significantly enhance the performance and practicality of image restoration systems. This would have far-reaching implications in various fields, including digital photography, medical imaging, and video processing. Improved image restoration capabilities could lead to better image quality in consumer devices, more accurate and reliable medical diagnoses, and enhanced visual experiences in multimedia applications. Furthermore, the ability to handle a wide range of degradation types with a single model would reduce the need for multiple specialized models, thereby simplifying the deployment and maintenance of image restoration systems.

# 7 Conclusion



This survey has comprehensively reviewed the recent advancements in all-in-one image restoration, focusing on multi-expert adaptive selection, non-parametric and contextualized multi-task learning, and degradation-aware models. Key findings include the effectiveness of adapter modules in introducing task-specific parameters without significantly increasing model size, the benefits of self-supervised pre-training and fine-tuning in enhancing model adaptability, and the role of lightweight adapters in facilitating rapid task adaptation. Additionally, the survey highlights the importance of localized structured prediction and multi-task learning with content and boundary contexts in improving the model's ability to generalize across different tasks. Gradient-guided parameter masking and hierarchical and feature-transform models are also discussed, emphasizing their contributions to handling diverse weather conditions and aligning feature distributions across degradation domains. Contrastive and degradation-driven learning techniques, such as the sparse prompt module and degradation-aware prompt state space models, are shown to enhance the discriminative power of prompts and improve the model's robustness. Finally, the survey examines unified multi-task networks for specific degradations, including spatial and frequency domain processing and multi-branch recurrent networks, which achieve state-of-the-art results while maintaining computational efficiency.

The significance of this survey lies in its comprehensive overview of the current state of the art in all-in-one image restoration, providing a valuable resource for researchers and practitioners. By synthesizing insights from various studies and experimental results, the survey identifies the most effective approaches and highlights areas for future research. The integration of advanced techniques such as multi-task learning, self-supervised pre-training, and adapter modules not only enhances the model's performance and adaptability but also reduces computational and storage costs. This is particularly important in real-world applications where the types of image degradations can vary widely and the need for efficient, deployable solutions is paramount.

In conclusion, the field of all-in-one image restoration is rapidly evolving, driven by the increasing demand for high-quality images in various applications. While significant progress has been made, there are still challenges to overcome, such as handling complex and mixed degradations, reducing computational overhead, and improving the robustness of models in real-world scenarios. Future research should focus on developing more efficient and accurate gating mechanisms, integrating advanced techniques like transformers and contrastive learning, and exploring the potential of unsupervised and semi-supervised learning to further enhance the performance and generalizability of all-in-one image restoration models. We call on the research community to continue pushing the boundaries of this exciting field, contributing to the development of more versatile and effective image restoration solutions.

# References
[1] All-in-one Multi-degradation Image Restoration Network via Hierarchical  Degradation Representation  
[2] Chain-of-Restoration  Multi-Task Image Restoration Models are Zero-Shot  Step-by-Step Universal Imag  
[3] Multi-Expert Adaptive Selection  Task-Balancing for All-in-One Image  Restoration  
[4] AdaIR  Exploiting Underlying Similarities of Image Restoration Tasks  with Adapters  
[5] UIR-LoRA  Achieving Universal Image Restoration through Multiple  Low-Rank Adaptation  
[6] Structured and Localized Image Restoration  
[7] Gradient-Guided Parameter Mask for Multi-Scenario Image Restoration  Under Adverse Weather  
[8] Cross-Stitched Multi-task Dual Recursive Networks for Unified Single  Image Deraining and Desnowing  
[9] DPMambaIR All-in-One Image Restoration via Degradation-Aware Prompt  State Space Model  
[10] Beyond Degradation Redundancy  Contrastive Prompt Learning for  All-in-One Image Restoration  
[11] Controlling Vision-Language Models for Multi-Task Image Restoration  
[12] Navigating Image Restoration with VAR's Distribution Alignment Prior  
[13] Referring Flexible Image Restoration  
[14] DocRes  A Generalist Model Toward Unifying Document Image Restoration  Tasks  
[15] Structure-Preserving Image Super-resolution via Contextualized  Multi-task Learning  
[16] Restoring Images with Unknown Degradation Factors by Recurrent Use of a  Multi-branch Network  