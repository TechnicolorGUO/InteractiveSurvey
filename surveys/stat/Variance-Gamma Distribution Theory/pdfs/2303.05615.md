# The Variance-Gamma Distribution: A Review  

Adrian Fischer,∗ Robert E. Gaunt $\dagger$ and Andrey Sarantsev $\ddag$  

# Abstract  

The variance-gamma (VG) distributions form a four-parameter family which includes as special and limiting cases the normal, gamma and Laplace distributions. Some of the numerous applications include financial modelling and distributional approximation on Wiener space. In this review, we provide an up-to-date account of the basic distributional theory of the VG distribution. Properties covered include probability and cumulative distribution functions, generating functions, moments and cumulants, mode and median, Stein characterisations, representations in terms of other random variables, and a list of related distributions. We also review methods for parameter estimation and some applications of the VG distribution, including the aforementioned applications to financial modelling and distributional approximation on Wiener space.  

Keywords: Variance-gamma distribution; distributional theory; estimation; variance-gamma process; financial modelling; approximation on Wiener space AMS 2010 Subject Classification: Primary 60E05; 62-02; 62E15; 62F10  

# 1 Introduction  

The variance-gamma (VG) distribution with parameters $r > 0$ , $\theta \in \mathbb { R }$ , $\sigma > 0$ , $\mu \in \mathbb { R }$ , denoted by $\mathrm { V G } ( r , \theta , \sigma , \mu )$ , has probability density function (PDF)  

$$
p ( x ) = \frac { 1 } { \sigma \sqrt { \pi \Gamma ( r / 2 ) } } \mathrm { e } ^ { \theta ( x - \mu ) / \sigma ^ { 2 } } \bigg ( \frac { | x - \mu | } { 2 \sqrt { \theta ^ { 2 } + \sigma ^ { 2 } } } \bigg ) ^ { \frac { r - 1 } { 2 } } K _ { \frac { r - 1 } { 2 } } \bigg ( \frac { \sqrt { \theta ^ { 2 } + \sigma ^ { 2 } } } { \sigma ^ { 2 } } | x - \mu | \bigg ) , \quad x \in \mathbb { R } .
$$  

In the limit $\sigma  0$ the support becomes the interval $( \mu , \infty )$ if $\theta > 0$ , and is $( - \infty , \mu )$ if $\theta < 0$ . Here $K _ { \nu } ( x )$ is a modified Bessel function of the second kind; a definition and basic properties that are used throughout the paper are given in Appendix A. The parametrisation (1.1) is taken from Gaunt [36] and is similar to one given by Finlay and Seneta [31]. Alternative parametrisations are given in Bibby and Sørensen [15] and the book of Kotz, Kozubowski and Podg´orski [60], in which they refer to the distribution as the generalized (asymmetric) Laplace distribution. Other names for the VG distribution include the Bessel function distribution (McKay [80]) and the McKay Type II distribution (Holm and Alouini [53]).  

The PDF (1.1) was first written down by Pearson, Jefferey and Elderton [93] as the exact PDF of the sample covariance for a random sample drawn from a bivariate normal population. Further distributional properties and applications were given by McKay [80] and Pearson, Stouffer and David [94]. The flexibility offered by the four parameters and the modified Bessel function of the second kind in the PDF mean that the VG distribution is often well-suited to statistical modelling; for example, Sichel [110] reported that the VG distribution provided an excellent fit when modelling the size of diamonds mined in South West Africa. The VG distribution (in the symmetric case $\theta = 0$ ) was introduced to the financial literature in a seminal work of Madan and  

Seneta [77], and has since become widely used in financial modelling; see, for example, Madan, Carr and Chang [73], Madan and Milne [74] and Seneta [108]. The VG distribution is a special case of the generalized hyperbolic (GH) distribution that is also popular in financial modelling; see, for example, Eberlein and Keller [25], Eberlein and Prause [25] and Rydberg [102]. In addition to its suitability in statistical modelling, the VG distribution has a rich distributional theory with special or limiting cases including the normal, gamma and Laplace distributions, and the product of two zero mean normals and the difference of two independent gammas. In virtue of this, starting with Gaunt [36] and Eichelsbacher and Th¨ale [28], the VG distribution has recently found application in the probability literature as a limiting distribution, most notably in analysis on Wiener space.  

To date, the most comprehensive account of the VG distribution in the literature is given in Chapter 4 of the excellent book of Kotz et al. [60], in which the VG distribution is viewed as a natural generalisation of the classical (asymmetric) Laplace distribution. As the VG distribution is a special case of the GH distribution, distributional properties can be inferred from results for the GH distribution found in, for example, Bibby and Sørensen [15] and Hammerstein [50]. The aforementioned references, however, do not contain even some of the most basic distributional properties of the VG distribution, such as formulas for absolute moments or the mode, and the interested researcher is left to search a rather large and difficult to navigate literature to track down many such results.  

In this review, we fill in a gap in the literature by providing an up-to-date account of the basic distributional theory of the VG distribution. The end result is that many of the most important distributional properties of the VG distribution are now contained in a single reference. Most results are already stated in the literature or can be inferred from the fact that VG distribution is a special case of the GH distribution and appealing to known results for this distribution. For the small number of results that we could not locate in the literature, we provide straightforward and concise derivations.  

This review covers formulas for the PDF (Section 2.1), the cumulative distribution function (Section 2.2), generating functions, infinite divisibility and self-decomposability (Section 2.3), representations in terms of other random variables (Section 2.4), lists of related distributions (Section 2.5), Stein characterisation (Section 2.6), moments and cumulants (Section 2.7), and mode and median (Section 2.8). The review covers some of the most basic and important properties of a probability distribution, but is not comprehensive; for example, we only briefly touch upon multivariate extensions.  

In Section 3, we review methods for parameter estimation for the VG distribution. This section provides a concise overview of a literature that is rather large on account of the popularity of the VG distribution in statistical modelling, particularly in mathematical finance. In Section 4, we provide applications of the VG distribution in several research domains. In Section 4.1, we provide examples in which the VG distribution appears as an exact distribution in connection to sample covariances and Wishart matrices. We review the well-known connection to the variance-gamma process (also referred to as Laplace motion; see for example, Kotz et al. [60]) and financial modelling in Sections 4.2 and 4.3, respectively. We provide an overview of the recent literature concerning application of the VG distribution to time series modelling in Section 4.4. In Section 4.5, we review some of the recent activity in the probability literature in which the VG distribution has arisen as a limiting distribution.  

Notation. To simplify formulae, we define $\lambda _ { \pm } : = ( \sqrt { \theta ^ { 2 } + \sigma ^ { 2 } } \pm \theta ) / \sigma ^ { 2 }$ .  

# 2 Distributional Properties  

# 2.1 Density and parametrisations  

We begin by recalling some other parametrisations given in the literature. The first is given in Finlay and Seneta [31]. For $x \in \mathbb { R }$ ,  

$$
p ( x ) = \sqrt { \frac { 2 } { \pi } } \frac { \alpha ^ { \alpha } \mathrm { e } ^ { \theta _ { 0 } ( x - \mu ) / \sigma _ { 0 } ^ { 2 } } } { \sigma _ { 0 } \Gamma ( \alpha ) } \biggl ( \frac { | x - \mu | } { \sqrt { \theta _ { 0 } ^ { 2 } + 2 \alpha \sigma _ { 0 } ^ { 2 } } } \biggr ) ^ { \alpha - 1 / 2 } K _ { \alpha - 1 / 2 } \biggl ( \frac { \sqrt { \theta _ { 0 } ^ { 2 } + 2 \alpha \sigma _ { 0 } ^ { 2 } } } { \sigma _ { 0 } ^ { 2 } } | x - \mu | \biggr ) .
$$  

It is related to the parametrisation in (1.1) by $r = 2 \alpha$ , $\sigma ^ { 2 } = \sigma _ { 0 } ^ { 2 } / ( 2 \alpha )$ , $\theta = \theta _ { 0 } / ( 2 \alpha )$ . If a random variable has PDF (2.2), we write $X \sim \operatorname { V G } _ { 2 } ( \alpha , \theta _ { 0 } , \sigma _ { 0 } , \mu )$ . Setting $\alpha = 1 / \nu$ gives the parametrisation of Madan et al. [73], and further setting $\theta _ { 0 } = 0$ yields the parametrisation of the (symmeric) VG distribution of Madan and Seneta [77]. Another parametrisation is given in Bibby and Sørensen [15]:  

$$
p ( x ) = \frac { \gamma ^ { 2 \lambda } } { \sqrt { \pi } \Gamma ( \lambda ) } \left( \frac { | x - \mu | } { 2 \alpha } \right) ^ { \lambda - 1 / 2 } \mathrm { e } ^ { \beta ( x - \mu ) } K _ { \lambda - 1 / 2 } ( \alpha | x - \mu | ) , \quad x \in \mathbb { R } ,
$$  

where $\gamma ^ { 2 } = \alpha ^ { 2 } - \beta ^ { 2 }$ , and is related to the parametrisation in (1.1) by $r = 2 \lambda$ , $\theta = \beta / \gamma ^ { 2 }$ , $\sigma = 1 / \gamma$ . Finally, we note the following parametrisation used by Kotz et al. [60]:  

$$
p ( x ) = \frac { \sqrt { 2 } \mathrm { e } ^ { \frac { \sqrt { 2 } } { 2 \sigma _ { 0 } } ( 1 / \kappa - \kappa ) ( x - \mu ) } } { \sigma _ { 0 } ^ { \tau + 1 / 2 } \Gamma ( \tau ) } \bigg ( \frac { \sqrt { 2 } | x - \mu | } { \kappa + 1 / \kappa } \bigg ) ^ { \tau - 1 / 2 } K _ { \tau - 1 / 2 } \bigg ( \frac { \sqrt { 2 } } { 2 \sigma _ { 0 } } \bigg ( \frac { 1 } { \kappa } - \kappa \bigg ) | x - \mu | \bigg ) , \quad x \in \mathbb { R } .
$$  

which is related to the parametrisation in (1.1) by $r = 2 \tau$ , $\theta = \sigma _ { 0 } ( 1 / \kappa - \kappa ) / 2 ^ { 3 / 2 }$ , $\sigma ^ { 2 } = \sigma _ { 0 } ^ { 2 } / 2$ . Henceforth, we shall work mostly with the parametrisation (1.1), with results in the other parametrisations being readily deduced using the above change of parameters.  

The presence of the modified Bessel function in the PDF (1.1) makes it a little difficult to parse on first inspection. The following limiting forms can help in this regard. Suppose $r > 0$ , $\theta \in \mathbb { R }$ , $\sigma > 0$ , $\mu \in \mathbb { R }$ . Using the limiting form (A.64) gives that, as $x \to \mu$ ,  

$$
p ( x ) \sim \left\{ \begin{array} { l l } { \displaystyle \frac { ( 1 + \theta ^ { 2 } / \sigma ^ { 2 } ) ^ { - ( r - 1 ) / 2 } } { 2 \sigma \sqrt { \pi } } \frac { \Gamma \left( ( r - 1 ) / 2 \right) } { \Gamma ( r / 2 ) } , } & { r > 1 , } \\ { \displaystyle - \frac { 1 } { \pi \sigma } \log | x - \mu | , } & { r = 1 , } \\ { \displaystyle \frac { 1 } { ( 2 \sigma ) ^ { r } \sqrt { \pi } } \frac { \Gamma \left( ( 1 - r ) / 2 \right) } { \Gamma ( r / 2 ) } | x - \mu | ^ { r - 1 } , } & { 0 < r < 1 } \end{array} \right.
$$  

(see Gaunt [35]). We see from (2.4) that the PDF has a singularity at the origin for $r \leq 1$ . Moreover, for all parameter values ( $r > 0$ , $\theta \in \mathbb { R }$ , $\sigma > 0$ , $\mu \in \mathbb { R }$ ), the $\mathrm { V G } ( r , \theta , \sigma , \mu )$ distribution is unimodal; further details are given in Section 2.8. The density is bounded for $r > 1$ . Plots of the VG PDF (1.1) that show the effect of varying the shape parameter $r$ (which agree with these assertions) and the skewness parameter $\theta$ are given in Figure 1. Also, applying the limiting form (A.65) to (1.1) gives that (see Gaunt [41])  

$$
\begin{array} { l } { { p ( x ) \sim \displaystyle \frac { x ^ { r / 2 - 1 } } { 2 ^ { r / 2 } ( \theta ^ { 2 } + \sigma ^ { 2 } ) ^ { r / 4 } \Gamma ( r / 2 ) } \mathrm { e } ^ { - \lambda _ { - } ( x - \mu ) } , ~ x  \infty , } } \\ { { { } } } \\ { { p ( x ) \sim \displaystyle \frac { ( - x ) ^ { r / 2 - 1 } } { 2 ^ { r / 2 } ( \theta ^ { 2 } + \sigma ^ { 2 } ) ^ { r / 4 } \Gamma ( r / 2 ) } \mathrm { e } ^ { \lambda _ { + } ( x - \mu ) } , ~ x  - \infty . } } \end{array}
$$  

![](images/486cb9d3f232f4071ce1145aabc8f6629ef0712e39f76d73778b231fff894d7b.jpg)  
Figure 1: The VG PDF for different parameter constellations: $\bullet \mathrm { V G } ( 3 , 0 , 1 , 0 )$ , $\bullet \mathrm { V G } ( 3 , 0 . 5 , 1 , 0 )$ , $\bullet \mathrm { V G } ( 3 , 1 , 1 , 0 )$ (left image) and $\bullet \mathrm { V G } ( 0 . 5 , 1 , 1 , 0 )$ , $\bullet \mathrm { V G } ( 2 , 1 , 1 , 0 )$ , $\boldsymbol { \circ } \mathrm { V G } ( 4 , 1 , 1 , 0 )$ (right image).  

We observe that the tails of the VG distribution are heavier than the tails of the normal distribution. This feature is important in financial modelling and allows for a better fit to real financial data than the normal distribution; see Section 4.3 for further details.  

When $r \in \mathbb { Z } ^ { + } = \{ 1 , 2 , 3 , . . . \}$ is even, we can use a standard simplification of the modified Bessel function of the second kind (see (A.63)) to obtain a formula for the PDF in terms of elementary functions (see Kotz et al. [60], and earlier Teichroew [113] for the case $\theta = 0$ ):  

$$
\begin{array} { l } { \displaystyle { p ( x ) = \frac { | x - \mu | ^ { r / 2 - 1 } } { 2 ^ { r / 2 } ( \theta ^ { 2 } + \sigma ^ { 2 } ) ^ { r / 4 } \Gamma ( r / 2 ) } \exp \left( \frac { \theta } { \sigma ^ { 2 } } ( x - \mu ) - \frac { \sqrt { \theta ^ { 2 } + \sigma ^ { 2 } } } { \sigma ^ { 2 } } | x - \mu | \right) \times } } \\ { \displaystyle { \times \sum _ { j = 0 } ^ { r / 2 - 1 } \frac { ( r / 2 - 1 + j ) ! } { ( r / 2 - 1 - j ) ! j ! } \biggl ( \frac { \sigma ^ { 2 } } { 2 \sqrt { \theta ^ { 2 } + \sigma ^ { 2 } } | x - \mu | } \biggr ) ^ { j } } , \quad x \in \mathbb { R } , r \in 2 \mathbb { Z } ^ { + } . } \end{array}
$$  

It is immediate from (1.1) that the class of VG distributions is closed under affine transformations (see Kotz et al. [60]). Let $X \sim \operatorname { V G } ( r , \theta , \sigma , \mu )$ . Then, for $a \neq 0$ and $b \in \mathbb { R }$ ,  

$$
a X + b \sim \mathrm { V G } ( r , a \theta , | a | \sigma , a \mu + b ) .
$$  

To simplify expressions, we shall sometimes set $\mu = 0$ , with results for the general case $\mu \in \mathbb { R }$ immediately following because $\mu + \mathrm { V G } ( r , \theta , \sigma , 0 ) = _ { d } \mathrm { V G } ( r , \theta , \sigma , \mu )$ (with obvious abuse of notation). We also observe that if $X \sim \operatorname { V G } ( r , \theta , \sigma , \mu )$ then $- X \sim \operatorname { V G } ( r , - \theta , \sigma , - \mu )$ , whilst if $X \sim \operatorname { V G } ( r , 0 , \sigma , 0 )$ then $- X = _ { d } X$ . In line with terminology of Kotz et al. [60], we say that $X \sim \mathrm { V G } ( r , 0 , \sigma , 0 )$ has a symmetric variance-gamma distribution.  

# 2.2 Cumulative distribution function  

A closed-form formula for the cumulative distribution function (CDF) of the VG distribution is not available for general parameter values $r > 0$ , $\theta \in \mathbb { R }$ , $\sigma > 0$ , $\mu \in \mathbb { R }$ . We note some cases for which exact formulas can be given. For $X \sim \operatorname { V G } ( r , \theta , \sigma , \mu )$ , let $F ( x ) = \mathbb { P } ( X \leq x )$ .  

Suppose $\theta = 0$ . Then, by the symmetry of the $\operatorname { V G } ( r , 0 , \sigma , \mu )$ distribution about $x = \mu$ , it follows that $\begin{array} { r } { F ( x ) = 1 / 2 + \mathrm { s g n } ( x ) \int _ { 0 } ^ { | x | } p ( t ) \mathrm { d } t } \end{array}$ , where $\operatorname { s g n } ( x )$ is the sign of $x$ . Calculating the integral using (A.67), gives that, for $x \in \mathbb { R }$ ,  

$$
{ \boldsymbol { \tau } } ( x ) = { \frac { 1 } { 2 } } + { \frac { ( x - \mu ) } { 2 \sigma } } \left[ K _ { { \frac { r - 1 } { 2 } } } \left( { \frac { | x - \mu | } { \sigma } } \right) \mathbf { L } _ { { \frac { r - 3 } { 2 } } } \left( { \frac { | x - \mu | } { \sigma } } \right) + \mathbf { L } _ { { \frac { r - 1 } { 2 } } } \left( { \frac { | x - \mu | } { \sigma } } \right) K _ { { \frac { r - 3 } { 2 } } } \left( { \frac { | x - \mu | } { \sigma } } \right) \right] .
$$  

where $\mathbf { L } _ { \nu } ( x )$ is a modified Struve function of the first kind (see Olver et al. [92, Chapter 11] for a definition and basic properties). Other formulas for the CDF for the case $\theta = 0$ are given by Jankov Maˇsirevi´c and Pog´any [55] and Nadarajah, Srivastava and Gupta [85].  

Now suppose $r \in 2  { \mathbb { Z } } ^ { + }$ and $\theta \in \mathbb { R }$ . Then, making use of the formula (2.7) one readily obtains the following formulas (see Nadarajah et al. [85]). For $x \leq \mu$ ,  

$$
{ \mathrm {  ~ \Psi ~ } } ( x ) = \frac { ( \theta ^ { 2 } + \sigma ^ { 2 } ) ^ { - r / 4 } } { ( 2 \lambda _ { + } ) ^ { r / 2 } ( r / 2 - 1 ) ! } \sum _ { j = 0 } ^ { r / 2 - 1 } \frac { ( r / 2 - 1 + j ) ! } { ( r / 2 - 1 - j ) ! j ! } \biggl ( \frac { \theta + \sqrt { \theta ^ { 2 } + \sigma ^ { 2 } } } { \sqrt { \theta ^ { 2 } + \sigma ^ { 2 } } } \biggr ) ^ { j } \Gamma \biggl ( \frac { r } { 2 } - j , - \lambda _ { + } ( x - \beta ) \biggr ) ,
$$  

and, for $x > \mu$ ,  

$$
F ( x ) = 1 - { \frac { ( \theta ^ { 2 } + \sigma ^ { 2 } ) ^ { - r / 4 } } { ( 2 \lambda _ { - } ) ^ { r / 2 } ( r / 2 - 1 ) ! } } \sum _ { j = 0 } ^ { r / 2 - 1 } { \frac { ( r / 2 - 1 + j ) ! } { ( r / 2 - 1 - j ) ! j ! } } { \Bigg ( } { \frac { \sqrt { \theta ^ { 2 } + \sigma ^ { 2 } } - \theta } { \sqrt { \theta ^ { 2 } + \sigma ^ { 2 } } } } { \Bigg ) } ^ { j } \Gamma { \Bigg ( } { \frac { r } { 2 } } - j , \lambda _ { - } ( x ) { \Bigg ) }
$$  

where $\textstyle \Gamma ( a , x ) = \int _ { x } ^ { \infty } t ^ { a - 1 } \mathrm { e } ^ { - t } \mathrm { d } t$ is the upper incomplete gamma function.  

Let us now return to the general setting $r > 0$ , $\theta \in \mathbb R$ , $\sigma > 0$ , $\mu \in \mathbb { R }$ . Since a closed-form formula is not available for the CDF, asymptotic approximations for the tail probabilities are of interest. Let $F ( x ) = 1 - F ( x ) = \mathbb { P } ( X > x )$ for $X \sim \operatorname { V G } ( r , \theta , \sigma , \mu )$ . Then, using (1.1) and the limiting form (A.69) gives that, as $x \to \infty$ ,  

$$
\bar { F } ( x ) \sim \frac { 1 } { 2 ^ { r / 2 } ( \theta ^ { 2 } + \sigma ^ { 2 } ) ^ { r / 4 } \lambda _ { - } \Gamma ( r / 2 ) } x ^ { r / 2 - 1 } \mathrm { e } ^ { - \lambda _ { - } ( x - \mu ) } ,
$$  

and, by symmetry, as $x \to - \infty$ ,  

$$
F ( x ) \sim { \frac { 1 } { 2 ^ { r / 2 } ( \theta ^ { 2 } + \sigma ^ { 2 } ) ^ { r / 4 } \lambda _ { + } \Gamma ( r / 2 ) } } ( - x ) ^ { r / 2 - 1 } \mathrm { e } ^ { \lambda _ { + } ( x - \mu ) } .
$$  

Upper and lower bounds for $F ( x )$ and $\overline { { F } } ( \boldsymbol { x } )$ can be obtained by using bounds of Gaunt [37, 39] for the integral $\begin{array} { r } { \int _ { x } ^ { \infty } \mathrm { e } ^ { \beta t } t ^ { \nu } K _ { \nu } ( t ) \mathrm { d } t } \end{array}$ , $x > 0$ , $- 1 < \beta < 1$ , $\nu > - 1 / 2$ . As an example, from inequality (2.9) of Gaunt [39] we have that $\begin{array} { r } { \int _ { x } ^ { \infty } \mathrm { e } ^ { \beta t } t ^ { \nu } K _ { \nu } ( \alpha t ) \mathrm { d } t \le ( \alpha - \beta ) ^ { - 1 } \mathrm { e } ^ { \beta x } x ^ { \nu } K _ { \nu } ( \alpha x ) } \end{array}$ , for $x > 0$ , $0 \leq \beta < \alpha$ , $- 1 / 2 < \nu \leq 1 / 2$ , with equality if and only if $\nu = 1 / 2$ , and the inequality is reversed if $\nu > 1 / 2$ . Applying this bound to (1.1) yields that, for $\theta \geq 0$ , $x > \mu$ ,  

$$
\bar { F } ( x ) \leq \frac { \mathrm { e } ^ { \theta ( x - \mu ) / \sigma ^ { 2 } } } { \sigma \sqrt { \pi } \lambda _ { - } \Gamma ( r / 2 ) } \Bigg ( \frac { | x - \mu | } { 2 \sqrt { \theta ^ { 2 } + \sigma ^ { 2 } } } \Bigg ) ^ { \frac { r - 1 } { 2 } } K _ { \frac { r - 1 } { 2 } } \Bigg ( \frac { \sqrt { \theta ^ { 2 } + \sigma ^ { 2 } } } { \sigma ^ { 2 } } | x - \mu | \Bigg ) = \frac { p ( x ) } { \lambda _ { - } } ,
$$  

with equality if and only if $r = 2$ , and the inequality is reversed if $r > 2$ . Here $p$ is the PDF (1.1). Inequality (2.10) is tight as $x \to \infty$ , which can be seen by applying the limiting form (A.65) to the bound in (2.10) and comparing to (2.9).  

# 2.3 Generating functions, infinite divisibility and self-decomposability  

The moment generating function of $X \sim \operatorname { V G } ( r , \theta , \sigma , \mu )$ is easily calculated using the integral formula (A.68) (see, for example, Bibby and Sørensen [15]),  

$$
M ( t ) = \mathbb { E } [ \mathrm { e } ^ { t X } ] = \mathrm { e } ^ { \mu t } \big ( 1 - 2 \theta t - \sigma ^ { 2 } t ^ { 2 } \big ) ^ { - r / 2 } ,
$$  

which exists provided $- \lambda _ { + } < t < \lambda _ { - }$ (see (2.5) and (2.6)). The characteristic function is  

$$
\varphi ( t ) = \mathbb { E } [ \mathrm { e } ^ { \mathrm { i } t X } ] = \mathrm { e } ^ { \mathrm { i } \mu t } \big ( 1 - 2 \mathrm { i } \theta t + \sigma ^ { 2 } t ^ { 2 } \big ) ^ { - r / 2 } .
$$  

The cumulant generating function is defined for $- \lambda _ { + } < t < \lambda _ { - }$ , and given by  

$$
\begin{array} { l } { { \displaystyle { K ( t ) = \log \mathbb { E } [ \mathrm { e } ^ { t X } ] = \mu t - \frac { r } { 2 } \log \big ( 1 - 2 \theta t - \sigma ^ { 2 } t ^ { 2 } \big ) } } } \\ { { \displaystyle ~ = \mu t - \frac { r } { 2 } \log \bigg ( 1 - \frac { t } { \lambda _ { - } } \bigg ) - \frac { r } { 2 } \log \bigg ( 1 + \frac { t } { \lambda _ { + } } \bigg ) . } } \end{array}
$$  

From the characteristic function (2.12) formula, it is clear that if $X _ { 1 } \sim \operatorname { V G } ( r _ { 1 } , \theta , \sigma , \mu _ { 1 } )$ and $X _ { 2 } \sim \mathrm { V G } ( r _ { 2 } , \theta , \sigma , \mu _ { 2 } )$ are independent, then  

$$
X _ { 1 } + X _ { 2 } \sim \mathrm { V G } ( r _ { 1 } + r _ { 2 } , \theta , \sigma , \mu _ { 1 } + \mu _ { 2 } )
$$  

(see Bibby and Sørensen [15]). Thus, the class of VG distributions is closed under convolution, provided the random variables have common values of $\theta$ and $\sigma$ .  

It is clear from (2.14) that the $\mathrm { V G } ( r , \theta , \sigma , \mu )$ distribution is infinitely divisible. Moreover, the VG characteristic function has the following Le´vy-Hinchin representation (see Madan et al. [73]):  

$$
\varphi ( t ) = \exp { \bigg ( } \mathrm { i } \mu t + \int _ { - \infty } ^ { \infty } ( \mathrm { e } ^ { \mathrm { i } t x } - 1 ) \nu ( x ) \mathrm { d } x { \bigg ) } ,
$$  

where the L´evy density is given by  

$$
\nu ( x ) = \frac { r } { 2 | x | } \mathrm { e } ^ { - \lambda _ { + } | x | } \mathbf { 1 } _ { x < 0 } + \frac { r } { 2 x } \mathrm { e } ^ { - \lambda _ { - } x } \mathbf { 1 } _ { x > 0 } .
$$  

A distribution $\mathcal { Q }$ on the real line is self-decomposable (Sato [103, Definition 15.1, p. 90]) if for any constant $c \in ( 0 , 1 )$ there exists a probability space with a random variable $X \sim \mathcal { Q }$ and independent random variable $Y$ such that $c X + Y \sim \mathcal { Q }$ . Self-decomposable distributions are infinitely divisible and have a special form of L´evy-Hinchin representation. As the Le´vy density $\nu ( x )$ , given by (2.16), can be written in the form $\nu ( x ) \ : = \ : h ( x ) / | x |$ , where $h ( x ) \geq 0$ is increasing for negative $x$ and decreasing for positive $x$ , it is immediate from the representation (2.15) (see Sato [103, Corollary 15.11]) that the $\mathrm { V G } ( r , \theta , \sigma , \mu )$ distribution is self-decomposable. An explicit construction of the self-decomposability of the $\mathrm { V G } ( r , \theta , \sigma , \mu )$ distribution is also available for the case that $r \in 2  { \mathbb { Z } } ^ { + }$ . Let $X \sim \mathrm { V G } ( 2 n , \theta , \sigma , \mu )$ , where $n \in \mathbb { Z } ^ { + }$ . Then, for any $c \in \lfloor 0 , 1 \rfloor$ ,  

$$
X = _ { d } c X + ( 1 - c ) \mu + \sum _ { i = 1 } ^ { n } V _ { i } ,
$$  

where $V _ { 1 } , \ldots , V _ { n }$ are i.i.d. random variables that can be expressed as $V _ { 1 } ~ { = } _ { d } ~ \sigma ( \delta _ { 1 } W _ { 1 } / ( \sigma \lambda _ { - } ) ~ -$ $\sigma \lambda _ { - } \delta _ { 2 } W _ { 2 } )$ . Here, $\delta _ { 1 }$ and $\delta _ { 2 }$ are 0-1 random variables with probabilities  

$$
\begin{array} { l } { \displaystyle \mathbb { P } \displaystyle ( \delta _ { 1 } = 0 , \delta _ { 2 } = 0 ) = c ^ { 2 } , \quad \mathbb { P } ( \delta _ { 1 } = 1 , \delta _ { 2 } = 0 ) = ( 1 - c ) \bigg ( c + \frac { 1 - c } { 1 + \sigma ^ { 2 } \lambda _ { - } ^ { 2 } } \bigg ) , } \\ { \displaystyle \mathbb { P } ( \delta _ { 1 } = 0 , \delta _ { 2 } = 1 ) = ( 1 - c ) \bigg ( c + \frac { ( 1 - c ) \sigma ^ { 2 } \lambda _ { - } ^ { 2 } } { 1 + \sigma ^ { 2 } \lambda _ { - } ^ { 2 } } \bigg ) , \quad \mathbb { P } ( \delta _ { 1 } = 1 , \delta _ { 2 } = 1 ) = 0 , } \end{array}
$$  

where $W _ { 1 }$ and $W _ { 2 }$ are exponential with rate parameter $1$ , and $X$ , $W _ { 1 }$ , $W _ { 2 }$ , and $( \delta _ { 1 } , \delta _ { 2 } )$ are mutually independent. The representation (2.17) is given in Kotz et al. [60, Proposition 4.1.4], in which they generalised the representation of Ramachandran [97] for the asymmetric Laplace distribution by combining the convolution property (2.14) of the VG distribution together with the fact that the $\mathrm { V G } ( 2 , \theta , \sigma , \mu )$ distribution is an asymmetric Laplace distribution (see part 1 of Section 2.5.1).  

# 2.4 Representation in terms of other random variables  

1. The VG distribution has the following fundamental representation in terms of independent normal and gamma random variables; see Kotz et al. [60, Proposition 4.1.2] for a statement of the result and a short proof involving characteristic functions. To fix notation, consider the $\Gamma ( r , \lambda )$ distribution with PDF $p ( x ) = \lambda ^ { r } x ^ { r - 1 } \mathrm { e } ^ { - \lambda x } / \Gamma ( r )$ , $x > 0$ . Suppose that $S \sim \Gamma ( r / 2 , 1 / 2 )$ and $T \sim$ $N ( 0 , 1 )$ are independent random variables. Then  

$$
\mu + \theta S + \sigma \sqrt { S } T \sim \mathrm { V G } ( r , \theta , \sigma , \mu ) .
$$  

The VG distribution is therefore a univariate normal variance-mean distribution (Barndorff-Nielsen, Kent and Sørensen [12]). Indeed, conditional on $S$ , the random variable $\mu + \theta S + \sigma { \sqrt { S } } T$ has the $N ( \mu + \theta S , \sigma ^ { 2 } S )$ distribution.  

2. When $r \geq 1$ is a positive integer, the VG distribution can be represented in terms of independent standard normal random variables $X _ { 1 } , \ldots , X _ { r }$ and $Y _ { 1 } , \ldots , Y _ { r }$ :  

$$
\mu + \theta \sum _ { i = 1 } ^ { r } X _ { i } ^ { 2 } + \sigma \sum _ { i = 1 } ^ { r } X _ { i } Y _ { i } \sim \mathrm { V G } ( r , \theta , \sigma , \mu ) .
$$  

(see Gaunt [36, Corollary 2.5]). To see this, first we define $Z _ { 1 } = \mu + \theta X _ { 1 } ^ { 2 } + \sigma X _ { 1 } Y _ { 1 }$ and $Z _ { i } = \theta X _ { i } ^ { 2 } +$ $\sigma X _ { i } Y _ { i }$ , $i = 2 , \ldots , r$ . Observe that, for $i = 1 , 2 , \dots , r$ , $X _ { i } Y _ { i } = _ { d } | X _ { i } | Y _ { i }$ and that $X _ { i } ^ { 2 } \sim \Gamma ( r / 2 , 1 / 2 )$ . Hence, by (2.18), we have that $Z _ { 1 } \sim \mathrm { V G } _ { 1 } ( 1 , \theta , \sigma , \mu )$ and $Z _ { i } \sim \mathrm { V G } _ { 1 } ( 1 , \theta , \sigma , 0 )$ , $i = 2 , \ldots , r$ . It therefore follows from (2.14) that $\begin{array} { r } { \sum _ { i = 1 } ^ { r } Z _ { i } \sim \mathrm { V G } ( r , \theta , \sigma , \mu ) } \end{array}$ .  

3. The VG distribution has a neat representation as a difference of independent gamma random variables (this was shown in the $\theta = 0$ case by McLeish [81]; for the general case see, for example, Press [96] or Kotz et al. [60]). Suppose $S \sim \Gamma ( r / 2 , ( \sqrt { \theta ^ { 2 } + \sigma ^ { 2 } } + \theta ) ^ { - 1 } )$ and $S ^ { \prime } \sim \Gamma ( r / 2 , ( \sqrt { \theta ^ { 2 } + \sigma ^ { 2 } } -$ $\theta ) ^ { - 1 }$ ) are independent. Then  

$$
\mu + S - S ^ { \prime } \sim \mathrm { V G } ( r , \theta , \sigma , \mu ) .
$$  

This representation is efficiently proved using a standard characteristic function argument with the $\mathrm { V G } ( r , \theta , \sigma , \mu )$ characteristic function formula (2.12) and the formula for the characteristic function of the $\Gamma ( r , \lambda )$ distribution, $\varphi _ { S } ( t ) = ( 1 - \mathrm { i } t / \lambda ) ^ { - r }$ .  

Suppose now that $r \geq 1$ is an integer. Then $S = _ { d } ( \sqrt { \theta ^ { 2 } + \sigma ^ { 2 } } + \theta ) V / 2$ and $S ^ { \prime } = _ { d }$ ( ${ \sqrt { \theta ^ { 2 } + \sigma ^ { 2 } } } -$ $\theta ) V ^ { \prime } / 2$ , where $V$ and $V ^ { \prime }$ are independent $\chi _ { r } ^ { 2 }$ random variables (chi-square distribution with $r$ degrees of freedom). From the representation of the $\chi _ { r } ^ { 2 }$ distribution as the sum of the squares of $r$ independent $N ( 0 , 1 )$ random variables and the representation (2.20), we deduce that  

$$
\mu + r \theta + \sum _ { j = 1 } ^ { 2 r } \lambda _ { j } ( N _ { j } ^ { 2 } - 1 ) \sim \mathrm { V G } ( r , \theta , \sigma , \mu ) ,
$$  

where $N _ { 1 } , \ldots , N _ { 2 r }$ are independent $N ( 0 , 1 )$ random variables, $\lambda _ { 1 } = \ldots = \lambda _ { r } = ( \sqrt { \theta ^ { 2 } + \sigma ^ { 2 } } + \theta ) / 2$ and $\lambda _ { r + 1 } = . . . = \lambda _ { 2 r } = - ( \sqrt { \theta ^ { 2 } + \sigma ^ { 2 } } - \theta ) / 2$ . So, for integer $r \geq 1$ the VG distribution is a member of the second Wiener chaos (see Nourdin and Peccati [88, Section 2.2]).  

4. If $r ~ \in ~ 2  { \mathbb { Z } } ^ { + }$ , the independent random variables $V \sim \chi _ { r } ^ { 2 }$ and $V ^ { \prime } \sim \chi _ { r } ^ { 2 }$ can be represented in terms of independent uniform $U ( 0 , 1 )$ random variables $U _ { 1 } , \dots , U _ { r }$ by $\begin{array} { r } { V = _ { d } \sum _ { j = 1 } ^ { r / 2 } \log U _ { j } } \end{array}$ and $\begin{array} { r } { V ^ { \prime } = _ { d } \sum _ { j = r / 2 + 1 } ^ { r } \log U _ { j } } \end{array}$ . Thus, from (2.20),  

$$
\mu + \frac { \sqrt { \theta ^ { 2 } + \sigma ^ { 2 } } + \theta } { 2 } \sum _ { j = 1 } ^ { r / 2 } \log U _ { j } - \frac { \sqrt { \theta ^ { 2 } + \sigma ^ { 2 } } - \theta } { 2 } \sum _ { j = r / 2 + 1 } ^ { r } \log U _ { j } \sim \mathrm { V G } ( r , \theta , \sigma , \mu ) .
$$  

This representation is convenient for simulating the VG distribution when $r \in 2  { \mathbb { Z } } ^ { + }$ . For other values of $r > 0$ , the $\mathrm { V G } ( r , \theta , \sigma , \mu )$ distribution can be simulated using the representation (2.20) and simulating the gamma distributions of $V$ and $V ^ { \prime }$ using the methods given in Chapter 9, Section 3 of Devroye [24].  

# 2.5 Related distributions  

# 2.5.1 Subclasses and limiting cases  

1. The $\mathrm { V G } ( 2 , \theta , \sigma , \mu )$ distribution corresponds to the asymmetric Laplace distribution. Indeed, setting $r = 2$ in (2.7) yields  

$$
p ( x ) = \frac { 1 } { \sqrt { \theta ^ { 2 } + \sigma ^ { 2 } } } \exp \Bigg ( \frac { \theta } { \sigma ^ { 2 } } ( x - \mu ) - \frac { \sqrt { \theta ^ { 2 } + \sigma ^ { 2 } } } { \sigma ^ { 2 } } \vert x - \mu \vert \Bigg ) .
$$  

Setting $\theta \ : = \ : 0$ in (2.21) gives the PDF of the classical Laplace distribution. A comprehensive account of the distributional theory of the Laplace and asymmetric Laplace distributions is given in Chapters 2 and 3 of Kotz et al. [60].  

2. The gamma distribution is a limiting case of the VG distribution (see, for example, Kotz et al. [60]). For fixed, $r , \lambda > 0$ , the sequence of random variables $X _ { \sigma } \sim \mathrm { V G } ( 2 r , ( 2 \lambda ) ^ { - 1 } , \sigma , 0 )$ converges in distribution to a $\Gamma ( r , \lambda )$ random variable, as $\sigma  0$ . This can be seen by letting $\sigma  0$ in the formula (2.12) for the characteristic function of VG distribution and comparing to the gamma characteristic function using L´evy’s continuity theorem.  

3. The normal distribution is also a limiting case of the VG distribution (see, for example, Kotz et al. [60]). For fixed, $\theta \in \mathbb R$ and $\sigma > 0$ , the sequence of random variables $Y _ { r } \sim \mathrm { V G } ( r , \theta / \sqrt { r } , \sigma / \sqrt { r } , - \theta \sqrt { r } )$ converges to a $N ( 0 , \sigma ^ { 2 } + 2 \theta ^ { 2 } )$ random variable, as $r  \infty$ . As in part 2, this can be deduced from a characteristic function argument. More insightfully, from the convolution property, for $r \in \mathbb { Z } ^ { + }$ , we can write $Y _ { r } = _ { d } r ^ { - 1 / 2 } \sum _ { i = 1 } ^ { r } Y _ { r , i }$ , where $Y _ { r , i } \sim \mathrm { V G } ( 1 , \theta , \sigma , - \theta )$ . The result now follows from the central limit theorem and  the formulas $\mathbb { E } [ Y _ { r , i } ] = 0$ and $\mathrm { V a r } ( Y _ { r , i } ) = \sigma ^ { 2 } + 2 \theta ^ { 2 }$ (see (2.30) and (2.31)).  

4. Let $( X , Y )$ be a bivariate normal random vector with zero mean vector, variances $( \sigma _ { X } ^ { 2 } , \sigma _ { Y } ^ { 2 } )$ and correlation coefficient $\rho$ . Denote the product of these correlated normal random variables by $Z = X Y$ . We will denote this distribution by $\mathrm { P N } ( \rho , \sigma _ { X } , \sigma _ { Y } )$ . Consider also the mean ${ \overline { { Z } } } _ { n } =$ $n ^ { - 1 } ( Z _ { 1 } + \cdots + Z _ { n } )$ , where $Z _ { 1 } , \ldots , Z _ { n }$ are independent copies of $Z$ . It was noted in the thesis of Gaunt [35] that $Z \sim \mathrm { V G } ( 1 , \rho \sigma _ { X } \sigma _ { Y } , \sigma _ { X } \sigma _ { Y } \sqrt { 1 - \rho ^ { 2 } , 0 ) }$ and later by Gaunt [40] that also  

$$
\overline { { Z } } _ { n } \sim \mathrm { V G } ( n , \rho \sigma _ { X } \sigma _ { Y } / n , \sigma _ { X } \sigma _ { Y } \sqrt { 1 - \rho ^ { 2 } } / n , 0 ) .
$$  

To see this, suppose $\sigma _ { X } = \sigma _ { Y } = 1$ , with the general case following by rescaling. One can readily verify that $X$ and $W = ( Y - \rho X ) / \sqrt { 1 - \rho ^ { 2 } }$ are independent $N ( 0 , 1 )$ random variables. Thus, $Z = X Y = X ( \sqrt { 1 - \rho ^ { 2 } W + \rho X } ) = \sqrt { 1 - \rho ^ { 2 } X W + \rho X ^ { 2 } }$ , so that $Z \sim \mathrm { V G } ( 1 , \rho , \sqrt { 1 - \rho ^ { 2 } } , 0 )$ by (2.19). Finally, we deduce (2.22) from properties (2.8) and (2.14).  

With (2.22), Gaunt [40] proved that the PDF of ${ \overline { { Z } } } _ { n }$ (previously given by independently by Mangilli, Plaszczynski and Tristram [79] and Nadarajah and Pog´any [84]) is given by  

$$
p ( x ) = \frac { n ^ { ( n + 1 ) / 2 } 2 ^ { ( 1 - n ) / 2 } | x | ^ { ( n - 1 ) / 2 } } { s ^ { ( n + 1 ) / 2 } \sqrt { \pi ( 1 - \rho ^ { 2 } ) } \Gamma ( n / 2 ) } \exp \bigg ( \frac { \rho n x } { s ( 1 - \rho ^ { 2 } ) } \bigg ) K _ { \frac { n - 1 } { 2 } } \bigg ( \frac { n | x | } { s ( 1 - \rho ^ { 2 } ) } \bigg ) , \quad x \in \mathbb { R } ,
$$  

where $s = \sigma _ { X } \sigma _ { Y }$ , with the PDF for $Z$ following on setting $n = 1$ . For an account of the distributional theory of $Z$ and $\overline { { Z } }$ , see Gaunt [42]. We note that the product of two normal random variables with non-zero means does not follow the VG distribution; the rather complicated exact formula for the PDF is given in Cui et al. [22].  

# 2.5.2 Superclasses  

1. The generalized hyperbolic (GH) distribution was introduced by Barndorff-Nielsen [10, 11], who studied it in the context of modelling dune movements. Like the VG distribution, GH distributions are widely used in financial modelling; see for example, Bibby and Sørensen [15], Eberlein and Keller [26] and Eberlein and Prause [27]. Properties of the GH distribution are given in Bibby and Sørensen [15] and Hammerstein [50]. The PDF is  

$$
p ( x ) = \frac { ( \gamma / \delta ) ^ { \lambda } } { \sqrt { 2 \pi } K _ { \lambda } ( \delta \gamma ) } \mathrm { e } ^ { \beta ( x - \mu ) } \frac { K _ { \lambda - 1 / 2 } ( \alpha \sqrt { \delta ^ { 2 } + ( x - \mu ) ^ { 2 } } ) } { ( \sqrt { \delta ^ { 2 } + ( x - \mu ) ^ { 2 } } / \alpha ) ^ { 1 / 2 - \lambda } } , \quad x \in \mathbb { R } ,
$$  

where $\gamma = \sqrt { \alpha ^ { 2 } - \beta ^ { 2 } }$ . The parameter domain is given by  

$$
\begin{array} { c c c } { \delta \geq 0 , } & { \gamma > 0 , } & { \lambda > 0 , } \\ { \delta > 0 , } & { \gamma > 0 , } & { \lambda = 0 , } \\ { \delta > 0 , } & { \gamma \geq 0 , } & { \lambda < 0 , } \end{array}
$$  

and in each case $\mu \in \mathbb { R }$ . If $\delta = 0$ or $\gamma = 0$ , the PDF (2.23) is defined as the limit obtained by using (A.64). In particular, taking $\delta \downarrow 0$ in (2.23) yields the density (2.3) of the VG distribution in the parametrisation of Bibby and Sørensen [15]. A detailed study of limiting cases of GH distributions is given by Eberlein and Hammerstein [25].  

2. The VG distribution is a special case of the CGMY distribution of Carr et al. [20], which was introduced in the context of financial modelling. The distribution is defined by its Le´vy-Hinchin representation $\begin{array} { r } { \varphi ( t ) = \exp \big ( \int _ { \mathbb { R } } ( \mathrm { e } ^ { \mathrm { i } t x } - 1 ) \nu _ { C G M Y } ( x ) \mathrm { d } x \big ) } \end{array}$ , where the Le´vy density is given by  

$$
\nu _ { C G M Y } ( x ) = \frac { C } { | x | ^ { 1 + Y } } \mathrm { e } ^ { - G | x | } \mathbf { 1 } _ { x < 0 } + \frac { C } { x ^ { 1 + Y } } \mathrm { e } ^ { - M x } \mathbf { 1 } _ { x > 0 } .
$$  

The VG distribution corresponds to the case $Y = 0$ . A closed-form formula is not available for the PDF of the CGMY distribution, although the characteristic function takes an elementary form (see Carr et al. [20]):  

$$
\varphi ( t ) = \exp { \left( C \Gamma ( - Y ) \big \{ ( M - \mathrm { i } t ) ^ { Y } - M ^ { Y } + ( G - \mathrm { i } t ) ^ { Y } - G ^ { Y } \big \} \right) } ,
$$  

from which one readily obtains formulas for lower order moments, as well the variance, skewness and kurtosis (again, see Carr et al. [20]).  

Being a subclass of the CGMY distributions, the VG distributions form a subclass of the tempered stable distributions that was introduced by Koponen [58]. For properties and references for this class of distributions see, for example, Ku¨chler and Tappe [65].  

3. Consider the distribution of the random variable $X = Z + L$ , with independent $Z \sim N ( 0 , \sigma ^ { 2 } )$ and $L$ is asymmetric Laplace. This distribution, introduced by Reed [99], called the normal-asymmetric Laplace, has four parameters. Some basic distributional properties are given in Reed [99], such as infinite divisibility, exact formulas for the PDF, CDF, moment and cumulants, and estimation methods are also discussed.  

More generally, if $L$ is VG distributed (generalized asymmetric Laplace), then $X$ is said to be generalized normal-Laplace (GNL) distributed, introduced in Reed [100]. This distribution has five parameters. The article of Reed [100] includes financial applications. In the thesis of Wu [119], one can find a systematic treatment and bibliography for GNL distributions.  

4. A multivariate generalisation of the VG distribution in the symmetric case was first proposed by Madan and Seneta [77]. A number of basic properties of the (general non-symmetric) multivariate  

VG distribution are reviewed by Kozubowski, Podg´orski and Rychlik [64] (they refer to it as the multivariate generalized Laplace distribution). For an account of the matrix variate VG distribution, see Kozubowski, Mazur and Podg´orski [61] and references therein. Here, we collect just a few of the most fundamental properties of the multivariate VG distribution, noting that they generalise properties of the univariate VG distribution in a natural manner.  

The multivariate VG distribution is often defined through its characteristic function. In line with Kozubowski et al. [64], we say that a random vector $\mathbf { X }$ in $\mathbb { R } ^ { d }$ follows the multivariate VG distribution if its characteristic function is given by  

$$
\begin{array} { r } { \varphi ( \mathbf t ) = \mathbb { E } \big [ \mathrm { e } ^ { \mathrm { i } \mathbf t ^ { \mathsf { T } } \mathbf { X } } \big ] = \mathrm { e } ^ { \mathrm { i } \mu ^ { \mathsf { T } } \mathbf t } \big ( 1 - \mathrm { i } \theta ^ { \mathsf { T } } \mathbf t + \frac { 1 } { 2 } \mathbf { t } ^ { \mathsf { T } } \Sigma \mathbf { t } \big ) ^ { - s } , \quad \mathbf t \in \mathbb { R } ^ { d } , } \end{array}
$$  

where $s > 0$ , $\pmb { \theta } \in \mathbb { R } ^ { d }$ , $\pmb { \mu } \in \mathbb { R } ^ { d }$ , and $\pmb { \Sigma }$ is $d \times d$ non-negative definite symmetric matrix. Note that when $d = 1$ , the characteristic function (2.24) reduces to the characteristic function (2.12) of the univariate VG distribution (under a slightly different parametrisation). We can represent the multivariate VG distribution as a normal variance-mean mixture  

$$
\mathbf { X } = _ { d } { \boldsymbol { \mu } } + \pmb { \theta } G + { \sqrt { G } } \mathbf { Z } ,
$$  

for independent $G \sim \Gamma ( s , 1 )$ and $\mathbf { Z } \sim N _ { d } ( \mathbf { 0 } , \pmb { \Sigma } )$ (the $d$ -dimensional multivariate normal distribution with mean vector 0 and covariance matrix $\pmb { \Sigma }$ ).  

If the matrix $\pmb { \Sigma }$ is positive-definite, then the distribution is non-degenerate, that is truly $d$ - dimensional, with PDF  

$$
p ( \mathbf { x } ) = \frac { 2 \exp ( \pmb { \theta } ^ { \top } \pmb { \Sigma } ^ { - 1 } ( \mathbf { x } - \pmb { \mu } ) ) } { ( 2 \pi ) ^ { d / 2 } \Gamma ( s ) | \pmb { \Sigma } | ^ { 1 / 2 } } \left( \frac { Q ( \mathbf { x } , \pmb { \mu } ) } { C ( \pmb { \Sigma } , \pmb { \theta } ) } \right) ^ { s - d / 2 } K _ { s - d / 2 } ( Q ( \mathbf { x } , \pmb { \mu } ) C ( \pmb { \Sigma } , \pmb { \theta } ) ) , \quad \mathbf { x } \in \mathbb { R } ^ { d } ,
$$  

where $Q ( \mathbf { x } , { \pmb \mu } ) = ( ( \mathbf { x } - { \pmb \mu } ) ^ { \intercal } \Sigma ^ { - 1 } ( \mathbf { x } - { \pmb \mu } ) ) ^ { 1 / 2 }$ and $C ( \Sigma , \pmb \theta ) = ( 2 + \pmb \theta ^ { \intercal } \Sigma ^ { - 1 } \pmb \theta ) ^ { 1 / 2 }$ .  

# 2.5.3 Products and quotients of VG random variables  

Let $( X _ { i } ) _ { 1 \leq i \leq n } \sim \mathrm { V G } ( r _ { i } , 0 , \sigma _ { i } , 0 )$ be independent, and set $\begin{array} { r } { Z _ { n } \ = \ \prod _ { i = 1 } ^ { n } X _ { i } } \end{array}$ and $\sigma = \sigma _ { 1 } \cdot \cdot \cdot \sigma _ { n }$ . A formula for the PDF of the product $Z _ { n }$ was obtained by Gaunt, Mijoule and Swan [47]:  

$$
f _ { Z _ { n } } ( x ) = \frac { 1 } { 2 ^ { n } \pi ^ { n / 2 } \sigma } \prod _ { j = 1 } ^ { n } \frac { 1 } { \Gamma ( r _ { j } / 2 ) } G _ { 0 , 2 n } ^ { 2 n , 0 } \bigg ( \frac { x ^ { 2 } } { 2 ^ { 2 n } \sigma ^ { 2 } } \bigg | \frac { r _ { 1 } - 1 } { 2 } , \ldots , \frac { r _ { n } - 1 } { 2 } , 0 , \ldots , 0 \bigg ) , \quad x \in \mathbb { R } ,
$$  

where $G _ { 0 , k } ^ { k , 0 } ( \boldsymbol { x } | \boldsymbol { ) }$ is a Meijer $G$ -function (see Chapter 16 of Olver et al. [92] for a definition and basic properties). We are not aware of an exact formula for the product of two or more independent $\mathrm { V G } ( r , \theta , \sigma , 0 )$ random variables with $\theta \neq 0$ .  

Suppose that $X \sim \mathrm { V G } ( r , \theta _ { 1 } , \sigma _ { 1 } , 0 )$ and $Y \sim \mathrm { V G } ( s , \theta _ { 2 } , \sigma _ { 2 } , 0 )$ are independent, where $r , s > 0$ , $\theta _ { i } \in \mathbb { R }$ , $\sigma _ { i } > 0$ , $i = 1 , 2$ . An exact formula for the PDF of ratio $Z = X / Y$ in terms of an infinite series involving Gaussian hypergeometric functions (See Chapter 15 of Olver et al. [92] for a definition and basic properties) was obtained by Gaunt and Li [45]. Previously, the following simpler exact formula, expressed as a single Gaussian hypergeometric function, for the case $\theta _ { 1 } = \theta _ { 2 } = 0$ and $\sigma _ { 1 } = \sigma _ { 2 } = 1$ was obtained by Nadarajah and Kotz [83]. For $x \in \mathbb { R }$ ,  

$$
f _ { Z } ( x ) = \frac { 2 | x | ^ { - s - 1 } \Gamma ( ( r + 1 ) / 2 ) \Gamma ( ( s + 1 ) / 2 ) } { \pi ( r + s ) \Gamma ( r / 2 ) \Gamma ( s / 2 ) } _ { 2 } F _ { 1 } \left( \frac { r + s } { 2 } , \frac { s + 1 } { 2 } ; \frac { r + s } { 2 } + 1 ; 1 - x ^ { - 2 } \right) .
$$  

We refer the reader to the two aforementioned works for further properties of the VG ratio distribution, such as formulas for the PDF expressed in terms of elementary functions for particular parameter values, a formula for the CDF, fractional moments, and asymptotic behaviour of the PDF and tail probabilities, from which it is seen that the mean does not exist.  

# 2.6 Stein characterisations  

The following Stein characterisation of the VG distribution was given by Gaunt [36]. Let $W$ be a real-valued random variable. Then $W \sim \mathrm { V G } ( r , \theta , \sigma , \mu )$ if and only if  

$$
\begin{array} { r } { \mathbb { E } \left[ \sigma ^ { 2 } ( W - \mu ) g ^ { \prime \prime } ( W ) + ( \sigma ^ { 2 } r + 2 \theta ( W - \mu ) ) g ^ { \prime } ( W ) + ( r \theta - ( W - \mu ) ) g ( W ) \right] = 0 } \end{array}
$$  

for all twice differentiable $g : \mathbb { R }  \mathbb { R }$ for which the expectations $\operatorname { \mathbb { E } } | g ( X ) |$ , $\mathbb { E } | X g ( X ) |$ , $\mathbb { E } | g ^ { \prime } ( X ) |$ , $\mathbb { E } | X g ^ { \prime } ( X ) |$ and $\mathbb { E } | X g ^ { \prime \prime } ( X ) |$ are finite for $X \sim \operatorname { V G } ( r , \theta , \sigma , \mu )$ .  

Here we provide a sketch of the argument. We start with necessity. The PDF (1.1) of the $\mathrm { V G } ( r , \theta , \sigma , \mu )$ distribution satisfies the ordinary differential equation (ODE)  

$$
\mathcal { L } p ( x ) : = \sigma ^ { 2 } x p ^ { \prime \prime } ( x ) - ( \sigma ^ { 2 } ( r - 2 ) + 2 \theta x ) p ^ { \prime } ( x ) + ( \theta ( r - 2 ) - x ) p ( x ) = 0 ,
$$  

which can be read off from a more general ODE satisfied by the PDF of the GH distribution given in Gaunt [38, Corollary 3.3]. From (2.26) we have that $\begin{array} { r } { \int _ { - \infty } ^ { \infty } g ( x ) \mathcal { L } p ( x ) \mathrm { d } x = 0 } \end{array}$ and integrating by parts twice yields (2.25). To prove sufficiency, suppose $W$ is a real-valued random variable. For ease of exposition, we set $\mu = 0$ , with the general case following by a simple translation. Taking $g ( x ) =  { \mathrm { e } } ^ { \mathrm { i } t x }$ (a twice differentiable and bounded function) in (2.25) and letting $\varphi ( t ) = \mathbb E [ \mathrm { e } ^ { \mathrm { i } t W } ]$ leads to the ODE  

$$
( \sigma ^ { 2 } t ^ { 2 } - 2 \mathrm { i } \theta t + 1 ) \varphi ^ { \prime } ( t ) + ( \mathrm { i } \sigma ^ { 2 } r t + r \theta ) \varphi ( t ) = 0 .
$$  

Here we applied the characterising equation to the real and imaginary parts of $g ( x ) = \mathrm { e } ^ { \mathrm { i } t x }$ . Solving (2.27) subject to the condition $\varphi ( 0 ) = 1$ gives that $\varphi ( t ) = ( 1 - 2 \mathrm { i } \theta t + \sigma ^ { 2 } t ^ { 2 } ) ^ { - r / 2 }$ , in agreement with the characteristic function (2.12) when $\mu = 0$ , and hence $W \sim \mathrm { V G } ( r , \theta , \sigma , 0 )$ .  

Stein characterisations are most commonly used in Stein’s method (Stein [111]) to bound the distance between two probability distributions with respect to a probability metric; however, one can also use them to establish distributional properties. Indeed, letting $Y \sim \mathrm { V G } ( r , \theta , \sigma , 0 )$ and substituting $g _ { 1 } ( x ) = x ^ { k }$ and $g _ { 2 } ( x ) = ( x - \mathbb { E } [ Y ] ) ^ { k } = ( x - r \theta ) ^ { k }$ into (2.25) (with $\mu = 0$ ) leads to the following recursions for the $k$ -th raw moment $\mu _ { k } ^ { \prime } = \mathbb { E } [ Y ^ { k } ]$ and the $k$ -th central moment $\mu _ { k } = \mathbb { E } [ ( Y - \mathbb { E } [ Y ] ) ^ { k } ]$ :  

$$
\begin{array} { r l } & { \mu _ { k + 1 } ^ { \prime } = \theta ( 2 k + r ) \mu _ { k } ^ { \prime } + \sigma ^ { 2 } k ( r + k - 1 ) \mu _ { k - 1 } ^ { \prime } , \quad k \geq 1 , } \\ & { \mu _ { k + 1 } = 2 k \theta \mu _ { k } + k \big ( \sigma ^ { 2 } ( r + k - 1 ) + 2 \theta ^ { 2 } r \big ) \mu _ { k - 1 } + k ( k - 1 ) r \theta \sigma ^ { 2 } \mu _ { k - 2 } , \quad k \geq 2 . } \end{array}
$$  

Lower order raw (central) moments can be efficiently computed using the recurrences given just the first raw (first and second central) moments, along with the basic condition $\mu _ { 0 } = 1$ .  

# 2.7 Moments and cumulants  

The mean and variance of $X \sim \operatorname { V G } ( r , \theta , \sigma , \mu )$ are readily calculated via the standard method of obtaining lower order moments from moment generating functions (using (2.11)). We have  

$$
\begin{array} { c } { \mathbb { E } [ X ] = \mu + r \theta , } \\ { \mathrm { V a r } ( X ) = r ( \sigma ^ { 2 } + 2 \theta ^ { 2 } ) . } \end{array}
$$  

Now, let $Y \sim \mathrm { V G } ( r , \theta , \sigma , 0 )$ . Lower order raw and central moments of $Y$ can be efficiently obtained from the recurrences (2.28) and (2.29). The central moments of $X \sim \operatorname { V G } ( r , \theta , \sigma , \mu )$ are equal to the central moments of $Y$ , and raw moments for $X$ are readily obtained through the formula $\begin{array} { r } { \mathbb { E } [ X ^ { k } ] = \sum _ { j = 0 } ^ { k } \binom { k } { j } \mu ^ { j } \mathbb { E } [ Y ^ { k } ] } \end{array}$ . The first four raw moments of $Y \sim \mathrm { V G } ( r , \theta , \sigma , 0 )$ are  

$$
\mu _ { 1 } ^ { \prime } = r \theta , \quad \mu _ { 2 } ^ { \prime } = r ( \sigma ^ { 2 } + ( r + 2 ) \theta ^ { 2 } ) , \quad \mu _ { 3 } ^ { \prime } = r ( r + 2 ) \theta \bigl ( 3 \sigma ^ { 2 } + ( r + 4 ) \theta ^ { 2 } \bigr ) ,
$$  

$$
\mu _ { 4 } ^ { \prime } = r ( r + 2 ) \big ( 3 \sigma ^ { 4 } + 6 ( r + 4 ) \theta ^ { 2 } \sigma ^ { 2 } + ( r + 4 ) ( r + 6 ) \theta ^ { 4 } \big ) ,
$$  

whilst the first four central moments are  

$$
\begin{array} { r l } & { \mu _ { 1 } = 0 , } \\ & { \mu _ { 2 } = r ( \sigma ^ { 2 } + 2 \theta ^ { 2 } ) , } \\ & { \mu _ { 3 } = 2 r \theta ( 3 \sigma ^ { 2 } + 4 \theta ^ { 2 } ) , } \\ & { \mu _ { 4 } = 3 r \big ( ( r + 2 ) \sigma ^ { 4 } + ( 4 r + 1 6 ) \theta ^ { 2 } \sigma ^ { 2 } + ( 4 r + 1 6 ) \theta ^ { 4 } \big ) . } \end{array}
$$  

The skewness $\gamma _ { 1 } = \mu _ { 3 } / \mu _ { 2 } ^ { 3 / 2 }$ and kurtosis $\beta _ { 2 } = \mu _ { 4 } / \mu _ { 2 } ^ { 2 }$ are thus given by  

$$
\gamma _ { 1 } = \frac { 2 \theta ( 3 \sigma ^ { 2 } + 4 \theta ^ { 2 } ) } { \sqrt { r } ( \sigma ^ { 2 } + 2 \theta ^ { 2 } ) ^ { 3 / 2 } } , \quad \beta _ { 2 } = \frac { 3 ( ( r + 2 ) \sigma ^ { 4 } + ( 4 r + 1 6 ) \theta ^ { 2 } \sigma ^ { 2 } + ( 4 r + 1 6 ) \theta ^ { 4 } ) } { r ( \sigma ^ { 2 } + 2 \theta ^ { 2 } ) ^ { 2 } } ,
$$  

and the excess kurtosis $\gamma _ { 2 } = \mu _ { 4 } / \mu _ { 2 } ^ { 2 } - 3$ is equal to  

$$
\gamma _ { 2 } = \frac { 6 ( \sigma ^ { 4 } + 8 \theta ^ { 2 } \sigma ^ { 2 } + 8 \theta ^ { 4 } ) } { r ( \sigma ^ { 2 } + 2 \theta ^ { 2 } ) ^ { 2 } } .
$$  

Formulas for the first four central moments of the VG distribution, as well as the skewness and kurtosis, were given by Seneta [108].  

Higher order moments can be calculated using the representation (2.20) (with $\mu = 0$ ) of the $\mathrm { V G } ( r , \theta , \sigma , 0 )$ distribution and the formula $\mathbb { E } [ V ^ { k } ] = \lambda ^ { - k } \Gamma ( r / 2 + k ) / \Gamma ( r / 2 )$ , $k \geq 1$ , where $V \sim$ $\Gamma ( r / 2 , \lambda )$ . For $k \geq 1$ ,  

$$
\mu _ { k } ^ { \prime } = \frac { \sigma ^ { 2 k } } { ( \Gamma ( r / 2 ) ) ^ { 2 } } \sum _ { j = 0 } ^ { k } { \binom { k } { j } } ( - \lambda _ { - } ) ^ { j } \lambda _ { + } ^ { k - j } \Gamma \Bigl ( \frac { r } { 2 } + j \Bigr ) \Gamma \Bigl ( \frac { r } { 2 } + k - j \Bigr ) .
$$  

We now return to the general case $r > 0$ , for which the following expressions, involving the hypergeometric function, for the raw and absolute moments of $Y \sim \mathrm { V G } ( r , \theta , \sigma , 0 )$ were obtained by Gaunt [43]. Let $k \in \mathbb { Z } ^ { + }$ , and define $\ell : = \lceil k / 2 \rceil + 1 / 2$ and $m : = k { \bmod { 2 } }$ . Then  

$$
\mu _ { k } ^ { \prime } = \frac { 2 ^ { k + m } \theta ^ { m } \sigma ^ { r + 2 k } } { \sqrt { \pi } ( \theta ^ { 2 } + \sigma ^ { 2 } ) ^ { ( r + k + m ) / 2 } \Gamma ( r / 2 ) } \Gamma \Big ( \frac { r - 1 } { 2 } + \ell \Big ) \Gamma ( \ell ) { } _ { 2 } F _ { 1 } \bigg ( \ell , \frac { r - 1 } { 2 } + \ell ; \frac { 1 } { 2 } + m ; \frac { \theta ^ { 2 } } { \theta ^ { 2 } + \sigma ^ { 2 } } \bigg ) ,
$$  

whilst, for $k > k _ { * } = k _ { * } ( r ) : = \operatorname* { m a x } \{ - 1 , - r \}$ ,  

$$
\mathbb { E } [ | Y | ^ { k } ] = \frac { 2 ^ { k } \sigma ^ { r + 2 k } } { \sqrt { \pi } ( \theta ^ { 2 } + \sigma ^ { 2 } ) ^ { ( r + k ) / 2 } \Gamma ( r / 2 ) } \Gamma \Big ( \frac { r + k } { 2 } \Big ) \Gamma \Big ( \frac { k + 1 } { 2 } \Big ) _ { 2 } F _ { 1 } \bigg ( \frac { k + 1 } { 2 } , \frac { r + k } { 2 } ; \frac { 1 } { 2 } ; \frac { \theta ^ { 2 } } { \theta ^ { 2 } + \sigma ^ { 2 } } \Big )
$$  

As ${ } _ { 2 } F _ { 1 } ( a , b ; c ; 0 ) = 1$ , we observe that in the case $\theta = 0$ the raw moments simplify to  

$$
\mu _ { k } ^ { \prime } = \left\{ \frac { 2 ^ { k } \sigma ^ { k } } { \sqrt { \pi } } \frac { \Gamma ( ( r + k ) / 2 ) \Gamma ( ( k + 1 ) / 2 ) } { \Gamma ( r / 2 ) } , \qquad \mathrm { i f ~ } k \mathrm { ~ i s ~ e v e n } , \right.
$$  

Central moments of general order of the $\mathrm { V G } ( r , \theta , \sigma , 0 )$ distribution can be calculated using the representation (2.20) and the formula $\begin{array} { r } { \mathbb { E } [ ( V - \mathbb { E } [ V ] ) ^ { k } ] = \lambda ^ { - k } U ( - k , 1 - k - r / 2 , - r / 2 ) } \end{array}$ , where $V \sim \Gamma ( r / 2 , \lambda )$ and $U ( a , b , x )$ is a confluent hypergeometric function of the second kind. This formula is given for the case that $V \sim \chi _ { r } ^ { 2 }$ by Weisstein [118], and the generalisation to the gamma distribution is obvious. We observe that $U ( a , b , x )$ is a polynomial when $a = - m$ , $m = 0 , 1 , 2 , \ldots$ :  

$\begin{array} { r } { U ( - m , b , x ) = ( - 1 ) ^ { m } \sum _ { j = 0 } ^ { m } { \binom { m } { j } } ( b + j ) _ { m - j } ( - x ) ^ { j } } \end{array}$ . Here the Pochhammer symbol is given by $( a ) _ { 0 } = 0$ and $( a ) _ { j } = a ( a + 1 ) ( a + 2 ) \cdot \cdot \cdot ( a + j - 1 )$ , $j \geq 1$ (see Olver et al. [92, Section 13.2(i)]). For $k \geq 1$ ,  

$$
\iota _ { k } = \sigma ^ { 2 k } \sum _ { j = 0 } ^ { k } \binom { k } { j } ( - \lambda _ { - } ) ^ { j } \lambda _ { + } ^ { k - j } U \Bigg ( - j , 1 - j - \frac { r } { 2 } , - \frac { r } { 2 } \Bigg ) U \Bigg ( j - k , 1 + j - k - \frac { r } { 2 } , - \frac { r } { 2 } \Bigg ) .
$$  

Other formulas for the raw and central moments of the VG distribution are given by Scott [105].  

The cumulants of the $\mathrm { V G } ( r , \theta , \sigma , \mu )$ distribution can be derived by Taylor expanding the logarithms in (2.13) or using the representation (2.20). The latter approach involves using the facts that, for independent random variables $S _ { 1 }$ and $S _ { 2 }$ and constant $c$ , the $k$ -th cumulant enjoys the properties $\kappa _ { k } ( c S _ { 1 } ) = c ^ { k } \kappa _ { k } ( S _ { 1 } )$ and $\kappa _ { k } ( S _ { 1 } + S _ { 2 } ) = \kappa _ { k } ( S _ { 1 } ) + \kappa _ { k } ( S _ { 2 } )$ , and $\kappa _ { k } ( V ) = \lambda ^ { - k } ( k - 1 ) ! r$ for $V \sim \Gamma ( r / 2 , \lambda )$ . For $k \geq 1$ ,  

$$
\kappa _ { k } = \mu \delta _ { k , 1 } + \frac { ( k - 1 ) ! r } { 2 } \big [ ( \theta + \sqrt { \theta ^ { 2 } + \sigma ^ { 2 } } ) ^ { k } + ( \theta - \sqrt { \theta ^ { 2 } + \sigma ^ { 2 } } ) ^ { k } \big ] ,
$$  

where $\delta _ { i , j }$ is the Kronecker delta (see McKay [80]). In particular,  

$$
\begin{array} { r l } & { \kappa _ { 1 } = \mu + r \theta , \quad \kappa _ { 2 } = r ( \sigma ^ { 2 } + 2 \theta ^ { 2 } ) , \quad \kappa _ { 3 } = 2 r \theta ( 3 \sigma ^ { 2 } + 4 \theta ^ { 2 } ) , \quad \kappa _ { 4 } = 6 r ( \sigma ^ { 4 } + 8 \theta ^ { 2 } \sigma ^ { 2 } + 8 \theta ^ { 4 } \sigma ^ { 2 } + 4 \theta ^ { 2 } \sigma ^ { 2 } ) , } \\ & { \kappa _ { 5 } = 2 4 r \theta ( 5 \sigma ^ { 4 } + 2 0 \theta ^ { 2 } \sigma ^ { 2 } + 1 6 \theta ^ { 4 } ) , \quad \kappa _ { 6 } = 1 2 0 r ( \sigma ^ { 6 } + 1 8 \theta ^ { 2 } \sigma ^ { 4 } + 4 8 \theta ^ { 4 } \sigma ^ { 2 } + 3 2 \theta ^ { 6 } ) . } \end{array}
$$  

# 2.8 Mode and median  

A detailed study of the mode and median of the GH and VG distributions was undertaken by Gaunt and Merkle [46]; here we provide a summary for the VG distribution.  

The $\sqrt { \operatorname { G } ( r , \theta , \sigma , \mu ) }$ distribution is unimodal. This follows since the distribution is self-decomposabl and self-decomposable distributions are unimodal (Yamazato [120]). Denote the mode of the $\mathrm { V G } ( r , \theta , \sigma , \mu )$ distribution by $M _ { r }$ . For $0 < r \le 2$ , $\theta \in \mathbb { R }$ , $\sigma > 0$ , or $r > 0$ , $\theta = 0$ , $\sigma > 0$ , we have $M _ { r } = \mu$ . This is clear when $\theta = 0$ , because the $V G ( r , 0 , \sigma , \mu )$ distribution is symmetric about $\mu$ ; for $0 \textless r \leq 2$ and $\theta \in \mathbb { R }$ this follows because, for $0 < \nu \leq 1 / 2$ and $| \beta | < 1$ , the function $x \mapsto \mathrm { e } ^ { \beta x } | x | ^ { \nu } K _ { \nu } ( | x | )$ is increasing on $( - \infty , 0 )$ and decreasing on $( 0 , \infty )$ (this is easily inferred from part (i) of Lemma 5.1 of Gaunt [41]).  

Suppose now that $r > 2$ , $\theta \in \mathbb { R }$ , $\sigma > 0$ , $\mu \in \mathbb { R }$ . Using (A.66), we obtain that $M _ { r } = \mu + \operatorname { s g n } ( \theta ) \cdot x ^ { * }$ , where $x ^ { * }$ is the unique positive solution of the equation  

$$
K _ { \frac { r - 3 } { 2 } } \bigg ( \frac { \sqrt { \theta ^ { 2 } + \sigma ^ { 2 } } } { \sigma ^ { 2 } } x \bigg ) = \frac { | \theta | } { \sqrt { \theta ^ { 2 } + \sigma ^ { 2 } } } K _ { \frac { r - 1 } { 2 } } \bigg ( \frac { \sqrt { \theta ^ { 2 } + \sigma ^ { 2 } } } { \sigma ^ { 2 } } x \bigg ) .
$$  

When $r = 4$ and $r = 6$ , applying (A.63) to (2.36) leads to simple algebraic equations for $x ^ { * }$ which when solved give  

$$
\mu + \theta { \Bigg ( } 1 + { \frac { 1 } { \sqrt { 1 + \kappa } } } { \Bigg ) } , \quad M _ { 6 } = \mu + { \frac { \theta } { 2 } } { \Bigg ( } 1 + { \frac { 1 } { \sqrt { 1 + \kappa } } } { \Bigg ) } { \Bigg ( } 3 - \sqrt { 1 + \kappa } + \sqrt { 6 \sqrt { 1 + \kappa } + \kappa - 2 \kappa } { \Bigg ) } ,
$$  

where $\kappa = \sigma ^ { 2 } / \theta ^ { 2 }$ . For $r = 8$ and $r = 1 0$ , we can apply (A.63) to (2.36) to obtain cubic and quartic equations for $x ^ { * }$ ; however, their solutions $M _ { 8 }$ and $M _ { 1 0 }$ are too complicated to be worth reporting. For other values of $r$ , exact formulas for $M _ { r }$ are not available, except for the case $\theta = 0$ in which we have already noted that the mode is equal to $\mu$ .  

Exact formulas for $M _ { r }$ are not available for general $r \ > \ 2$ ; however, simple and accurate lower and upper bounds can be obtained. Fix $\theta > 0$ ; bounds for $\theta < 0$ follow immediately as if $X \sim \operatorname { V G } ( r , \theta , \sigma , \mu )$ then $- X \sim \mathrm { V G } ( r , - \theta , \sigma , - \mu )$ (see (2.8)). Applying the lower and upper bounds of (A.70) to (2.36) yields simple algebraic inequalities for $x ^ { * }$ . Solving these inequalities and using that $M _ { r } > \mu$ , for $r > 2$ and $\theta > 0$ , leads to the following double inequality:  

$$
\theta ( r - 3 ) _ { + } < M _ { r } - \mu < \theta ( r - 2 ) , \quad r > 2 ,
$$  

where $x _ { + } = \operatorname* { m a x } \{ 0 , x \}$ . Note that there is equality in the upper bound when $r \ = 2$ . Applying inequality (A.71) to equation (2.36) gives that  

$$
M _ { r } > \mu + \frac { \theta } { 2 } \biggl [ r - 2 + \sqrt { \frac { \theta ^ { 2 } ( r - 2 ) ^ { 2 } + \sigma ^ { 2 } ( r - 4 ) ^ { 2 } } { \theta ^ { 2 } + \sigma ^ { 2 } } } \biggr ] , \quad r > 4 ,
$$  

with equality if and only if $r = 4$ , and the inequality is reversed if $2 < r < 4$ . Inequality (2.38) improves on the lower bound in (2.37) in its range of validity $r > 4$ . The reversed inequality (2.38) is more accurate than the upper bound in (2.37) for $3 < r < 4$ , but the reverse is true for $2 < r < 3$ .  

Let $X \sim \operatorname { V G } ( r , \theta , \sigma , \mu )$ . We note that exact formulas for the median are available for certain parameter values: $\operatorname { M e d } ( X ) = \mu$ if $\theta = 0$ , whilst, for $r = 2$ ,  

$$
\operatorname { M e d } ( X ) = \mu + \operatorname { s g n } ( \theta ) \cdot \left( \left| \theta \right| + { \sqrt { \theta ^ { 2 } + \sigma ^ { 2 } } } \right) \log { \biggl ( } 1 + { \frac { \left| \theta \right| } { \sqrt { \theta ^ { 2 } + \sigma ^ { 2 } } } } { \biggr ) } ,
$$  

which follows from the formula for the median of the asymmetric Laplace distribution (see Kozubowsk and Podg´orski [62]). For other parameter values, an exact closed-form formula is not available. Moreover, in contrast to the mode, accurate lower and upper bounds for the median are not available in the literature. Gaunt and Merkle [46] have conjectured accurate bounds for the median, which we present below. The numerical results of Table 1, which are taken from Gaunt and Merkle [46], support the conjectured bounds, since each entry in the table lies between the conjectured lower and upper bounds.  

Conjecture 2.1. Let $X \sim \operatorname { V G } ( r , \theta , \sigma , \mu )$ with $r , \theta , \sigma > 0$ . Then it is conjectured that  

$$
\mu + ( r - 1 ) \theta < \operatorname { M e d } ( X ) < \mu + r \theta \mathrm { e } ^ { - 2 / 3 r } < \mu + \biggl ( r - \frac { 2 } { 3 } + \frac { 2 } { 9 r } \biggr ) \theta , \quad r > 0 ,
$$  

and  

$$
\operatorname { M e d } ( X ) \leq \mu + ( r + 2 \log 2 - 2 ) \theta , \quad r \geq 2 .
$$  

Table 1: Median of the $\lceil \mathrm { G } ( r , 1 , \sigma , 0 )$ distribution.   


<html><body><table><tr><td>0</td><td>0.1</td><td>0.3</td><td>1</td><td>3</td><td>10</td><td>30</td></tr><tr><td>r 0.5</td><td>0.0863</td><td>0.0798</td><td>0.0502</td><td>0.0195</td><td>0.00582</td><td>0.00192</td></tr><tr><td>1</td><td>0.454</td><td>0.444</td><td>0.380</td><td>0.276</td><td>0.198</td><td>0.157</td></tr><tr><td>2.5</td><td>1.872</td><td>1.861</td><td>1.775</td><td>1.621</td><td>1.531</td><td>1.507</td></tr><tr><td>5</td><td>4.350</td><td>4.338</td><td>4.246</td><td>4.084</td><td>4.012</td><td>4.001</td></tr><tr><td>10</td><td>9.340</td><td>9.328</td><td>9.233</td><td>9.071</td><td>9.009</td><td>9.001</td></tr></table></body></html>  

Since $\mathbb { E } [ X _ { r } ] = \mu + r \theta$ for $X _ { r } \sim \mathrm { V G } ( r , \theta , \sigma , \mu )$ , it follows from (2.37) and the fact that $M _ { r } = \mu$ for $0 < r \leq 2$ that, if $\theta > 0$ , then $M _ { r } \leq \mathbb { E } [ X _ { r } ]$ for all $r > 0$ . Moreover, if the conjectured median bounds hold, then it would follow that $M _ { r } \leq \mathrm { M e d } ( X _ { r } ) \leq \mathbb { E } [ X _ { r } ]$ for all $r , \theta , \sigma > 0$ , meaning that the $\mathrm { V G } ( r , \theta , \sigma , \mu )$ distribution would satisfy the mean-median-mode inequality (Groeneveld and Meeden [49] and van Zwet [117]).  

# 3 Parameter Estimation  

Due to its numerous applications, parameter estimation of the VG distribution is of much interest. In this section, we give an overview of available techniques from the literature. In the following, we let $\mathbf { X } = \left( X _ { 1 } , \ldots , X _ { n } \right)$ be an i.i.d. sample of $\mathrm { V G } ( r , \theta , \sigma , \mu )$ random variables from which we wish to estimate the four unknown parameters $r , \theta , \sigma$ and $\mu$ .  

# 3.1 Method of moments estimation  

Moment estimation consists of estimating the raw or central moments through the arithmetic means, i.e. $\begin{array} { r } { \hat { \mu } _ { j } ^ { \prime } = n ^ { - 1 } \sum _ { i = 1 } ^ { n } X _ { i } ^ { j } } \end{array}$ , $j = 1 , \dotsc , 4$ , and $\begin{array} { r } { \hat { \mu } _ { j } = n ^ { - 1 } \sum _ { i = 1 } ^ { n } ( X _ { i } - \hat { \mu } _ { j } ^ { \prime } ) ^ { { j } } } \end{array}$ , $j = 1 , \dotsc , 4$ . As noted by Finlay and Seneta [32], in the four parameter case, it is not possible to resolve ${ \hat { \mu } } _ { j } = \mu _ { j }$ , $j = 1 , \hdots , 4$ , for $( r , \theta , \sigma , \mu )$ explicitly. However, in th symmetric case $\theta = 0$ , this is possible. To illustrate this, we will work in the parameterisation (2.2) of Madan and Seneta [77]. Using the formulas for the first, second and fourth central moments of the VG distribution (2.32), (2.33) and (2.35), one readily obtains the following explicit consistent estimators, which is also unbiased in the case of the estimator for $\mu$ (Madan and Seneta [77]):  

$$
{ \hat { \mu } } = { \frac { 1 } { n } } \sum _ { i = 1 } ^ { n } X _ { i } , \quad { \hat { \sigma } } _ { 0 } ^ { 2 } = { \frac { 1 } { n } } \sum _ { i = 1 } ^ { n } ( X _ { i } - { \overline { { X } } } ) ^ { 2 } , \quad { \hat { \nu } } = { \frac { 1 } { 3 { \hat { \sigma } } _ { 0 } ^ { 4 } n } } { \bigg \{ } \sum _ { i = 1 } ^ { n } ( X _ { i } - { \overline { { X } } } ) ^ { 4 } { \bigg \} } - 1 .
$$  

In Finlay and Seneta [32], the moment estimates are obtained by minimising the quantity $\textstyle \sum _ { j = 1 } ^ { 4 } ( ( \hat { \mu } _ { j } ^ { \prime } -$ $\mu _ { j } ^ { \prime } ) / { \hat { \mu } _ { j } ^ { \prime } } ) ^ { 2 }$ with respect to $( r , \theta , \sigma , \mu )$ , where $\mu _ { j } ^ { \prime }$ , $j = 1 , \hdots , 4$ , are as in Section 2.7. In Seneta [108], explicit moment estimators are obtained for the parametrisation (2.2) by assuming that expressions of the form $\theta _ { 0 } ^ { k }$ , $k \geq 2$ are negligible since the true value of $\theta _ { 0 }$ is often small in finanical modelling applications. An advantage of the moment estimators is the easy numerical implementation. A competitive simulation study in order to evaluate the performance of the moment estimators is carried out in Finlay and Seneta [32].  

# 3.2 Maximum-likelihood estimation  

We maximise the log-likelihood function  

$$
\ell ( \mathbf { X } , r , \theta , \sigma , \mu ) = \sum _ { i = 1 } ^ { n } \log p ( X _ { i } , r , \theta , \sigma , \mu )
$$  

with respect to $( r , \theta , \sigma , \mu )$ , where $p$ is the VG density (1.1). Due to the complexity of the density involving the modified Bessel function of the second kind, there is no analytic solution to this optimisation problem and one relies on numerical methods in order to determine the global maximum. We also stress the density function admits a singularity at $\mu$ for $r \leq 1$ . There exist implementations of numerical procedures for maximum-likelihood estimation, such as the VarianceGamma R package of Scott and Dong [104] through the VGFit-function. Madan and Seneta [77] proposed a transformed maximum likelihood method which permits to perform optimisation with respect to a more tractable density function (see also Madan and Seneta [76]). In Madan et al. [73], MLE is used in order to estimate the parameters for a real financial data example. In Bee, Dickson and Santi [14], the VarianceGamma package is compared to the ghyp R package of Breymann and Lu¨thi [16], which implements the more general GH distribution, and to the ECM algorithm that we describe in Section 3.3. In Cervellera and Tucci [19], the authors investigate three different numerical optimisation procedures (including the VarianceGamma R package, Matlab and Ezgrad) and point out several difficulties that can be encountered when using MLE. More precisely, the authors exhibit that the likelihood function is sensitive to the removal of a single observation and that in some cases the algorithms produce different output for different starting values. Due to the non-differentiability of the likelihood function with respect to $\mu$ , the variance-gamma distribution does not fulfil the classical regularity assumptions that are required to apply the standard asymptotic theory of maximum likelihood estimators. However, in special cases in which certain parameters are known, the asymptotic theory has already been studied (see, for example, Kotz et al. [60] for the Laplace and asymmetric Laplace distributions).  

# 3.3 ECM algorithms  

Motivated by the complexity of the optimisation of the likelihood function, several approaches using ECM (Expectation-Conditional Maximisation) algorithms have been studied recently. The algorithm we present here was first introduced by Nitithumbundit and Chan [86] and McNicholas, McNicholas and Browne [82] for the multivariate VG model and mixtures of the latter. We restrict ourselves to the one-dimensional case and present the algorithm described in detail in Bee et al. [14]. Here we will consider the VG model under the parametrisation (2.2). ECM algorithms are considered as iterative procedures based on the maximisation of the likelihood function with missing data. Letting $S \sim \Gamma ( \alpha , \alpha )$ , $T \sim N ( 0 , 1 )$ be independent and using (2.18) we know that  

$$
X = \mu + \theta _ { 0 } S + \sigma _ { 0 } \sqrt { S } T \sim \mathrm { V G } _ { 2 } ( \alpha , \theta _ { 0 } , \sigma _ { 0 } , \mu ) .
$$  

We now treat $\mathbf { S } = ( S _ { 1 } , \ldots , S _ { n } )$ as missing data because the conditional distribution of $X$ on $S$ is $N ( \mu + \theta _ { 0 } S , \sigma _ { 0 } ^ { 2 } S )$ , which means we can write the respective joint log-likelihood function as a product of a conditional normal and a gamma density. More precisely,  

$$
\begin{array} { l } { \displaystyle \ell _ { c } ( \mathbf { X } , \mathbf { S } , \alpha , \boldsymbol { \theta } _ { 0 } , \sigma _ { 0 } , \mu ) = - \frac { n } { 2 } \log \left( \sqrt { r } \sigma _ { 0 } ^ { 2 } \right) - \frac { 1 } { 2 } \sum _ { i = 1 } ^ { n } \frac { 1 } { S _ { i } } \frac { ( X _ { i } - \mu - S _ { i } \boldsymbol { \theta } _ { 0 } ) ^ { 2 } } { \sigma _ { 0 } ^ { 2 } } } \\ { \displaystyle ~ + n \alpha \log ( \alpha ) - n \log ( \gamma ( \alpha ) ) + ( \alpha - 1 ) \sum _ { i = 1 } ^ { n } \log S _ { i } - \alpha \sum _ { i = 1 } ^ { n } S _ { i } } \\ { \displaystyle = \ell _ { c } ^ { ( 1 ) } ( \mathbf { X } , \mathbf { S } , \boldsymbol { \theta } _ { 0 } , \sigma _ { 0 } , \mu ) + \ell _ { c } ^ { ( 2 ) } ( \mathbf { X } , \mathbf { S } , \alpha ) . } \end{array}
$$  

ECM-type algorithms iterate an expectation (E)-step and a conditional maximisation (CM)-step.  

$\mathbf { E }$ -step: Here one computes the conditional expectation $\mathbb { E } [ \ell _ { c } ( \mathbf { X } , \mathbf { S } , \alpha , \theta _ { 0 } , \sigma _ { 0 } , \mu ) | \mathbf { X } ]$ , which breaks down to the computation of $\mathbb { E } [ S _ { i } | \mathbf { X } ]$ , $\mathbb { E } [ 1 / S _ { i } | \mathbf { X } ]$ and $\mathbb { E } [ \log S _ { i } \mid \mathbf { X } ]$ . Embrechts [29] showed that the conditional distribution of $S$ on $X$ is generalized inverse Gaussian and hence we can estimate $S _ { i }$ , $1 / S _ { i }$ and $\log { S _ { i } }$ by the corresponding conditional expectations  

$$
\begin{array} { r l } & { \hat { S } _ { i } = \mathbb { E } [ S _ { i } \mid \mathbf { X } ] = \frac { \delta _ { i } K _ { \alpha + 1 / 2 } \big ( \sqrt { 2 \alpha + \theta _ { 0 } ^ { 2 } / \sigma _ { 0 } ^ { 2 } } \delta _ { i } \big ) } { \sqrt { 2 \alpha + \theta _ { 0 } ^ { 2 } / \sigma _ { 0 } ^ { 2 } } K _ { \alpha - 1 / 2 } \big ( \sqrt { 2 \alpha + \theta _ { 0 } ^ { 2 } / \sigma _ { 0 } ^ { 2 } } \delta _ { i } \big ) } \mathrm { , } } \\ & { \widehat { 1 / S _ { i } } = \mathbb { E } [ 1 / S _ { i } \mid \mathbf { X } ] = \frac { \sqrt { 2 \alpha + \theta _ { 0 } ^ { 2 } / \sigma _ { 0 } ^ { 2 } } K _ { \alpha - 3 / 2 } \big ( \sqrt { 2 \alpha + \theta _ { 0 } ^ { 2 } / \sigma _ { 0 } ^ { 2 } } \delta _ { i } \big ) } { \delta _ { i } K _ { \alpha - 1 / 2 } \big ( \sqrt { 2 \alpha + \theta _ { 0 } ^ { 2 } / \sigma _ { 0 } ^ { 2 } } \delta _ { i } \big ) } \mathrm { , } } \\ & { \widehat { \mathrm { l o g ~ } S _ { i } } = \mathbb { E } [ \log S _ { i } \mid \mathbf { X } ] = \log \bigg ( \frac { \delta _ { i } } { \sqrt { 2 \alpha + \theta _ { 0 } ^ { 2 } / \sigma _ { 0 } ^ { 2 } } } \bigg ) + \frac { \hat { K } _ { \alpha - 1 / 2 } ^ { ( 1 , 0 ) } \big ( \sqrt { 2 \alpha + \theta _ { 0 } ^ { 2 } / \sigma _ { 0 } ^ { 2 } } \delta _ { i } \big ) } { K _ { \alpha - 1 / 2 } \big ( \sqrt { 2 \alpha + \theta _ { 0 } ^ { 2 } / \sigma _ { 0 } ^ { 2 } } \delta _ { i } \big ) } \mathrm { , } } \end{array}
$$  

where $\delta _ { i } = ( X _ { i } - \mu ) ^ { 2 } / \sigma _ { 0 } ^ { 2 }$ and $\hat { K } _ { \alpha } ^ { ( 1 , 0 ) } ( z ) = ( K _ { \alpha + h } ( z ) - K _ { \alpha - h } ( z ) ) / ( 2 h )$ , for some small constant $h > 0$ , is an approximation of $\partial K _ { \tau } ( z ) / \partial \tau | _ { \tau = \alpha }$ (see Bee et al. [14, p. 76]).  

CM-step: In this step, one maximises the conditional expectation of the log-likelihood function $\mathbb { E } [ \ell _ { c } ( \mathbf { X } , \mathbf { S } , \alpha , \theta _ { 0 } , \sigma _ { 0 } , \mu ) \mid \mathbf { X } ]$ with respect to the parameter vector $( \alpha , \theta _ { 0 } , \sigma _ { 0 } , \mu )$ . One can maximise $\mathbb { E } [ \ell _ { c } ^ { ( 1 ) } ( \mathbf { X } , \mathbf { S } , \theta _ { 0 } , \sigma _ { 0 } , \mu ) \mid \mathbf { X } ]$ and $\mathbb { E } [ \ell _ { c } ^ { ( 2 ) } ( \mathbf { X } , \mathbf { S } , \alpha ) \mid \mathbf { X } ]$ separately. The first optimisation problem can be solved analytically by  

$$
\begin{array} { l } { \hat { \mu } = \displaystyle \frac { \sum _ { i } \widetilde { \lambda _ { i } \bigcap _ { i } } \sum _ { \lambda } \hat { S } _ { i } - n \sum X _ { i } } { \sum \overbrace { 1 / S _ { i } } \sum _ { \lambda } \hat { S } _ { i } - n ^ { 2 } } , } \\ { \hat { \theta } _ { 0 } = \displaystyle \frac { \sum _ { i } X _ { i } - n \hat { \mu } } { \hat { S } _ { i } } , } \\ { \hat { \sigma } _ { 0 } ^ { 2 } = \displaystyle \frac { 1 } { n } \sum \overbrace { 1 / S _ { i } } ^ { \sum } ( X _ { i } - \hat { \mu } ) ^ { 2 } - \frac { 1 } { n } \hat { \theta } _ { 0 } ^ { 2 } \sum _ { i } . } \end{array}
$$  

For optimisation with respect to $\alpha$ , no analytic solution is available. It is suggested to optimise either $\mathbb { E } [ \ell _ { c } ^ { ( 2 ) } ( \mathbf { X } , \mathbf { S } , \alpha ) \mid \mathbf { X } ]$ or the likelihood of the VG distribution with updated parameters $\ell ( \mathbf { X } , \mathbf { S } , \alpha , \hat { \theta } _ { 0 } , \hat { \sigma } _ { 0 } , \hat { \mu } )$ . Bee et al. [14] carried out a competitive simulation study, finding the latter of the two options to be preferable. Given a vector of starting values $( \hat { \alpha } ^ { ( 0 ) } , \hat { \theta } _ { 0 } ^ { ( 0 ) } , \hat { \sigma } _ { 0 } ^ { ( 0 ) } , \hat { \mu } ^ { ( 0 ) } )$ , a pseudo-code for the $t$ -th iteration of the algorithm is:  

• E-step 1: Compute Si(t−1/2) $\hat { \alpha } ^ { ( t - 1 ) } , \hat { \theta } _ { 0 } ^ { ( t - 1 ) } , \hat { \sigma } _ { 0 } ^ { ( t - 1 ) }$ nbd $\hat { \mu } ^ { ( t - 1 ) }$ and 1/Si . using (3.40) and (3.41) and the current estimates • CM-step 1: Compute $\hat { \theta } _ { 0 } ^ { ( t ) } , \hat { \sigma } _ { 0 } ^ { ( t ) }$ and $\hat { \mu } ^ { ( t ) }$ using (3.43), (3.44) and (3.45).   
• $\mathbf { E }$ -step 2: Compute $\widehat { S } _ { i } ^ { ( t ) }$ and $\widehat { \log S _ { i } } ^ { ( t ) }$ through (3.40) and (3.42) using the updated parameters $\hat { \theta } _ { 0 } ^ { ( t ) }$ , $\hat { \sigma } _ { 0 } ^ { ( t ) }$ and $\hat { \mu } ^ { ( t ) }$ as wbell as $\hat { \alpha } ^ { ( t - 1 ) }$ .   
• CM-step 2: Compute $\hat { \alpha } ^ { ( t ) }$ with a numerical optimisation method using the updated expectations Si(t) a nd $\widehat { \log S _ { i } } ^ { ( t ) }$  

The algorithm encounters difficulties during the E-step when $X _ { i }$ is very close to $\mu$ . In this case, it is recommended to replace $\delta _ { i }$ by $\delta _ { i } ^ { * } = \Delta / \sqrt { 2 \alpha + \theta _ { 0 } ^ { 2 } / \sigma _ { 0 } ^ { 2 } }$ for some $\Delta > 0$ . Recommendations for values of $\Delta$ are given in Bee et al. [14]. An improved version of the algorithm in the multivariate case is available in Nitithumbundit and Chan [87].  

# 3.4 Further estimation techniques  

For the sake of completeness, we mention several other estimation methods in the literature. In Loregian, Mercuri and Rroji [69], a Gaussian quadrature is used to approximate an integral representation of the VG density by a mixture of Gaussian densities, and then an ECM algorithm with respect to the mixing variable is used to estimate the parameters. Nzokem [91] uses a fractional Fourier transform in order to approximate the VG density. In Finaly and Seneta [32], a minimum $\chi ^ { 2 }$ -approach is studied, which compares theoretical and empirical quantiles (see also Finlay and Seneta [31] and Tjetjep and Seneta [114]). Finlay and Seneta [32] further present an estimation procedure based on the characteristic function. It is worth noting that this approach is still valid when there is a certain dependency structure in the data. Finlay and Seneta [32] describe a Bayesian procedure, and a Markov Chain Monte Carlo method is used in order to sample from the posterior distribution. We also refer to Rathgeber, Johannes and St¨ockl [98], in which a number of the estimation techniques described in this section are compared on the basis of real financial data.  

# 4 Applications  

# 4.1 Exact distribution in mathematical statistics  

# 4.1.1 Connection to sample correlation  

Let $( X _ { i } , Y _ { i } )$ , $1 \leq i \leq n$ , be i.i.d. bivariate normal random vectors with mean vector $( \mu _ { X } , \mu _ { Y } )$ , variances $( \sigma _ { X } ^ { 2 } , \sigma _ { Y } ^ { 2 } )$ and correlation coefficient $\rho$ . It was shown by Pearson, Jefferey and Elderton [93] that the product-moment coefficient  

$$
p _ { n } = { \frac { 1 } { n } } \sum _ { i = 1 } ^ { n } ( X _ { i } - { \overline { { X } } } ) ( Y _ { i } - { \overline { { Y } } } )
$$  

has a VG distribution (they referred to it as the Bessel function distribution). An alternative proof is given by Kotz et al. [60, Proposition 4.1.5]. In our parametrisation,  

$$
p _ { n } \sim \mathrm { V G } ( n - 1 , \rho \sigma _ { X } \sigma _ { Y } / n , \sigma _ { X } \sigma _ { Y } \sqrt { 1 - \rho ^ { 2 } } / n , 0 ) .
$$  

Here we applied the scaling property (2.8) of the VG distribution to deal with the case of general variances $\sigma _ { X } ^ { 2 } , \sigma _ { Y } ^ { 2 } > 0$ ; Kotz et al. [60] proved the result for the case $\sigma _ { X } = \sigma _ { Y } = 1$ . As observed by Kotz et al. [60], when $n = 3$ the product-moment coefficient $p _ { 3 }$ has an asymmetric Laplace distribution (see part 1 of Section 2.5.1). Moreover, as in part 4 of Section 2.5.1, let $Z = U V$ , where $( U , V )$ is a bivariate normal random vector with zero mean vector, variances $( \sigma _ { X } ^ { 2 } , \sigma _ { Y } ^ { 2 } )$ and correlation coefficient $\rho$ . Consider also the mean $Z _ { n - 1 } = ( n - 1 ) ^ { - 1 } ( Z _ { 1 } + Z _ { 2 } + \cdots + Z _ { n - 1 } )$ , where $Z _ { 1 } , Z _ { 2 } , \ldots , Z _ { n - 1 }$ are independent copies of $Z$ . Then, by the relation (2.22) and the scaling property (2.8), we have that, for $n \geq 2$ ,  

$$
p _ { n } = _ { d } ( 1 - 1 / n ) \overline { { Z } } _ { n - 1 } .
$$  

In particular, $p _ { 2 } ~ = _ { d } ~ Z / 2$ . It follows from (4.46) and the central limit theorem that $\sqrt { n } ( p _ { n } \mathrm { ~ - ~ }$ $\rho \sigma _ { X } \sigma _ { Y } )  _ { d } N ( 0 , \sigma _ { X } ^ { 2 } \sigma _ { Y } ^ { 2 } ( 1 + \rho ^ { 2 } ) )$ , as $n \to \infty$ .  

# 4.1.2 Connection to the Wishart distribution  

Let $N$ be a $p \times n$ matrix, whose $n$ columns are independent $p$ -dimensional multivariate normal random vectors with zero mean vector and positive definite covariance matrix $V = ( v _ { i j } )$ . Then the Wishart distribution is the probability distribution of the $p \times p$ random matrix $X = N N ^ { \mathsf { T } }$ . We denote such a random matrix by $W _ { p } ( V , n )$ . The positive integer $n \geq 1$ is referred to as the number of degrees of freedom, and when $V = p = 1$ , the Wishart distribution reduces to the $\chi _ { n } ^ { 2 }$ distribution. The Wishart distribution is widely used in multivariate statistics, Bayesian analysis and random matrix theory.  

A fundamental distributional property of the Wishart distribution is the marginal distribution of its entries. It is well-known that the diagonal entries are suitably scaled chi-square random variables: $X _ { i i } \sim v _ { i i } \chi _ { n } ^ { 2 }$ , $1 \leq i \leq p$ (see, for example, Kollo [57, Corollary 2.4.2.2]). It is perhaps less well-known that the off-diagonal entries are VG distributed (see Pearson et al. [93] for the two-dimensional case). More precisely,  

$$
X _ { i j } \sim \mathrm { V G } ( n , v _ { i j } , ( v _ { i i } v _ { j j } - v _ { i j } ^ { 2 } ) ^ { 1 / 2 } , 0 ) , \quad i \neq j .
$$  

As $V$ is a covariance matrix, it is natural to set $v _ { i i } = \sigma _ { i } ^ { 2 }$ and $v _ { i j } = \rho _ { i j } \sigma _ { i } \sigma _ { j }$ , $i \neq j$ , where $\sigma _ { i } ^ { 2 }$ is the variance of the $i$ -th component of a $p$ -dimensional $N _ { p } ( \mathbf { 0 } , V )$ multivariate normal random vector, whilst $\rho _ { i j }$ is the correlation coefficient of the $i$ -th and $j$ -th components. With this notation, we have that $X _ { i j } \sim \mathrm { V G } ( n , \rho _ { i j } \sigma _ { i } \sigma _ { j } , \sigma _ { i } \sigma _ { j } ( 1 - \rho _ { i j } ^ { 2 } ) ^ { 1 / 2 } , 0 )$ , $i \neq j$ . From (2.22), it therefore follows that $X _ { i j }$ has a neat representation as a sum of independent copies of correlated zero mean normal random variables. Let $Z _ { 1 } , \ldots , Z _ { n }$ be independent $\mathrm { P N } ( \rho _ { i j } , \sigma _ { i } , \sigma _ { j } )$ random variables (recall that this notation was introduced in part 4 of Section 2.5.1). Then  

$$
X _ { i j } = _ { d } Z _ { 1 } + \cdot \cdot \cdot + Z _ { n } , \quad i \neq j .
$$  

That the off diagonal entries are VG distributed can be deduced from the Bartlett decomposition of the Wishart distribution (see Anderson [4]) and the representation (2.18) of the VG distribution in terms of independent normal and chi-square random variables. The Bartlett decomposition of $X \sim W _ { p } ( V , n )$ is  

$$
X = _ { d } L A A ^ { \intercal } L ^ { \intercal } ,
$$  

where $L$ is the Cholesky factor of $V$ and $A$ is a lower triangular matrix with diagonal entries $S _ { i } \sim \chi _ { n - i + 1 }$ (so that $S _ { i } ^ { 2 } \sim \chi _ { n - i + 1 } ^ { 2 } ,$ ), $1 \leq i \leq p$ , and off-diagonal entries 0 for $j < i$ , and $N _ { i j } \sim N ( 0 , 1 )$ for $i > j$ . All entries in the matrix $A$ are mutually independent. From the Bartlett decomposition (4.48) we obtain that  

$$
X _ { 1 2 } = _ { d } v _ { 1 2 } S _ { 1 } ^ { 2 } + ( v _ { 1 1 } v _ { 2 2 } - v _ { 1 2 } ^ { 2 } ) ^ { 1 / 2 } S _ { 1 } N _ { 1 2 } ,
$$  

where we used that $L _ { 1 1 } = \sqrt { v _ { 1 1 } }$ , $L _ { 1 2 } = v _ { 1 2 } / \sqrt { v _ { 1 1 } }$ and $L _ { 2 2 } = ( v _ { 2 2 } - v _ { 1 2 } ^ { 2 } / v _ { 1 1 } ) ^ { 1 / 2 }$ . It therefore follows from the representation (2.18) of the VG distribution that $X _ { 1 2 } \sim \mathrm { V G } ( n , v _ { 1 2 } , ( v _ { 1 1 } v _ { 2 2 } - v _ { 1 2 } ^ { 2 } ) ^ { 1 / 2 } , 0 )$ . We can use the Bartlett decomposition (4.48) to obtain similar representations of the off-diagonal elements $X _ { i j }$ , $i \neq j$ , in terms of independent normal and chi-square random variables, although these representations are more complicated and it is harder to infer that the elements are indeed VG distributed through this approach. However, the fact that the off-diagonal entries are VG distributed with parameters given as in (4.47) follows from (4.49) and symmetry considerations. This can be seen analytically, for a general off-diagonal element $X _ { i j }$ , by suitably reordering the elements in the Wishart matrix $X$ and making the corresponding reordering in the matrix $V$ , and then obtaining the Bartlett decomposition of the new Wishart matrix $X ^ { \prime }$ . The entry $X _ { i j }$ (entry $X _ { 1 2 } ^ { \prime }$ in the re-ordered Wishart matrix $X ^ { \prime }$ ) then can be seen to have a representation of the form $X _ { i j } = _ { d } v _ { i j } S _ { 1 } ^ { 2 } + ( v _ { i i } v _ { j j } - v _ { i j } ^ { 2 } ) ^ { 1 / 2 } S _ { 1 } N _ { 1 2 }$ , and the claim follows.  

# 4.2 Variance-gamma process  

In Section 2.3, we saw that the VG distribution is infinitely divisible. As a consequence of the theory of infinitely divisible distributions and processes (see Ferguson and Klass [30]), we can define a L´evy process with VG distributed increments. The resulting Le´vy process is known as the VG process, which, as we shall discuss in Section 4.3, is widely used in financial modelling. The terminolgy Laplace motion is also often employed; see, for example, Kotz et al. [60] and Kozubowski and Podg´orski [63]. The first complete presentation of the VG model was given by Madan and Seneta [77] for the case of symmetric VG distributed increments ( $\theta = 0$ ), which was extended to incorporate skewness ( $\theta \in \mathbb { R }$ ) by Madan and Milne [74] and Madan et al. [73]. A few years before the seminal paper of Madan and Seneta [77], the same authors published two papers (Madan and Seneta [75, 76]) which contained some basic properties of the VG process; see Seneta [109] for an account of the early years of the VG process.  

In this section, we shall review some of the most fundamental properties of the VG process and briefly discuss why these properties are desirable in the context of financial modelling. We shall only consider the univariate VG process; for an account of the multivariate VG process, which was introduced by Madan and Seneta [77], we refer the reader to Luciano and Schoutens [70],  

![](images/5e5c7d8d08f1e1a24945ade1c1cf62286c31384e7c6b7d1f439d9eb9941f241e.jpg)  
Figure 2: Three realisations of the VG process $X ( t ; 1 , 1 , 0 )$ (left image) and $X ( t ; 1 , 2 , 0 )$ (right image).  

Semeraro [107], Luciano and Semeraro [71] and Luciano, Marena and Semeraro [72], and Linders and Stassen [68] for applications to basket options calibration on the DJIA index. We also do not discuss methods for simulating VG processes, and refer the reader to Avramidis and L’Ecyuer [6], Fu [34] and Korn, Korn and Kroisandt [59, Section 7.3.3] for algorithms.  

Madan et al. [73] constructed the VG process as a subordinated Brownian motion with a time change by a gamma process. Consider a Brownian motion with drift $\theta$ and volatility $\sigma$ given by $b ( t ; \theta , \sigma ) = \theta t + \sigma B ( t )$ , where $B ( t )$ is standard Brownian motion. Recall that the gamma process $\gamma ( t ; \mu , \nu )$ with mean rate $\mu$ and variance rate $\nu$ is a Le´vy process with increment $\tau _ { h } =$ $\gamma ( t + h ; \mu , \nu ) - \gamma ( t ; \mu , \nu )$ following the $\Gamma ( \mu ^ { 2 } h / \nu , \mu / \nu )$ distribution. Suppose that the processes $B ( t )$ and $\gamma ( t ; \mu , \nu )$ are independent. Then, the VG process $X ( t ) = X ( t ; \sigma , \nu , \theta )$ , with parameters $\nu > 0$ , $\theta \in \mathbb R$ and $\sigma > 0$ , is defined as  

$$
X ( t ) = b ( \gamma ( t ; 1 , \nu ) ; \theta , \sigma ) .
$$  

As we shall see, control over skewness and kurtosis can be attained via the parameters $\theta$ and $\nu$ , respectively. This feature is important in financial modelling. As noted by Madan and Seneta [77, p. 517], the random gamma time change in (4.50) has an interesting economic interpretation of supposing that economically relevant time is random in that the market (price process $X ( t )$ ) moves at different speeds on different days, and the process $\gamma ( t ; 1 , \nu )$ is a measure of this speed. Samples paths showing the effect of varying the parameter $\nu$ in the symmetric VG process are given in Figure 2.  

To see that the increments of the VG process (4.50) are VG distributed, we observe that  

$$
X ( t + h ) - X ( t ) = \theta \tau _ { h } + \sigma ( B ( \gamma ( t + h ; 1 , \nu ) ) - B ( \gamma ( t ; 1 , \nu ) ) = _ { d } \theta \tau _ { h } + \sigma \tau _ { h } ^ { 1 / 2 } B ( 1 ) .
$$  

As $B ( 1 ) \sim N ( 0 , 1 )$ and $\tau _ { h } \sim \Gamma ( \mu ^ { 2 } h / \nu , \mu / \nu )$ are independent, it follows from (2.18) that  

$$
X ( t + h ) - X ( t ) \sim \mathrm { V G } ( 2 h / \nu , \theta \nu / 2 , \sigma \sqrt { \nu / 2 } , 0 ) .
$$  

In particular, since $X ( 0 ) = 0$ ,  

$$
X ( t ) \sim \mathrm { V G } ( 2 t / \nu , \theta \nu / 2 , \sigma \sqrt { \nu / 2 } , 0 ) .
$$  

As we shall see shortly, the VG process is of finite variation, so can be expressed as the difference of two independent increasing processes. These increasing processes are in fact gamma processes, and we have the representation (see Madan et al. [73])  

$$
X ( t ) = _ { d } \gamma _ { p } ( t ; \mu _ { p } , \nu _ { p } ) - \gamma _ { n } ( t ; \mu _ { n } , \nu _ { n } ) ,
$$  

where  

$$
\mu _ { p } = \frac { 1 } { 2 } \sqrt { \theta ^ { 2 } + \frac { 2 \sigma ^ { 2 } } { \nu } } + \frac { \theta } { 2 } , \mu _ { n } = \frac { 1 } { 2 } \sqrt { \theta ^ { 2 } + \frac { 2 \sigma ^ { 2 } } { \nu } } - \frac { \theta } { 2 } , \nu _ { p } = \mu _ { p } ^ { 2 } \nu , \nu _ { n } = \mu _ { n } ^ { 2 } \nu .
$$  

Here $\gamma _ { p } ( t ; \mu _ { p } , \nu _ { p } )$ plays the role of a returns process, whilst $\gamma _ { n } ( t ; \mu _ { n } , \nu _ { n } )$ is a losses process. The representation (4.53) of the VG process as a difference of two independent gamma processes follows from the representation (2.20) and the fact that $\gamma ( t ; \mu , \nu ) \sim \Gamma ( \mu ^ { 2 } t / \nu , \mu / \nu )$ .  

From (4.52) and the moments formulas (2.30) and (2.33)–(2.35) we obtain that  

$$
\begin{array} { c } { { \mathbb { E } [ X ( t ) ] = \theta t , } } \\ { { \mathbb { E } [ ( X ( t ) - \mathbb { E } [ X ( t ) ] ) ^ { 2 } ] = ( \theta ^ { 2 } \nu + \sigma ^ { 2 } ) t , } } \\ { { \mathbb { E } [ ( X ( t ) - \mathbb { E } [ X ( t ) ] ) ^ { 3 } ] = ( 2 \theta ^ { 3 } \nu ^ { 2 } + 3 \sigma ^ { 2 } \theta \nu ) t , } } \\ { { \mathbb { E } [ ( X ( t ) - \mathbb { E } [ X ( t ) ] ) ^ { 4 } ] = ( 3 \sigma ^ { 4 } \nu + 1 2 \sigma ^ { 2 } \theta ^ { 2 } \nu ^ { 2 } + 6 \theta ^ { 4 } \nu ^ { 3 } ) t + ( 3 \sigma ^ { 4 } + 6 \sigma ^ { 2 } \theta ^ { 2 } \nu + 3 \theta ^ { 4 } \nu ^ { 2 } ) t ^ { 2 } } } \end{array}
$$  

(see Madan et al. [73]). We see that the parameter $\theta$ does not directly control skewness, although skewness is zero when $\theta = 0$ , and positive when $\theta > 0$ . When $\theta = 0$ , the kurtosis is $3 ( 1 + \nu / t )$ , and so $\nu$ is the percentage of excess kurtosis for a unit interval of time $t = 1$ . As $t$ increases, the kurtosis decreases to 3, the kurtosis of the standard normal distribution. As noted by Madan and Seneta [77], this is consistent with the empirical evidence that daily returns are heavy tailed, whilst monthly returns are normally distributed.  

From (4.52) and (2.12), we have that the characteristic function of the VG process is given by  

$$
\varphi _ { X ( t ) } ( u ) = \mathbb { E } [ \mathrm { e } ^ { \mathrm { i } u X ( t ) } ] = \big ( 1 - \mathrm { i } \theta \nu u + ( \sigma ^ { 2 } \nu / 2 ) u ^ { 2 } \big ) ^ { - t / \nu }
$$  

(see Madan et al. [73]). That the characteristic function (4.54) takes a simple form is important in option pricing, since, for example, the fast fourier transform approach from the classic paper of Carr and Madan [21] can be applied to numerically determine option values. From (2.15) and (4.52) we have that the Le´vy-Hinchin representation of the VG process is given by $\varphi _ { X ( t ) } ( u ) = $ $\begin{array} { r } { \exp \big ( t \int _ { \mathbb { R } } ( \mathrm { e } ^ { \mathrm { i } u x } - 1 ) \nu _ { V G } ( x ) \mathrm { d } x \big ) } \end{array}$ , with L´evy density  

$$
\nu _ { V G } ( x ) = \frac { \mu _ { n } ^ { 2 } } { \nu _ { n } | x | } \mathrm { e } ^ { - \mu _ { n } | x | / \nu _ { n } } \mathbf { 1 } _ { x < 0 } + \frac { \mu _ { p } ^ { 2 } } { \nu _ { p } x } \mathrm { e } ^ { - \mu _ { p } x / \nu _ { p } } \mathbf { 1 } _ { x > 0 } .
$$  

From its L´evy-Hinchin representation, it follows that the VG process is a pure jump process (there is no diffusion component). The pure jump nature of the VG process represented a departure from much of the literature on option pricing; for example, the Black-Scholes model is a pure diffusion model. It was noted by Bakshi, Chen and Cao [9] that a jump component is important in option pricing, as pure diffusion models have difficulties in explaining smile effects, in particular in shortdated option prices. Moreover, as asserted by Madan et al. [73], the Black-Scholes model is a parametric special case of the VG model (recall from Section 2.5.1 that the normal distribution is a limiting case of the VG distribution), meaning high activity is already accounted for and so it is not necessary to include a diffusion component in addition. Indeed, due to the factor of $| x | ^ { - 1 }$ , the L´evy density integrates to infinity, and so the VG process is of infinite activity. Also, since $| x |$ is integrable with respect to the L´evy density, the process is of finite variation. As noted by Carr et al. [20], finite variation processes may be more useful than infinite variation processes in explaining the measure change from the statistical to the risk neutral process, since they allow more flexibility between the local characteristic of the martingale components under the two measures. Finally, again as noted by Carr et al. [20], the VG process has a completely monotone Le´vy density. In particular, the derivative of the L´evy density is positive for negative jumps and negative for positive jumps, so that large jumps arrive less frequently than small jumps, which is consistent with what we observe in price movements. Indeed, most jumps are of a vanishingly small size; for a compound Poisson approximation and a detailed account of the fine structure of the jumps see Madan and Seneta [77] and Kotz et al. [60, Section 4.2].  

![](images/ff5e9b792d4942493cf535cc08759d184ed9d882b9496b580cd3ea07d5cdb526.jpg)  
Figure 3: A real data example: We see the daily log returns of the Mercedes Benz Group $A G$ (left picture, 01.01.2013 – 01.01.2023, 2517 observations) and the Global X $D A X$ Germany ETF (right picture, 01.01.2015 – 01.01.2023, 2013 observations) fitted to a VG distribution (●) and a normal distribution (●). We used maximum likelihood estimation in order to fit the VG distribution.  

# 4.3 Financial modelling  

The Black-Scholes model is the paradigm model in mathematical finance. Under this model, the asset price $S ( t )$ at time $t$ obeys geometric Brownian motion  

$$
S ( t ) = S ( 0 ) \exp ( ( \mu - \sigma ^ { 2 } / 2 ) t + \sigma B ( t ) ) ,
$$  

where $\mu \in \mathbb { R }$ and $\sigma > 0$ are constants denoting drift and volatility, and $B ( t )$ is standard Brownian motion. Whilst widely used in financial modelling, a number of deficiencies have been noted. For example, as detailed by Heyde [51], under geometric Brownian motion, the log returns $Y ( t ) =$ $\log S ( t ) - \log S ( t - 1 )$ are i.i.d. normal random variables, which is often in contrast to empirical log returns data; see Eberlein and Keller [26] and Leonenko, Petherick and Sikorskii [67] for empirical studies. In particular, the tails of the normal distribution are not heavy enough for modelling of daily returns; this was one of the original motivations of Madan and Seneta [77] to introduce the VG process with an additional parameter to control kurtosis to allow for heavier tails. On account of the flexibility to control skewness and kurtosis to allow for a better empirical fit to financial data, together with other desirable properties such as those discussed in Section 4.2, the VG model has become widely used in financial modelling; a comparison of the fit of the VG distribution and the normal distribution to real financial data is given in Figure 3. In this section, we give a brief introduction to an extensive literature.  

The statistical and risk neutral dynamics of a stock price in terms of the VG process was given by Madan et al. [73]. The statistical stock price is obtained by replacing the role of Brownian motion in the geometric Brownian motion model (4.55) by the VG process:  

$$
S ( t ) = S ( 0 ) \exp ( m t + X ( t ; \sigma _ { S } , \nu _ { S } , \theta _ { S } ) + \omega _ { S } t ) ,
$$  

where $X ( \cdot )$ is the VG process, $m$ is the mean rate of return on the stock under the statistical probability measure and the subscript $S$ in the VG parameters stresses that they are the statistical  

parameters. The value $\omega _ { S } = \nu _ { S } ^ { - 1 } \log ( 1 - \theta _ { S } \nu _ { S } - \sigma _ { S } ^ { 2 } \nu _ { S } / 2 )$ is determined by the non-arbitrage condition to ensure that $\mathbb { E } [ S ( t ) ] = S ( 0 ) \exp ( m t )$ , that is $\mathbb { E } [ \exp ( X ( t ) ) ] = \exp ( - \omega _ { S } t )$ , with $\mathbb { E } [ \exp ( X ( t ) ) ]$ evaluated using (4.52) and the moment generating function formula (2.11).  

Under the risk neutral process, stock prices discounted at the risk free interest rate are martingales. Therefore the mean rate of return on the stock under this probability measure is the continuously compounded interest rate $r$ . The risk neutral process is  

$$
S ( t ) = S ( 0 ) \exp ( r t + X ( t ; \sigma _ { R N } , \nu _ { R N } , \theta _ { R N } ) + \omega _ { R N } t ) ,
$$  

where the subscripts $R N$ indicate that these are the risk free parameters, and $\omega _ { R N } = \nu _ { R N } ^ { - 1 } \log ( 1 -$ $\theta _ { R N } \nu _ { R N } - \sigma _ { R N } ^ { 2 } \nu _ { R N } / 2 )$ , derived using the same considerations as for the statistical stock price. As discussed in detail by Madan et al. [77], unlike for diffusion based price processes, the statistical and risk free parameters do not need to be equal, and are often quite different.  

As noted by Madan et al. [77], the log stock price relative $\log ( S ( t ) / S ( 0 ) )$ when prices follow the VG process dynamics of (4.56) is VG distributed (this follows from (2.8) and (4.52)):  

$$
\begin{array} { r } { \log ( S ( t ) / S ( 0 ) ) \sim \mathrm { V G } ( 2 t / \nu , \theta \nu / 2 , \sigma \sqrt { \nu / 2 } , ( m + \omega ) t ) , } \end{array}
$$  

where $\omega = \nu ^ { - 1 } \log ( 1 - \theta \nu - \sigma ^ { 2 } \nu / 2 )$ and we have dropped the subscript $S$ from the parameters. This time using (4.51), we see that the log returns are also VG distributed:  

$$
Y ( t ) = \log S ( t ) - \log S ( t - 1 ) \sim \mathrm { { V G } } ( 2 / \nu , \theta \nu / 2 , \sigma \sqrt { \nu / 2 } , m + \omega ) ;
$$  

see Finlay and Seneta [31], who also give formulas to describe the covariance structure of the log returns process $\{ Y ( t ) \}$ .  

Madan et al. [77] derived a closed-form formula for the price of a European call option when the risk neutral dynamics of the stock price follows the VG model (4.57). A standard result states that the price of a European call option $c ( S ( 0 ) ; K , t )$ , for a strike $K$ and maturity $t$ , is given by  

$$
c ( S ( 0 ) ; K , t ) = \mathrm { e } ^ { - r t } \mathbb { E } [ \operatorname* { m a x } ( S ( t ) - K , 0 ) ] .
$$  

Building on the approach of Madan and Milne [74], Madan et al. [73] evaluated the expectation in (4.58) by first conditioning on the random gamma process time change, under which the VG process $X ( t )$ is normally distributed (see part 1 of Section 2.4) and the option value is given by a Black-Scholes type formula. Finally, the European option price for VG risk neutral dynamics is attained on integrating the resulting conditional Black-Scholes formula with respect to the gamma density. The formula is  

$$
\begin{array} { r } { c ( S ( 0 ) ; K , t ) = S ( 0 ) \Psi \bigg ( d \sqrt { \frac { 1 - c _ { 1 } } { \nu } } , ( \alpha + s ) \sqrt { \frac { \nu } { 1 - c _ { 1 } } } , \frac { t } { \nu } \bigg ) } \\ { - K \mathrm { e } ^ { - r t } \Psi \bigg ( d \sqrt { \frac { 1 - c _ { 2 } } { \nu } } , \alpha s \sqrt { \frac { \nu } { 1 - c _ { 2 } } } , \frac { t } { \nu } \bigg ) , } \end{array}
$$  

where $\alpha = - \theta / \sqrt { \sigma ^ { 2 } + \theta ^ { 2 } \nu / 2 }$ , $c _ { 1 } = \nu ( \alpha + s ) ^ { 2 } / 2$ , $c _ { 2 } = \nu \alpha ^ { 2 } / 2$ , and  

$$
d = \frac { 1 } { s } \bigg [ \log \bigg ( \frac { S ( 0 ) } { K } \bigg ) + r t + \frac { t } { \nu } \log \bigg ( \frac { 1 - c _ { 1 } } { 1 - c _ { 2 } } \bigg ) \bigg ] ,
$$  

and $\Psi$ is expressed explicitly in terms of the modified Bessel function of the second kind and the degenerate hypergeometric function of two variables; see Madan et al. [73] for the formula. As noted by Madan et al. [73], on letting $\nu \to 0$ in (4.59), we recover the classical Black-Scholes option pricing formula.  

Madan et al. [73] compared the pricing performance on S&P 500 option data of the pricing formula (4.59) with the Black-Scholes model and the symmetric special case ( $\theta = 0$ ). They found that the performance was superior over the Black-Scholes model, and provided evidence that whilst the statistical density of the underlying risk is typically symmetric, the risk neutral density implied option data is negatively skewed, demonstrating the importance of considering the general nonsymmetric VG model.  

Beyond the work of Madan et al. [73], the VG model has been successfully tested on real market data and has been found to outperform that Black-Scholes model and Jump-Diffusion models in a number of other situations, such as European-style options on the HSI index by Lam, Chang and Lee [66] and currency options by Daal and Madan [23]. Closed-form pricing formulas have also been obtained for various path-independent payoffs under the VG model; see, for example, Aguilar [3] and Ivanov [54]. Typically, however, closed-form option formulas are unavailable; see, for example, Hirsa and Madan [52], in which a partial integro-differential equation is derived for pricing American options under the VG process. In such cases, numerical methods are required, and we refer the reader to the thesis of Fiorani [33] for an extensive account of methods, as well as the recent article of Aguilar [3] for an overview of some popular numerical methods.  

# 4.4 Time series modelling  

Recall from Section 4.3, that the VG distribution is a useful alternative to the normal distribution in financial modelling on account of its heavier tails and capacity to incorporate skewness. This applies equally well to innovations in time series modelling. As discussed in detail by Johannesson [56], VG distributed innovations are a natural alternative to the widely used normally distributed innovations, on account of a natural interpretation of conditionally normally distributed innovations with gamma distributed variance (which results in heavier tails), whilst retaining some analytic tractability and are relatively simple to simulate from. In this section, we provide a brief overview of a growing literature on time series models with VG distributions for innovations.  

In Tomy and Jose [115], an autoregression of order 1 with generalized Gaussian-Laplace innovations was studied:  

$$
X _ { t } = a X _ { t - 1 } + Z _ { t } + V _ { t } ,
$$  

where $a$ is a model parameter and $Z _ { t } \sim N ( 0 , \rho ^ { 2 } )$ and $V _ { t } \sim \mathrm { V G } ( r , \theta , \sigma , \mu )$ are independent. Here the distribution for the innovations is more general than the VG distribution: it is the sum of independent VG and normal random variables (centered, without loss of generality). Tomy and Jose [115] fitted parameters using the classic method of moments, by computing the first six moments; however, the problem of goodness-of-fit with this method was not discussed. Nitithumbundit and Chan [87] considered autoregression of order 1 in a slightly different setting than in (4.60). They only had a VG component $V _ { t }$ (no $Z _ { t }$ ), but the setting was multivariate. The authors successfully used ECM (expectation-conditional maximisation) to fit the model even in the case of unbounded VG density of innovations. They applied their methods to financial data, and reported a superior fit to the data than analogous models with multivariate normally distributed innovations. More general $\mathrm { A R M A } ( p , q )$ models driven by asymmetric Laplace (the $\mathrm { V G } ( 2 , \theta , \sigma , \mu )$ distribution) noise and $\mathrm { A R M A } ( p , q )$ models driven by GARCH asymmetric Laplace noise were studied by Trindade, Zhu and Andrews [116]. Similarly to Nitithumbundit and Chan [87], they applied their models to financial data, again reporting a better fit to the data than for corresponding models with normal innovations.  

Johannesson [56] considered a more complicated time series model in the context of road topography. For innovations, a symmetric VG random variable $Y = \mu + \sigma { \sqrt { S } } T$ is taken from (2.18) (with asymmetry parameter $\theta = 0$ ), replacing $T$ with $T _ { t }$ , an autoregressive process of order 1 with  

Gaussian innovations, and $S$ with $S _ { t }$ , a (nonlinear) autoregressive process of order 1 constructed so that $S _ { t }$ has a gamma distribution for each $t$ and is stationary. They presented two methods to fit the autoregressive parameters, and fitted the model to real-life road topology data, showing that it satisfactorily retrieves the distributions of the length, average slope and height of hills.  

Finally, we mention that there has been recent interest in the study of non-Gaussian random fields built on the VG distribution, and we refer the reader to ˚Aberg, Podg´orski and Rychlik [2], ˚Aberg and Podg´orski [1], Bolin [18], Baxevani, Podg´orski and Wegener [13] and the survey of Kozubowski and Podg´orski [63] for an overview, as well as Podg´orski and Wegener [95] for a discussion of estimation methods, and Bogsj¨o, Podg´orski and Rychlik [17] for an application to the modelling of road surface irregularities.  

# 4.5 Approximation on Wiener space  

In Section 2.3, we saw that the VG distribution is infinitely divisible and in Section 2.4 we saw that the VG distribution has simple representations in terms of independent standard normal and gamma random variables. In virtue of these properties, the VG distribution is a natural candidate as a limiting distribution. Indeed, there has been recent interest in VG approximation on Wiener space. VG approximations for double Wiener-Itˆo integrals have been studied by Azmoodeh, Eichelsbacher and Th¨ale [7], Eichelsbacher and Th¨ale [28] and Gaunt [41] via Stein’s method for VG approximation, which was first developed by Gaunt [36], for which the starting point is the Stein characterisation (2.25).  

# 4.5.1 A six moment theorem for double Wiener-Itˆo integrals  

Let ${ \mathfrak H }$ be a real separable Hilbert space and denote by ${ \mathfrak { H } } ^ { \odot 2 }$ the second symmetric tensor product of $\mathfrak { H }$ . For $f \in \mathfrak { H } ^ { \odot 2 }$ , we denote the double Wiener-Itˆo integral by $I _ { 2 } ( f )$ (see Nourdin and Peccati [88, Section 2.7] for a definition and fundamental properties). If $f \in L ^ { 2 } ( [ 0 , T ] ^ { 2 } , \mathrm { d } t )$ is symmetric then  

$$
I _ { 2 } ( f ) = \int _ { [ 0 , T ] ^ { 2 } } f ( t _ { 1 } , t _ { 2 } ) \mathrm { d } B _ { t _ { 1 } } \mathrm { d } B _ { t _ { 2 } } ,
$$  

where $B = ( B _ { t } ) _ { t \in [ 0 , T ] }$ is a standard two-dimensional Brownian motion (see Nourdin and Peccati [88, Exercise 2.7.6]). Consider the Wasserstein $d _ { \mathrm { W } } ( F , G )$ and smooth Wasserstein distance $d _ { 2 } ( F , G )$ between the distributions of two random elements $F$ and $G$ , defined by  

$$
d _ { \mathcal { H } } ( F , G ) : = \operatorname* { s u p } _ { h \in \mathcal { H } } | \mathbb { E } [ h ( F ) ] - \mathbb { E } [ h ( G ) ] | ,
$$  

where the supremum is taken over the function classes  

$$
\begin{array} { r l } & { \mathcal { H } _ { \mathbb { W } } = \{ h : { \mathbb R } \to { \mathbb R } | h ^ { \prime } \mathrm { ~ i s ~ L i p s c h i t z } , \| h ^ { \prime } \| _ { \infty } \leq 1 \} , } \\ & { \quad \mathcal { H } _ { 2 } = \{ h : { \mathbb R } \to { \mathbb R } | h ^ { \prime } \mathrm { ~ i s ~ L i p s c h i t z } , \| h ^ { \prime } \| _ { \infty } \leq 1 , \| h ^ { \prime \prime } \| _ { \infty } \leq 1 \} , } \end{array}
$$  

respectively, where the supremum norm of $g : \mathbb { R }  \mathbb { R }$ is defined by $\| g \| _ { \infty } = \operatorname* { s u p } _ { x \in \mathbb { R } } | g ( x ) |$ . Clearly, $d _ { 2 } ( F , G ) \leq d _ { \mathrm { W } } ( F , G )$ for any random elements $F$ and $G$ for which $d _ { \mathrm { W } } ( F , G )$ is well-defined.  

Let $F _ { n } ~ = ~ I _ { 2 } ( f _ { n } )$ with $f _ { n } \in \mathfrak { H } ^ { \odot 2 }$ , $n \geq 1$ . Following Eichelsbacher and Th¨ale [28], we write $\mathrm { V G } _ { c } ( r , \theta , \sigma )$ for $\mathrm { V G } ( r , \theta , \sigma , - r \theta )$ , the VG distribution with zero mean. Then, Theorem 5.8 of Eichelsbacher and Th¨ale [28] gives that, as $\boldsymbol { \mathscr { n } }  \boldsymbol { \infty }$ , the sequence $( F _ { n } ) _ { n \geq 1 }$ converges in distribution to $Y \sim \mathrm { V G } _ { c } ( r , \theta , \sigma )$ if and only if $\kappa _ { i } ( F _ { n } ) \to \kappa _ { i } ( Y )$ , $i = 2 , 3 , 4 , 5 , 6$ . The cumulants $\kappa _ { i } ( Y )$ are readily obtained through the formulas of Section 2.7 and the formula $\kappa _ { j } ( S + c ) = \kappa _ { j } ( S )$ , $j \geq 2$ , for any $c \in \mathbb { R }$ . This “six moment” theorem implies that the convergence of a sequence of double  

Wiener-Itˆo integrals to the $\mathrm { V G } _ { c } ( r , \theta , \sigma )$ distribution is governed solely by the behaviour of the first six cumulants (equivalently, first six moments). This is a VG analogue of the celebrated “fourth moment” theorem of Nualart and Peccati [90] for normal approximation of multiple Wiener-Itˆo integrals.  

Furthermore, quantitative “six moment” theorems are also available. Let  

$$
\begin{array} { r } { \mathbf { M } ( F _ { n } ) = \operatorname* { m a x } \{ | \kappa _ { i } ( F _ { n } ) - \kappa _ { i } ( Y ) | : i = 2 , 3 , 4 , 5 , 6 \} . } \end{array}
$$  

Then, there exists a universal constant $C > 0$ , which only depends on $r$ , $\theta$ , $\sigma$ , such that  

$$
d _ { \mathrm { W } } ( F _ { n } , Y ) \leq C \sqrt { \mathbf { M } ( F _ { n } ) }
$$  

(Eichelsbacher and Th¨ale [28] and Gaunt [41]), and, in the weaker $d _ { 2 }$ metric, it was shown by Azmoodeh et al. [7] that there exist universal constants $C _ { 1 } , C _ { 2 } > 0$ such that  

$$
C _ { 1 } \mathbf { M } ( F _ { n } ) \leq d _ { 2 } ( F _ { n } , Y ) \leq C _ { 2 } \mathbf { M } ( F _ { n } ) .
$$  

The rate of convergence in (4.62) is optimal, and thus constitutes an analogue of the optimal fourth moment theorem of Nourdin and Peccati [89] for normal approximation.  

# 4.5.2 The generalized Rosenblatt process at extreme critical exponent  

We now review how Azmoodeh et al. [7] and Gaunt [41] used the bounds (4.61) and (4.62) to derive bounds on the rate of convergence for a remarkable limit theorem of Bai and Taqqu [8]. Consider the generalized Rosenblatt process $Z _ { \gamma _ { 1 } , \gamma _ { 2 } } ( t )$ , which was introduced by Maejima and Tudor [78] as the double Wiener-Itˆo integral  

$$
Z _ { \gamma _ { 1 } , \gamma _ { 2 } } ( t ) = \int _ { \mathbb { R } ^ { 2 } } ^ { \prime } \left( \int _ { 0 } ^ { t } ( s - x _ { 1 } ) _ { + } ^ { \gamma _ { 1 } } ( s - x _ { 2 } ) _ { + } ^ { \gamma _ { 2 } } \mathrm { d } s \right) \mathrm { d } B _ { x _ { 1 } } \mathrm { d } B _ { x _ { 2 } } ,
$$  

where $B _ { x }$ is standard Brownian motion, $\gamma _ { i } \in ( - 1 , - 1 / 2 )$ , $i = 1 , 2$ , and $\gamma _ { 1 } + \gamma _ { 2 } > - 3 / 2$ , and the prime $\prime$ indicates exclusion of the diagonals $x _ { 1 } = x _ { 2 }$ in the stochastic integral. The Rosenblatt process is $Z _ { \gamma } ( t ) = Z _ { \gamma , \gamma } ( t )$ , $- 3 / 4 < \gamma < - 1 / 2$ (see Taqqu [112]). As $Z _ { \gamma _ { 1 } , \gamma _ { 2 } } ( t ) = _ { d } t ^ { 2 + \gamma _ { 1 } + \gamma _ { 2 } } Z _ { \gamma _ { 1 } , \gamma _ { 2 } } ( 1 )$ , we will consider the random variable $Z _ { \gamma _ { 1 } , \gamma _ { 2 } } ( 1 )$ ; results for general $t > 0$ follow from rescaling. For $\rho \in ( 0 , 1 )$ , define the random variable $Y _ { \rho }$ by  

$$
Y _ { \rho } = \frac { a _ { \rho } } { \sqrt { 2 } } ( X _ { 1 } - 1 ) - \frac { b _ { \rho } } { \sqrt { 2 } } ( X _ { 2 } - 1 ) ,
$$  

where $X _ { 1 }$ and $X _ { 2 }$ are independent $\chi _ { 1 } ^ { 2 }$ random variables and  

$$
a _ { \rho } = \frac { ( 2 \sqrt { \rho } ) ^ { - 1 } + ( \rho + 1 ) ^ { - 1 } } { \sqrt { ( 2 \rho ) ^ { - 1 } + 2 ( \rho + 1 ) ^ { - 2 } } } , \quad b _ { \rho } = \frac { ( 2 \sqrt { \rho } ) ^ { - 1 } - ( \rho + 1 ) ^ { - 1 } } { \sqrt { ( 2 \rho ) ^ { - 1 } + 2 ( \rho + 1 ) ^ { - 2 } } } .
$$  

Assume that $\gamma _ { 1 } \geq \gamma _ { 2 }$ and $\gamma _ { 2 } = ( \gamma _ { 1 } { + } 1 / 2 ) / \rho { - } 1 / 2$ . Then, Bai and Taqqu [8] showed that $Z _ { \gamma _ { 1 } , \gamma _ { 2 } } ( 1 )  _ { d }$ $Y _ { \rho }$ as $\gamma _ { 1 }  - 1 / 2$ . (Note that if $\gamma _ { 1 }  - 1 / 2$ , then $\gamma _ { 2 }  - 1 / 2$ .)  

By the representation (2.20), we have that $Y _ { \rho } \sim \mathrm { V G } _ { c } ( 1 , ( a _ { \rho } - b _ { \rho } ) / \sqrt { 2 } , \sqrt { 2 a _ { \rho } b _ { \rho } } )$ . It was shown by Arras et al. [5] that, for any $i \geq 2$ , $\kappa _ { i } ( Z _ { \gamma _ { 1 } , \gamma _ { 2 } } ( 1 ) ) = \kappa _ { i } ( Y _ { \rho } ) + O ( - \gamma _ { 1 } - 1 / 2 )$ , as $\gamma _ { 1 }  - 1 / 2$ , and combining with (4.61) and (4.62) yields that, as $\gamma _ { 1 }  - 1 / 2$ ,  

$$
d _ { \mathrm { W } } ( Z _ { \gamma _ { 1 } , \gamma _ { 2 } } ( 1 ) , Y _ { \rho } ) \leq C _ { \rho } \sqrt { - \gamma _ { 1 } - \frac 1 2 } , \quad d _ { 2 } ( Z _ { \gamma _ { 1 } , \gamma _ { 2 } } ( 1 ) , Y _ { \rho } ) \leq C _ { \rho } ^ { \prime } \Big ( - \gamma _ { 1 } - \frac 1 2 \Big ) .
$$  

where $C _ { \rho }$ and $C _ { \rho } ^ { \prime }$ only depend on $\rho$ . By employing a standard smoothing technique to the above $d _ { 2 }$ metric bound, Gaunt and Li [44] deduced the Kolmogorov distance bound  

$$
\operatorname* { s u p } _ { z \in \mathbb { R } } \left. \mathbb { P } ( Z _ { \gamma _ { 1 } , \gamma _ { 2 } } ( 1 ) \leq z ) - \mathbb { P } ( Y _ { \rho } \leq z ) \right. \leq C _ { \rho } ^ { \prime \prime } \bigg ( - \gamma _ { 1 } - \frac 1 2 \bigg ) ^ { 1 / 3 } \log \bigg ( \frac 1 { - \gamma _ { 1 } - 1 / 2 } \bigg ) , \quad \mathrm { a s } \ \gamma _ { 1 } \to - 1
$$  

# A The modified Bessel function of the second kind  

In this appendix, we state some basic properties of the modified Bessel function of the second kind that are used in this review. Unless otherwise stated, these properties are given in Olver et al. [92]. The modified Bessel function of the second kind $K _ { \nu } ( x )$ is defined for $\nu \in \mathbb R$ by  

$$
K _ { \nu } ( x ) = \int _ { 0 } ^ { \infty } \mathrm { e } ^ { - x \cosh ( t ) } \cosh ( \nu t ) \mathrm { d } t , \quad x > 0 .
$$  

For $x > 0$ , the function $K _ { \nu } ( x )$ is positive for all $\nu \in \mathbb { R }$ . For $\nu = m + 1 / 2$ , $m = 0 , 1 , 2 , \ldots$ ,  

$$
K _ { m + 1 / 2 } ( x ) = \sqrt { { \frac { \pi } { 2 x } } } \sum _ { j = 0 } ^ { m } { \frac { ( m + j ) ! } { ( m - j ) ! j ! } } ( 2 x ) ^ { - j } \mathrm { e } ^ { - x } .
$$  

The modified Bessel function $K _ { \nu } ( x )$ has the following asymptotic behaviour:  

$$
\begin{array} { r l l } { K _ { \nu } ( x ) } & { \sim } & { \left\{ \begin{array} { l l } { 2 ^ { | \nu | - 1 } \Gamma ( | \nu | ) x ^ { - | \nu | } , } & { \quad x \downarrow 0 , \nu \ne 0 , } \\ { - \log x , } & { \quad x \downarrow 0 , \nu = 0 , } \end{array} \right. } \\ { K _ { \nu } ( x ) } & { \sim } & { \sqrt { \displaystyle \frac { \pi } { 2 x } } \mathrm { e } ^ { - x } , \quad x \to \infty , \nu \in \mathbb { R } . } \end{array}
$$  

The following differentiation formula holds:  

$$
\frac { \mathrm { d } } { \mathrm { d } x } \bigl ( x ^ { \nu } K _ { \nu } ( x ) \bigr ) = - x ^ { \nu } K _ { \nu - 1 } ( x ) .
$$  

An integral formula of Gradshetyn and Ryzhik [48] states that for $a , \alpha > 0$ and $\nu > - 1 / 2$ ,  

$$
\int _ { 0 } ^ { a } t ^ { \nu } K _ { \nu } ( \alpha t ) \mathrm { d } t = \frac { \sqrt { \pi } 2 ^ { \nu - 1 } \Gamma ( \nu + 1 / 2 ) } { \alpha ^ { \nu } } a \big ( K _ { \nu } ( \alpha a ) \mathbf { L } _ { \nu - 1 } ( \alpha a ) + K _ { \nu - 1 } ( \alpha a ) \mathbf { L } _ { \nu } ( \alpha a ) \big ) ,
$$  

It is immediate from the PDF (2.3) that, for $\nu > - 1 / 2$ and $0 \leq | \beta | < \alpha$ ,  

$$
\int _ { - \infty } ^ { \infty } | t | ^ { \nu } \mathrm { e } ^ { \beta t } K _ { \nu } ( \alpha | t | ) \mathrm { d } t = { \frac { { \sqrt { \pi } } ( 2 \alpha ) ^ { \nu } \Gamma ( \nu + 1 / 2 ) } { ( \alpha ^ { 2 } - \beta ^ { 2 } ) ^ { \nu + 1 / 2 } } } .
$$  

The following asymptotic approximation is readily deduced from a rescaling of the limiting form (2.13) in Gaunt [39]. For $\beta < \alpha$ and $\nu > - 1 / 2$ ,  

$$
\int _ { x } ^ { \infty } \mathrm { e } ^ { \beta t } t ^ { \nu } K _ { \nu } ( \alpha t ) \mathrm { d } t \sim \sqrt { \frac { \pi } { 2 \alpha } } \frac { 1 } { ( \alpha - \beta ) } x ^ { \nu - 1 / 2 } \mathrm { e } ^ { - ( \alpha - \beta ) x } , \quad x \to \infty .
$$  

The ratio $K _ { \nu - 1 } ( x ) / K _ { \nu } ( x )$ satisfies the following bounds. For $x > 0$ ,  

$$
\begin{array} { r l r } & { } & { \frac { x } { - 1 / 2 + \sqrt { ( \nu - 1 / 2 ) ^ { 2 } + x ^ { 2 } } } < \frac { K _ { \nu - 1 } ( x ) } { K _ { \nu } ( x ) } < \frac { x } { \nu - 1 + \sqrt { ( \nu - 1 ) ^ { 2 } + x ^ { 2 } } } , \nu > 1 / 2 ; } \\ & { } & { \frac { K _ { \nu - 1 } ( x ) } { K _ { \nu } ( x ) } \leq \frac { x } { \nu - 1 / 2 + \sqrt { ( \nu - 3 / 2 ) ^ { 2 } + x ^ { 2 } } } , \nu \geq 3 / 2 , } \end{array}
$$  

with equality in (A.71) if and only if $\nu = 3 / 2$ . The lower and upper bounds in (A.70) were derived by Segura [106] and Ruiz-Antolı´n and Segura [101], respectively. Inequality (A.71) is given in Gaunt and Merkle [46].  

# References  

[1] ˚Aberg, S. and Podg´orski, K. A class of non-Gaussian second order random fields. Extremes 14 (2011), 187–222.   
[2] ˚Aberg, S., Podg´orski, K. and Rychlik, I. Fatigue damage assessment for a spectral model of non-Gaussian random loads. Probabilist. Eng. Mech. 24 (2009), 608–617.   
[3] Aguilar, J. P. Some pricing tools for the Variance Gamma model. Int. J. Theor. Appl. Financ. 23 (2020), 2050025.   
[4] Anderson, T. W. An Introduction to Multivariate Statistical Analysis (3rd ed.). Hoboken, N. J.: Wiley Interscience, 2003. [5] Arras, B., Azmoodeh, E., Poly, G. and Swan, Y. A bound on the 2-Wasserstein distance between linear combinations of independent random variables. Stoch. Proc. Appl. 129 (2019), 2341–2375. [6] Avramidis, A. N. and L’Ecyuer, P. Efficient Monte Carlo and quasi-Monte Carlo option pricing under the Variance-Gamma model. Manage. Sci. 52 (2006), 1930–1944. [7] Azmoodeh, E., Eichelsbacher, P. and Th¨ale, C. Optimal Variance-Gamma approximation on the second Wiener chaos. J. Funct. Anal. 282 (2022), Art. 109450. [8] Bai, S. and Taqqu, M. S. Behavior of the generalized Rosenblatt process at extreme critical exponent values. Ann. Probab. 45 (2017), 1278–1324. [9] Bakshi, G., Chen, C. and Cao, Z. Empirical Performance of Alternative Option Pricing Models. J. Financ. 52 (1997), 2003–2049.   
[10] Barndorff-Nielsen, O. E. Exponentially decreasing distributions for the logarithm of particle size. Proc. Roy. Soc. London A 353 (1977), 401–419.   
[11] Barndorff-Nielsen, O. E. Hyperbolic distributions and distributions on hyperbolae. Scand. J. Stat. 5 (1978), 151–157.   
[12] Barndorff-Nielsen, O. E., Kent, J. and Sørensen, M. Normal Variance-Mean Mixtures and $z$ -Distributions. Int. Stat. Rev. 50 (1982), 145–159.   
[13] Baxevani, A., Podg´orski, K. and Wegener, J. Sample Path Asymmetries in Non-Gaussian Random Processes. Scand. J. Stat. 41 (2014), 1102–1123.   
[14] Bee, M., Dickson, M. M. and Santi, F. Likelihood-based risk estimation for variance-gamma models. Stat. Method. Appl. 27 (2018), 69–89.   
[15] Bibby, B. M. and Sørensen, M. Hyperbolic Processes in Finance. In: Rachev, S. (Ed.), Handbook of Heavy Tailed Distributions in Finance. Elsevier Science, Amsterdam (2003), 211–248.   
[16] Breymann, W. and L¨uthi, D. ghyp: A package on generalized hyperbolic distributions. Manual for R Package ghyp, 2013.   
[17] Bogsj¨o, K. Podg´orski, K. and Rychlik, I. Models for road surface roughness. Veh. Syst. Dyn. 50 (2012), 725–747.   
[18] Bolin, D. Spatial Mat´ern Fields Driven by Non-Gaussian Noise. Scand. J. Stat. 41 (2014), 557–579.   
[19] Cervellera, G. P. and Tucci, M. P. A note on the Estimation of a Gamma-Variance Process: Learning from a Failure. Comput. Econ. 49 (2017), 363–385.   
[20] Carr, P., Geman, H., Madan, D. and Yor, M. The Fine Structure of Asset Returns: An Empirical Investigation. J. Bus. 75 (2002), 305–332.   
[21] Carr. P. and Madan, D. Option valuation using the fast Fourier transform. J. Comput. Financ. 2 (1999), 61–73.   
[22] Cui, G., Yu, X. Iommelli, S. and Kong, L. Exact Distribution for the Product of Two Correlated Gaussian Random Variables. IEEE Signal Process. Lett. 23 (2016), 1662–1666.   
[23] Daal, E. A. and Madan, D. B. An Empirical Examination of the Variance-Gamma Model for Foreign Currency Options. J. Bus. 78 (2005), 2121–2152.   
[24] Devroye, L. Non-Uniform Random Variate Generation. New York: Springer-Verlag, 1986.   
[25] Eberlein, E. and Hammerstein E. Generalized Hyperbolic and Inverse Gaussian Distributions: Limiting Cases and Approximation of Processes. In: Dalang, R. C. Dozzi, M. Russo, F. (Eds.), Seminar on Stochastic Analysis, Random Fields and Applications IV, in: Progress in Probability 58 Birkh¨auser Verlag, (2004), 105–153.   
[26] Eberlein, E. and Keller, U. Hyperbolic distributions in finance. Bernoulli 1 (1995), 281–299.   
[27] Eberlein, E. and Prause, K. The generalized hyperbolic model: financial derivatives and risk measures. In: Geman, H., Madan, D. B., Pliska, S. and Vorst, T. Eds., Mathematical finance – Bachelier Congress 2000 Springer, Berlin, (2001), 245–267.   
[28] Eichelsbacher, P. and Th¨ale, C. Malliavin-Stein method for Variance-Gamma approximation on Wiener space. Electron. J. Probab. 20 no. 123 (2015), 1–28.   
[29] Embrechts, P. A property of the generalized inverse Gaussian distribution with some applications. J. Appl. Probab. 20 (1983), 537–544. ponents. Ann. Math. Statist. 43 (1972), 1634–1643.   
[31] Finlay, R. and Seneta, E. Stationary-Increment Student and Variance-Gamma Processes. J. Appl. Probab. 43 (2006), 441–453.   
[32] Finlay, R. and Seneta, E. Stationary-Increment Variance-Gamma and t Models: Simulation and Parameter Estimation. Int. Stat. Rev. 76 (2008), 167–186.   
[33] Fiorani, F. Option Pricing Under the Variance Gamma Process. PhD thesis, Universti\`a Degli Studi Di Trieste, 2004.   
[34] Fu, M. C. Variance-Gamma and Monte Carlo. In: Fu, M. C. Jarrow, R. A., Yen, J.-Y. J. and Elliot, R. J. (Eds.), in: Advances in Mathematical Finance Birkh¨auser Boston, (2007), 21–34.   
[35] Gaunt, R. E. Rates of Convergence of Variance-Gamma Approximations via Stein’s Method. DPhil thesis, University of Oxford, 2013.   
[36] Gaunt, R. E. Variance-Gamma approximation via Stein’s method. Electron. J. Probab. 19 no. 38 (2014), 1–33.   
[37] Gaunt, R. E. Inequalities for modified Bessel functions and their integrals. J. Math. Anal. Appl. 420 (2014), 373–386.   
[38] Gaunt, R. E. A Stein characterisation of the generalized hyperbolic distribution. ESAIM: Probab. Stat. 21 (2017), 303–316.   
[39] Gaunt, R. E. Inequalities for integrals of modified Bessel functions and expressions involving them. J. Math. Anal. Appl. 462 (2018), 172–190.   
[40] Gaunt, R. E. A note on the distribution of the product of zero mean correlated normal random variables. Stat. Neerl. 73 (2019), 176–179.   
[41] Gaunt, R. E. Stein factors for variance-gamma approximation in the Wasserstein and Kolmogorov distances. J. Math. Anal. Appl. 514 (2022), Art. 126274.   
[42] Gaunt, R. E. The basic distributional theory for the product of zero mean correlated normal random variables. Stat. Neerl. 76 (2022), 450–470.   
[43] Gaunt, R. E. On the moments of the variance-gamma distribution. arXiv:2209.07767, 2022.   
[44] Gaunt, R. E. and Li, S. Bounding Kolmogorov distances through Wasserstein and related integral probability metrics. J. Math. Anal. Appl. 522 (2023), Art. 126985.   
[45] Gaunt, R. E. and Li, S. The variance-gamma ratio distribution. arXiv:2302.12581, 2023.   
[46] Gaunt, R. E. and Merkle, M. On bounds for the mode and median of the generalized hyperbolic and related distributions. J. Math. Anal. Appl. 493 (2021), Art. 124508, 1–19.   
[47] Gaunt, R. E., Mijoule, G. and Swan Y. An algebra of Stein operators. J. Math. Anal. Appl. 469 (2019), 260–279.   
[48] Gradshetyn, I. S. and Ryzhik, I. M. Table of Integrals, Series and Products, 7th ed. Academic Press, 2007.   
[49] Groeneveld, R. A. and Meeden, G. The Mode, Median, and Mean Inequality. Amer. Stat. 31 (1977), 120–121.   
[50] Hammerstein, E. A. V. Generalized hyperbolic distributions: Theory and applications to CDO pricing. PhD thesis, University of Freiburg, 2010.   
[51] Heyde, C. C. A Risky Asset Model with Strong Dependence through Fractal Activity Time. J. Appl. Probab. 36 (1999), 1234–1239.   
[52] Hirsa, A. and Madan, D. B. Pricing American options under variance gamma. J. Comput. Financ. 7 (2004), 63–80.   
[53] Holm, H. and Alouini, M.–S. Sum and Difference of two squared correlated Nakagami variates with the McKay distribution. IEEE T. Commun. 52 (2004), 1367–1376.   
[54] Ivanov, R. V. Option pricing in the variance-gamma model under the drift jump. Int. J. Theor. Appl. Financ. 21 (2018), 1–19.   
[55] Jankov Maˇsirevic´, D. and Pog´any, T. K. On new formulae for cumulative distribution function for McKay Bessel distribution. Commun. Stat. Theory 50 (2021), 143–160.   
[56] Johannesson, P., Podg´orski, K., Rychlik, I. and Shariati, N. AR(1) time series with autoregressive gamma variance for road topography modeling. Probabilist. Eng. Mech. 43 (2016), 106–116.   
[57] Kollo, T. Advanced Multivariate Statistics with Matrices. Springer, 2005.   
[58] Koponen, I. (1995) Analytic approach to the problem of convergence of truncated L´evy flights towards the Gaussian stochastic process. Phys. Rev. E 52, 1197–1199.   
[59] Korn, R., Korn, E. and Kroisandt, G. Monte Carlo Methods and Models in Finance and Insurance. Boca Raton, Fla.: Chapman and Hall/CRC, 2010   
[60] Kotz, S., Kozubowski, T. J. and Podg´orski, K. The Laplace Distribution and Generalizations: A Revisit with Applications to Communications, Economics, Engineering, and Finance. Springer, 2001.   
[61] Kozubowski, T. J., Mazur, S. and Podg´orski, K. Matrix Variate Generalized Laplace Distributions. Working Papers 2022:7, ¨Orebro University, School of Business.   
[62] Kozubowski, T. J. and Podg´orski, K. Asymmetric Laplace Laws and Modeling Financial Data. Math. Comput. Model. 34 (2001), 1003–1021.   
[63] Kozubowski, T. J. and Podg´orski, K. Laplace probability distributions and related stochastic processes. In: Shmaliy, Y., Ed. Probability: Interpretation, Theory and Applications. New York: Nova Science Publishers, Inc., (2012), pp. 105–145.   
[64] Kozubowski, T. J., Podg´orski, K. and Rychlik, I. Multivariate generalized Laplace distribution and related random fields. J. Multivariate Anal. (2013), 59–72.   
[65] Ku¨chler, U. and Tappe, S. Tempered stable distributions and processes. Stoch. Proc. Appl. 123 (2013), 4256– 4293.   
[66] Lam, K., Chang, E. and Lee, M. C. Option pricing in the variance-gamma model under the drift jump. Pac.- Basin Financ. J. 10 (2002), 267–285   
[67] Leonenko, N. N., Petherick, S. and Sikorskii, A. The Student Subordinator Model with Dependence for Risky Asset Returns. Commun. Stat. Theory 40 (2011), 3509–3523.   
[68] Linders, D. and Stassen, B. The multivariate Variance Gamma model: basket option pricing and calibration. Quant. Financ. 16 (2016), 555–572.   
[69] Loregian, A., Mercuri, L. and Rroji, E. Approximation of the variance gamma model with a finite mixture of normals. Stat. Probabil. Lett. 82 (2012), 217–224.   
[70] Luciano, E. and Schoutens, W. A multivariate jump-driven financial asset model. Quant. Financ. 6 (2006), 385–402.   
[71] Luciano, E. and Semeraro, P. Multivariate time changes for L´evy asset models: Characterization and calibration. J. Comput. Appl. Math. 233 (2010), 1937–1953.   
[72] Luciano, E., Marena, M. and Semeraro, P. Dependence calibration and portfolio fit with factor-based subordinators. Quant. Financ. 16 (2016), 1037–1052.   
[73] Madan, D. B., Carr, P. and Chang, E. C. The variance gamma process and option pricing, Eur. Finance Rev. 2 (1998), 74–105.   
[74] Madan, D. B. and Milne, F. Option pricing with V.G. martingale components. Math. Financ. 1 (1991), 39–55.   
[75] Madan, D. B. and Seneta, E. Simulation of Estimates Using the Empirical Characteristic Function. Int. Stat. Rev. 55 (1987), 153–161.   
[76] Madan, D. B. and Seneta, E. Chebyshev Polynomial Approximation and Characteristic Function Estimation. J. Roy. Stat. Soc. B 49 (1987), 163–169.   
[77] Madan, D. B. and Seneta, E. The Variance Gamma (V.G.) Model for Share Market Returns. J. Bus. 63 (1990), 511–524.   
[78] Maejima, M. and Tudor, C. A. Selfsimilar processes with stationary increments in the second Wiener chaos. Probab. Math. Stat.-Pol. 32 (2012), 167–186.   
[79] Mangilli, A., Plaszczynski, S. and Tristram, M. (2015). Large-scale cosmic microwave background temperature and polarization cross-spectra likelihoods. Mon. Not. R. Astron. Soc. 453 (2015), 3174–3189.   
[80] McKay, A. T. A Bessel function distribution. Biometrika 24 (1932), 39–44.   
[81] McLeish, D. L. A robust alternative to the normal distribution. Can. J. Statist. 10 (1982), 89–102.   
[82] McNicholas, S. M., McNicholas, P. D. and Browne, R. P. Mixtures of variance-gamma distributions. arXiv:1309.2695, 2013.   
[83] Nadarajah, S. and Kotz, S. The Bessel ratio distribution. C. R. Acad. Sci. Paris, Ser. I 343 (2006) 531–534.   
[84] Nadarajah, S. and Pog´any, T. K. On the distribution of the product of correlated normal random variables. C.R. Acad. Sci. Paris, Ser. I 354 (2016), 201–204.   
[85] Nadarajah, S., Srivastava, H. M. and Gupta, A. K. Skewed Bessel function distributions with application to rainfall data. Statistics 41 (2007), 333–344.   
[86] Nitithumbundit, T. and Chan, J. S. An ECM algorithm for skewed multivariate variance gamma distribution in normal mean-variance representation. arXiv:1504.01239, 2015.   
[87] Nitithumbundit, T. and Chan, J. S. ECM algorithm for auto-regressive multivariate skewed variance gamma model with unbounded density. Methodol. Comput. Appl. 22 (2020), 1169–1191.   
[88] Nourdin, I. and Peccati, G. Normal approximations with Malliavin calculus: from Stein’s method to universality. Vol. 192. Cambridge University Press, 2012.   
[89] Nourdin, I. and Peccati, G. The optimal fourth moment theorem. Proc. Amer. Math. Soc. 143 (2015), 3123– 3133.   
[90] Nualart, D. and Peccati, G. Central limit theorems for sequences of multiple stochastic integrals. Ann. Probab. 33 (2005), 177–193. [91] Nzokem, A. H. Gamma variance model: Fractional fourier transform (FRFT). In Journal of Physics: Conference Series (Vol. 2090, No. 1, p. 012094). IOP Publishing, 2021. [92] Olver, F. W. J., Lozier, D. W., Boisvert, R. F. and Clark, C. W. NIST Handbook of Mathematical Functions. Cambridge University Press, 2010. [93] Pearson, K., Jefferey, G. B. and Elderton, E. M. On the distribution of the first product moment-coefficient, in samples drawn from an indefinitely large normal population. Biometrika 21 (1929), 164–193. [94] Pearson, K., Stouffer, S. A. and David, F. N. Further applications in statistics of the $T _ { m } ( x )$ Bessel function. Biometrika 24 (1932), 293–350.   
[95] Podg´orski, K. and Wegener, J. Estimation for Stochastic Models Driven by Laplace Motion. Commun. Stat. Theory 40 (2011), 3281–3302 [96] Press, S. J. On the sample covariance from a bivariate normal distribution, Ann. Inst. Statist. Math. 19 (1967), 355–361. [97] Ramachandran, B. On geometric stable laws, a related property of stable processes, and stable densities. Ann. Inst. Statist. Math. 49 (1997), 299–313. [98] Rathgeber, A. W., Johannes, S. and St¨ockl, S. Modeling share returns - an empirical study on the Variance Gamma model. J. Econ. Finance 40 (2016), 653–682. [99] Reed, W. J. The Normal-Laplace Distribution and Its Relatives. Advances in Distribution Theory, Order Statistics, and Inference (2006). 61–74.   
[100] Reed, W. J. Brownian–Laplace Motion and Its Use in Financial Modelling. Commun. Stat. Theory 36 (2007), 473–484.   
[101] Ruiz-Antol´ın, D. and Segura. J. A new type of sharp bounds for ratios of modified Bessel functions. J. Math. Anal. Appl. 443 (2016), 1232–1246.   
[102] Rydberg, T. H. Generalized hyperbolic diffusions with applications towards finance. Math. Financ. 9, 183–201.   
[103] Sato, K. L´evy Processes and Infinitely Divisible Distributions. Cambridge: Cambridge University Press, 1999.   
[104] Scott, D. and Dong, C. Y. Package ‘VarianceGamma’, 2018.   
[105] Scott, D. J., W¨urtz, D., Dong, C. and Tran, T. T. Moments of the generalized hyperbolic distribution. Computation. Stat. 26 (2011), 459–476.   
[106] Segura, J. Bounds for ratios of modified Bessel functions and associated Tur´an-type inequalities. J. Math. Anal. Appl. 374 (2011), 516–528.   
[107] Semeraro, P. A multivariate variance gamma model for financial applications. Int. J. Theor. Appl. Financ. 11 (2008), 1–18.   
[108] Seneta, E. Fitting the Variance-Gamma Model to Financial Data. J. Appl. Probab. 41 (2004), 177–187.   
[109] Seneta, E. The early years of the Variance-Gamma process. In: Fu, M. C., Jarrow, R. A., Yen, J. J. and Elliott, R. J. (Eds.), Advances in Mathematical Finance. (2007), Birkhauser, Boston, 3–19.   
[110] Sichel, H. S. Statistical valuation of diamondiferous deposits. J. S. Afr. Inst. Min. Metall. 73 (1973), 235–243.   
[111] Stein, C. A bound for the error in the normal approximation to the distribution of a sum of dependent random variables. In Proc. Sixth Berkeley Symp. Math. Statis. Prob. (1972), vol. 2, Univ. California Press, Berkeley, 583–602.   
[112] Taqqu, M. S. Weak convergence to fractional Brownian motion and to the Rosenblatt process. Probab. Theory Rel. 31 (1975), 287–302.   
[113] Teichroew, D. The mixture of normal distributions with different variances. Ann. Math. Statist. 28 (1957), 510–512.   
[114] Tjetjep, A. and Seneta, E. Skewed normal variance-mean models for asset pricing and the method of moments. Int. Stat. Rev. 74 (2008), 109–126.   
[115] Tomy, L. and Jose, K. K. Generalized normal-Laplace AR process. Statist. Probabil. Lett. 79 (2009), 1615–1620.   
[116] Trindade, A. A., Zhu, Y. and Andrews, B. Time series models with asymmetric Laplace innovations. J. Stat. Compu. Sim. 80 (2010), 1317–1333.   
[117] van Zwet, W. R. Mean, median, mode II. Stat. Neerl. 33 (1979), 1–5.   
[118] Weisstein, E. W. Chi-Squared Distribution. From MathWorld—A Wolfram Web Resource, https://mathworld.wolfram.com/Chi-SquaredDistribution.html. Last visited on 07/03/2023.   
[119] Wu, F. Applications of The Normal Laplace and Generalized Normal Laplace Distributions. MSc thesis, University of Victoria, 2008.   
[120] Yamazato, M. Unimodality of infinitely divisible distribution functions of class L. Ann. Probab. 6 (1978), 523–531.  