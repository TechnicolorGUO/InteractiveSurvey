# A Survey of Numerical Algorithms for Lasso Problems

# 1 Abstract


High-dimensional regression and optimization problems pose significant challenges in machine learning and data science, particularly due to issues like overfitting and computational inefficiency. This survey paper focuses on numerical algorithms for solving Lasso problems, which are central to regularized regression. The paper aims to provide a comprehensive overview of the latest developments in these algorithms, covering both convex and non-convex formulations, and to bridge the gap between theoretical advancements and practical applications. Key findings include the effectiveness of advanced regularization techniques, such as nonconvex sparsity penalties and regularized EM algorithms, in enhancing model generalization and computational efficiency. The survey also highlights the importance of optimization algorithms for non-convex problems, including stochastic and decentralized methods, and the integration of flow-based and variational methods for robust and scalable solutions. Finally, this survey serves as a valuable resource for researchers and practitioners, offering insights into the design and implementation of efficient algorithms for high-dimensional data analysis.

# 2 Introduction
The field of numerical algorithms for solving high-dimensional regression and optimization problems has seen significant advancements in recent years, driven by the increasing complexity and size of datasets in machine learning and data science. High-dimensional data, characterized by a large number of features relative to the number of observations, poses unique challenges such as overfitting, computational inefficiency, and the need for robust regularization techniques. Regularization methods, such as L1 and L2 regularization, have become essential tools for promoting sparsity and improving model generalization [1]. However, as datasets continue to grow in size and complexity, there is a growing need for more sophisticated and efficient algorithms that can handle these challenges effectively.

This survey paper focuses on numerical algorithms for Lasso problems, which are a cornerstone of regularized regression [2]. The Lasso, or Least Absolute Shrinkage and Selection Operator, is a widely used technique for variable selection and shrinkage in high-dimensional settings [3]. The Lasso problem involves minimizing a loss function with an L1 penalty term, which encourages sparsity in the model coefficients [4]. Despite its simplicity, the Lasso problem is computationally challenging, especially for large-scale datasets [5]. This survey provides a comprehensive overview of the latest developments in numerical algorithms for solving Lasso problems, including both convex and non-convex formulations [5]. The paper aims to bridge the gap between theoretical advancements and practical applications, offering insights into the design and implementation of efficient algorithms for high-dimensional data analysis.

The survey begins by exploring regularization techniques in machine learning, with a focus on high-dimensional regression. It delves into the asymptotic analysis and random matrix theory, which provide a theoretical framework for understanding the behavior of high-dimensional statistical models. The paper discusses the implicit regularization effects of gradient descent and the role of the Jacobian matrix in promoting low-rank structures [6]. It also examines empirical risk minimization and concentration inequalities, which are crucial for bounding the difference between empirical and true risks in high-dimensional settings. The survey then moves on to recursive algorithms for sparse identification, highlighting methods that incorporate sparsity-inducing regularization terms into the recursive framework.

Next, the paper explores graphical models and network dependencies, with a focus on network convolutional regression and transfer learning [1]. It discusses how these techniques leverage the structural information in network data to enhance predictive performance. The survey also covers the Neighborhood-Fused Lasso and Block-Weighted Lasso, which incorporate spatial or structural information through fusion and block-weighted penalties, respectively [7]. These methods are particularly useful for handling high-dimensional data with inherent spatial or network structures.

The survey further examines advanced regularization and optimization techniques, including nonconvex sparsity penalties and regularized EM algorithms for mixed models. It discusses the challenges and benefits of using nonconvex penalties, such as SCAD and MCP, and the role of majorization-minimization algorithms in optimizing these penalties. The paper also explores the integration of regularization techniques into the EM framework to handle high-dimensional mixed models, emphasizing the importance of reducing parameter space and improving model generalization.

Finally, the paper discusses optimization algorithms for non-convex problems, including stochastic and decentralized optimization methods. It covers Nested-SGD for regularized Sinkhorn DRO, Decentralized Federated Learning with Gradient Tracking, and the non-asymptotic analysis of conjugate gradient methods. The survey also examines surrogate and preconditioned methods, such as surrogate loss functions for constrained optimization and preconditioned gradient descent for matrix factorization [8]. Additionally, it explores flow-based and variational methods, including the theoretical analysis of flow-based generative models and the use of asymmetric projected gradient descent for exponential decay matrix completion.

The contributions of this survey paper are multifaceted. First, it provides a comprehensive and up-to-date overview of the latest numerical algorithms for solving Lasso problems, covering both theoretical foundations and practical applications [5]. Second, it highlights the key challenges and advancements in the field, offering insights into the design and implementation of efficient algorithms for high-dimensional data analysis. Third, it serves as a valuable resource for researchers and practitioners, providing a detailed reference for understanding and applying these algorithms in various domains, including machine learning, data science, and signal processing. By synthesizing the latest research and practical insights, this survey aims to advance the field and inspire further innovation in numerical algorithms for Lasso problems.

# 3 Regularization Techniques in Machine Learning

## 3.1 High-Dimensional Regression and Regularization

### 3.1.1 Asymptotic Analysis and Random Matrix Theory
Asymptotic analysis and random matrix theory (RMT) play a pivotal role in understanding the behavior of high-dimensional statistical models, particularly in the context of neural networks and deep learning [9]. RMT provides a framework for analyzing the eigenvalue distributions of large random matrices, which are crucial for understanding the spectral properties of the Jacobian matrix of a neural network. The Jacobian matrix, ∇f(x), captures the sensitivity of the network's output with respect to its input, and its singular values provide insights into the network's stability and generalization capabilities. The implicit regularization effect of gradient descent (GD) can be viewed as a shrinkage operator on these singular values, applying a masking function m(s; α, q) that depends on the learning rate α and the number of iterations q [6]. This shrinkage operator effectively reduces the influence of the less significant singular values, thereby promoting a low-rank structure in the Jacobian matrix.

The connection between the Jacobian's spectral properties and the rank-1 Parabolic Eigenvalue Problem (PEP) is particularly significant [10]. The rank-1 PEP is a mathematical framework that arises naturally in the study of deep linear networks and provides a theoretical basis for understanding the low-rank adaptation observed during training. By leveraging the Sturm-Liouville theorem (SLT) and its multidimensional extension, the Elliptic Eigenvalue Problem, we can derive the conditions under which the Jacobian matrix converges to a low-rank structure. This convergence is crucial for efficient model training and generalization, as it reduces the effective dimensionality of the problem and mitigates overfitting. The PEP framework also allows for the development of fast iterative algorithms that can efficiently solve the optimization problem, making it feasible to train large-scale neural networks.

In the context of high-dimensional data, the asymptotic analysis of the sample covariance matrix, Sn = X⊤X/n, and its eigenvalues provides a deeper understanding of the regularization effects in statistical models. The penalty parameter λn, which scales with the inverse square root of the sample size, ensures that the estimated covariance matrix remains positive definite and well-conditioned. This regularization is essential for stabilizing the model and preventing numerical instabilities. The asymptotic analysis also reveals the trade-offs between bias and variance in the estimation of the covariance matrix, highlighting the importance of choosing appropriate regularization parameters. The insights gained from RMT and asymptotic analysis are crucial for developing robust and efficient algorithms for high-dimensional data analysis, particularly in the context of deep learning and neural networks.

### 3.1.2 Empirical Risk Minimization and Concentration Inequalities
Empirical Risk Minimization (ERM) is a fundamental principle in machine learning, where the goal is to minimize the average loss over a training dataset [11]. This approach is particularly useful in scenarios where the true distribution of the data is unknown, and only a finite set of samples is available. The empirical risk, defined as the average loss over the training set, serves as a proxy for the true risk, which is the expected loss over the entire data distribution. Concentration inequalities, such as Hoeffding's inequality and McDiarmid's inequality, play a crucial role in bounding the difference between the empirical risk and the true risk. These inequalities provide probabilistic guarantees that the empirical risk is close to the true risk with high probability, thus justifying the use of ERM as a practical strategy for model selection and training.

In the context of deep learning, ERM is often combined with regularization techniques to prevent overfitting and improve generalization. Regularization methods, such as L1 and L2 regularization, introduce additional terms to the loss function that penalize complex models, thereby encouraging simpler solutions that are more likely to generalize well to unseen data. The theoretical underpinnings of these methods rely on concentration inequalities to ensure that the regularized empirical risk is a good approximation of the true risk. For instance, the use of L2 regularization can be interpreted as a form of smoothness constraint, which helps in controlling the model complexity and reducing the variance of the empirical risk estimator.

Moreover, the connection between ERM and concentration inequalities extends to the analysis of generalization bounds in deep neural networks. Recent studies have shown that the spectral properties of the network's Jacobian matrix, which captures the sensitivity of the network's output to input perturbations, can be used to derive tighter generalization bounds. Specifically, the singular values of the Jacobian matrix, which are influenced by the choice of activation functions, play a key role in determining the network's capacity and its ability to generalize. By leveraging concentration inequalities, researchers have been able to establish theoretical guarantees on the generalization performance of deep neural networks, providing a deeper understanding of the interplay between model architecture, optimization, and generalization.

### 3.1.3 Recursive Algorithms for Sparse Identification
Recursive algorithms for sparse identification have gained significant attention due to their ability to handle non-stationary and high-dimensional data efficiently. These algorithms are particularly useful in scenarios where the underlying system parameters are sparse, meaning that only a small subset of the parameters are non-zero. The key challenge in designing such algorithms is to incorporate sparsity-inducing regularization terms, such as the L1 norm, into the recursive framework. The non-smooth nature of the L1 penalty term complicates the derivation of recursive solutions, as traditional gradient-based methods are not directly applicable.

To address this challenge, several approaches have been proposed. One prominent method is the alternating optimization of different sets of variables, where the algorithm alternates between updating the non-zero parameters and the regularization parameters. This approach leverages the idea of proximal gradient methods, which are well-suited for non-smooth optimization problems. Another approach is the weighted Lp (0 < p < 1) regularization method, which provides a smoother approximation to the L1 penalty and facilitates the derivation of recursive updates. These methods have been shown to achieve consistent estimates for the non-zero entries of the unknown parameter matrix, even in the presence of non-stationary observations.

Moreover, the theoretical guarantees for these recursive algorithms have been rigorously established. For instance, it has been demonstrated that under appropriate assumptions regarding the tail dependence structure of the noise, the guarantees on the standard Lasso, such as consistency and sparsity recovery, carry over to the recursive setting [12]. This theoretical foundation not only ensures the robustness of the algorithms but also provides a basis for their practical application in various domains, including signal processing, system identification, and machine learning. The numerical validation of these theoretical results further confirms the effectiveness of recursive algorithms for sparse identification in handling high-dimensional and non-stationary data [13].

## 3.2 Graphical Models and Network Dependencies

### 3.2.1 Network Convolutional Regression and Transfer Learning
Network Convolutional Regression (NCR) is a powerful framework that leverages the structural information embedded in network data to enhance the predictive performance of regression models. In high-dimensional settings, where the number of features can far exceed the number of observations, NCR models integrate graph convolutional operations to capture the dependencies among nodes, thereby improving the model's ability to generalize. The key idea is to incorporate the network structure into the regression model by defining a convolution operation that aggregates information from neighboring nodes. This convolution operation can be formulated as a weighted sum of the features of the neighboring nodes, where the weights are learned during the training process.

Transfer learning in the context of NCR further enhances the model's performance by leveraging information from related tasks or networks. When informative source networks are available, the transfer learning framework can significantly reduce the estimation error and improve the convergence rates of the NCR model [1]. The transfer learning approach in NCR involves two main components: the estimation procedure and the source detection algorithm [1]. The estimation procedure involves adapting the lasso estimator to the high-dimensional NCR model, where the network structure is used to regularize the model parameters. The source detection algorithm, on the other hand, identifies the most informative source networks that can be used to improve the target network's performance. This is particularly useful in scenarios where the target network has limited or noisy data, and the source networks provide valuable structural information.

The theoretical properties of the NCR model under transfer learning have been rigorously analyzed, providing insights into how network randomness influences the estimation error and convergence rates [1]. Specifically, the lasso estimator in the NCR framework is shown to achieve optimal convergence rates under certain conditions, such as the sparsity of the network and the smoothness of the regression function. These theoretical results not only validate the effectiveness of the NCR model but also highlight the importance of network structure in high-dimensional regression tasks. The practical implications of these findings are significant, as they provide a robust foundation for developing and applying NCR models in various domains, including social networks, biological networks, and recommendation systems.

### 3.2.2 Neighborhood-Fused Lasso and Spatial Regularity
The Neighborhood-Fused Lasso (NFL) extends the traditional Lasso framework by incorporating spatial or structural information through a fusion penalty term [7]. This term penalizes the differences between the coefficients of neighboring nodes in a predefined graph, promoting local smoothness and consistency. By doing so, NFL effectively leverages the inherent structure of the data, making it particularly suitable for scenarios where the relationships between variables exhibit spatial or temporal regularity. The fusion penalty is designed to enforce the principle of local constancy, which posits that nearby nodes in a graph are likely to have similar coefficients, thereby reducing the risk of overfitting and enhancing the interpretability of the model [7].

In the context of high-dimensional data, the NFL approach addresses the challenge of estimating a large number of parameters by imposing a structured sparsity pattern. This is achieved through the combination of the L1 penalty, which promotes overall sparsity, and the fusion penalty, which ensures that the selected variables are spatially coherent. The resulting optimization problem can be solved using efficient algorithms such as the block coordinate descent (BCD) method, which iteratively updates the coefficients of blocks of variables while maintaining the sparsity-inducing properties of the L1 norm. The NFL method is particularly advantageous in applications such as image processing, genomics, and social network analysis, where the underlying data often exhibit strong spatial or network structures.

The theoretical foundations of the NFL method are grounded in the principles of regularized regression and graph theory. The fusion penalty term can be interpreted as a form of regularization that encourages the coefficients of adjacent nodes to be similar, thereby capturing the intrinsic smoothness of the data. This approach not only improves the stability and generalizability of the model but also facilitates the identification of meaningful patterns in the data. Empirical studies have demonstrated the effectiveness of NFL in various domains, showing that it can outperform traditional Lasso and other regularization methods in terms of prediction accuracy and model interpretability, especially when the data exhibit clear spatial or structural dependencies.

### 3.2.3 Block-Weighted Lasso and Memory Depth Optimization
In the context of kernel selection and memory depth optimization, the standard Lasso approach often fails to effectively reduce the memory depth, retaining the maximum available depth and thus failing to meet the design objectives of minimizing computational resources and enhancing efficiency [14]. To address this limitation, a novel formulation known as the block-weighted Lasso has been proposed. This approach assigns different regularization weights to kernels of varying polynomial orders, grouping kernels of the same order into blocks. By doing so, the block-weighted Lasso not only promotes sparsity but also encourages a reduction in the overall memory depth, aligning with the design goals of efficient resource utilization and improved performance.

The block-weighted Lasso problem is solved using the block coordinate descent (BCD) algorithm, which iteratively updates the coefficients of each block while keeping the others fixed [14]. This iterative process ensures that the optimization converges to a solution that balances sparsity and memory depth reduction. The BCD algorithm leverages the structure of the problem to efficiently compute updates, making it suitable for high-dimensional settings where standard Lasso might struggle. The key advantage of this approach is its ability to adaptively adjust the regularization strength for different blocks, thereby fine-tuning the trade-off between model complexity and computational efficiency.

To further enhance the effectiveness of the block-weighted Lasso, the optimization framework incorporates additional constraints and penalties that explicitly target the memory depth. These constraints ensure that the selected kernels collectively contribute to a reduced memory footprint, without compromising the linearization performance of the system. Experimental results have demonstrated that this approach not only achieves the desired reduction in memory depth but also maintains or even improves the accuracy and robustness of the model. The block-weighted Lasso thus represents a significant advancement in the field of kernel selection and memory depth optimization, offering a practical and efficient solution to the challenges posed by high-dimensional and computationally intensive systems [14].

## 3.3 Advanced Regularization and Optimization

### 3.3.1 Nonconvex Sparsity Penalties and Estimation
Nonconvex sparsity penalties have emerged as a powerful alternative to the traditional convex ℓ1-norm for promoting sparsity in high-dimensional models. Unlike the ℓ1-norm, which can lead to biased estimates and suboptimal sparsity patterns, nonconvex penalties such as the smoothly clipped absolute deviation (SCAD), minimax concave penalty (MCP), and capped L1 penalty offer a more flexible and precise control over the sparsity structure. These penalties are designed to shrink small coefficients to zero more aggressively while leaving larger coefficients relatively unaffected, thereby achieving a more accurate model selection.

The optimization of nonconvex sparsity penalties poses significant challenges due to the non-convexity of the objective function, which can result in multiple local minima. To address this, various algorithms have been developed, including the majorization-minimization (MM) algorithm and its variants [15]. The MM algorithm constructs a surrogate function that majorizes the nonconvex penalty, transforming the original problem into a sequence of convex subproblems. This approach has been shown to converge to a stationary point under mild conditions, making it a robust and efficient method for nonconvex optimization. Furthermore, the use of nonconvex penalties in combination with the MM algorithm has been demonstrated to improve the estimation accuracy and model selection consistency in high-dimensional settings.

In the context of graphical models, nonconvex penalties have been particularly effective in learning sparse precision matrices, which are essential for capturing the conditional dependencies between variables [16]. Traditional methods such as the graphical lasso, which rely on the ℓ1-norm, often fail to promote sparsity effectively in the presence of complex dependencies [17]. Nonconvex penalties, on the other hand, can better capture the underlying sparsity structure, leading to more interpretable and accurate graphical models. This has been validated through both theoretical analysis and empirical studies, which have shown that nonconvex penalties can achieve better performance in terms of both estimation accuracy and model selection consistency, especially in high-dimensional and non-Gaussian settings.

### 3.3.2 Regularized EM Algorithms for Mixed Models
Regularized EM algorithms for mixed models represent a significant advancement in handling high-dimensional data, particularly in scenarios where the number of parameters \(P\) and the dimensions of the covariance matrices \(Q_1\) and \(Q_2\) far exceed the number of observations \(n\). In such settings, traditional EM algorithms often suffer from numerical instability and overfitting. To address these issues, regularization techniques are integrated into the EM framework, effectively reducing the parameter space and improving model generalization. Specifically, the Expectation-Maximization (EM) algorithm is modified to incorporate penalties such as the LASSO (Least Absolute Shrinkage and Selection Operator) or the Smoothly Clipped Absolute Deviation (SCAD) penalty, which help in inducing sparsity and stabilizing the estimation process.

The key innovation in regularized EM algorithms lies in the M-step, where the objective function is augmented with a regularization term. For instance, in the context of linear mixed models, the log-likelihood function \(-\ell(\beta)\) is combined with a penalty function \(J(\beta)\), leading to the optimization of \(-\ell(\beta) + \lambda J(\beta)\). Here, \(\lambda\) is a tuning parameter that balances the trade-off between fitting the data and controlling model complexity. The choice of the penalty function \(J(\beta)\) is crucial, as it determines the nature of the regularization. Common choices include the \(\ell_1\)-norm for inducing sparsity and the \(\ell_2\)-norm for ridge regression, which helps in stabilizing the estimates by shrinking the coefficients towards zero.

Moreover, the regularized EM algorithms are designed to handle the specific challenges posed by mixed models, such as the presence of both fixed and random effects. By assuming that the fixed effect matrix \(B\) is sparse and the covariance matrices \(\Sigma_1\) and \(\Sigma_2\) are approximately low-rank, the algorithms reduce the parameter dimension from \(O(P_1P_2 + Q_1^2 + Q_2^2)\) to \(O(P_1P_2 + Q_1S_1 + Q_2S_2)\), where \(S_1\) and \(S_2\) are the ranks of the low-rank approximations. This reduction significantly enhances computational efficiency and numerical stability, making the algorithms suitable for large-scale data analysis. The iterative nature of the EM algorithm, combined with the regularization, ensures that the model converges to a solution that is both sparse and stable, thereby providing a robust framework for mixed model estimation.

### 3.3.3 Operator Decomposition and Quantum Dynamics
In the context of operator decomposition and quantum dynamics, the focus shifts towards understanding how quantum operators evolve over time and how this evolution can be efficiently modeled and decomposed. The decomposition of operators into simpler, more manageable components is crucial for both theoretical analysis and practical applications, particularly in the realm of quantum computing and quantum information theory. This section delves into the mathematical techniques and physical principles that underpin the decomposition of quantum operators, highlighting the role of spectral theory and the importance of operator norms in characterizing the dynamics of quantum systems.

The dynamics of quantum systems are governed by the Schrödinger equation, which describes the time evolution of the quantum state vector. However, in many practical scenarios, it is more insightful to study the evolution of operators, such as observables, rather than state vectors. The Heisenberg picture provides a natural framework for this, where operators evolve according to the Heisenberg equation of motion. This equation can be linearized and decomposed into a series of simpler operators, each representing a distinct aspect of the system's dynamics. For instance, the decomposition of a time-evolved operator into a sum of local operators allows for the efficient simulation of quantum dynamics, particularly in systems with many degrees of freedom.

Furthermore, the concept of operator decomposition is closely tied to the notion of quantum chaos, where the dynamics of a quantum system can become highly complex and non-local. In such cases, the decomposition of operators into a hierarchy of simpler, local components can help in understanding the emergence of chaotic behavior. Techniques such as the Trotter-Suzuki decomposition and the use of Lie-Trotter products are particularly useful in this context, as they allow for the approximation of the time evolution operator by a sequence of simpler, local operations. This not only aids in the numerical simulation of quantum systems but also provides insights into the underlying physical processes that drive the dynamics. The interplay between operator decomposition and quantum dynamics is thus a rich area of research, with implications for both fundamental physics and applied quantum technologies.

# 4 Optimization Algorithms for Non-Convex Problems

## 4.1 Stochastic and Decentralized Optimization

### 4.1.1 Nested-SGD for Regularized Sinkhorn DRO
Nested-SGD for Regularized Sinkhorn DRO leverages the strengths of stochastic gradient descent (SGD) while addressing the computational challenges associated with large-scale datasets and complex optimization landscapes [11]. The key innovation lies in the integration of nested stochastic programming within the SGD framework, specifically designed for regularized Sinkhorn distributionally robust optimization (DRO) problems [11]. By incorporating a regularization term based on the Sinkhorn distance, the algorithm ensures that the optimization process remains robust to distributional shifts and noise, which are common in real-world applications.

The nested structure of the algorithm involves an inner loop that handles the stochastic nature of the data, while the outer loop manages the optimization of the regularized objective function. This dual-loop mechanism allows for efficient handling of the nonconvex and unbounded loss functions typical in modern machine learning tasks. The inner loop updates the dual variables based on the sampled data, while the outer loop adjusts the primal variables to minimize the regularized objective. This separation of concerns enhances the algorithm's scalability and convergence properties, making it suitable for large-scale datasets.

Experiments conducted on large-scale datasets have demonstrated the effectiveness of Nested-SGD in improving both the convergence speed and the robustness of the optimization process. The algorithm's ability to handle nested stochastic programming, combined with the regularization provided by the Sinkhorn distance, results in a more stable and accurate solution compared to traditional SGD approaches [11]. Furthermore, the strong duality guarantee of the dual formulation ensures that the algorithm converges to the optimal solution, even under relaxed assumptions, thereby broadening its applicability to a wide range of machine learning problems.

### 4.1.2 Decentralized Federated Learning with Gradient Tracking
Decentralized Federated Learning with Gradient Tracking (DFL-GT) extends the traditional federated learning (FL) framework by eliminating the need for a central server, thereby enhancing robustness and reducing communication overhead [18]. In DFL-GT, each client updates its local model parameters using a combination of local gradients and a weighted average of gradients from neighboring clients. This approach ensures that the global model converges to a consensus, even in the presence of heterogeneous data distributions across clients. The key innovation lies in the gradient tracking mechanism, which maintains an estimate of the global gradient at each client, allowing for more accurate and stable updates compared to methods that rely solely on local gradients.

The gradient tracking mechanism in DFL-GT operates by maintaining two sets of variables at each client: the local model parameters and an auxiliary variable that tracks the difference between the local and global gradients. At each iteration, clients update their local models using a combination of the local gradient and the auxiliary variable, which is updated based on the gradients received from neighbors. This dual update process ensures that the local models converge to a common solution, effectively mitigating the issue of client drift caused by data heterogeneity. Theoretical analyses have shown that DFL-GT achieves linear convergence rates under mild assumptions, making it suitable for large-scale and resource-constrained environments.

Moreover, DFL-GT offers several practical advantages over centralized FL approaches. By decentralizing the learning process, DFL-GT reduces the risk of a single point of failure and enhances the resilience of the system to network disruptions. Additionally, the reduced communication requirements between clients and the absence of a central server significantly lower the overall communication costs, making it particularly appealing for applications involving a large number of edge devices. Despite these benefits, DFL-GT faces challenges such as ensuring efficient and reliable peer-to-peer communication and managing the increased computational complexity of maintaining and updating auxiliary variables. Future research directions include optimizing the communication topology and developing adaptive algorithms to further improve the efficiency and scalability of DFL-GT.

### 4.1.3 Non-Asymptotic Analysis of Conjugate Gradient
Conjugate gradient (CG) methods are renowned for their efficiency in solving large-scale linear systems, particularly in the context of machine learning and statistics, where they are often used for regression problems and partial least squares (PLS) methods. The non-asymptotic analysis of CG methods focuses on providing precise bounds on the convergence rate and error after a finite number of iterations, which is crucial for practical applications where computational resources are limited. This analysis is particularly challenging due to the iterative nature of CG, which involves a sequence of orthogonal projections onto the Krylov subspace generated by the matrix and the initial residual.

A key aspect of the non-asymptotic analysis of CG methods is the control of the error after \( t \) iterations, which can be tightly linked to the spectral properties of the matrix. Specifically, the convergence rate of CG is influenced by the condition number of the matrix, \(\kappa\), which characterizes the ratio of the largest to the smallest eigenvalue. Recent studies have shown that the prediction error for CG after \( t \) iterations can be bounded by the prediction error of a gradient flow at a reparametrized time \(\tau_t\). This reparametrization is crucial for understanding the relationship between the discrete and continuous dynamics of the optimization process, providing a bridge between the theoretical analysis of gradient methods and the practical performance of CG.

Furthermore, the non-asymptotic analysis of CG methods has been extended to regularized settings, where a ridge penalty is introduced to improve the conditioning of the problem and enhance numerical stability. This regularization not only helps in reducing the impact of noise in the data but also leads to better generalization properties. The analysis in this context often involves bounding the error in terms of the regularization parameter and the number of iterations, providing a clear trade-off between bias and variance. These results are particularly useful in high-dimensional settings where the data matrix is often ill-conditioned, and standard CG methods may suffer from slow convergence or numerical instability.

## 4.2 Surrogate and Preconditioned Methods

### 4.2.1 Surrogate Loss Functions for Constrained Optimization
Surrogate loss functions play a pivotal role in constrained optimization by transforming the original problem into a more tractable form, facilitating the application of standard optimization algorithms. In the context of constrained online convex optimization, these functions are designed to penalize constraint violations, thereby aligning the optimization process with the feasible region [19]. The construction of a surrogate loss function typically involves adding a penalty term to the original objective function, which reflects the degree of constraint violation. This approach ensures that the optimization algorithm not only minimizes the original loss but also adheres to the given constraints, leading to improved performance and stability.

The choice of the penalty term is crucial, as it directly influences the convergence properties and the overall efficiency of the optimization algorithm. For instance, a quadratic penalty function can lead to smooth and well-behaved optimization landscapes, but it may also result in slower convergence rates compared to more aggressive penalties. On the other hand, non-smooth penalties, such as those based on the ℓ1 norm, can promote sparsity and robustness but may introduce additional computational challenges. Recent research has focused on developing adaptive penalty schemes that dynamically adjust the penalty strength based on the current state of the optimization process, ensuring a balance between constraint satisfaction and convergence speed.

Moreover, the integration of surrogate loss functions with advanced optimization techniques, such as mirror descent and accelerated gradient methods, has shown promising results. Mirror descent, in particular, benefits from the flexibility offered by surrogate loss functions, as it can adapt to the geometry of the problem through the choice of a suitable Bregman divergence [20]. This adaptability allows mirror descent to handle non-smooth and non-Euclidean constraints more effectively, making it a powerful tool for constrained optimization in machine learning and other domains. The combination of these techniques not only enhances the theoretical guarantees of the optimization algorithms but also improves their practical performance in real-world applications.

### 4.2.2 Preconditioned Gradient Descent for Matrix Factorization
Preconditioned Gradient Descent (PrecGD) represents a significant advancement in the optimization of nonconvex matrix factorization problems, particularly in addressing issues related to ill-conditioning and over-parameterization [8]. Unlike traditional gradient descent methods, which may struggle with slow convergence in poorly conditioned or over-parameterized settings, PrecGD introduces a preconditioner that effectively mitigates these challenges. The preconditioner is designed to adaptively adjust the learning rate for each parameter, thereby accelerating convergence and improving the overall efficiency of the optimization process. This approach is particularly beneficial in matrix sensing, a common application of matrix factorization, where the goal is to recover a low-rank matrix from a limited number of linear measurements.

The theoretical foundations of PrecGD are rooted in the observation that ill-conditioning and over-parameterization are not independent phenomena but rather interconnected aspects of the optimization landscape. By treating them as a unified concept, the preconditioner can simultaneously correct for both issues, leading to a more robust and efficient optimization algorithm. Specifically, for the matrix sensing problem, the preconditioner ensures that the gradient descent steps are aligned with the intrinsic geometry of the low-rank manifold, thus facilitating faster convergence to the optimal solution [8]. Numerical experiments have confirmed the effectiveness of PrecGD, showing that it can achieve convergence rates comparable to those of classical gradient descent, even in the presence of severe ill-conditioning and over-parameterization [8].

Moreover, the versatility of PrecGD extends beyond matrix sensing to other variants of nonconvex matrix factorization, including those involving different empirical loss functions. For instance, experiments with ℓp norms (1 ≤ p < 2) have demonstrated that PrecGD maintains its superiority over standard gradient descent, even when the loss function is highly nonsmooth. This robust performance across a range of loss functions underscores the adaptability and reliability of PrecGD, making it a valuable tool for a wide array of matrix factorization tasks. The ability to handle nonsmooth losses without sacrificing convergence speed or accuracy is particularly noteworthy, as it broadens the applicability of PrecGD to real-world problems where data may be noisy or incomplete.

### 4.2.3 Reformulating Optimal Transport as Min-Max Problems
Reformulating the optimal transport (OT) problem as a min-max problem provides a novel perspective that leverages the strengths of game theory and optimization. By converting the marginal constraints of the OT problem into a form involving Kullback-Leibler (KL) divergences, the OT problem can be expressed as a min-max game where the objective is to minimize the transport cost while maximizing the KL divergence weights. This reformulation not only simplifies the problem but also allows for the application of powerful optimization techniques, such as gradient flows, to find the optimal transport plan.

The min-max formulation of the OT problem is particularly advantageous because it facilitates the development of efficient and scalable algorithms. Specifically, the Nash equilibrium of the min-max problem corresponds to the solution of the original OT problem, enabling the use of gradient-based methods to approximate the optimal transport plan dynamically [21]. This approach is particularly useful in high-dimensional settings, where traditional methods may struggle due to computational complexity. By treating the problem as a min-max game, one can leverage the rich theory of two-timescale dynamics and singularly perturbed dynamical systems to prove convergence results in infinite dimensions, thereby providing a solid theoretical foundation for the method [21].

Moreover, the min-max reformulation opens up new avenues for regularization and stabilization of the OT problem. Regularization techniques can be seamlessly integrated into the min-max framework, enhancing the robustness of the solution against noise and distribution shifts. This is crucial in practical applications where data may be noisy or the distributions may not be perfectly known. The ability to incorporate regularization terms directly into the min-max formulation also allows for the development of algorithms that are more flexible and adaptable to various problem settings, making the min-max approach a versatile tool in the optimal transport landscape.

## 4.3 Flow-Based and Variational Methods

### 4.3.1 Theoretical Analysis of Flow-Based Generative Models
Flow-based generative models have gained significant attention due to their ability to model complex data distributions while maintaining tractable likelihoods. The theoretical analysis of these models primarily revolves around understanding their convergence properties and the role of the underlying transformations in shaping the learned distribution. By leveraging the concept of normalizing flows, these models transform a simple base distribution into a complex target distribution through a series of invertible mappings, each of which is parameterized by neural networks. The key theoretical insight is that the Jacobian determinant of these transformations can be efficiently computed, enabling the exact computation of the likelihood of the data under the model.

The convergence of flow-based generative models is often analyzed through the lens of gradient flows in the space of probability distributions. Specifically, the evolution of the model distribution towards the target distribution can be viewed as a gradient flow in the Wasserstein-2 metric space. This perspective provides a rigorous framework for understanding how the model parameters update in response to the discrepancy between the current and target distributions. The use of the Wasserstein-2 metric ensures that the gradient flow is well-behaved even when the target distribution is highly multimodal or has complex support, which is a common scenario in real-world datasets.

Moreover, the theoretical analysis of flow-based generative models also explores the impact of the choice of transformation functions and the architecture of the neural networks used to parameterize them. For instance, the use of coupling layers, autoregressive flows, and residual flows has been shown to influence the expressiveness and efficiency of the models. Theoretical results have established conditions under which these transformations can achieve universal approximation capabilities, meaning that they can approximate any continuous probability distribution to arbitrary precision. This theoretical foundation not only supports the empirical success of flow-based models but also guides the design of new architectures and training algorithms to improve their performance and scalability.

### 4.3.2 Two-Stage Iterative Optimization for LLM-ICL Rec
In the context of Large Language Model In-Context Learning Recommendation (LLM-ICL Rec), a two-stage iterative optimization process has been proposed to enhance the robustness and scalability of recommendation systems. The first stage involves the perturbation of the initial demonstration set to explore a broader solution space, ensuring that the model can adapt to a variety of user preferences and contexts. This perturbation step is crucial for mitigating the risk of overfitting to a narrow set of examples and for improving the generalization capability of the LLM-ICL Rec system. The perturbation is carefully designed to balance exploration and exploitation, allowing the model to discover new and potentially more effective recommendations while maintaining a high level of relevance to the user's current context.

The second stage of the optimization process incorporates regularization terms to stabilize the learning dynamics and prevent the model from converging to suboptimal solutions [22]. This stage leverages advanced regularization techniques, such as those inspired by Mirror Descent (MD) and Generalized Exponentiated Gradient (GEG) descent, to guide the optimization towards a more globally optimal solution [20]. The regularization terms are specifically tailored to the geometry of the optimization problem, ensuring that the model can handle non-smooth and non-Euclidean constraints effectively. By integrating these regularization terms, the two-stage iterative optimization process not only accelerates convergence but also enhances the robustness of the LLM-ICL Rec system against noise and distribution shifts in the data.

The effectiveness of this two-stage iterative optimization approach is further validated through the introduction of a novel evaluation metric, Effect𝐷, which measures the impact of demonstrations on the gradient descent convergence. This metric provides a systematic way to assess the quality of demonstrations and their influence on the optimization process, thereby facilitating the optimization of demonstration sets for improved recommendation performance [23]. The combination of perturbation and regularization in the two-stage process, along with the use of Effect𝐷, ensures that the LLM-ICL Rec system can efficiently generate high-quality recommendations while maintaining theoretical stability and computational efficiency.

### 4.3.3 Asymmetric Projected Gradient Descent for EDMC
Asymmetric Projected Gradient Descent (APGD) represents a significant advancement in the realm of Exponential Decay Matrix Completion (EDMC) by addressing the limitations of traditional Projected Gradient Descent (PGD) methods. APGD introduces an asymmetric projection step that ensures the iterates remain incoherent, a critical property for maintaining the low-rank structure of the matrix being estimated. This asymmetric projection is designed to enforce constraints that are more aligned with the intrinsic geometry of the EDMC problem, thereby enhancing the convergence properties and robustness of the algorithm. By carefully balancing the projection and gradient steps, APGD can effectively navigate the non-convex landscape of EDMC, leading to faster convergence and improved accuracy.

The key innovation in APGD lies in its ability to handle the non-smooth and non-Euclidean nature of the EDMC problem. Unlike standard PGD, which often struggles with non-smooth objective functions and constraints, APGD leverages the flexibility of mirror descent (MD) techniques to adapt to the specific geometry of the problem. This adaptation is achieved through the use of a carefully chosen Bregman divergence, which serves as a regularizer and guides the optimization process. The Bregman divergence ensures that the updates are more aligned with the underlying structure of the data, thus facilitating a more efficient exploration of the solution space. Furthermore, the asymmetric projection step in APGD helps in mitigating the effects of noise and outliers, making the algorithm more robust in practical applications.

In the context of EDMC, APGD demonstrates superior performance by achieving a near-linear convergence rate, which is a significant improvement over the sublinear rates observed in standard PGD methods. This enhanced convergence is attributed to the careful design of the projection and gradient steps, which together ensure a monotonic decrease in the objective function. The theoretical analysis of APGD reveals that the algorithm can achieve an error bound that is information-theoretically optimal, making it a highly effective tool for matrix completion tasks. Additionally, the computational efficiency of APGD is maintained through the use of simple and computationally lightweight operations, making it suitable for large-scale and high-dimensional datasets.

# 5 Sparse Signal Recovery and Inverse Problems

## 5.1 Stochastic and Augmented Lagrangian Methods

### 5.1.1 Stochastic Perturbed Augmented Lagrangian for CoA
The Stochastic Perturbed Augmented Lagrangian (SPAL) method for Constrained Optimization (CoA) is a robust approach designed to address the challenges posed by noisy and complex optimization landscapes. This method combines the strengths of stochastic perturbation techniques with the classical Augmented Lagrangian framework to enhance the convergence properties and stability of the optimization process. Specifically, the SPAL method introduces controlled randomness into the Lagrangian updates, which helps in escaping local minima and saddle points, thus facilitating a more thorough exploration of the solution space.

In the SPAL framework, the Lagrangian multipliers are updated using a combination of deterministic and stochastic terms. The deterministic component ensures that the constraints are satisfied asymptotically, while the stochastic perturbations help in navigating the optimization landscape more effectively. The perturbations are typically drawn from a distribution that balances exploration and exploitation, ensuring that the algorithm remains stable while still exploring potentially beneficial regions of the solution space. This hybrid approach is particularly useful in scenarios where the objective function and constraints are subject to significant noise or uncertainty, such as in real-world applications involving sensor data or financial markets.

The theoretical analysis of the SPAL method reveals that it achieves a faster convergence rate compared to traditional Augmented Lagrangian methods, especially in the presence of strong convexity or smoothness properties of the objective function or constraints. The method's convergence is analyzed using tools from stochastic approximation theory and Lyapunov stability analysis, which provide rigorous bounds on the convergence rate and the quality of the solutions obtained. Numerical experiments on a variety of constrained optimization problems, including those with non-smooth and non-convex components, have demonstrated the effectiveness and robustness of the SPAL method, making it a valuable tool in the arsenal of optimization techniques for complex and noisy environments.

### 5.1.2 Poisson-Gaussian Deep Plug-and-Play Image Restoration
In the realm of image restoration, the Poisson-Gaussian Deep Plug-and-Play (PG-DPIR) method represents a significant advancement by addressing the complexities of mixed Poisson-Gaussian noise, which is prevalent in many imaging scenarios, particularly in low-light conditions and medical imaging [24]. The PG-DPIR framework integrates a deep learning-based denoiser with a variational optimization framework, leveraging the strengths of both to achieve superior restoration performance. The key innovation lies in the adaptation of the DPIR hyperparameters specifically for Poisson-Gaussian noise, which involves a careful balance between the data fidelity term and the regularization term.

The data fidelity term in PG-DPIR is designed to accurately model the Poisson-Gaussian noise, which is crucial for the effectiveness of the restoration process [24]. To this end, an efficient procedure is developed to compute the proximal operator associated with the data fidelity term. This procedure initializes the gradient descent with an approximated proximal operator that can be computed in closed form, significantly reducing the computational burden. This initialization step is followed by a few iterations of gradient descent, which refine the approximation and ensure convergence to the optimal solution. This approach not only accelerates the restoration process but also enhances the robustness of the method against noise.

Furthermore, the PG-DPIR framework demonstrates flexibility and adaptability by allowing the integration of various deep learning-based denoisers, which can be trained on diverse datasets to capture a wide range of image features and textures. This flexibility is particularly beneficial in scenarios where the noise characteristics vary across different imaging modalities or environments. The experimental results show that PG-DPIR outperforms traditional methods and other state-of-the-art techniques in terms of both quantitative metrics and visual quality, making it a promising approach for practical image restoration applications [24].

### 5.1.3 Iterative Algorithms for Square-Root Lasso
Iterative algorithms for the Square-Root Lasso (SR-Lasso) have gained significant attention due to their ability to handle high-dimensional data while maintaining robustness to noise [25]. The SR-Lasso, introduced as an alternative to the standard Lasso, addresses the issue of variance estimation by minimizing the sum of the absolute residuals rather than the squared residuals. This formulation leads to a more stable and less biased estimator, particularly in settings where the noise variance is unknown or varies across observations. The primary challenge in solving the SR-Lasso problem lies in the non-differentiability of the objective function, which necessitates the development of specialized algorithms.

One of the most prominent iterative algorithms for solving the SR-Lasso is the Iterative Soft-Thresholding Algorithm (ISTA) [25]. ISTA is a first-order method that combines gradient descent steps with soft-thresholding operations to promote sparsity in the solution. Despite its simplicity, ISTA can be slow to converge, especially for large-scale problems. To accelerate convergence, variants such as the Fast Iterative Soft-Thresholding Algorithm (FISTA) have been developed. FISTA incorporates an adaptive step size and momentum term, leading to a faster convergence rate of \(O(1/k^2)\) compared to the \(O(1/k)\) rate of ISTA. These algorithms are particularly useful in scenarios where the design matrix is ill-conditioned or the problem is highly underdetermined.

In recent years, second-order methods have also been explored to further enhance the efficiency of SR-Lasso solvers. The Dual Newton-based Preconditioned Proximal Point Algorithm (PPDNA) is a notable example, which leverages the structure of the SR-Lasso problem to achieve superlinear convergence [26]. PPDNA combines the strengths of the proximal point method and the dual Newton method, making it highly effective for large-scale problems. By carefully deriving the generalized Jacobian of the proximal operator, PPDNA can efficiently solve the subproblems arising in each iteration. Numerical experiments have shown that PPDNA outperforms first-order methods in terms of both computational efficiency and solution accuracy, making it a preferred choice for practical applications involving SR-Lasso.

## 5.2 Non-Linear and Adaptive Recovery Techniques

### 5.2.1 Non-Linear Recovery with Square Root Lasso and OMP
Non-linear recovery methods, such as the square root Lasso (rLasso) and orthogonal matching pursuit (OMP), have gained significant attention due to their robustness and effectiveness in high-dimensional settings [3]. The square root Lasso, introduced by Belloni, Chernozhukov, and Wang, extends the traditional Lasso by incorporating a scaling factor that normalizes the residual sum of squares [25]. This normalization makes the rLasso less sensitive to the noise level, thereby providing more stable and accurate estimates. The rLasso has been extensively analyzed by researchers such as H. Petersen and P. Jung, who have demonstrated its superiority in function recovery tasks, particularly in scenarios where the noise variance is unknown or varies across observations.

In contrast, the orthogonal matching pursuit (OMP) is a greedy algorithm that iteratively selects features to include in the model based on their correlation with the current residual. OMP is computationally efficient and has been widely used in compressed sensing and sparse signal recovery. The recovery guarantees for OMP are well-established in the literature, with theoretical foundations provided by works such as Foucart and Rauhut. These guarantees ensure that OMP can recover the true support of a sparse signal with high probability, given a sufficient number of measurements and appropriate coherence conditions on the measurement matrix. The iterative nature of OMP allows it to adaptively refine the solution, making it particularly suitable for non-linear recovery tasks.

Both the square root Lasso and OMP offer distinct advantages in non-linear recovery. The rLasso's robustness to varying noise levels and its ability to handle high-dimensional data make it a preferred choice in many applications, including image processing and genomics. On the other hand, OMP's computational efficiency and simplicity make it a practical option for real-time and resource-constrained environments. The combination of these methods can lead to improved recovery performance, especially when integrated into more complex machine learning pipelines. For instance, the use of rLasso for initial feature selection followed by OMP for fine-tuning can leverage the strengths of both approaches, resulting in more accurate and reliable non-linear recovery.

### 5.2.2 Adaptive Sieving and Semismooth Newton Proximal AL
Adaptive sieving and semismooth Newton proximal augmented Lagrangian (Ssnpal) algorithms represent a significant advancement in solving large-scale optimization problems, particularly those involving structured sparsity-inducing regularizers [5]. The Ssnpal algorithm leverages the semismooth Newton method, which is renowned for its efficiency and rapid convergence properties, to address the inner optimization problems. By utilizing the KKT conditions, the algorithm enhances its efficiency, making it particularly suitable for problems where the objective function is nonsmooth due to the presence of regularizers like the exclusive lasso.

The core of the Ssnpal approach lies in its ability to adaptively sieve out irrelevant variables through a series of reduced subproblems, thereby focusing computational resources on the most significant components. This adaptive sieving mechanism significantly reduces the dimensionality of the problem, leading to faster convergence and lower computational costs. Moreover, the semismooth Newton method, when applied to these reduced subproblems, ensures that the algorithm maintains a superlinear or even quadratic convergence rate, which is crucial for handling large-scale datasets efficiently.

Numerical experiments have demonstrated the superior performance of the Ssnpal algorithm compared to other state-of-the-art methods such as ADMM, APG, CD, and ILSA. These experiments, conducted on both synthetic and real-world datasets, highlight the algorithm's robustness and effectiveness in solving complex optimization problems. The results not only validate the theoretical foundations of the Ssnpal algorithm but also underscore its practical utility in various machine learning applications, including regression and classification tasks. The combination of adaptive sieving and semismooth Newton methods provides a powerful framework for optimizing models with structured sparsity, making it a valuable tool in the field of large-scale optimization.

### 5.2.3 Truncated Huber Penalty for Sparse Signal Recovery
The Truncated Huber Penalty (THP) is a robust loss function that combines the benefits of the least squares (LS) and Huber loss functions, making it particularly suitable for sparse signal recovery problems where outliers are common. Unlike the standard Huber loss, which transitions smoothly from a quadratic to a linear penalty, the THP truncates the linear part of the Huber loss at a certain threshold, thereby reducing the influence of large residuals. This truncation ensures that the penalty remains bounded, which is crucial for robustness against outliers while maintaining the convexity of the optimization problem. The THP is defined as a piecewise function, where the quadratic part is used for small residuals to ensure smoothness and the truncated linear part is used for large residuals to limit their impact.

In the context of sparse signal recovery, the THP is often incorporated into the objective function as a regularization term alongside a sparsity-inducing norm, such as the ℓ1-norm. This combination allows the optimization algorithm to effectively balance the trade-off between fitting the data and promoting sparsity in the solution. The use of the THP in this setting not only enhances the robustness of the recovery process by down-weighting the influence of outliers but also improves the convergence properties of the optimization algorithm. The truncated nature of the penalty helps in avoiding overfitting to noisy data, which is a common issue in sparse recovery problems where the signal-to-noise ratio is low.

Numerical experiments have shown that the THP outperforms both the standard Huber loss and the least squares loss in scenarios with significant outliers. The improved robustness of the THP leads to more accurate and reliable signal recovery, especially in applications such as image denoising, where the presence of outliers can severely degrade the performance of traditional methods. The effectiveness of the THP in sparse signal recovery is further enhanced by the use of efficient optimization algorithms, such as the proximal gradient method, which can handle the non-differentiability of the THP at the truncation point. These algorithms leverage the structure of the THP to ensure fast and stable convergence, making the THP a valuable tool in the sparse signal recovery toolkit.

## 5.3 Variational and Diffusion Methods

### 5.3.1 Variational Inference for Backdoor Elimination
Variational Inference for Backdoor Elimination (VIBE) represents a significant advancement in the field of robust machine learning, particularly in the context of defending against backdoor attacks [27]. VIBE leverages variational inference to model the uncertainty in the training data, treating the dataset examples and their corrupted labels as observed random variables. By doing so, it aims to infer the latent clean labels, which are assumed to be the true underlying labels before the data was poisoned. This approach is fundamentally different from traditional methods that either attempt to detect and remove poisoned samples or train models that are inherently robust to the presence of backdoors [27].

The core mechanism of VIBE involves constructing a probabilistic model where the clean labels are treated as latent variables, and the observed data (including both the inputs and the potentially corrupted labels) are used to infer these latent variables. The inference process is performed using variational inference techniques, which approximate the posterior distribution over the clean labels given the observed data. This allows VIBE to effectively marginalize out the uncertainty in the corrupted labels, leading to a more robust model that is less susceptible to the influence of backdoor triggers. The variational inference framework also enables VIBE to incorporate prior knowledge about the distribution of clean labels, further enhancing its ability to resist backdoor attacks.

To implement VIBE, a variational autoencoder (VAE) is often employed to model the complex dependencies between the input features and the latent clean labels. The encoder part of the VAE maps the input data to a distribution over the latent space, while the decoder reconstructs the input data from the latent representation. During training, the model is optimized to minimize the reconstruction loss and the Kullback-Leibler divergence between the approximate posterior and the prior distribution over the latent variables. This dual objective ensures that the learned latent representations are both informative and consistent with the prior assumptions about the clean labels. Empirical evaluations have shown that VIBE can significantly reduce the success rate of backdoor attacks, making it a promising approach for enhancing the security of machine learning models trained on potentially poisoned datasets [27].

### 5.3.2 Primal-Dual Algorithms for Saddle Problems
Primal-dual algorithms are a class of methods designed to solve saddle point problems, which are prevalent in various fields such as optimization, game theory, and machine learning. A fundamental approach in this category is the Arrow-Hurwicz method, a primal-dual full-splitting algorithm that addresses the saddle problem by iteratively minimizing over the primal variable and maximizing over the dual variable. This method is particularly useful for problems where the objective function is convex in the primal variable and concave in the dual variable, allowing for a natural alternation between the two optimization steps.

The Arrow-Hurwicz method, while simple and intuitive, has been the foundation for more advanced primal-dual algorithms [28]. These algorithms often incorporate acceleration techniques and adaptive step sizes to improve convergence rates and robustness. For instance, a new primal-dual algorithm (NPDA) has been developed, which not only ensures global convergence but also achieves an O(1/N) ergodic convergence rate [28]. This NPDA is particularly effective for solving large-scale matrix games and other optimization problems where the saddle point structure is evident [28]. The algorithm's efficiency is further enhanced by the use of linesearch strategies, which dynamically adjust the step sizes to better navigate the optimization landscape.

In recent years, primal-dual algorithms have been extended to handle more complex and structured problems, such as those involving non-smooth regularizers and constraints. For example, the dual Newton method based proximal point algorithm (PPDNA) has been designed to solve exclusive lasso models, which are common in multi-task learning and feature selection [4]. This algorithm leverages the superlinear convergence properties of the dual Newton method, combined with a preconditioned proximal point framework, to efficiently solve large-scale optimization problems [26]. The PPDNA not only provides a closed-form solution to the proximal mapping but also demonstrates superior performance compared to existing state-of-the-art algorithms in numerical experiments.

### 5.3.3 Diffusion Posterior Sampling for Noisy Inverse Problems
Diffusion posterior sampling (DPS) has emerged as a powerful technique for addressing noisy inverse problems, particularly in scenarios where the data is corrupted by noise and the underlying problem is ill-posed. In DPS, the goal is to sample from the posterior distribution of the latent clean signal given the noisy observations. This is achieved by formulating the problem within a Bayesian framework, where the posterior distribution is defined by the likelihood of the observations and a prior that encodes structural assumptions about the signal. The diffusion process is used to iteratively refine the estimate of the posterior, effectively propagating information from the noisy observations to the latent clean signal.

The key advantage of DPS lies in its ability to handle complex noise models and to incorporate sophisticated priors that can capture the inherent structure of the signal. For instance, in image processing applications, the prior might be designed to promote sparsity in a transform domain, such as wavelet or total variation, which is particularly useful for denoising and deblurring tasks. The diffusion process, often implemented using Markov Chain Monte Carlo (MCMC) methods, allows for the exploration of the posterior distribution, thereby providing a principled way to quantify uncertainty in the recovered signal. This is crucial for applications where robustness and reliability are paramount, such as in medical imaging and remote sensing.

In practice, the implementation of DPS involves several technical challenges, including the choice of the diffusion kernel, the design of the prior, and the efficient sampling of the posterior. Recent advancements have focused on developing more efficient sampling algorithms, such as Hamiltonian Monte Carlo (HMC) and Langevin dynamics, which can significantly reduce the computational burden. Additionally, the integration of deep learning techniques, particularly in the form of neural network-based priors, has shown promise in enhancing the performance of DPS. These deep priors can learn complex signal structures from large datasets, leading to more accurate and robust reconstructions. The combination of these techniques has the potential to revolutionize the field of noisy inverse problems, enabling more effective solutions in a wide range of applications.

# 6 Future Directions


Despite the significant advancements in numerical algorithms for solving high-dimensional regression and optimization problems, several limitations and gaps remain. Current methods often struggle with the computational efficiency required for handling extremely large datasets, and the scalability of existing algorithms is a critical concern. Additionally, while regularization techniques have improved model generalization, they sometimes fail to capture the intricate dependencies and structures present in high-dimensional data, leading to suboptimal performance. There is also a need for more robust methods that can handle noisy and non-stationary data effectively, as well as algorithms that can adapt to changing environments and distributions. Furthermore, the theoretical foundations of many advanced techniques, such as nonconvex sparsity penalties and flow-based generative models, require further exploration to ensure their reliability and practical applicability.

To address these limitations, several directions for future research are proposed. First, the development of more efficient and scalable algorithms is essential. This could involve the creation of parallel and distributed computing frameworks that can handle the computational demands of large-scale datasets. Techniques such as randomized algorithms and sketching methods could be explored to reduce the computational complexity while maintaining the accuracy of the solutions. Second, there is a need to enhance the ability of algorithms to capture and leverage the inherent structures in high-dimensional data. This could be achieved by integrating advanced machine learning techniques, such as deep learning and graph neural networks, into the optimization and regularization frameworks. These techniques can help in identifying and exploiting latent structures, such as sparsity, low-rank, and network dependencies, which are often present in real-world datasets.

Another important direction is the development of more robust and adaptive methods. This includes the design of algorithms that can handle noisy and non-stationary data, as well as methods that can adapt to changes in the data distribution over time. Techniques such as online learning and reinforcement learning could be integrated into the existing frameworks to enable real-time adaptation and continuous learning. Additionally, there is a need to develop theoretical guarantees for the performance of these algorithms, particularly in nonconvex and high-dimensional settings. This could involve the derivation of tighter bounds on the convergence rates and the establishment of conditions under which the algorithms are guaranteed to converge to optimal or near-optimal solutions.

The potential impact of the proposed future work is substantial. More efficient and scalable algorithms will enable the analysis of increasingly large and complex datasets, opening up new opportunities in fields such as genomics, finance, and social network analysis. Enhanced methods for capturing and leveraging data structures will lead to more accurate and interpretable models, which can provide deeper insights into the underlying processes and phenomena. Robust and adaptive algorithms will improve the reliability and performance of machine learning systems in dynamic and uncertain environments, making them more suitable for real-world applications. Overall, these advancements will contribute to the broader goal of advancing the field of numerical algorithms for high-dimensional regression and optimization, driving innovation and practical improvements in data science and machine learning.

# 7 Conclusion



This survey provides a comprehensive overview of the latest developments in numerical algorithms for solving Lasso problems, which are central to regularized regression in high-dimensional settings. The main findings include the exploration of advanced regularization techniques, such as nonconvex sparsity penalties and regularized EM algorithms, which offer more precise control over model sparsity and stability. The survey also delves into optimization algorithms for non-convex problems, including stochastic and decentralized methods, which are crucial for handling large-scale datasets and complex optimization landscapes. Additionally, the paper discusses the integration of structural information through methods like Network Convolutional Regression and the Neighborhood-Fused Lasso, which enhance model performance by leveraging inherent network and spatial dependencies. The theoretical foundations and practical applications of these algorithms are rigorously analyzed, providing a solid basis for their implementation in various domains.

The significance of this survey lies in its comprehensive and up-to-date coverage of the latest advancements in numerical algorithms for Lasso problems. By bridging the gap between theoretical advancements and practical applications, this survey serves as a valuable resource for researchers and practitioners in machine learning, data science, and signal processing. The detailed exploration of regularization techniques, optimization algorithms, and structural methods not only highlights the key challenges and solutions in the field but also offers insights into the design and implementation of efficient algorithms for high-dimensional data analysis. The survey's focus on both convex and non-convex formulations, as well as its emphasis on the practical implications of these algorithms, makes it a crucial reference for anyone working on or interested in the development of advanced numerical methods for high-dimensional regression and optimization.

In conclusion, this survey underscores the importance of continued research and innovation in numerical algorithms for Lasso problems. While significant progress has been made, there remains a need for further advancements in handling large-scale datasets, improving computational efficiency, and developing robust methods for real-world applications. Future research directions should focus on the integration of emerging techniques, such as quantum computing and advanced machine learning models, to further enhance the performance and applicability of these algorithms. We call upon the research community to build upon the findings presented in this survey, addressing the remaining challenges and pushing the boundaries of what is possible in high-dimensional data analysis. By doing so, we can continue to advance the field and contribute to the development of more sophisticated and efficient numerical algorithms for Lasso problems.

# References
[1] Transfer Learning Under High-Dimensional Network Convolutional  Regression Model  
[2] High-dimensional model-assisted inference for treatment effects with  multi-valued treatments  
[3] Instance optimal function recovery -- samples, decoders and asymptotic  performance  
[4] A dual Newton based preconditioned proximal point algorithm for  exclusive lasso models  
[5] Adaptive sieving with semismooth Newton proximal augmented Lagrangian  algorithm for multi-task Lass  
[6] Gradient Descent as a Shrinkage Operator for Spectral Bias  
[7] Local Neighborhood Fusion in Locally Constant Gaussian Graphical Models  
[8] Preconditioned Gradient Descent for Over-Parameterized Nonconvex Matrix  Factorization  
[9] High-dimensional ridge regression with random features for  non-identically distributed data with a  
[10] Deep Sturm--Liouville  From Sample-Based to 1D Regularization with  Learnable Orthogonal Basis Funct  
[11] Nested Stochastic Gradient Descent for (Generalized) Sinkhorn  Distance-Regularized Distributionally  
[12] Weak Signals and Heavy Tails  Machine-learning meets Extreme Value  Theory  
[13] Recursive Algorithms for Sparse Parameter Identification of Multivariate  Stochastic Systems with No  
[14] Block-Weighted Lasso for Joint Optimization of Memory Depth and Kernels  in Wideband DPD  
[15] Dominating Hyperplane Regularization for Variable Selection in  Multivariate Count Regression  
[16] Does the $ ell 1$-norm Learn a Sparse Graph under Laplacian Constrained  Graphical Models   
[17] Selective Inference in Graphical Models via Maximum Likelihood  
[18] Decentralized Nonconvex Composite Federated Learning with Gradient  Tracking and Momentum  
[19] Optimal Bounds for Adversarial Constrained Online Convex Optimization  
[20] Mirror Descent and Novel Exponentiated Gradient Algorithms Using  Trace-Form Entropies and Deformed  
[21] Computing Optimal Transport Plans via Min-Max Gradient Flows  
[22] An Overview of Low-Rank Structures in the Training and Adaptation of  Large Models  
[23] Decoding Recommendation Behaviors of In-Context Learning LLMs Through  Gradient Descent  
[24] PG-DPIR  An efficient plug-and-play method for high-count  Poisson-Gaussian inverse problems  
[25] An iterative algorithm for the square-root Lasso  
[26] A Highly Efficient Algorithm for Solving Exclusive Lasso Problems  
[27] Seal Your Backdoor with Variational Defense  
[28] New Primal-Dual Algorithm for Convex Problems  