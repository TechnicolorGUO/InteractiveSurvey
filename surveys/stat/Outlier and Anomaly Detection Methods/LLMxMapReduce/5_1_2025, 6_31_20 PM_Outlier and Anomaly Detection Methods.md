# 5/1/2025, 6:31:20 PM_Outlier and Anomaly Detection Methods  

# 0. Outlier and Anomaly Detection Methods  

# 1. Introduction  

Anomaly detection, also referred to as outlier detection, is fundamentally concerned with identifying data points or patterns that deviate significantly from the norm or expected behavior within a dataset [7,24,26,30]. These atypical observations, known as anomalies or outliers, can manifest as errors, system malfunctions, or indicators of previously unidentified processes or behaviors [18,28,30]. While the terms "anomaly" and "outlier" are often used interchangeably, related concepts such as novelty detection, forgery detection, and out-of-distribution detection carry subtle distinctions depending on the specific application and context [7,24].  

<html><body><table><tr><td>Feature</td><td>Outlier Detection</td><td>Novelty Detection</td></tr><tr><td>Training Data</td><td>May contain outliers</td><td>Assumed to be clean (no outliers)</td></tr><tr><td>Objective</td><td>Identify outliers within the dataset</td><td>Identify anomalies in new data points</td></tr><tr><td>Paradigm</td><td>Often Unsupervised</td><td>Often Semi-supervised</td></tr><tr><td>Algorithms</td><td>LOF, Isolation Forest, some Clustering</td><td>One-Class SvM (on clean data), Autoencoders</td></tr></table></body></html>  

A key differentiation exists between outlier detection and novelty detection: outlier detection typically addresses datasets potentially containing outliers and is often approached as an unsupervised task, whereas novelty detection focuses on identifying anomalies in new data points given a training dataset assumed to be free of outliers, thus being framed as a semi-supervised problem [1,5,9]. The core principle involves comparing new data against established patterns derived from a training set to recognize deviations [26].  

The necessity for automated anomaly detection has surged with the explosive growth in data volume and velocity across diverse domains [7,18,31]. Identifying anomalies is critical because they frequently encapsulate vital information, ranging from indications of cyber intrusions and malicious network activity to signs of financial fraud, manufacturing defects, or medical abnormalities [11,18,28,30]. Automated systems are essential for efficiently processing large datasets and providing reliable detection, enabling timely responses that can save costs, improve reliability, and enhance decision-making in areas such as IT analytics, network security, medical diagnostics, and industrial quality control [3,17,24]. The limitations of traditional techniques in handling complex data structures, especially high-dimensional and sequential data at scale, further underscore the demand for more advanced detection methods [24,28].  

Despite its importance, anomaly detection presents significant challenges. A fundamental difficulty lies in the often vague and dynamic boundary separating normal from anomalous behavior [28,30], and the very definition of an outlier can vary across different applications [30]. The inherent class imbalance, where anomalies are significantly less frequent than normal instances, poses a major hurdle [6,10]. The unexpected nature and diverse forms of anomalies also make them difficult to model exhaustively [10]. High-dimensional data can challenge traditional methods [24,28]. Furthermore, the scarcity of labeled anomaly data is a pervasive issue, often requiring unsupervised or semi-supervised learning approaches [2,3,6,30]. Noisy data can be difficult to distinguish from true outliers [13,30], and in adversarial scenarios, anomalies may be deliberately designed to mimic normal patterns [30]. The need for model generalization to avoid misclassifying unusual but normal instances is also critical [26], alongside challenges in handling evolving data streams and real-time detection requirements [2,17].  

To address these challenges, a wide spectrum of anomaly detection techniques has been developed. These methods can be broadly categorized into traditional approaches such as statistical methods (e.g., Gaussian fitting), distance-based techniques, density-based methods, and clustering-based methods [2,4,7]. Other categories include tree-based, dimensionality reduction-based, classification-based, and prediction-based approaches [4]. In recent years, deep learningbased methods (DAD) have emerged as powerful tools, particularly effective for handling complex, large-scale, and highdimensional data that pose difficulties for traditional algorithms [7,24,28].  

This survey aims to provide a comprehensive overview of outlier and anomaly detection methods. The remainder of this paper is structured as follows: Section \ref{section:definitions_and_background} delves deeper into the formal definitions and theoretical underpinnings. Section \ref{section:traditional_methods} reviews traditional anomaly detection techniques, detailing their principles, strengths, and weaknesses. Section \ref{section:deep_learning_methods} focuses on deep learning-based approaches, discussing various architectures and their applications. Section \ref{section:evaluation} covers methods for evaluating anomaly detection performance. Section \ref{section:applications} explores the diverse applications of anomaly detection across various domains. Finally, Section \ref{section:future_directions} discusses current open challenges and future research directions in the field.​  

# 2. Types of Anomalies  

![](images/8e7485279ee4fb025e5ae7b73a9f9405872123e288729db778522d15e4f62f6e.jpg)  

Anomalies, or outliers, can be broadly categorized into three primary types based on their characteristics and relationship to the surrounding data [8,18,28,30]. These categories are point anomalies, contextual anomalies, and collective anomalies, although variations in terminology such as Type I, Type II, and Type III outliers [30], or continuous (contextual) and team (collective) anomalies [7], are also used in the literature.​  

Point Anomalies (also known as Type I outliers) represent individual data instances that significantly deviate from the majority of the dataset [7,8,18,28,30]. They are characterized by attribute values that are inconsistent with normal instances [30]. Examples include a sudden large expense in financial transactions [8] or a large, single credit card transaction [7,30]. Point anomalies are often described as random irregularities or deviations [28].  

Contextual Anomalies (referred to as Type II outliers or continuous anomalies) are data instances that are considered unusual only within a specific context [8,18,28,30]. The abnormality of such instances is dependent on context-based knowledge, meaning they might not appear anomalous in a different context [18,30]. Detecting contextual anomalies necessitates the consideration of both contextual and behavioral features, such as time and space [28]. For example, a temperature of $3 5 ^ { \circ } \mathsf { F }$ is normal in winter but would be considered an outlier in summer [18]. Similarly, a sudden surge in website traffic might be normal during a product launch but anomalous during off-peak hours [8]. Contextual anomalies are frequently explored in time-series and spatial data [2,30].  

Collective Anomalies (also termed Type III outliers or team anomalies) involve a set or group of related data points that are anomalous when considered together, even if individual points within the group do not appear anomalous in isolation [7,8,18,28,30]. The collective summation or occurrence of these instances signifies the outlying behavior [18,28,30].  

Examples include a sequence of events occurring in an unexpected order, unexpected combinations of values [8], multiple small credit card transactions happening within a short timeframe [7], or a flat line in an electrocardiogram output indicating an unusually long period with the same low value [30]. The detection of Type III outliers has been widely investigated for sequential data like operating system call data and genome sequences [30]. Identifying collective anomalies often requires analyzing the relationships and dependencies among data points, as opposed to merely examining individual instances in isolation.  

# 3. Data Preprocessing and Feature Engineering  

<html><body><table><tr><td>Step/Technique</td><td>Description</td><td>Examples/Purpose</td></tr><tr><td>Data Cleaning</td><td>Handling missing values and noise.</td><td>Filling missing values, identifying/managing noisy outliers.</td></tr><tr><td>Data Transformation</td><td>Converting data into a suitable format.</td><td>Smoothing, Aggregation, Generalization, Normalization/Scaling.</td></tr><tr><td>Normalization/Scaling</td><td>Adjusting feature ranges/distributions.</td><td>MinMaxScaler, StandardScaler; Ensures features contribute equally.</td></tr><tr><td>Feature Engineering</td><td>Creating/selecting features that highlight anomalies.</td><td>Color Histograms (images), Reconstruction Error (Autoencoders), Log parsing.</td></tr><tr><td>Dimensionality Reduction</td><td>Reducing the number of features while preserving key information.</td><td>PCA, Autoencoders (as feature encoders). Simplifies detection.</td></tr></table></body></html>  

Effective data preprocessing and feature engineering are fundamental prerequisites for achieving robust and accurate anomaly detection results [13,31]. Raw data often contains noise, missing values, and requires transformation to a format suitable for analysis, highlighting the importance of steps like data cleaning, integration, transformation, and reduction [31]. Data cleaning, in particular, is crucial for handling missing and noisy data, with techniques such as filling missing values being essential steps [3,31]. For instance, in a credit card fraud detection case study, missing values were addressed by filling them with the mean of the respective columns [3]. Data cleaning also involves managing outliers, and some methods specifically focus on identifying and potentially replacing outliers while preserving the majority of the original data [13].  

Common data transformation techniques include smoothing, aggregation, generalization, normalization, and attribute construction [31]. Among these, normalization and feature scaling are frequently employed to ensure that features contribute equally to the anomaly detection process and to meet the requirements of certain algorithms. Several studies utilize scaling methods from scikit-learn; for example, Autoencoder models often standardize data using preprocessing.MinMaxScaler() to scale training and testing datasets [15,16]. Another common approach is StandardScaler, which scales features to have zero mean and unit variance, as applied to the 'Amount' feature in a credit card fraud detection dataset [3]. Normalization is also applied in domain-specific contexts, such as normalizing 3D color histograms used as features for image-based anomaly detection [5].​  

Feature engineering approaches vary widely, aiming to extract or construct features that best discriminate between normal and anomalous instances [30]. The ability to identify a strong set of features is a key challenge, directly influencing both detection accuracy and computational efficiency [30]. Increasing the number of relevant features can often improve the accuracy of anomaly detection [26]. Traditional methods involve feature extraction, such as quantifying images using color histograms in the HSV color space for image analysis [5]. More advanced techniques, particularly in deep learning, leverage representation learning. For example, Autoencoders can serve as feature encoders, abstracting original data into features like hidden representations, reconstruction residual vectors, and notably, reconstruction errors, which are designed to highlight deviations of anomalous samples [14]. Deep Anomaly Detection (DAD) techniques are particularly effective at  

extracting complex hierarchical features from high-dimensional data, with deeper network architectures generally yielding better performance [28].  

Dimensionality reduction and attribute selection are also critical aspects of feature engineering, especially in highdimensional spaces. The core idea is to find a lower-dimensional space or a better data representation where anomaly detection becomes simpler, often by measuring similarity in the transformed space [6]. Strategies include attribute subset selection, dimensionality reduction techniques, and numerosity reduction [31].​  

For domain-specific applications, tailored preprocessing is often required. Time series data, for instance, necessitates transformation into a suitable format for analysis. This can involve discretizing the series into training samples or chunks with comparable statistical properties, a process that often benefits from domain expertise [24]. Automated systems may assess time-series datasets to select the most appropriate algorithm and techniques [17]. In image analysis, specific steps like loading images, converting color spaces (e.g., to HSV), and calculating descriptive features like color histograms are essential before applying detection algorithms [5]. While not detailed in the provided digests, other domains such as system logs often require specific steps like log parsing to structure unstructured text data into usable features. Datasets can broadly be categorized by structure (sequential vs. non-sequential) and dimensionality (high-dimensional vs. lowdimensional), influencing the choice of preprocessing and feature engineering techniques [28]. The characteristics of the data, such as multimodality and the proportion of noise inherent to the data generation or preprocessing, also significantly impact algorithm performance [27].​  

In summary, effective preprocessing techniques like cleaning, handling missing values, normalization, and scaling are foundational. Feature engineering, ranging from manual extraction to automated representation learning and dimensionality reduction, is equally vital, as the choice and quality of features directly dictate the accuracy and efficiency of anomaly detection methods across various data types and domains [26,30].​  

# 4. Categories of Anomaly Detection Methods  

<html><body><table><tr><td>Category</td><td>Core Principle /Assumption</td><td>Examples</td></tr><tr><td>Statistical</td><td>Deviate from assumed statistical distribution.</td><td>Z-score, Boxplot, Elliptic Envelope.</td></tr><tr><td>Distance-Based</td><td>Far from majority or nearest neighbors.</td><td>KNN, k-th Nearest Neighbor.</td></tr><tr><td>Density-Based</td><td>Located in low-density regions.</td><td>LOF, COF, SOS.</td></tr><tr><td>Clustering-Based</td><td>Do not belong to clusters, far from centroids, small clusters.</td><td>K-means, GMM, DBSCAN.</td></tr><tr><td>Tree-Based</td><td>Easily isolated by random partitioning.</td><td>Isolation Forest.</td></tr><tr><td>Ensemble Methods</td><td>Combine multiple models for improved robustness.</td><td>Isolation Forest (inherently), Stacking.</td></tr><tr><td>Model-Based</td><td>Deviate from an explicit generative model or boundary.</td><td>Elliptic Envelope, One-Class SVM.</td></tr><tr><td>Deep Learning-Based</td><td>Learn complex features/patterns; identify deviations.</td><td>Autoencoders,GANs, OC-NN, CNNs,RNNs,Transformers.</td></tr></table></body></html>  

Anomaly detection methods can be broadly categorized based on their underlying assumptions about the data and the nature of anomalies they aim to identify. These distinct approaches offer varying strengths and weaknesses, making their suitability dependent on the specific characteristics of the dataset and the problem domain.  

Statistical methods form a fundamental category, operating under the assumption that normal data conforms to a specific statistical distribution. Anomalies are identified as instances that deviate significantly from this assumed model [26,31]. Examples include univariate techniques like the Z-score and Boxplot, and multivariate methods such as those based on the multivariate Gaussian distribution or robust estimators like EllipticEnvelope with Minimum Covariance Determinant (MCD) [1,5,8]. While often interpretable and computationally efficient for simple cases, their performance can degrade when underlying distributional assumptions are violated or in high-dimensional spaces [4,15].  

Distance-based methods quantify the dissimilarity between data points and identify anomalies as instances that are far from the majority of the data or their nearest neighbors [15,31]. Key examples include K-Nearest Neighbors (KNN) and $k$ -th Nearest Neighbor methods [29]. A major advantage is their non-parametric nature, not requiring assumptions about data distribution. However, they face challenges with computational cost on large datasets and are susceptible to the curse of dimensionality, which can render distance metrics less effective in high-dimensional spaces [6,29].  

Density-based methods approach anomaly detection by identifying data points located in regions of significantly lower density compared to their surroundings [15,16,31]. This makes them effective at detecting local anomalies that might be missed by global distance-based methods. The Local Outlier Factor (LOF) is a prominent algorithm in this category, measuring the local density deviation of a point relative to its neighbors [8,15]. Variants like COF address specific issues in sparse data, while SOS uses a probabilistic affinity model [15]. These methods are generally robust to varying data densities [27].​  

Clustering-based methods utilize the principle that normal data tends to form clusters, while anomalies appear as points that do not belong to any cluster, are distant from cluster centers, or constitute very small clusters [3,31]. Algorithms like Kmeans, Gaussian Mixture Models (GMM), and DBSCAN are commonly adapted for this purpose [3,8,24]. DBSCAN is particularly noted for its ability to identify noise points (anomalies) and discover clusters of arbitrary shape, though its performance is sensitive to parameter selection [4,15].​  

Tree-based methods, exemplified by Isolation Forest (iForest), adopt a different strategy by focusing on the isolation of anomalies rather than modeling normal data [19,20]. iForest isolates anomalies through random partitioning in decision trees, leveraging the observation that anomalies are easier to separate from the bulk of the data, resulting in shorter path lengths [19]. This approach is known for its efficiency, linear time complexity, and effectiveness on high-dimensional and multimodal data [16,19].​  

Ensemble methods enhance robustness and performance by combining the outputs of multiple individual anomaly detection models [5,6]. This paradigm mitigates the limitations of single models and improves generalization. Isolation Forest is inherently an ensemble method [19]. Other ensemble strategies include combining multiple deep learning models or using stacking techniques with diverse base learners like Random Forest and Neural Networks [11,28].​  

Model-based methods explicitly learn a generative model or a decision boundary that characterizes normal data. Deviations from this learned model are then treated as anomalies. Elliptic Envelope assumes normal data follows a Gaussian distribution and uses robust covariance estimation to identify outliers based on Mahalanobis distance [1,5]. One-Class Support Vector Machine (One-Class SVM) learns a hyperplane or boundary enclosing normal data in feature space, often used for novelty detection where training data is assumed clean [1,5,20]. These methods provide a structured framework but can be constrained by model assumptions or sensitivity to training data contamination [21,27].​  

Deep Learning-based methods leverage the power of neural networks to automatically extract complex features and model intricate patterns in data, particularly beneficial for high-dimensional and non-linear datasets [7,24]. Various architectures are employed, including Autoencoders that detect anomalies based on reconstruction errors [24], GANs that model the normal data distribution [24], One-Class Neural Networks that learn boundaries in feature space [28], and models like CNNs, RNNs, and Transformers tailored for specific data types like images or sequences [2,10,28]. Advanced techniques like knowledge distillation and weakly-supervised learning are also integrated to improve performance and address data limitations [10,12,14]. Deep learning methods excel at capturing complex dependencies but often require substantial data for training and careful hyperparameter tuning.​  

Each category offers distinct perspectives and tools for tackling the multifaceted challenge of anomaly detection. The selection of an appropriate method or combination of methods depends heavily on the specific data characteristics, the definition of an anomaly in the given context, computational resources, and the availability of labeled data.  

# 4.1 Statistical Methods  

Statistical methods for anomaly detection are predicated on the assumption that normal data conforms to a specific statistical distribution, while outliers deviate significantly from this assumed model [26,31]. These methods typically involve estimating parameters of the distribution from the data and identifying instances with low probability or significant deviation from the estimated model as anomalies [24,26].  

Several fundamental statistical techniques are employed for univariate anomaly detection. The 3-sigma rule is a widely used parametric method that assumes data follows a normal distribution. It identifies data points as anomalies if they fall outside the range defined by three standard deviations from the mean [4,15,16]. The lower and upper bounds for normal data are calculated as  

$$
{ \mathrm { l o w e r } } = \mu - 3 \sigma
$$  

and  

$$
{ \mathrm { u p p e r } } = \mu + 3 \sigma ,
$$  

where $\mu$ is the mean and $\sigma$ is the standard deviation [3,4,15,16].  

Closely related is the Z-score method, which quantifies the distance of a data point from the mean in terms of standard deviations. The Z-score for a data point $s$ is calculated as  

$$
z _ { \mathrm { s c o r e } } = { \frac { s - \mu } { \sigma } } ,
$$  

with a Z-score threshold of 3 being equivalent to the 3-sigma rule. These methods are computationally simple and effective for univariate data that is genuinely normally distributed [4,15]. However, their performance degrades significantly when the normality assumption is violated, making them sensitive to deviations from unimodal or Gaussian distributions.  

In contrast, the Boxplot method offers a non-parametric approach to univariate outlier detection, relying on the interquartile range (IQR) rather than distributional assumptions [8]. Outliers are identified as points falling below  

$$
Q 1 - 1 . 5 \cdot I Q R
$$  

or above  

$$
Q 3 + 1 . 5 \cdot I Q R ,
$$  

where $Q 1$ and $Q 3$ are the first and third quartiles, respectively, and  

$$
I Q R = Q { \bf 3 } - Q { \bf 1 } .
$$  

This method is more robust to skewed distributions compared to the Z-score or 3-sigma methods.  

Grubbs' test is another statistical hypothesis testing method specifically designed to detect a single outlier in a univariate dataset assumed to be normally distributed. It calculates a test statistic based on the maximum or minimum deviation from the mean and compares it to a critical value determined by the sample size and desired significance level. If the test statistic exceeds the critical value, the most extreme point is deemed an outlier. A key limitation of Grubbs' test is its "one-by-one" nature; it only tests for a single outlier at a time and requires iterative application to detect multiple outliers, which can increase computational cost for larger datasets. Furthermore, it is restricted to single-dimensional data and does not provide a precise interval for normal values.​  

For multivariate data, statistical methods extend to consider dependencies between dimensions. The multivariate Gaussian distribution assumes that data points are generated from a multivariate normal distribution. The mean vector and covariance matrix are estimated from the data. For an $n$ -dimensional dataset with ​m samples, the mean vector is given by  

$$
\mu = \frac { 1 } { m } \sum _ { i = 1 } ^ { m } x _ { i } ,
$$  

and the covariance matrix is  

$$
\Sigma = \frac { 1 } { m - 1 } \sum _ { i = 1 } ^ { m } ( x _ { i } - \mu ) ( x _ { i } - \mu ) ^ { T } .
$$  

The probability density function for a data point $x$ is given by  

$$
p ( x ) = { \frac { 1 } { ( 2 \pi ) ^ { n / 2 } | \Sigma | ^ { 1 / 2 } } } \exp \left( - { \frac { 1 } { 2 } } ( x - \mu ) ^ { T } \Sigma ^ { - 1 } ( x - \mu ) \right) .
$$  

Points with probability $p ( x ) < \epsilon$ , where $\epsilon$ is a predefined threshold, are considered anomalies. A simpler variant for multivariate data calculates the anomaly score based on independent Gaussian distributions for each dimension:  

$$
p ( x ) = \prod _ { j = 1 } ^ { n } \frac { 1 } { \sqrt { 2 \pi \sigma _ { j } ^ { 2 } } } \exp \left( - \frac { ( x _ { j } - \mu _ { j } ) ^ { 2 } } { 2 \sigma _ { j } ^ { 2 } } \right) .
$$  

Robust statistical methods, such as those implemented in scikit-learn's EllipticEnvelope, address the sensitivity of standard methods to outliers in the parameter estimation phase. EllipticEnvelope assumes that the regular data follows a Gaussian distribution and fits an ellipse to the central data points while being robust to outliers. It employs robust covariance estimation, such as the Minimum Covariance Determinant (MCD). MCD seeks a subset of data points whose covariance matrix has the lowest determinant. The degree of abnormality is then measured using the Mahalanobis distance, computed based on these robust estimates of location and covariance. MCD performs best with elliptically symmetric unimodal distributions. Its performance diminishes with decreasing unimodality and increasing data size, and it is not recommended for multi-modal data.  

Principal Component Analysis (PCA) is utilized in anomaly detection primarily for dimensionality reduction and identifying deviations from the principal components. PCA transforms data into a new coordinate system where dimensions (principal components) are uncorrelated and capture the maximum variance. Anomalies can be detected based on their large reconstruction error after projecting onto the subspace spanned by the leading principal components or by their large scores on the minor principal components that capture noise and anomalies rather than normal variance. While useful for reducing dimensionality and revealing linear correlations, PCA may struggle with non-linear data structures. Some research indicates that unsupervised deep anomaly detection (DAD) techniques can outperform traditional PCA methods.​  

In summary, statistical methods offer a range of approaches for anomaly detection, from simple univariate tests like the Zscore and Boxplot methods to more complex multivariate and robust techniques like EllipticEnvelope with MCD. Their primary advantage lies in their interpretability and relatively low computational complexity for simple cases. However, they are often constrained by strict assumptions about data distribution, particularly normality and unimodality, and can be sensitive to violations of these assumptions. Robust methods like MCD aim to mitigate the impact of outliers on parameter estimation but still perform optimally under specific distributional shapes. Scalability can become an issue for methods requiring operations like matrix inversion (e.g., in the multivariate Gaussian or MCD) in high-dimensional space. Applicability varies significantly; univariate methods are limited to single features, while multivariate methods are necessary for detecting anomalies based on feature interactions. Non-parametric methods like the Boxplot offer greater flexibility regarding distribution assumptions but are generally limited to univariate data.​  

# 4.2 Distance-Based Methods  

Distance-based methods constitute a fundamental class of techniques for identifying anomalies, predicated on the principle that anomalous data points are situated far from the bulk of the data or their nearest neighbors [15,16,29,31]. These methods typically quantify the dissimilarity between data instances using various distance metrics [6].  

<html><body><table><tr><td>Method</td><td>Anomaly Score Basis</td><td>Key Parameter</td><td>Strengths</td><td>Weaknesses</td></tr><tr><td>KNN</td><td>Average distance to k- nearest neighbors</td><td>k</td><td>Non-parametric.</td><td>High computational cost on large datasets, susceptible to curse of dimensionality, primarily global outliers.</td></tr><tr><td>k-th Nearest Neighbor</td><td>Distance to the k-th nearest neighbor</td><td>k</td><td>Simple, conceptually intuitive.</td><td>High computational cost, susceptible to</td></tr></table></body></html>  

<html><body><table><tr><td></td><td></td><td></td><td>outliers.</td><td>curse of dimensionality, primarily global</td></tr></table></body></html>  

Two prominent algorithms within this category are the K-Nearest Neighbors (KNN) and K-th Nearest Neighbor (k-th NN) methods [29]. In KNN-based anomaly detection, the anomaly score for a data point is often computed as the average distance to its k nearest neighbors [4,15,16]. If this average distance surpasses a predefined threshold, the data point is classified as an outlier [4,15,16]. In contrast, the k-th NN algorithm defines the anomaly score of an instance as its distance to its k-th nearest neighbor [29]. The choice of the parameter $" k "$ is critical in both methods, influencing the neighborhood size considered and, consequently, the resulting anomaly scores [15,29]. A commonly used distance metric in these methods is the Euclidean distance [29]. Another relevant distance metric is the Mahalanobis Distance [18], which is advantageous over Euclidean distance when dealing with correlated data as it accounts for the covariance structure of the data.​  

Distance-based methods possess notable strengths, such as not requiring assumptions about the underlying data distribution. However, they also exhibit significant weaknesses. A primary limitation is their substantial computational cost, particularly when applied to large datasets, due to the necessity of calculating pairwise distances between data points. Furthermore, these methods are susceptible to the curse of dimensionality [6,29]. Common similarity measures like Euclidean distance often become less effective or fail entirely in high-dimensional spaces [6]. Another drawback is that KNNbased methods primarily tend to identify global outliers, potentially failing to detect local anomalies that are outliers relative to their immediate, potentially dense, neighborhood but not necessarily far from the entire dataset [4,15,16].  

Studies have compared the performance of various anomaly detection algorithms, including distance-based ones, on different datasets, such as 2D simulation datasets [27]. While the digest content does not detail these comparisons for distance-based methods specifically on multi-modal datasets or provide experimental results, such comparisons are essential for understanding algorithm efficacy across diverse data structures. To mitigate the computational burden, strategies for improving efficiency, such as employing approximate nearest neighbor search techniques, can be considered, although specific details on such strategies are not elaborated in the provided digests.​  

# 4.3 Density-Based Methods  

Density-based methods for anomaly detection identify outliers as data points situated in regions of significantly lower density compared to their surroundings [4,15,16,31]. This approach is particularly effective in datasets where anomalies are not merely far from the global mean but reside in sparsely populated areas within clusters or between clusters.  

<html><body><table><tr><td>Method</td><td>Anomaly Score Basis</td><td>How it Measures Density</td><td>Addresses Limitations of...</td><td>Characteristic</td></tr><tr><td></td><td>neighbor's LRD to own LRD (Local Outlier Factor)</td><td>Reachability Density (LRD)</td><td></td><td>multimodal data with varying</td></tr><tr><td>COF</td><td>Based on chain- based distance</td><td>Connectivity within neighborhood</td><td>LOF in sparse regions</td><td>Better handles outliers in sparse data.</td></tr><tr><td></td><td>affinity to other points</td><td>Global affinity/binding probability</td><td>Local density instability</td><td>Evaluates outlierness based on global association.</td></tr></table></body></html>  

A prominent algorithm in this category is the Local Outlier Factor (LOF) [8,9,15]. LOF quantifies the degree of outlierness for each data point by measuring its local density deviation relative to its neighbors [1,5,16,20]. Points with a substantially lower local density than their neighbors are flagged as potential anomalies [1,5,20]. The LOF algorithm operates by first determining the ${ \sf k }$ -distance of a point $p$ , which is the distance to its ${ \sf k }$ -th nearest neighbor. Based on this, the k-distance neighborhood $N _ { k } ( p )$ is defined, containing all points within $\boldsymbol { p } ^ { \prime } \ s \boldsymbol { \mathsf { k } }$ -distance [20]. The reachability distance between point $p$ and point $o$ is calculated as the maximum of the $k$ -distance of $o$ and the actual distance between $p$ and $\mathbf { \xi } _ { o }$ :​  

​reach-dista $\mathrm { n c e } _ { k } ( p , o ) = \operatorname* { m a x } \left( d _ { k } ( o ) , d ( p , o ) \right)$  

where $d _ { k } ( o )$ is the $k$ -distance of point $\mathbf { \chi } _ { o }$ , and $d ( p , o )$ is the Euclidean distance between $p$ and $o$ [15,16,20]. The local reachability density (LRD) of point $p$ is then defined as the inverse of the average reachability distance of $p$ to its neighbors in $N _ { k } ( p )$ :​  

$$
l r d _ { k } ( p ) = \frac { 1 } { \frac { 1 } { | N _ { k } ( p ) | } \sum _ { o \in N _ { k } ( p ) } { \mathrm { r e a c h } } \mathrm { - d i s t a n c e } _ { k } ( p , o ) }
$$  

The LOF score for point $P$ is computed as the ratio of the average local reachability density of its $k$ -nearest neighbors to its own local reachability density [1,4,5]:​  

For normal points within a dense cluster, the LOF score is expected to be close to 1. Anomalies in sparse regions exhibit a significantly lower local density than their neighbors, resulting in a higher LOF score [5]. LOF demonstrates strong performance on multimodal datasets with varying densities due to its focus on local comparisons [21,27].  

While LOF is effective, it faces challenges in extremely low-density regions where the concept of local density becomes less stable. The Connectivity-Based Outlier Factor (COF) was developed as a variant to address these limitations, particularly for outliers in sparse data [4,15,16]. Instead of relying solely on reachability distance, COF considers the connectivity among a point and its neighbors by utilizing chain-based distances [4,15,16]. This involves computing the minimum spanning tree of the point and its neighbors and determining a Set Based Nearest Path, from which the chain distance is derived [15]. The COF score incorporates this chain distance, offering a different perspective on density in sparse areas [15].​  

Distinct from LOF and COF, Stochastic Outlier Selection (SOS) assigns an anomaly probability to each data point based on its affinity to all other points in the dataset [4,15,16]. The fundamental premise of SOS is that an outlier exhibits a very low association or "binding probability" with the majority of other points [15,16]. The algorithm typically involves computing a dissimilarity matrix and an association matrix to derive an outlier probability vector [15]. Unlike LOF and COF which focus on local neighborhood density relative to neighbors, SOS evaluates outlierness based on a point’s affinity within the global data distribution.  

Comparing these methods, LOF is a foundational algorithm quantifying local density deviation. COF refines the density estimation for sparse environments by incorporating connectivity. SOS takes a different approach entirely, using a probabilistic model based on global affinity rather than local density comparisons. While LOF and COF require the parameter $k$ (number of neighbors), SOS’s behavior is influenced by how affinity is defined and computed. A key advantage of LOF and COF is their ability to detect local anomalies and effectively handle datasets with varying densities [21,27].​  

# 4.4 Clustering-Based Methods  

Clustering algorithms offer a prominent approach to anomaly detection by leveraging the inherent structure of data. The fundamental assumption underlying these methods is that normal data instances tend to aggregate into clusters, while anomalies represent points that deviate significantly from these clusters [3,24]. Outliers can be identified based on several criteria: they may not belong to any defined cluster, be located far from cluster centers, or constitute very small clusters [3,31].​  

Various clustering algorithms are adapted for this task, including K-means, Gaussian Mixture Model (GMM), and DBSCAN [3,8,24]. Other methods like Self-organizing maps (SOMs), ROCK, and SNN clustering are also utilized [3,24].  

Density-Based Spatial Clustering of Applications with Noise (DBSCAN) is particularly well-suited for identifying anomalies as "noise points" [4,15,16,17,31]. DBSCAN operates by grouping densely packed points, classifying points into core points (having at least MinPts objects within radius Eps), border points (within Eps of a core point but not core themselves), and  

noise points (neither core nor border) [17,31]. Anomalies are precisely these noise points—isolated data points located in low-density regions that do not belong to any cluster [4,15,16]. A key advantage of DBSCAN is its ability to discover clusters of arbitrary shape, unlike partition-based methods like K-means [15,16]. However, DBSCAN's performance is highly dependent on the appropriate selection of its core parameters: the neighborhood radius (Eps) and the minimum number of points required to form a dense region (MinPts) [15,16]. Sensitivity to these parameters represents a significant weakness, as their optimal values are often non-trivial to determine without prior knowledge.  

In contrast to density-based methods, distance-based clustering algorithms like K-means and GMM identify anomalies based on their distance from cluster centroids [3,24]. Normal data instances are expected to be close to their respective cluster centroids, while outliers are typically situated far from the centroid of their nearest cluster [3,24]. Anomaly scoring is often based on this distance [24]. GMM, being a probabilistic model, is sometimes considered a more advanced alternative to K-means for modeling cluster distributions [8].  

The performance of clustering-based anomaly detection methods is also intrinsically linked to the choice of distance metric used, particularly in algorithms that rely on distance or density calculations like K-means and DBSCAN. The metric defines how similarity or proximity between data points is measured, directly influencing the formation of clusters and the identification of points as outliers or noise.​  

# 4.5 Tree-Based Methods  

Tree-based methods represent a distinct approach to anomaly detection, with Isolation Forest (iForest) being a prominent example. Unlike traditional methods that model normal data distributions, iForest focuses on directly isolating anomalies [19,20].  

The core principle is that anomalies are data points that are "easily isolated" or separate from the majority of the data, typically residing in sparse regions away from dense clusters [19,20].  

iForest achieves this isolation by constructing an ensemble of isolation trees (iTrees) [19]. Each iTree is built by recursively partitioning the data space. At each step of the partitioning process, a feature is randomly selected, and then a split value is randomly chosen between the minimum and maximum values of the selected feature within the current data subset [1,5,19,22]. This random partitioning continues until a data point is isolated or a maximum depth is reached.  

The number of partitions required to isolate a specific data point corresponds to its path length from the root node to the terminating node in the iTree [1,5,19,22]. Anomalies, being easier to isolate, generally have significantly shorter path lengths compared to normal instances, which are deeply embedded within dense clusters and require more partitions to be separated [1,5,9,15,16,19].  

To obtain a robust measure of anomaly, iForest averages the path lengths of a sample across the ensemble of isolation trees [5,15,19]. This average path length serves as the basis for calculating an anomaly score [9,22]. The anomaly score $s ( x , n ) = 2 ^ { - { \frac { E ( h ( x ) ) } { c ( n ) } } }$  

for a sample $x$ in a dataset of size $n$ is typically calculated using the formula above, where $h ( x )$ is the path length for sample $x$ in an iTree, $E ( h ( x ) )$ is the average path length of $x$ over all trees in the forest, and $c ( n )$ is the average path length of an unsuccessful search in a Binary Search Tree used to normalize $h ( x )$ [4,15,16,22]. A path length of $c ( n )$ represents the average path length, so samples with shorter paths than average receive scores greater than 0.5 [22]. An anomaly score close to 1 indicates a strong anomaly, while a score close to 0 indicates a normal point [22].  

iForest possesses several advantages. It is particularly suitable for continuous numerical data [19,20]. The algorithm is noted for its efficiency, exhibiting low computational complexity and linear time complexity [16,19]. Its ability to handle highdimensional data is also highlighted [16,19]. Furthermore, iForest has demonstrated good performance on multimodal datasets [21,27]. Some evaluations suggest iForest performs well, even compared to methods like K-means [8]. An extension known as Extended Isolation Forest (EIF) has also been proposed as an upgrade [8].  

Key parameters influencing iForest performance include the parameter n_estimators (the number of isolation trees in the forest) and max_samples (the number of samples used to train each tree, denoted as $\psi$ in some contexts) [5,9]. The maximum depth of each tree is typically limited, often set to $\log _ { 2 } ( N )$ , where $N$ is the number of samples used to build the tree [1,5]. The ensemble approach with a sufficient number of trees (n_estimators) helps to average out the randomness inherent in the splitting process, leading to more stable and reliable anomaly scores [19]. The subsampling size (max_samples) impacts the structure and diversity of individual trees. The scikit-learn implementation of iForest also  

supports warm_start=True, allowing the addition of more trees to an already trained model [5]. While these sources mention the parameters and the formula structure, a detailed analysis of their quantitative impact on performance metrics like accuracy or computational cost is not extensively provided.  

# 4.6 Ensemble Methods  

Ensemble methods represent a powerful paradigm in anomaly detection, aiming to combine the outputs of multiple individual models to achieve improved accuracy, robustness, and generalization capabilities compared to single-model approaches [5,9]. The inherent complexity of anomaly detection tasks, particularly in high-dimensional data spaces, often necessitates the integration of multiple models, as a single model may fail to capture the diverse patterns of anomalies [6]. Ensemble learning leverages the principle that aggregating predictions from diverse models can mitigate the weaknesses of individual components and enhance the overall detection performance. For unsupervised anomaly detection, parallel ensemble strategies such as averaging and bagging are commonly employed, contrasting with sequential methods like boosting often seen in supervised contexts [6].​  

A prominent example of an ensemble technique widely applied in anomaly detection is the Isolation Forest (iForest) [1,4,5,8,9,17,19,20,22,25,27]. Isolation Forest is a tree-based ensemble method, typically built upon an ensemble of tree.ExtraTreeRegressor or random trees [1,5]. It operates on the principle that anomalies are few and different, making them easier to isolate in a tree structure than normal instances. The anomaly score is derived from the average path length required to isolate an instance across the forest [1]. This method is recognized for its linear time complexity and high precision [19].​  

Beyond Isolation Forest, other ensemble strategies have been explored. In the domain of deep learning, ensemble learning has been applied to models like autoencoders, which can be sensitive to noise and require substantial training data [28]. Ensembles of autoencoders, particularly those with randomly altered connection structures, have demonstrated improved performance and reduced overfitting, alongside decreased training time [28]. Autoencoder ensembles comprising various randomly connected models have shown promising results on benchmark datasets [28].  

Another powerful ensemble approach gaining traction is stacking, which involves training a meta-learner to combine the predictions of multiple base models.  

A novel stacking ensemble model proposed for real-time anomaly detection exemplifies this strategy [11]. This model integrates diverse base models, specifically Random Forest and Artificial Neural Networks (ANN), and uses XGBoost as the meta-learner [11]. The core principle of this stacking approach is to strategically combine the strengths of each individual base model. The predictions of the base models serve as input features for the meta-learner, which then makes the final anomaly decision. This hierarchical integration aims to optimize the overall anomaly detection performance and enhance robustness by leveraging different modeling paradigms [11]. The successful application of stacking with models like XGBoost, Random Forest, and ANN highlights its potential for improving detection accuracy in complex scenarios [11].  

# 4.7 Model-Based Methods  

Model-based anomaly detection methods operate under the assumption that normal data conforms to a specific underlying statistical distribution or generative model. Deviations from this learned model are then indicative of anomalous instances. These techniques aim to explicitly characterize the pattern of regular data, identifying points that do not fit this established profile as outliers or novelties.​  

covariance.EllipticEnvelopecovariance.EllipticEnvelopecovariance.EllipticEnvelopecovariance .EllipticEnvelope e\` in libraries like scikit-learn [1,5,9,27]. This method posits that the inlying data follows a Gaussian distribution [1,5,9,17,21,27]. It proceeds by estimating the location (mean) and covariance matrix of the assumed Gaussian distribution [1,17]. To mitigate the influence of potential outliers on these estimates, the method employs robust estimation techniques [1,17]. Anomalous data points are then identified based on their Mahalanobis distance from the estimated distribution center; points with a large Mahalanobis distance are considered outliers [1,17]. A key strength of Elliptic Envelope lies in its clear statistical foundation when the Gaussian assumption holds. However, its primary limitation is the strict requirement for the data to be Gaussian [5,9,27]. While robust estimation helps, significant deviations from Gaussianity can lead to suboptimal performance. The method is often described as robust to outliers due to its use of robust covariance estimation [27].​  

<html><body><table><tr><td>svm.OneClassSvMsvm.0neClasssvMsvm.0neClassvMsvm.0neClassSVMsvm.0neClasssvMsvm.0neClassSVMs</td></tr><tr><td>vm.0neClassSvMsvm.0neClassSvMsvm.0neClassSVMsvm.0neClassSVM [1,5]. One-Class SVM is an</td></tr><tr><td>unsupervised algorithm trained exclusively on normal samples [20]. Its objective is to</td></tr><tr><td>learn a decision boundary or hyperplane that encloses the majority of the normal data</td></tr><tr><td></td></tr><tr><td>points in the feature space [4,15,16,20,24]. Data points falling outside this learned</td></tr><tr><td>boundary are flagged as anomalies [15,16,20]. The method can also be conceptualized as</td></tr><tr><td>Support Vector Domain Description (SvDD)，aiming to minimize the volume of ahypersphere</td></tr><tr><td>enclosing the data [4,16]. A crucial aspect of One-Class SVM is the selection of a kernel</td></tr><tr><td>function to define the decision boundary， with the Radial Basis Function (RBF) kernel being</td></tr><tr><td>a common choice [1,5]. The bandwidth parameter (gammagamma) for the RBF kernel often</td></tr><tr><td>requires empirical tuning or cross-validation [5]. The scalar parameter $\nu$ (nu) is also</td></tr><tr><td>critical， as it controls the width of the boundary and can be interpreted as an upper bound</td></tr><tr><td>on the fraction of training errors and a lower bound on the fraction of support vectors</td></tr><tr><td>[1,5,9,17]. One-Class SVM is particularly popular for novelty detection tasks, where the</td></tr><tr><td>training data is assumed to be free of outliers [1,5,21,27]. However， when applied to</td></tr><tr><td>outlier detection scenarios with potentially contaminated training data， it can be</td></tr><tr><td>sensitive to outliers and requires careful hyperparameter tuning to avoid overfitting</td></tr><tr><td>[9,21,27]. Despite this, it can be effective in high-dimensional spaces or when specific</td></tr><tr><td>data distribution assumptions are not met， provided hyperparameters are set appropriately</td></tr><tr><td>[21]. For larger datasets， online variants like linear_model.SGD0neClassSVMM`,which</td></tr><tr><td>approximatethe kernelizedversionwithlinearcomplexity,havebeen introduced[5].Furthermore,One-ClassSVMconcepts have been integrated withdeeplearning,suchasin Deep Mixture Models (DHM)using autoencodersforfeature extraction,</td></tr></table></body></html>  

Comparing Elliptic Envelope and One-Class SVM reveals distinct characteristics. Elliptic Envelope relies fundamentally on the assumption of a Gaussian distribution for normal data [5,9,27], whereas One-Class SVM learns a boundary based on the data structure itself, potentially offering more flexibility for non-Gaussian data [21]. In terms of performance and suitability, digests indicate that One-Class SVM is highly sensitive to outliers in the training data when used for outlier detection [9,21,27], making it more suited for novelty detection where the training set is clean [1,5,21,27]. Elliptic Envelope, with its robust estimation, is designed to be less affected by outliers [1,27]. Complexity wise, the standard One-Class SVM's kernel methods can be computationally intensive, although linear approximations exist [5]. Elliptic Envelope involves covariance estimation, which can also have computational considerations depending on the dimensionality and dataset size. The choice between these methods often depends on the underlying data distribution and whether the task is novelty detection (clean training data) or outlier detection (potentially contaminated training data) [9].​  

# 4.8 Deep Learning-Based Methods  

Deep learning methodologies have gained significant prominence in the field of anomaly detection, offering distinct advantages over traditional approaches, particularly when confronting complex data patterns and high-dimensional datasets [7,24,28]. Unlike many traditional methods that may struggle with the inherent complexity and non-linearity of modern data, deep learning models possess the capability to automatically extract hierarchical features and learn intricate, non-linear relationships within the data [24,28]. This capacity facilitates the effective handling of multivariate and highdimensional data, enabling the seamless integration of information from diverse sources and mitigating the challenges associated with individual variable modeling and subsequent result aggregation [24]. Furthermore, deep learning approaches are well-suited to jointly model interactions among multiple variables, learning the distribution of normal input data and deriving a measure of anomaly from this learned representation [24]. While hyperparameter tuning is still necessary, deep learning models often require less task-specific engineering compared to some traditional techniques [24].  

![](images/02a574c70d175cee685135c443bb735975fd15ce3c39d4f150a1d99b2587ad5f.jpg)  

Deep learning-based anomaly detection methods can be broadly classified based on the underlying neural network architectures employed [8,28]. These architectures are designed to capture different types of data structures and dependencies, making them suitable for various anomaly detection tasks and data types, including sequential and nonsequential data [7,28]. The primary architectural categories explored in this survey include Autoencoder-Based Methods, which leverage reconstruction error to identify anomalies [3,24]; GAN-Based Methods, which model the data distribution to distinguish anomalies [7,24]; One-Class Neural Networks (OC-NN), which learn a boundary around normal data in a learned feature space [7,28]; CNN-Based Methods, particularly effective for spatial and spatio-temporal data [2,28]; RNN-Based Methods, well-suited for sequential and time series data due to their ability to model temporal dependencies [7,28]; and Transformer-Based Methods, which excel at capturing complex global dependencies [10]. Beyond these core architectures, specific training paradigms like Knowledge Distillation and Weakly-Supervised methods further adapt these networks for scenarios with limited labeled data, enhancing their applicability in real-world settings [10,12,14].  

# 4.8.1 Autoencoder-Based Methods  

Autoencoders (AEs) represent a fundamental approach within deep learning-based unsupervised anomaly detection, operating under the premise that normal data instances occur with higher frequency than anomalies [28]. This differential frequency is leveraged by training the autoencoder to effectively learn and reconstruct the patterns inherent in normal data [3,4,7,15,16,24,28]. Consequently, when presented with normal data, a well-trained autoencoder is expected to produce a high-fidelity reconstruction with minimal error [3,16,24]. Conversely, anomalies that deviate significantly from the learned normal patterns are poorly reconstructed, resulting in substantially larger reconstruction errors [3,4,15,16,24].  

![](images/4cee2baabb3e027446342ce49b3dce35babd544d759b627c14766d54e1126a44.jpg)  

This difference in reconstruction performance forms the basis for anomaly detection [7,8].  

An autoencoder is fundamentally composed of two interconnected neural networks: an encoder and a decoder [24]. The encoder maps the input data to a lower-dimensional latent representation, often referred to as the bottleneck [24]. This lowdimensional representation captures the most salient features of the input data necessary for its reconstruction [24]. The decoder then takes this latent representation and attempts to reconstruct the original input data [24]. The training objective for autoencoders in this context is to minimize the reconstruction error, which is the discrepancy between the original input and the output produced by the decoder [15,24]. Common metrics for quantifying the reconstruction error include the mean squared error (MSE) [24].  

The reconstruction error serves directly as the anomaly score [14,16,24]. Higher reconstruction errors correspond to higher anomaly scores, indicating that the data point deviates significantly from the normal patterns the autoencoder was trained on [24]. Anomaly detection is then performed by comparing this anomaly score to a predefined threshold [24]. Data points with a reconstruction error exceeding this threshold are flagged as anomalies [24]. The choice of threshold is critical and is typically determined based on the distribution of reconstruction errors on the training or validation data, often employing statistical or percentile-based approaches; however, the specific methods for setting thresholds require careful consideration [28].​  

Various architectural variants of autoencoders have been explored to enhance their ability to capture complex data distributions and improve anomaly detection performance across different data types [28]. These include Deep Autoencoders, which utilize multiple layers in both the encoder and decoder; Denoising Autoencoders, which are trained to reconstruct the input from a corrupted version; Variational Autoencoders (VAEs), which learn a probabilistic mapping to the latent space; and other models such as Restricted Boltzmann Machines (RBMs), Deep Boltzmann Machines (DBMs), and Deep Belief Networks (DBNs) used in autoencoder-like structures [28]. For data with specific structures, such as images or sequences, specialized autoencoder variants like Convolutional Autoencoders (CAEs) for spatial data and LSTM Autoencoders for sequential data have proven effective [28]. For instance, combining a Convolutional Neural Network (CNN) encoder with a multilayer LSTM decoder has shown promise in reconstructing complex input data such as images, thereby enhancing anomaly detection [28]. The choice of variant and the specific loss function depends heavily on the characteristics of the data and the nature of the anomalies being detected [17]. Although autoencoders are often discussed in the context of unsupervised learning, training them effectively typically requires access to a dataset composed primarily or entirely of normal instances, thereby leaning towards a semi-supervised paradigm in practice [8,24].  

# 4.8.2 GAN-Based Methods  

Generative Adversarial Networks (GANs) are widely utilized in anomaly detection due to their capability to learn a generative model of the input data distribution [24]. A classic GAN comprises a generator (G) and a discriminator (D), trained jointly. The generator learns to map a latent noise vector to data samples resembling the training distribution, while the discriminator learns to distinguish real data from generated samples [24]. For anomaly detection, GANs are typically trained exclusively on normal data samples. This process enables the generator to model the intricate distribution of normal behavior and the discriminator to become adept at identifying deviations from this learned distribution [7,24].  

Anomaly detection using GANs hinges on the principle that anomalous data points will deviate significantly from the distribution learned from normal data [7,28]. Specifically, anomalies are identified based on two primary mechanisms: the generator's inability to accurately reproduce the anomalous input or the discriminator flagging the input as abnormal [7,28]. Architectures like AnoGAN and GANomaly are prominent examples in this domain [17,24].​  

In models incorporating an encoder (e.g., BiGAN-based approaches like GANomaly), a test sample $X$ is first encoded into a latent representation $Z$ . The generator then attempts to reconstruct the sample, yielding $\hat { X }$ , from $Z$ . For normal data, $\hat { X }$ should be a faithful reconstruction of $X$ . However, for anomalous data, the generator—trained only on normal patterns— struggles to produce an accurate reconstruction, resulting in a high reconstruction error (e.g., measured by the difference between $X$ and $\hat { X }$ ) [24]. Concurrently, the discriminator assesses both the input sample $X$ and its reconstruction $\hat { X }$ . Anomalies are likely to be flagged by the discriminator, either directly or through discrepancies in intermediate feature representations compared to normal samples [24].  

An anomaly score is typically computed by combining the reconstruction error and the discriminator's response or difference in internal feature representations [17,24]. A higher score indicates a greater likelihood of the sample being anomalous.  

GAN-based methods offer significant advantages in anomaly detection. They are particularly effective at handling highdimensional data and modeling complex, non-linear data distributions, which is a challenge for many traditional techniques [7]. Furthermore, research indicates that GANs trained in a semi-supervised setting demonstrate promising performance, even when labeled data is scarce [28].  

# 4.8.3 One-Class Neural Networks  

One-Class Neural Networks (OC-NN) represent a category of deep learning models specifically designed for anomaly detection [7]. These models integrate the powerful feature extraction capabilities of deep neural networks with a one-class objective [28]. The fundamental principle involves learning a representation in a hidden feature space such that a "tight envelope" or boundary can be established around the normal data instances [7,28]. The data representation within the hidden layers is explicitly driven and customized by the one-class training objective to facilitate this separation [28]. Anomalies are subsequently identified as data points that fall outside this learned boundary or envelope in the feature space [7]. A notable variant, Deep Support Vector Data Description (D-SVDD), trains the neural network to map all normal data points towards the center of a learned hypersphere in the feature space, effectively defining the normal region as the interior of this sphere [28]. A key advantage of OC-NNs, as with many one-class methods, is their suitability for scenarios where labeled anomaly data is scarce or unavailable, relying primarily on the characteristics of the normal data distribution [7]. However, a notable limitation often cited is their sensitivity to hyperparameter choices, which can significantly impact the learned boundary and, consequently, the detection performance [7].​  

# 4.8.4 CNN-Based Methods  

Convolutional Neural Networks (CNNs) have emerged as a powerful technique for anomaly detection, particularly wellsuited for data exhibiting spatial and temporal correlations, such as time series, images, and video streams [2,23,28]. The core strength of CNNs lies in their ability to automatically extract hierarchical features from raw data through convolutional and pooling layers. These layers effectively capture local patterns and their spatial relationships, which is crucial for understanding the inherent structure of the data [28].  

In the context of anomaly detection, CNNs are typically employed to learn a representation of "normal" data patterns. Anomalies are then identified based on their deviation from these learned representations. For time series data, CNNs can be used within predictor modules to forecast future values based on historical windows. DeepAnT, for instance, utilizes CNNs for this purpose, leveraging their parameter sharing property to achieve good generalization even with limited datasets [2]. This forecasting approach allows for anomaly detection by comparing predicted values to actual observations; significant discrepancies indicate potential anomalies.  

Beyond direct prediction, CNNs can form components of more complex architectures designed for anomaly detection. Convolutional autoencoders, mentioned as specific CNN architectures, learn compressed representations of input data and reconstruct it [17]. Anomalies, being different from the training data used to build the normal model, are typically reconstructed poorly, leading to a high reconstruction error which serves as an anomaly score [17]. Hybrid models, such as those combining CNNs with Recurrent Neural Networks (RNNs), can capture both spatial and temporal dependencies effectively, making them suitable for complex spatio-temporal data like video or interconnected sensor networks [17]. In spatio-temporal networks (STN), local CNNs specifically model local spatial correlations, demonstrating their effectiveness in outlier detection within such structured data [28]. The application of CNNs to video sensor frames further illustrates their utility in extracting relevant features from visual data streams for anomaly detection [23]. By learning robust feature representations and modeling the expected patterns of normal data, CNNs enable the detection of deviations that signify anomalous instances across various data types.  

# 4.8.5 RNN-Based Methods  

Recurrent Neural Networks (RNNs) are particularly well-suited for handling sequential data, making them a natural choice for anomaly detection in time series [7,23]. Their ability to model temporal dependencies and capture correlations between consecutive data points is crucial for identifying patterns in sequences [17,23,28]. Specifically, variants like Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU) networks are frequently employed due to their effectiveness in learning long-range dependencies in time series data [17,23,28]. LSTMs, for instance, are used in spatio-temporal networks to model temporal features by capturing correlations between near time points [28].​  

RNN-based anomaly detection methods primarily operate by modeling the normal behavior of sequential data and identifying deviations from this learned model [3,24]. A common approach involves training the RNN, often configured as a sequence-to-sequence model, on a dataset of normal sequences [24]. Sequence-to-sequence models, traditionally composed of LSTMs, consist of an encoder that generates a hidden representation of the input sequence and a decoder that produces an output sequence based on this representation [24]. For anomaly detection, this structure can be adapted to function like an autoencoder, trained to reconstruct the input sequence or predict the next elements in the sequence [17,24].  

Anomalies are subsequently detected based on the discrepancy between the model's output (prediction or reconstruction) and the actual observed sequence [3,24]. The magnitude of the prediction or reconstruction error serves as the anomaly score [2,3,24,28]. For instance, the Mean Squared Error (MSE) between the predicted and actual values over a segment of the sequence can quantify this error [24]. A high error value indicates that the current sequence deviates significantly from the expected patterns learned from normal data, thus signaling a potential anomaly [3,24]. This principle of using prediction or reconstruction errors is central to how RNNs are applied for anomaly detection in time series, demonstrating their effectiveness in capturing temporal dependencies for this task [2,17,28].​  

# 4.8.6 Transformer-Based Methods  

The application of Transformer models has extended into the domain of anomaly detection, leveraging their powerful capability to model complex relationships within data [10]. Transformer‐based methods are employed for both unsupervised anomaly detection and localization tasks [10]. A key aspect of these models in this context is their ability to establish relationships between features, which can include multiresolution interactions, thereby enhancing the capacity to accurately fit the manifold of normal data [10]. This improved modeling of normalcy is crucial for distinguishing anomalous patterns. Various Transformer architectures have been adopted; for instance, the Vision Transformer (ViT) has been utilized as a backbone network in anomaly detection frameworks [12]. While Transformer models offer significant advantages in capturing dependencies and modeling data distributions, common challenges associated with their deployment—such as the substantial data requirements for effective training—are important considerations in their practical application, although these specific challenges are not detailed within the scope of the provided digests.  

# 4.8.7 Knowledge Distillation / Feature Distillation  

Knowledge distillation and feature distillation techniques have emerged as valuable strategies in anomaly detection, particularly when labeled data is scarce or for enhancing model performance [10,12].  

The core concept involves transferring knowledge or learned feature representations from a pre-trained teacher model to a student model. This process allows the student network to learn a better representation of normal data or capture nuances that improve anomaly detection capabilities, often with a simpler architecture or reduced data requirements.  

The transfer of knowledge typically leverages the insights gained by the teacher network, which may have been trained on a larger dataset or possess a more complex architecture. One approach employs an Anomaly Guided Network (AGN) as a pretrained teacher [10]. The AGN provides "tacit knowledge guidance" to a student network, such as a Transformer, enabling the student to learn the manifold of normal data more effectively [10]. This guidance helps the student network better distinguish between normal and anomalous patterns.​  

Another technique utilizes a feature-constrained distillation learning method [12]. In this framework, knowledge transfer is achieved by employing a central feature strategy. This strategy dynamically generates feature representation centers of normal samples using the teacher network, which are then used to guide the student network's learning process [12]. Furthermore, a Gram loss function can be incorporated to constrain the relationship between the coding layers of the student and teacher networks [12]. The Gram loss aims to minimize the difference in the feature representations of normal images between the two networks, thereby ensuring that the student network captures the essential characteristics of normal data learned by the teacher [12].  

These specific techniques demonstrate the utility of distillation in guiding student models to learn robust representations for anomaly detection by leveraging the knowledge embedded within more capable teacher networks.  

# 4.8.8 Weakly-Supervised Methods (e.g., with Autoencoders)  

Weakly-supervised anomaly detection presents a promising approach for scenarios where obtaining fully labeled datasets is challenging, particularly when labels for anomalous instances are scarce or difficult to acquire. This paradigm leverages limited or noisy labels to guide the learning process [14]. Autoencoders have emerged as a significant architecture within this domain, primarily utilizing their ability to learn compressed representations of normal data [14,17].  

The typical architecture for autoencoder-based weakly-supervised anomaly detection involves a feature encoder and an anomaly score generator [14,17]. The autoencoder, comprising an encoder and a decoder, learns to reconstruct input data. Various features derived from the autoencoder are then employed for anomaly detection [14,17]. These include the hidden representation learned by the encoder, the reconstruction residual vector (the difference between the original input and its reconstruction), and the reconstruction error (typically measured by the mean squared error or similar metrics) [14,17].  

Anomalous samples are expected to have higher reconstruction errors or distinct hidden representations compared to normal samples, as the model is primarily trained on data assumed to contain predominantly normal instances.  

The training process often involves a joint loss function designed to accommodate the weak supervision [14]. A representative loss function structure is given by:  

$$
L _ { e } = \sum _ { i } ( 1 - y _ { i } ) e _ { i } + \lambda y _ { i } \operatorname* { m a x } ( 0 , a _ { 0 } - e _ { i } )
$$  

In this function, $\mathsf { \backslash } ( \mathsf { y \_ i } )$ is the weak label for sample $\backslash ( \mathfrak { i } \backslash )$ , where $\lvert ( \boldsymbol { \mathsf { y } } _ { - } \boldsymbol { \mathsf { i } } = \boldsymbol { 0 } \backslash )$ typically indicates a normal sample and $\mathsf { \backslash } ( \mathsf { y \_ i = 1 } \mathsf { \backslash } )$ indicates a potentially anomalous sample (or a sample from a potentially anomalous class) [14]. $\mathsf { \backslash } ( \mathsf { e \_ i } )$ represents the reconstruction error for sample $\left. { \bf ( \dot { \omega } ) } \right.$ . The first term, \(\sum_{i} $( 1 - y _ { - } \{ 1 \} ) \ e _ { - } \{ 1 \} \backslash )$ , encourages the minimization of reconstruction error for samples labeled as normal, consistent with the standard autoencoder objective for reconstruction [14]. The second term, \(\lambda y_{i} $\mathsf { \backslash m a x } ( 0 , \mathsf { a \_ { 0 } } \{ 0 \} \cdot \mathsf { e \_ { \ell } } \{ \mathsf { i } \} ) \backslash )$ , incorporates the weak supervision for potentially anomalous samples. It penalizes low reconstruction errors $\displaystyle ( \backslash ( { \mathsf { e } } _ { - } { \mathsf { i } } < { \mathsf { a } } _ { - } 0 \backslash ) )$ for samples labeled as anomalous, pushing their reconstruction errors above a predefined threshold $\backslash ( \mathsf { a } _ { - } 0 \backslash )$ [14]. The hyperparameter \(\lambda\) balances the influence of the two terms [14]. The training may also involve stages like pre-training on unsupervised data followed by formal training with weak labels to further refine the model's anomaly detection capability [14]. While ablation studies are valuable for understanding the contribution of different components, specific results were not detailed in the provided digests [14].  

# 5. Supervised, Semi-Supervised, and Unsupervised Paradigms  

<html><body><table><tr><td>Paradigm</td><td>Labeled Data Availability</td><td>Data Composition Training</td><td></td><td>Common Methods (Examples)</td><td>Challenge</td></tr><tr><td>Supervised</td><td>Labels for both Normal & Anomalies</td><td>Mixed data with class labels.</td><td>Learn boundary between classes.</td><td>Classification algorithms (RF, ANN, XGBoost)</td><td>Class imbalance, scarcity of anomaly labels.</td></tr><tr><td>Semi- Supervised</td><td>Labels only for Normal class</td><td>Primarily normal data (assumed clean).</td><td>Identify deviations from normal model.</td><td>One-Class SVM, Autoencoder s.</td><td>data contaminati on (if present). Training</td></tr><tr><td>ed</td><td>No labels</td><td>Unlabeled data.</td><td>Identify inherent outliers based on data properties.</td><td>LOF, Isolation Forest, K- means, GMM, Unsupervise d Autoencoder</td><td>Lack of ground truth, noisy outputs, defining 'normal'.</td></tr></table></body></html>  

Anomaly detection techniques are broadly categorized into supervised, semi-supervised, and unsupervised paradigms based on the availability and utilization of labeled data [7,24,28,30]. This classification dictates the approach to model training and the data requirements for effective implementation.​  

Supervised anomaly detection necessitates a training dataset where instances are explicitly labeled as either normal or anomalous [30]. This allows the task to be framed as a binary or multi-class classification problem [24,28]. Algorithms traditionally used for classification, such as Random Forest, XGBoost, and Artificial Neural Networks (ANN), can be adapted for this paradigm by training on the labeled data to learn the boundaries between normal and anomalous classes [11,30]. While this approach can be effective when sufficient labeled data is available, a primary challenge is the inherent scarcity of labeled anomalous instances in real-world datasets [24,28]. The cost of acquiring and labeling anomalous data is often prohibitively high, and the significant class imbalance further complicates model training [6,28].  

Semi-supervised anomaly detection represents a compromise, leveraging datasets where labels are available for only one class, typically the normal class [30]. This setting is often referred to as novelty detection, where the goal is to identify instances that are novel compared to the distribution of known normal data [1,5]. This paradigm is widely adopted because normal data is considerably easier to obtain than anomalous data [7,24]. Techniques commonly employed in this category include modeling the distribution of the normal class and identifying instances that deviate significantly [30]. Deep learning approaches like autoencoders are frequently trained in a semi-supervised manner on data comprising solely of normal instances [7,28]. When trained this way, autoencoders learn to reconstruct normal data with low error; instances with high reconstruction error are then flagged as anomalies. Some perspectives even consider autoencoders trained on normal data as a form of supervised learning, as the training data is implicitly labeled as 'normal' [4,15,16]. Other methods like One-Class SVM can also be applied in a semi-supervised setting for novelty detection [5]. Weakly-supervised approaches, utilizing a small amount of labeled data, also fall under or are closely related to the semi-supervised paradigm [14].  

Unsupervised anomaly detection operates under the assumption that no labeled data is available for training [7,30]. These methods rely solely on the intrinsic properties of the data, such as density, distance, or statistical distributions, to distinguish outliers from normal instances [28,30]. This approach is particularly valuable in real-world scenarios like monitoring large streams of data from heterogeneous sensors where manual labeling is impractical and expensive [2,17]. Techniques such as One-Class SVM [4,15,16,20], Isolation Forest [8,19,20], Local Outlier Factor (LOF) [8,20], K-means [8], and GMM [8] are prominent unsupervised methods. Deep learning models like autoencoders are also extensively used in unsupervised settings, learning representations directly from unlabeled data [7,10]. While unsupervised methods alleviate the burden of labeling, they often make assumptions about the data distribution or the characteristics of anomalies [30]. Outlier detection is commonly synonymous with unsupervised anomaly detection [1,5,25].  

The choice among these paradigms is primarily governed by the availability of labeled data and the associated costs [17,30]. Given the prevalent data scarcity and cost of labeling anomalies, semi-supervised and unsupervised approaches are more generally adopted in practice [24,30]. While supervised methods can potentially achieve high accuracy with sufficient highquality labeled data, their applicability is limited. Unsupervised methods offer the most flexibility in terms of data requirements but may face challenges in achieving optimal performance without any guidance from labels [21]. Semisupervised methods strike a balance, utilizing readily available normal data to constrain the problem while requiring minimal or no anomalous labels. Evaluating performance in anomaly detection, especially in unsupervised settings or with severe class imbalance, requires careful consideration of metrics; accuracy or error rate may be misleading, and metrics like the F1 score, balancing precision and recall, are often more suitable [3]. The F1 score is defined as:​  

$F _ { 1 } = 2 \cdot \frac { P r e c i s i o n \cdot R e c a l l } { P r e c i s i o n + R e c a l l }$ where Precision is $\frac { T P } { T P + F P }$ and Recall is $\frac { T P } { T P + F N }$ [3].  

# 6. Novelty Detection vs. Outlier Detection  

A fundamental distinction exists between novelty detection and outlier detection, primarily concerning the characteristics assumed for the training dataset. In novelty detection, the underlying assumption is that the training data is "clean," meaning it contains no outliers or anomalies ([1,5,9]). The objective is to identify future observations that deviate significantly from the distribution learned from this clean data ([5]). Conversely, outlier detection assumes that the training data may contain contaminating outliers mixed within the normal observations ([1,5,9]). The goal is to separate the core of regular observations from these existing contaminating data points ([1]).  

This core difference in training data assumptions directly influences the algorithmic approaches employed for each task. Novelty detection typically involves learning a model that tightly represents the distribution of the normal, clean training data ([1,5]). This model defines an approximate boundary around the initial observation distribution in a potentially highdimensional space ([1,5]). Subsequent observations falling outside this learned boundary are then classified as anomalies or novelties ([1,5]). Algorithms specifically designed for this setting include One-Class Support Vector Machines (OCSVMs), which were explicitly introduced for novelty detection or the detection of unfamiliar samples ([24]). OCSVM is considered well-suited for novelty detection when the training data is not contaminated with outliers ([20,21,27]).  

Outlier detection, on the other hand, must handle the presence of anomalies within the training data itself. Algorithms for outlier detection are designed to robustly identify points that lie far from the majority of the data, even when some anomalies are present during training ([1]). Commonly used algorithms for outlier detection, as opposed to strict novelty detection with clean data, include Local Outlier Factor (LOF) and Isolation Forest (iForest) ([20]). While iForest can also be used to detect new samples as outliers ([19]), its application often falls under the broader umbrella of anomaly or outlier detection where training contamination is expected.​  

Further differentiating the two, it is noted that in outlier detection, anomalies often do not form dense clusters, whereas in novelty detection, newly observed anomalies can potentially form dense clusters in regions of low density relative to the original training data distribution ([5]). It is also relevant that novel patterns, once detected, may sometimes be incorporated into the normal model ([30]). While novelty detection focuses on identifying data points that deviate from known categories, related concepts like out-of-distribution (OOD) detection distinguish between different target distributions in a multi-class scenario ([7]). It is acknowledged that novel data can represent either abnormal points or novel yet important normal variations, often distinguished via a scoring mechanism ([28]). Despite the conceptual differences, data used for anomaly detection can sometimes be utilized for novelty detection and vice versa ([28]). The fundamental distinction in training data cleanliness remains the key factor influencing the choice and performance characteristics of detection algorithms.​  

# 7. Online and Real-Time Anomaly Detection  

Online and real-time anomaly detection presents a distinct set of challenges compared to offline methods, primarily driven by the nature of streaming data and the need for immediate insights.  

<html><body><table><tr><td>Aspect</td><td>Challenges</td><td>Requirements /Approaches</td></tr><tr><td>Speed/Latency</td><td>Need for immediate processing.</td><td>Efficient algorithms, low computational cost.</td></tr><tr><td>Data Volume/Velocity</td><td>Handling large, high-speed data streams.</td><td>Scalable methods, streaming processing.</td></tr><tr><td>Concept Drift</td><td>Evolving data distributions and anomaly types.</td><td>Online model updates, adaptive methods.</td></tr><tr><td>Computational Constraints</td><td>Limited resources (e.g., edge devices).</td><td>Lightweight models, efficient computation.</td></tr><tr><td>Data Characteristics</td><td>Non-stationary, non-linear sensor data.</td><td>Methods tailored for streamingdata, specific data types.</td></tr></table></body></html>  

Key challenges include stringent requirements on processing speed, computational constraints, and low latency, which are critical for rapid decision-making in various domains [11,13,23,24]. Systems must process high data volume and velocity efficiently, as seen in applications like network intrusion detection systems that require real-time monitoring of suspicious traffic [28]. A significant issue in online anomaly detection is handling concept drift, which refers to the change in the underlying data distribution or the evolving nature of anomalies over time [6,28]. This necessitates methods capable of adapting to new patterns and evolving abnormal characteristics.  

Various approaches have been developed to address these challenges in streaming data environments. Some methods are specifically designed for on-line outlier detection, making them suitable for real-time applications and streaming data processing [13]. These techniques often focus on processing data sequentially as it arrives, maintaining computational efficiency. Adaptation to concept drift can involve techniques like online model updates or combining estimation with filtering approaches [13]. The ability to speedily retrain or update existing models as new data becomes available is crucial for maintaining detection accuracy in evolving environments [24]. Deep learning methods, such as DeepAnT, have also been applied to streaming time series data, demonstrating their applicability in online and real-time scenarios [2].  

The efficiency of anomaly detection during live data transmission is paramount. For instance, models designed for real-time anomaly detection in environments like Internet of Medical Things (IoMT) networks must operate efficiently under lowlatency constraints [11]. Stacking models have been proposed and shown to efficiently detect anomalies during live data streams in such contexts through real-time prediction analysis [11]. Real-time anomaly detection systems find applications across diverse sectors, including manufacturing, healthcare, shipping, and retailing, where timely identification of deviations is critical for system integrity and operational efficiency [23]. These systems typically process data originating from various sensors, though the specific types of sensor data handled can vary greatly depending on the application domain.​  

# 8. Evaluation Metrics and Performance Comparison  

The evaluation of anomaly detection methods presents unique challenges, primarily due to the inherent class imbalance where anomalies constitute a very small fraction of the total data [24]. Standard evaluation metrics like accuracy can be misleading in such scenarios, as a model predicting only the normal class would still achieve high accuracy [24,26]. This necessitates the use of appropriate metrics that are sensitive to the correct identification of the minority class [11,25].  

<html><body><table><tr><td>Metric</td><td>Definition</td><td>Relevance to Anomaly Detection</td><td>Note</td></tr><tr><td>Accuracy</td><td>(TP + TN) /Total</td><td>Misleading due to high class imbalance.</td><td>Avoid as sole metric.</td></tr><tr><td>Precision</td><td>TP/(TP + FP)</td><td>Measures relevance of detected anomalies.</td><td>Important for minimizing false positives.</td></tr><tr><td>Recall (Sensitivity)</td><td>TP /(TP + FN)</td><td>Measures ability to find all anomalies.</td><td>Important for minimizing false negatives.</td></tr><tr><td>F1-score</td><td>2. Precision·Recall Precision+ Recall</td><td>Balances Precision and Recall.</td><td>Useful when balancing FP and FN is important.</td></tr><tr><td>AUC-ROC</td><td>Area Under Receiver Operating Characteristic Curve</td><td>Evaluates TPR vs FPR trade-off across thresholds.</td><td>Standard,but less informative than AUC-PR for extreme imbalance.</td></tr><tr><td>AUC-PR</td><td>Area Under Precision-Recall Curve</td><td>Evaluates Precision vs Recall trade-off.</td><td>Recommended for highly imbalanced datasets.</td></tr></table></body></html>  

Several metrics are commonly employed to address the class imbalance issue and provide a more accurate assessment of anomaly detection performance [2,3,17,21,24,25]. Key metrics include precision, recall, F1-score, Area Under the Receiver Operating Characteristic Curve (AUC-ROC), and Area Under the Precision-Recall Curve (AUC-PR). Precision is defined as ${ \frac { \mathrm { T P } } { \mathrm { T P } + \mathrm { F P } } } ,$   
measuring the accuracy of positive predictions, while recall is   
${ \frac { \mathrm { T P } } { \mathrm { T P } + \mathrm { F N } } } ,$   
measuring the ability to identify all positive instances (where TP are true positives, FP are false positives, and FN are false negatives) [24]. The F1-score, the harmonic mean of precision and recall, provides a single score that balances both metrics. AUC-ROC evaluates the trade-off between true positive rate (recall) and false positive rate across different thresholds, while AUC-PR focuses on the trade-off between precision and recall. AUC-PR is often considered particularly informative for highly  

imbalanced datasets because it is not influenced by the number of true negatives [3,14]. Some studies also consider computation time, memory usage, and robustness as important evaluation criteria [25]. Visualizations such as ROC curves are also used to evaluate outlier detection estimators [5,25].  

Benchmark datasets play a crucial role in comparing anomaly detection algorithms. Evaluations are conducted on various datasets, including general anomaly detection benchmarks, real-world industrial datasets [12], time series datasets (including real and synthetic series) [2], network intrusion datasets like UNSW-NB15, and specialized datasets such as healthcare-specific data [11]. The MVTec AD dataset is commonly used for visual anomaly detection [10]. Dataset characteristics significantly influence algorithm performance. For instance, in uniformly distributed data, choosing an appropriate anomaly scoring method is crucial; good estimators should ideally assign similar scores to all samples [21,27]. Performance can also vary based on the number of labeled anomaly samples available, with some methods performing better when labeled samples are scarce [14].​  

Comparative studies report varying performance across different algorithms and datasets. A stacking ensemble model demonstrated significant improvements in accuracy, precision, recall, and F1-score compared to individual models on both UNSW-NB15 and a healthcare dataset [11]. DeepAnT was shown to outperform or perform comparably to 15 state-of-the-art algorithms across numerous time series benchmarks [2]. Methods evaluated on the MVTec AD dataset, such as GTrans, have reported high AUROC scores for both image-level $( 9 9 . 0 \% )$ and pixel-level $( 9 7 . 9 \% )$ ) anomaly detection [10]. On specific datasets, algorithms like Isolation Forest and Local Outlier Factor (LOF) have shown good performance, while One-Class SVM can be sensitive to outliers and hyperparameters [5,9]. Comparative evaluations using metrics like ROC, precisionrecall, time, memory, and robustness highlight the trade-offs between different approaches [25]. It is important to note that model parameters are often manually selected and may require further optimization for specific applications [21].​  

Despite the availability of metrics and benchmarks, challenges persist in evaluating anomaly detection algorithms. A significant challenge is the lack of comprehensive ground truth labels, particularly in unsupervised or semi-supervised settings, making definitive performance assessment difficult [2]. Appropriate benchmarks tailored to specific application domains are also often lacking [2]. Furthermore, evaluating performance on new, unseen data requires careful model tuning and validation on separate validation sets [26].  

# 9. Applications and Case Studies  

<html><body><table><tr><td>Domain</td><td>Examples of Applications</td></tr><tr><td>Cybersecurity</td><td>Network intrusion detection, Malware detection,Insider threat detection, Abnormal file access.</td></tr><tr><td>Finance</td><td>Credit card fraud detection,Insurance/Tax fraud, Banking fraud.</td></tr><tr><td>Healthcare/Medical</td><td>Medical image analysis (X-rays, MRl), ECG analysis,loMT monitoring (patient safety).</td></tr><tr><td>Manufacturing/lndustrial</td><td>Defect detection,Process validation, Fault detection in critical systems.</td></tr><tr><td>Internet of Things (loT)</td><td>Monitoring device traffic, Sensor network data analysis.</td></tr><tr><td>IT Operations</td><td>System health monitoring, Server/Traffic data analysis,Log anomaly detection.</td></tr><tr><td>Other</td><td>Video surveillance, Retail, Shipping, Telecom, Biology, Social Networks, Military.</td></tr></table></body></html>  

Anomaly detection is a fundamental technique with widespread applicability across numerous domains, offering significant improvements in efficiency, cost reduction, security, and quality control [7,8,17,23,24,28]. Its utility spans from detecting critical system failures and fraudulent activities to ensuring product quality and safeguarding sensitive networks.  

In the realm of cybersecurity, anomaly detection plays a crucial role in protecting systems and data. Applications include network intrusion detection, aimed at identifying suspicious traffic patterns and user activities [7,24,26,28,30,31]. This involves analyzing system call logs for host-based detection or monitoring network traffic for external threats [28]. Furthermore, anomaly detection is vital for malware detection, despite challenges posed by the large volume of data and the adaptive nature of malicious software [28]. Other cybersecurity applications include insider threat detection and identifying abnormal file access behaviors [8]. By detecting unusual activities, these methods enhance security and prevent potential breaches.​  

The finance sector heavily relies on anomaly detection for fraud prevention. This encompasses detecting fraudulent transactions across various platforms, including credit cards, insurance claims, taxes, banking operations, mobile networks, and even healthcare billing [3,7,17,19,24,25,26,30,31]. Fraudulent activities are typically cast as deviations from normal transaction patterns [24]. A significant challenge in this domain is the extreme imbalance between legitimate and fraudulent transactions [3]. Case studies demonstrate the application of techniques like unsupervised autoencoders on datasets like the Kaggle credit card fraud data, identifying anomalies based on reconstruction error [3]. The ability to quickly and correctly identify fraud is critical for service providers, especially in rapidly changing market conditions [17,24].  

Healthcare and medical diagnosis present unique opportunities and challenges for anomaly detection. It can be applied to analyze various data types, such as X-rays, MRIs, and ECGs, to highlight abnormal readings indicative of health conditions or precursor signals of medical incidents [7,19,23,24,26,28]. A specific and critical application is in the Internet of Medical Things (IoMT), where real-time monitoring is essential for patient safety and healthcare service reliability, addressing cybersecurity risks like falsification and denial-of-service (DoS) attacks [11]. Domain-specific challenges include significant data imbalances and the crucial need for interpretability in deep learning models used for diagnosis [28].  

In the manufacturing and industrial sectors, anomaly detection is integral to quality assurance and operational safety. It is used for detecting defects in manufactured items, process validation, and in-process quality assurance [23,24]. This helps ensure that items meet quality standards and identifies rare events that could damage equipment [7,28]. Fault detection in safety-critical systems is another key application [30]. Successful deployments include Siemens Healthineers using AI Anomaly Detector to identify anomalies in their production process early [17], and Airbus applying it for aircraft condition monitoring to proactively fix potential problems [17]. Evaluation often utilizes datasets like MVTec AD and other novel industrial datasets, highlighting the focus on generalizing to real-world industrial parts and materials [10,12,25].  

The growth of the Internet of Things (IoT) has made anomaly detection essential for monitoring devices and sensor networks. This includes monitoring IoT device traffic [17], analyzing data from heterogeneous sensors [2], and handling IoT big data [7]. Challenges in this domain arise from the complexity introduced by the interconnection of heterogeneous devices, as well as noise and the non-stationary, non-linear nature of time series data from sensors [28].  

Anomaly detection is also fundamental for IT operations and system monitoring. Applications include system health monitoring, ensuring the reliability of products and services like Microsoft Azure, Office, Windows, and Bing [17]. It involves analyzing server data, traffic data, and port data, often requiring time series anomaly detection to identify failures [6]. For multi-dimensional data in operations and maintenance, it is used for root cause analysis [6]. Log anomaly detection is another critical area, focusing on the challenging task of processing unstructured and diverse log data to identify unusual events [7,8,28]. Effective multivariate time series anomaly detection, in particular, can enable detailed fault isolation diagnostics [28].​  

Beyond these major areas, anomaly detection finds applications in diverse fields such as video surveillance, although challenges include the scarcity of labeled data and ambiguity in defining anomalies [7,28]. It is also relevant in retailing, shipping, telecommunications, biological data analysis, social network analysis (for online fraud, fake news, and rumors), and military surveillance [23,28,30,31]. These varied applications underscore the versatility of anomaly detection techniques in identifying deviations from expected patterns across numerous types of data and operational contexts.  

# 10. Challenges and Future Directions  

<html><body><table><tr><td>Category</td><td>Key Challenges</td></tr><tr><td>Data Issues</td><td></td></tr></table></body></html>  

<html><body><table><tr><td></td><td>High dimensionality, Data imbalance, Noise, Concept drift, Lack/Scarcity of labeled data, Defining'normal'</td></tr><tr><td>Algorithm Issues</td><td>Hyperparameter sensitivity, Computational cost/Scalability, Robustness to data variations, Handling complex anomaly types (contextual, collective).</td></tr><tr><td>Model Issues</td><td>Lack of interpretability ('black box'), Generalization issues,Model selection difficulty (unsupervised).</td></tr><tr><td>Application Issues</td><td>Domain-specific requirements, Adaptive adversaries, Ethical concerns (privacy, security).</td></tr></table></body></html>  

Anomaly detection remains a dynamic field facing numerous challenges that hinder the widespread adoption and effectiveness of current techniques across diverse applications [6,7,8,10]. A primary difficulty lies in effectively handling high-dimensional data. As dimensionality increases, the concept of distance, fundamental to many traditional methods, becomes less meaningful, leading to the 'curse of dimensionality' [3,5,17,21,27,29]. Outlier detection in high dimensions without prior assumptions about the inlier distribution is particularly challenging [5], and intuitions derived from lowerdimensional spaces may not generalize [21].  

The prevalence of unsupervised and semi-supervised scenarios, often due to the scarcity or complete lack of labeled anomaly data, presents significant hurdles [14,17,21,24,26,27,28,30]. Unsupervised methods can suffer from noisy outputs and generate a high volume of false positives [24]. The presence of contaminated normal examples within large unlabeled datasets further complicates training [24]. Defining a clear 'normal' region is often difficult [30], and handling unlabeled data typically relies on statistical tools like probability density functions [26]. The challenge of class imbalance, where anomalies are rare compared to normal instances, is also pronounced [3,10].  

Interpretability remains a critical concern, particularly with complex models such as those based on deep learning [3,17,24,28]. Deep learning models are often perceived as 'black boxes,' making it difficult to understand the rationale behind an anomaly detection decision [24]. This lack of transparency is a significant barrier in domains requiring trust and verification of model outputs.​  

Furthermore, real-world data streams are rarely static; they exhibit evolving patterns, known as concept drift, and have fuzzy boundaries between normal and anomalous states [17,24,28,30]. Detecting outliers in specific data types, such as autocorrelated time series, without prior knowledge of the underlying process model adds another layer of complexity [13]. The definition of an 'anomaly' can also vary significantly across different applications [30]. Challenges also include detecting more complex types of anomalies, such as contextual and collective anomalies [17,28], and dealing with noisy data inputs [17,24,28,30]. Models may also suffer from generalization issues, misinterpreting unusual features as normal [26], or be optimized only for normal samples, leading to false positives or missed anomalies [19].  

Computational cost and scalability are significant issues, especially when dealing with large-scale datasets or requiring realtime performance [3,17,24,28]. Measuring similarity, a common step in many algorithms, can be computationally expensive [6]. Additionally, many algorithms are highly sensitive to parameter tuning, requiring manual selection of hyperparameters [5,9,17,21,24,28,29]. Specific methods like One-Class SVM are known to be sensitive to outliers and require careful tuning [5,9]. Challenges extend to broader data mining concerns like adaptive adversaries and the social impacts of data mining, including privacy and security [30,31].​  

Addressing these challenges points towards several crucial future research directions [6,7]. Developing more efficient, scalable, and robust algorithms is paramount, including methods less sensitive to parameter choices [17,21]. Research into computational optimization techniques, such as utilizing data structures like kd-trees or dynamic programming, can help reduce complexity, especially for similarity calculations [6].​  

Improving the interpretability of anomaly detection models, particularly deep learning methods, is a significant area for future work [3,14,17]. This could involve focusing on understanding how feature adjustments affect anomaly scores or exploring the intersection with Human-Computer Interaction (HCI), where humans provide explanations and correct model predictions through active learning or crowdsourcing [6].  

Exploring novel data representations is essential, especially to mitigate the issues associated with high-dimensional data. Finding better ways to represent data and controlling dimensionality are considered fundamental approaches to this problem [6,14]. Incorporating domain knowledge into anomaly detection models can lead to more accurate and contextually relevant results [17].​  

Further research is needed to handle diverse data types, such as multi-modal data [3], and to develop methods specifically tailored for complex data streams like time series, including testing performance on various real-world datasets and comparing against other online detection algorithms [13]. Addressing the ethical concerns related to anomaly detection, such as privacy and security, is also a critical future direction [17,31]. Other potential areas include developing improved evaluation methodologies and exploring new application domains [17], as well as strengthening the theoretical foundations of the field [31].​  

# 11. Conclusion  

Anomaly detection is a critical field with diverse applications, serving as a powerful tool for revealing abnormal phenomena in data [3,26]. This survey has reviewed various approaches, broadly categorized into statistical, distance-based, densitybased, clustering, tree-based, dimensionality reduction, classification, and prediction-based methods [4].  

The choice of method is contingent upon data characteristics, application requirements, and the distinction between outlier and novelty detection [5,9,28]. Statistical methods, such as EllipticEnvelope, demonstrate robustness under specific assumptions like Gaussian data distributions [27]. Density-based methods like Local Outlier Factor (LOF) quantify abnormality based on local density and perform well on multimodal datasets [9,20,27]. Tree-based methods, exemplified by Isolation Forest (iForest), utilize ensemble learning [20]; iForest is particularly effective for smaller datasets and also performs well on multimodal data, though its performance may be less intuitive in very high dimensions [19,21,27]. Classification-based methods like One-Class SVM learn a decision boundary from normal data [20] and are suitable for novelty detection, although they often require careful hyperparameter tuning [9,27]. Ensemble techniques, such as stacking, have demonstrated improved performance for specific applications like real-time anomaly detection in IoMT networks [11].​  

Dimensionality reduction techniques, particularly autoencoders, play a significant role, especially for handling highdimensional data [3]. Autoencoders can be effectively used in weakly-supervised scenarios with limited labeled data, providing superior performance, especially in terms of AUC-PR, when labels are scarce [14].​  

Deep learning approaches have gained prominence, addressing limitations of traditional methods, especially for complex data types like time series with periodic or seasonality patterns [2]. DeepAnT, which employs a CNN-based predictor, exemplifies the success of deep learning in unsupervised time series anomaly detection [2]. Furthermore, advanced architectures like Transformers have achieved state-of-the-art results in domains like visual anomaly detection, as shown by methods like GTrans [10]. Feature constrained distillation is another technique improving performance in visual anomaly detection [12]. However, selecting the appropriate deep learning method involves considering specific application domains, anomaly definitions, data characteristics, and the inherent trade-offs [28]. For autocorrelated time series data, specialized methods like modified Kalman filters can be employed for on-line outlier detection and cleaning without requiring a priori process models [13].​  

Despite significant advancements, the field faces ongoing challenges. These include issues related to model adaptation and robustness [26], handling high-dimensional data effectively [3,21,27], addressing data imbalance, dealing with the absence or scarcity of labeled anomaly data [3,21,27], and the need for careful hyperparameter tuning in many algorithms [9]. The importance of anomaly scoring for uniformly distributed data and the difficulty in model selection for unlabeled data also remain challenges [27].​  

Promising directions for future research involve enhancing model accuracy, interpretability, and real-time performance across different data types and applications [3]. Further exploration is needed to develop robust methods for highdimensional and unlabeled data [21,27]. Improving techniques for weak supervision, leveraging the strengths of deep learning architectures for complex patterns and data modalities, and tailoring solutions to the specific needs and constraints of diverse application domains remain crucial steps forward [2,14,28]. The development of more automated and less hyperparameter-dependent methods is also desirable.​  

# References  

[1] 奇异值与离群点检测 https://scikit-learn.org.cn/view/112.html  

[2] DeepAnT: 深度学习在时间序列无监督异常检测中的应用 https://www.zhangqiaokeyan.com/academic-journal-foreign_quality-control-transactions_thesis/0204112932722.html  

[3] 异常检测方法与Python实现：统计学、深度学习及应用 https://www.cnblogs.com/haohai9309/p/18180010  

[4] 14种数据异常值检测方法总结 https://mp.weixin.qq.com/s?_biz=MzA3NzIxNDQ3MQ $\scriptstyle 1 = =$ &mid=2650328627&idx $\vdots = \thinspace$ 3&sn $=$ 0fe5926b21f5b2c07451a4195f9fe2a6&chksm $\mid =$ 86ff925dc85d35cb5  
84e005cfe02fee9d30c36bce99c65c6446cd9aab37e65ee8098412ccf6c&scene=27  

[5] Scikit-learn新颖性与异常值检测技术详解 https://cloud.tencent.com/developer/article/2447993  

[6] 异常检测领域的研究方向与挑战 https://mp.weixin.qq.com/s?   
_biz=MzU0NjgzMDIxMQ $\scriptstyle = =$ &mid=2247601680&id $\iota =$ 2&sn=489c4cec8ba23e151d945a4497254cd9&chksm=fb54acfccc2325ead   
c7ad5228e6448e2c7f1879c0eec68f011a91e4abd7dba58615674a3d389&scene=27  

] 深度学习异常检测综述：概念、方法与应用 https://cloud.tencent.com/developer/article/1748464  

[8] Anomaly Detection Techniques and Applications: A S https://www.cnblogs.com/mashuai-191/p/11764353.html  

[9] Sklearn异常检测方法：离群检测与新奇检测 https://www.jingsailian.com/zlk/257199.html  

[10] GTrans: Multiresolution Feature Guidance Transform http://irp.fzu.edu.cn/item/704776  

[11] Real-Time Anomaly Detection in IoMT using Stacking https://ieeexplore.ieee.org/document/10972116/  

[12] Feature Constrained Distillation for Visual Anomal https://www.jos.org.cn/josen/ch/reader/view_abstract.aspx? file_no=6643​  

[13] On-line Outlier Detection and Data Cleaning for Au https://www.mendeley.com/research/online-outlier-detection-datacleaning/  

[14] 弱监督异常检测：基于AutoEncoder的特征编码模型 https://blog.csdn.net/qq_43166192/article/details/134401224   
[15] 异常检测方法综述与总结 https://it.sohu.com/a/553465691_121124366  

[16] 14种常见异常检测方法总结及代码示例 https://mp.weixin.qq.com/s? biz=MzU0MDQ1NjAzNg==&mid=2247543837&idx $\underline { { \underline { { \mathbf { \Pi } } } } } = \mathbf { \Pi }$ 2&sn=2065a4284c8ab938f677b076e4891222&chksm $\mid =$ fb3a8916cc4d0000   
fb93ea9d99fc09c6c806ff61c9686fb0369c2691acd32968058f90405429&scene=27  

[17] Azure AI Anomaly Detector: Detect Problems Early & http://azure.microsoft.com/en-us/products/ai-services/ai-anomaly detector/  

[18] 异常检测算法综述 https://blog.csdn.net/weixin_26739079/article/details/109123172  

[19] 孤立森林：一种高效的异常检测算法 https://www.pianshen.com/article/4766797850/  

[20] 异常业务预警算法：OneClassSVM、Isolation Forest与LOF总结 https://blog.csdn.net/weixin_47939744/article/details/122655677  

[21] sklearn异常检测算法比较及异常点检测示例 https://vimsky.com/article/4458.html  

[22] Scikit-learn异常检测实战：Isolation Forest与其他算法 https://blog.csdn.net/weixin_69882801/article/details/145718756  

23] 实时异常检测系统与方法 https://wenku.baidu.com/view/d8cd0ce482c758f5f61fb7360b4c2e3f57272577.html  

[24] Deep Learning for Anomaly Detection: A Concise Ove http://ff12.fastforwardlabs.com/  

[25] Outlier Detection Algorithms: Comparative Evaluati https://www.aminer.cn/pub/5a260c5717c44a4ba8a29406  

6] 异常检测入门：定义、方法与应用 https://zhidao.baidu.com/question/404984746209307245.html  

[27] 四种异常检测算法在2D仿真数据集上的比较 https://blog.csdn.net/zhongkeyuanchongqing/article/details/117522900  

[28] 深度学习异常检测技术综述 https://blog.csdn.net/m0_38052500/article/details/117386336  

[29] 基于距离的近邻异常检测：k-NN与kth-NN https://blog.csdn.net/I_am_huang/article/details/92842799  

[30] 异常值检测算法综述 https://m.360docs.net/doc/1c8804997.html  

[31] 数据挖掘：概念与技术（英文版第2版） https://www.dushu.com/book/11309856/[32] 异常检测算法分析 https://wenku.baidu.com/view/bfb9ca869ec3d5bbfd0a74f9.html  