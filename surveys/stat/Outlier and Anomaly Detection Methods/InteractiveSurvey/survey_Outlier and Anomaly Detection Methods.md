# A Survey of Outlier and Anomaly Detection Methods

# 1 Abstract


Anomaly detection, a critical component of data analysis and machine learning, plays a pivotal role in identifying unusual patterns that deviate from the norm, spanning various domains such as finance, healthcare, and cybersecurity. This survey paper focuses on the latest developments in outlier and anomaly detection methods, with a particular emphasis on the integration of pre-trained models, vision and language integration, deep learning and dimensionality reduction, and efficient and adaptive algorithms. The main findings include the effectiveness of sequence contrast methods in time-series anomaly detection, the robustness of Random Forest-based approaches like RFuni, the enhancement of anomaly detection through Vision-Language Models (VLMs), and the computational efficiency of methods like DeepHYDRA and EILOF. The paper also highlights the importance of interpretability and robustness, with a focus on techniques like Cepstral Linear Discriminant Analysis (CLDA) and Hierarchical Robust Principal Component Analysis (HrPCA). Finally, this survey aims to serve as a comprehensive resource for researchers, practitioners, and students interested in the field of anomaly detection, bridging the gap between theoretical advancements and practical applications.

# 2 Introduction
Anomaly detection, a critical component of data analysis and machine learning, plays a pivotal role in identifying unusual patterns that deviate from the norm [1]. These patterns, often referred to as outliers or anomalies, can indicate errors, fraud, or significant events that require attention [1]. The importance of anomaly detection spans across various domains, including finance, healthcare, cybersecurity, and industrial monitoring [2]. Traditional methods, such as statistical techniques and rule-based systems, have been widely used but often fall short in handling the complexity and volume of modern datasets. With the advent of advanced machine learning and deep learning techniques, the field of anomaly detection has seen significant advancements, enabling more accurate and robust identification of anomalies in high-dimensional and dynamic data environments [3].

This survey paper focuses on the latest developments in outlier and anomaly detection methods, with a particular emphasis on the integration of pre-trained models, vision and language integration, deep learning and dimensionality reduction, and efficient and adaptive algorithms. The paper aims to provide a comprehensive overview of the current state-of-the-art techniques, highlighting their strengths, limitations, and potential applications. By synthesizing recent research contributions, this survey seeks to offer a structured and insightful resource for researchers, practitioners, and students interested in the field of anomaly detection [4].

The survey begins by exploring the enhancement of anomaly detection through the use of pre-trained models, particularly in the context of time-series data [3]. Sequence contrast methods, which leverage contrastive learning to create representations that emphasize the differences between normal and anomalous sequences, have shown promising results in various applications. These methods are particularly effective in scenarios where anomalies are rare and the data distribution is non-stationary. Additionally, the paper delves into the use of Random Forest-based approaches, such as RFuni, which integrate a unique ensemble mechanism to enhance the model's ability to distinguish between in-distribution and out-of-distribution samples. The inclusion of post-hoc calibration techniques, which improve the reliability of machine learning models by adjusting the output probabilities, further enriches the discussion.

The integration of vision and language models, such as Vision-Language Models (VLMs), represents another significant advancement in the field. VLMs leverage the rich semantic understanding from both visual and textual data to improve the detection of anomalies, particularly in scenarios where labeled anomaly data is scarce. The paper discusses the use of abnormal pseudo-samples and the alignment of visual and textual features to enhance the model's ability to generalize and detect anomalies. Learning via Surprisability (LvS), which focuses on the unexpectedness of data points, and the Teacher-Student spherical perceptron model, which addresses the challenges of class imbalance, are also covered in detail.

Deep learning and dimensionality reduction techniques, such as Deep Hybrid DBSCAN/Reduction-Based Anomaly Detection (DeepHYDRA) and Contextual Normality Network (CON2), are explored for their effectiveness in handling high-dimensional and variable-dimensional data streams. These methods combine the strengths of dimensionality reduction and clustering to achieve a balance between computational efficiency and detection accuracy. The paper also examines semi-supervised continual learning (SSCL) and the development of robust and contextually aware models, which are crucial for real-world applications where data is often complex and dynamic [5].

Efficient and adaptive anomaly detection algorithms, including histogram and probabilistic methods, generative and self-supervised approaches, and early stopping and incremental algorithms, are discussed in the latter part of the survey [4]. These methods, such as the Extended Histogram-based Outlier Score (EHBOS), Sliced-Wasserstein Distance (SWD), and GradStop, offer solutions to the computational and practical challenges associated with anomaly detection in large-scale and real-time environments [1]. The paper also highlights the importance of interpretability and robustness in anomaly detection, with a focus on techniques like Cepstral Linear Discriminant Analysis (CLDA) and Hierarchical Robust Principal Component Analysis (HrPCA).

Finally, the survey paper makes several contributions to the field of anomaly detection [4]. It provides a comprehensive review of the latest research trends and methodologies, offering a structured and detailed overview of the current landscape. The paper identifies key areas for future research, including the development of more adaptive and scalable algorithms, the integration of fairness and explainability in anomaly detection systems, and the application of advanced techniques to new and emerging domains. By bridging the gap between theoretical advancements and practical applications, this survey aims to serve as a valuable resource for the scientific community and industry practitioners alike.

# 3 Enhancing Anomaly Detection with Pre-trained Models

## 3.1 Contrastive Learning and One-Class Classification

### 3.1.1 Sequence Contrast for Time-Series Anomaly Detection
Sequence contrast in time-series anomaly detection leverages the temporal dependencies within sequences to identify deviations from normal patterns [6]. Traditional methods often rely on static feature extraction, which may fail to capture the dynamic nature of anomalies. Sequence contrast, on the other hand, utilizes contrastive learning to create representations that emphasize the differences between normal and anomalous sequences. By training on pairs of sequences, where one sequence is considered normal and the other is a perturbed version or an anomaly, the model learns to distinguish subtle variations that indicate abnormal behavior. This approach is particularly effective in scenarios where anomalies are rare and the data distribution is non-stationary.

In practice, sequence contrast methods involve constructing a contrastive loss function that maximizes the similarity between positive pairs (normal sequences and their slightly perturbed versions) and minimizes the similarity between negative pairs (normal sequences and anomalous sequences). This loss function encourages the model to learn a representation space where normal sequences cluster closely together, while anomalies are pushed far away. Techniques such as time-domain and frequency-domain data augmentation are employed to generate diverse positive and negative pairs, enhancing the robustness of the model. Additionally, semi-supervised training strategies can be used to incorporate limited labeled anomaly data, further improving the model's ability to generalize to unseen anomalies [7].

The effectiveness of sequence contrast in time-series anomaly detection has been demonstrated across various domains, including industrial monitoring, healthcare, and financial transactions. For instance, in industrial settings, sequence contrast can help detect equipment failures by identifying unusual patterns in sensor data. In healthcare, it can aid in early diagnosis by spotting deviations from normal physiological signals. The key advantage of sequence contrast lies in its ability to adapt to evolving data distributions and handle class imbalance, making it a powerful tool for real-world anomaly detection tasks. By focusing on the temporal dynamics of sequences, sequence contrast methods provide a more nuanced and accurate approach to identifying anomalies compared to traditional static methods.

### 3.1.2 RFuni for Anomaly Detection
RFuni, a novel Random Forest-based approach, is designed to address the challenges of anomaly detection in high-dimensional and imbalanced datasets. Unlike traditional Random Forest methods, RFuni integrates a unique ensemble mechanism that enhances the model's ability to distinguish between in-distribution (ID) and out-of-distribution (OOD) samples. This is achieved by leveraging the inherent structure of the data and the diversity of the forest to capture subtle anomalies that might be overlooked by simpler models. RFuni's architecture is particularly effective in scenarios where anomalies are rare and the feature space is complex, making it a robust solution for real-world applications such as industrial fault detection and medical imaging.

The key innovation of RFuni lies in its ability to adaptively learn the distribution of normal data and identify deviations without requiring extensive labeled anomaly data. This is accomplished through a combination of feature importance analysis and anomaly scoring. Each tree in the forest contributes to an anomaly score, which is computed based on the depth at which a data point is isolated. Data points that are isolated at shallower depths are considered more anomalous, as they are likely to be outliers in the feature space. By aggregating these scores across the ensemble, RFuni provides a comprehensive and interpretable measure of anomaly, which is crucial for applications where understanding the reasons behind an anomaly is as important as detecting it.

RFuni's performance is further enhanced by its computational efficiency and scalability. The method can handle large datasets and high-dimensional feature spaces with minimal computational overhead, making it suitable for real-time monitoring and large-scale deployments. Experimental results on a variety of benchmark datasets, including CIFAR-10, CIFAR-100, and SVHN, demonstrate that RFuni outperforms existing state-of-the-art anomaly detection methods in terms of both accuracy and robustness. The approach's ability to generalize well to unseen data and its effectiveness in realistic anomaly detection setups, as shown in Figure 1, highlight its potential for practical applications in diverse domains [4].

### 3.1.3 Post-hoc Calibration Techniques
Post-hoc calibration techniques are essential for enhancing the reliability of machine learning models, particularly in anomaly detection, where the confidence in predictions can significantly impact decision-making processes. These techniques are applied after the initial training phase to adjust the output probabilities of a model, ensuring that the predicted probabilities align more closely with the true likelihoods of the outcomes. Common post-hoc calibration methods include Platt scaling, isotonic regression, and temperature scaling. Platt scaling involves fitting a logistic regression model to the classifier’s outputs, transforming the raw scores into calibrated probabilities. Isotonic regression, on the other hand, fits a piecewise constant non-decreasing function to the data, which can be more flexible but may overfit if the dataset is small. Temperature scaling, a popular method in deep learning, adjusts the logits of a neural network by dividing them by a scalar temperature parameter, effectively sharpening or smoothing the output distribution.

Despite their simplicity, these calibration techniques can significantly improve the performance of anomaly detection systems by reducing the discrepancy between predicted and actual probabilities. For instance, in the context of anomaly detection, a well-calibrated model can provide more reliable uncertainty estimates, which are crucial for identifying subtle deviations from normal behavior. However, the effectiveness of these techniques can vary depending on the specific characteristics of the dataset and the underlying model architecture. For example, deep neural networks often require more sophisticated calibration methods due to their tendency to produce overconfident predictions. Moreover, the choice of calibration technique can influence the trade-off between calibration and discrimination, where overly aggressive calibration might degrade the model’s ability to distinguish between normal and anomalous samples.

Recent advancements in post-hoc calibration have focused on developing more adaptive and data-efficient methods. Techniques such as Bayesian calibration and ensemble-based approaches have been proposed to address the limitations of traditional methods. Bayesian calibration incorporates prior knowledge about the model’s uncertainty, providing a principled way to adjust the posterior probabilities. Ensemble-based methods, such as stacking multiple calibration techniques or using ensembles of calibrated models, can further enhance the robustness and reliability of the predictions. These advanced techniques are particularly valuable in safety-critical applications where the consequences of misclassification can be severe. Overall, post-hoc calibration remains an active area of research, with ongoing efforts to develop more effective and scalable methods for improving the trustworthiness of machine learning models in anomaly detection tasks.

## 3.2 Vision and Language Integration

### 3.2.1 VisionLanguage Model for Anomaly Detection
Vision-Language Models (VLMs) have emerged as a powerful tool for anomaly detection, leveraging the rich semantic understanding from both visual and textual data [8]. In the context of anomaly detection, VLMs, such as CLIP, integrate vision and language encoders to map visual inputs to a high-dimensional feature space where textual descriptions of normal and abnormal conditions can guide the detection process [8]. This approach addresses the limitations of traditional vision-only models, which often struggle with generalization and robustness to transformations. By incorporating textual prompts, VLMs can dynamically adjust their understanding of what constitutes an anomaly, making them more adaptable to real-world scenarios where anomalies can be diverse and context-dependent.

The key innovation in VLMs for anomaly detection lies in their ability to generate and utilize abnormal pseudo-samples during training [9]. These pseudo-samples are created by combining visual features with textual descriptions of anomalies, allowing the model to learn the boundaries between normal and abnormal data more effectively. This is particularly important in scenarios where labeled anomaly data is scarce or unavailable. The vision encoder is trained to map anomaly images to visual features that align more closely with text features of abnormal descriptions, thereby enhancing the model's ability to detect and localize anomalies [10]. This alignment is achieved through a two-stage process: first, the model learns to recognize and map normal visual features to corresponding text descriptions, and then it refines this mapping by aligning patch-level visual features with specially adapted texture anchors that emphasize anomaly-relevant regions [10].

In practice, VLMs for anomaly detection have shown significant improvements in both precision and recall, especially in datasets with a low percentage of anomalies [4]. The use of textual prompts and the generation of abnormal pseudo-samples help the model to generalize better and to be more robust to transformations that do not preserve semantics. This is crucial in real-world applications where anomalies can manifest in various forms and under different conditions [1]. Furthermore, the interpretability of VLMs, facilitated by the alignment of visual and textual features, provides valuable insights into the nature of detected anomalies, making the models more actionable and trustworthy in critical applications such as industrial quality inspection and autonomous driving.

### 3.2.2 Learning via Surprisability
Learning via Surprisability (LvS) is a novel approach that leverages the concept of surprisal to enhance the robustness and effectiveness of anomaly detection models. Surprisal, rooted in information theory, quantifies the unexpectedness of an event based on its deviation from a learned distribution. In the context of anomaly detection, surprisal can be used to identify data points that significantly deviate from the norm, thereby serving as a powerful indicator of potential anomalies. By focusing on features that exhibit high surprisal, LvS aims to improve the model's ability to distinguish between normal and anomalous data points, even in the presence of complex and varied transformations.

The core idea behind LvS is to transform the input data in a way that amplifies the differences between normal and anomalous samples [11]. This transformation is guided by the surprisal metric, which measures the degree to which a sample deviates from the expected distribution. During training, the model learns to adjust its internal representations to maximize the surprisal of anomalous samples while minimizing that of normal samples. This process ensures that the model becomes more sensitive to subtle changes in the data, thereby improving its ability to detect anomalies [5]. The use of surprisal as a guiding principle also helps the model to generalize better to unseen data, as it focuses on the most informative and discriminative features.

To implement LvS, the model first computes the surprisal of each input sample using a pre-trained language or vision model, such as CLIP, which has been trained on a diverse and extensive dataset. The surprisal values are then used to guide the transformation of the input data, ensuring that the transformed samples retain their semantic meaning while emphasizing the differences between normal and anomalous data. This approach not only enhances the model's ability to detect anomalies but also reduces the risk of false positives by focusing on the most salient features. Empirical evaluations on various datasets have shown that LvS outperforms traditional methods, particularly in scenarios with limited labeled data, demonstrating its potential for real-world applications in anomaly detection.

### 3.2.3 Teacher-Student Spherical Perceptron Model
The Teacher-Student (TS) spherical perceptron model serves as a foundational framework for understanding the effects of class imbalance (CI) on learning and anomaly detection. This model, originally developed to study the learning dynamics in neural networks, has been adapted to incorporate various sources of CI, including intrinsic, training, and testing imbalances. By tuning these parameters, the TS spherical perceptron allows for an analytical exploration of how different levels of imbalance affect the learning process and the performance of anomaly detection algorithms.

In the context of anomaly detection, the TS spherical perceptron model is particularly useful for elucidating the role of training data distribution on the model's ability to generalize and detect anomalies. The model's simplicity and analytical tractability provide a clear understanding of how the training set's imbalance influences the decision boundary and the model's sensitivity to anomalies. For instance, the optimal training imbalance is found to be a function of the intrinsic imbalance and the amount of available data, highlighting the importance of carefully designing the training set to avoid overfitting to the majority class and to ensure robust detection of rare anomalies [12].

Furthermore, the TS spherical perceptron model offers insights into the trade-offs between different performance metrics, such as precision, recall, and the area under the receiver operating characteristic curve (AUROC), under varying conditions of imbalance. These insights are crucial for developing more effective and robust anomaly detection systems, especially in real-world applications where data imbalance is a common challenge [13]. The model's ability to provide exact solutions through replica theory also facilitates the development of new training strategies and algorithms that can better handle imbalanced datasets, ultimately improving the overall performance of anomaly detection systems.

## 3.3 Deep Learning and Dimensionality Reduction

### 3.3.1 Deep Hybrid DBSCAN/Reduction-Based Anomaly Detection
Deep Hybrid DBSCAN/Reduction-Based Anomaly Detection, or DeepHYDRA, is a novel approach that combines the strengths of dimensionality reduction and clustering to address the challenges of anomaly detection in high-dimensional and variable-dimensional data streams [3]. The method leverages a two-pronged strategy: first, it applies a massive dimensionality reduction technique to the input data, effectively transforming the high-dimensional space into a more manageable and interpretable lower-dimensional space. This reduction step is crucial for mitigating the curse of dimensionality and enhancing computational efficiency, making the method suitable for real-time applications and resource-constrained environments such as miniaturized sensor networks.

The second stage of DeepHYDRA involves the parallel application of a fast detection method on the unreduced data and a transformer-based anomaly detection method on the reduced data stream. The fast detection method, which is a variation of the DBSCAN clustering algorithm, is designed to quickly identify dense regions in the data and flag potential anomalies based on their deviation from these regions. This step is essential for maintaining high recall, as it helps to capture anomalies that might be lost during the dimensionality reduction process. Meanwhile, the transformer-based method applied to the reduced data stream provides a more nuanced and detailed analysis, ensuring that the system can detect subtle anomalies that may not be apparent in the original high-dimensional space.

By integrating these two methods, DeepHYDRA achieves a balance between computational efficiency and detection accuracy. The combination of dimensionality reduction and clustering allows the method to handle the heterogeneity and variability of real-world data streams, making it particularly suitable for applications where data distributions are complex and dynamic. Additionally, the parallel processing of unreduced and reduced data ensures that the system can maintain high recall while also providing detailed and interpretable anomaly scores, thus addressing the critical need for both performance and explainability in anomaly detection systems.

### 3.3.2 Semi-Supervised Continual Learning
Semi-Supervised Continual Learning (SSCL) represents a novel paradigm that bridges the gap between continual learning and semi-supervised learning, addressing the challenges of learning from a stream of data with limited labeled instances [5]. In SSCL, the model is exposed to a sequence of disjoint datasets, each containing a mix of labeled and unlabeled data. The primary goal is to leverage the small amount of labeled data to guide the learning process, while effectively utilizing the abundant unlabeled data to improve the model's performance and adaptability over time. This setting is particularly relevant in real-world applications where labeled data is scarce or expensive to obtain, but large amounts of unlabeled data are readily available.

The key challenge in SSCL lies in balancing the exploitation of labeled data with the exploration of unlabeled data, while preventing catastrophic forgetting—a phenomenon where the model forgets previously learned information as it adapts to new data. To address this, various strategies have been proposed, such as using memory replay mechanisms to store and replay past labeled data, or employing regularization techniques to constrain the model's updates. Additionally, pseudo-labeling approaches, where the model generates labels for the unlabeled data based on its current knowledge, have shown promise in improving the model's ability to generalize to new tasks. These methods often involve iterative refinement of the pseudo-labels, ensuring that the model's predictions become increasingly accurate over time.

Another important aspect of SSCL is the development of robust evaluation metrics and benchmarks to assess the model's performance across different tasks and datasets. Traditional metrics such as accuracy and F1-score may not fully capture the model's ability to adapt and generalize in a continual learning setting. Therefore, researchers have introduced new metrics, such as forward transfer and backward transfer, to evaluate the model's capacity to learn from new tasks without forgetting previous ones. Furthermore, the integration of semi-supervised learning techniques with advanced architectures, such as transformers and graph neural networks, has opened up new avenues for improving the efficiency and effectiveness of SSCL models. These advancements are crucial for developing systems that can handle the dynamic and evolving nature of real-world data streams.

### 3.3.3 CON2 for Contextual Anomaly Detection
In the realm of anomaly detection, the development of robust and contextually aware models is crucial, especially when dealing with complex, high-dimensional data. The Contextual Normality Network (CON2) is a novel approach designed to address the limitations of traditional anomaly detection methods, which often fail to capture the nuanced differences between normal and anomalous data points [2]. CON2 introduces a method for learning tightly clustered representations of normal data through context augmentations, which are transformations that simulate variations in normal data [2]. By doing so, CON2 ensures that the learned representations are invariant to these variations, thereby enhancing the model's ability to distinguish between normal and anomalous samples.

The core innovation of CON2 lies in its use of context augmentations, which are carefully designed to model the invariances present in normal data. These augmentations are applied during the training phase, allowing the model to learn a representation space where normal samples are tightly clustered, and anomalies are more easily identifiable. This approach is particularly beneficial in scenarios where anomalies are rare or unknown during training, as it does not require prior knowledge of the anomalies. Instead, CON2 focuses on learning a robust representation of normality, which is then used to compute anomaly scores for new samples [2]. The anomaly score function, Nearest Neighbor Distance (NND), measures the distance of a new sample from the learned normal cluster, providing a quantitative measure of its anomalousness.

Empirical evaluations on various datasets, including CIFAR-10, CIFAR-100, and SVHN, have demonstrated the effectiveness of CON2 in both generalization and realistic anomaly detection tasks. The method has shown improved performance in detecting anomalies that are contextually relevant, as opposed to those that are merely statistical outliers [1]. Furthermore, the use of context augmentations has led to a more interpretable and robust model, capable of adapting to different data distributions and maintaining high detection accuracy even in the presence of a small percentage of anomalies. This makes CON2 a promising approach for real-world applications where the nature of anomalies can be highly variable and unpredictable.

# 4 Efficient and Adaptive Anomaly Detection Algorithms

## 4.1 Histogram and Probabilistic Methods

### 4.1.1 Extended Histogram-based Outlier Score
The Extended Histogram-based Outlier Score (EHBOS) represents a significant advancement over the traditional Histogram-based Outlier Score (HBOS) by addressing its primary limitations [1]. While HBOS efficiently models the distribution of feature values using univariate histograms and aggregates inverse likelihoods to score anomalies, it fails to capture feature interactions, leading to suboptimal performance in datasets where such interactions are crucial [1]. EHBOS mitigates this issue by incorporating mechanisms to account for these interactions, thereby enhancing its ability to detect outliers in complex, multidimensional data.

EHBOS achieves this enhancement through a multi-step process. First, it constructs univariate histograms for each feature, similar to HBOS, but then extends this by building bivariate histograms to capture pairwise interactions between features. These bivariate histograms provide a more nuanced understanding of how feature values co-vary, which is essential for identifying outliers that arise from unusual combinations of feature values [1]. Additionally, EHBOS employs a weighted aggregation scheme that assigns higher importance to feature interactions that are more indicative of outliers, ensuring that the final outlier scores are more accurate and reliable.

Furthermore, EHBOS introduces a robustness mechanism to handle noisy data and outliers within the training set. This is achieved by applying smoothing techniques to the histograms, which helps to reduce the impact of spurious data points on the outlier scores. The smoothing process can be adaptive, adjusting the degree of smoothing based on the local density of the data, thus maintaining the sensitivity to genuine outliers while reducing false positives. Overall, EHBOS strikes a balance between computational efficiency and the ability to capture complex feature interactions, making it a versatile tool for outlier detection in a wide range of applications.

### 4.1.2 MVG-CRPS for Multivariate Probabilistic Forecasting
To overcome the limitations of traditional evaluation metrics in multivariate probabilistic forecasting, we introduce MVG-CRPS, a strictly proper scoring rule designed specifically for models with Gaussian distribution outputs [14]. This method leverages a Principal Component Analysis (PCA) whitening transformation to decorrelate the multivariate variables, converting them into a new random vector with zero mean and an identity covariance matrix. By doing so, MVG-CRPS simplifies the evaluation of multivariate forecasts, making it easier to assess the accuracy and reliability of the model's predictions across multiple dimensions.

While univariate probabilistic forecasting has benefited from well-established scoring rules, the development of analogous metrics for multivariate settings has lagged behind [14]. Multivariate time series data, characterized by their high dimensionality and intricate interdependencies, pose unique challenges that traditional metrics often fail to address adequately. MVG-CRPS addresses these issues by providing a principled way to evaluate the joint distribution of forecasted variables, ensuring that the model captures both the marginal distributions and the dependencies between variables accurately. This is particularly important in applications where the relationships between variables are as critical as the individual predictions themselves.

To achieve accurate and reliable multivariate probabilistic forecasts, it is essential to not only develop sophisticated forecasting models but also to employ robust evaluation metrics during the training process [14]. MVG-CRPS serves as a powerful tool in this regard, facilitating the optimization of model parameters to better capture the underlying data distribution. By integrating MVG-CRPS into the training pipeline, practitioners can ensure that their models are not only accurate but also robust to the complexities inherent in multivariate data, ultimately leading to more trustworthy and actionable forecasts.

### 4.1.3 PyOD 2 with LLM-driven Model Selection
PyOD 2 represents a significant advancement in the field of outlier detection (OD) by integrating an automated model selection mechanism driven by large language models (LLMs). This feature is particularly innovative as it addresses the common challenge of selecting the most appropriate OD model for a given dataset, a task that traditionally requires substantial domain expertise and manual tuning. By leveraging the reasoning capabilities of LLMs, PyOD 2 can dynamically evaluate and recommend the best model from a diverse pool, thereby democratizing access to advanced OD techniques for users with varying levels of expertise [15].

The LLM-driven model selection in PyOD 2 operates by analyzing the characteristics of the input dataset, such as dimensionality, sparsity, and distribution, and comparing these features against a knowledge base of model performance metrics [15]. This process involves a sophisticated evaluation framework that assesses the suitability of each model in the library, which includes both classical and deep learning-based methods. The LLM then synthesizes this information to provide a ranked list of models, prioritizing those that are most likely to perform well on the given dataset. This automated approach not only saves time but also enhances the robustness and accuracy of OD tasks by reducing the risk of suboptimal model selection.

Moreover, PyOD 2's integration of 12 state-of-the-art neural models, refactored into a unified PyTorch framework, further underscores its commitment to providing a comprehensive and efficient OD solution. The enhanced performance and ease of use of these models, combined with the LLM-driven model selection, make PyOD 2 a powerful tool for both research and practical applications [15]. The demonstration of PyOD 2's capabilities, which includes the seamless integration of models like LUNAR and the effective guidance provided by the LLM, highlights its potential to significantly advance the field of OD by making sophisticated techniques more accessible and user-friendly.

## 4.2 Generative and Self-Supervised Approaches

### 4.2.1 GAN-inspired Event Outlier Detection
In the realm of event outlier detection, Generative Adversarial Networks (GANs) have emerged as a powerful tool, offering a novel approach to identifying anomalies in complex, high-dimensional data [16]. Unlike traditional methods that rely on predefined models or statistical thresholds, GANs leverage the adversarial training paradigm to learn the underlying distribution of normal events. This is achieved through a generator network that aims to synthesize data points that mimic the normal distribution, and a discriminator network that tries to distinguish between the generated data and the real data. The adversarial training process ensures that the generator becomes increasingly adept at producing realistic data points, effectively capturing the nuances of the normal event distribution.

The application of GANs in event outlier detection is particularly advantageous in scenarios where the data is inherently complex and the boundaries between normal and anomalous events are not well-defined [16]. By continuously refining the generator and discriminator, GAN-inspired methods can adapt to the evolving nature of event data, making them suitable for dynamic environments such as network traffic monitoring, financial transactions, and sensor data analysis. The key to the effectiveness of GAN-inspired outlier detection lies in the ability of the generator to identify and correct potential outliers in the data [16]. This is achieved through a feedback loop where the discriminator provides signals that guide the generator to improve its synthetic data, thereby enhancing the model's ability to detect anomalies.

However, the success of GAN-inspired event outlier detection is contingent on several factors, including the quality of the training data, the architecture of the GAN, and the optimization techniques used. To address these challenges, researchers have proposed various enhancements, such as using self-supervised learning to generate pseudo-labels for training, incorporating domain-specific knowledge to guide the training process, and employing advanced optimization algorithms to stabilize the training dynamics. These advancements have led to the development of more robust and versatile GAN-inspired models, capable of handling a wide range of event outlier detection tasks with high accuracy and reliability.

### 4.2.2 Self-Supervised Pseudo-Classification for OoD Detection
Self-Supervised Pseudo-Classification for Out-of-Distribution (OoD) Detection is a novel approach that leverages self-supervised learning to generate pseudo-labels for object instances, enabling the detection of anomalies that do not belong to the training distribution [17]. This method is particularly useful in scenarios where labeled data is scarce or expensive to obtain, making it a valuable addition to the unsupervised and semi-supervised outlier detection (OD) paradigms [18]. By clustering deep features extracted from an object localization network (OLN) and using these clusters to train a neural network, the approach can learn to assign pseudo-labels to objects, which are then used to fit class-conditional Gaussian distributions in the feature space [17]. This allows for the computation of an energy-based score that can be thresholded to identify outliers.

The key innovation in this approach lies in the alternating process of deep feature clustering and neural network-based prediction, which is similar to the DeepCluster method. The clustering step groups objects with similar features, while the prediction step refines the network's ability to assign accurate pseudo-labels. This iterative process ensures that the model can adapt to the distribution of the data over time, making it robust to changes in the data stream. The use of an energy-based score, derived from the class-conditional Gaussian distributions, provides a principled way to measure the anomaly of each object. This score is particularly effective in detecting outliers that are far from the learned distribution, thereby enhancing the model's ability to generalize to unseen data.

Experimental evaluations across diverse imaging modalities and applications have demonstrated the effectiveness of this self-supervised pseudo-classification approach. By leveraging the object localization network (OLN) as the backbone, the method can achieve high accuracy in detecting OoD objects while maintaining computational efficiency. The ability to learn object pseudo-labels in an unsupervised manner not only reduces the dependency on labeled data but also enables the model to adapt to new and unseen object categories. This makes the approach highly versatile and suitable for a wide range of real-world applications, from medical imaging to autonomous driving, where the detection of out-of-distribution objects is crucial for safety and performance.

### 4.2.3 UNO for Uncertainty and Negative Objectness
In the realm of unsupervised outlier detection (UOD), the concept of UNO (Uncertainty over K inlier classes and Negative Objectness) emerges as a powerful approach to address the challenges posed by the presence of outliers in complex datasets [19]. UNO leverages the ensemble of uncertainty measures over the K known inlier classes and introduces the notion of negative objectness, which serves as a posterior probability for a hypothetical K+1-th class representing outliers [19]. This dual formulation allows UNO to effectively capture the nuances of both in-distribution and out-of-distribution (OoD) data, thereby enhancing the robustness and accuracy of the outlier detection process [18].

The negative objectness component of UNO is particularly significant as it explicitly models the likelihood of a data point belonging to an unknown or anomalous class. By treating outliers as a distinct class, UNO can provide a more principled way to handle the inherent uncertainty associated with OoD data. This is achieved through the integration of prediction uncertainty over the K known classes, which complements the negative objectness score [19]. The interplay between these two components ensures that UNO is sensitive to different types of test outliers, making it a versatile tool for various applications, including image and video analysis, where the identification of unseen objects is crucial.

Moreover, the application of UNO in pixel-level anomaly detection demonstrates its effectiveness in localizing and identifying anomalous regions within images. This capability is particularly valuable in scenarios such as self-driving vehicles, where the detection of unexpected obstacles or animals is essential for safety. The robustness of UNO in handling the complexities of real-world data, combined with its ability to provide interpretable outlier scores, positions it as a promising approach in the field of unsupervised anomaly detection [18].

## 4.3 Early Stopping and Incremental Algorithms

### 4.3.1 Sliced-Wasserstein Distance for Anomaly Detection
The Sliced-Wasserstein Distance (SWD) has emerged as a powerful tool for anomaly detection, particularly in scenarios where the data distribution is complex and high-dimensional. Unlike traditional distance metrics that may struggle with the curse of dimensionality, SWD leverages the concept of optimal transport to provide a robust and computationally efficient measure of discrepancy between distributions. By projecting the high-dimensional data onto multiple one-dimensional slices, SWD reduces the computational complexity while preserving the essential structural information of the data. This property makes it particularly suitable for unsupervised anomaly detection tasks where the goal is to identify outliers that deviate significantly from the normal data distribution [18].

In the context of anomaly detection, SWD is used to compare the empirical distribution of the data with a reference distribution, typically derived from the inlier data. The reference distribution is often modeled using a generative model or a set of representative samples from the training data. The SWD between the empirical distribution of a test sample and the reference distribution is then computed, and a higher distance indicates a higher likelihood of the sample being an anomaly. This approach is particularly effective in handling class-imbalance and non-stationary data distributions, as it does not rely on explicit thresholding or density estimation, which can be sensitive to outliers and noise. Moreover, the differentiability of the SWD allows it to be integrated into deep learning frameworks, enabling end-to-end training of anomaly detection models [4].

Recent advancements in the application of SWD for anomaly detection have focused on enhancing its robustness and scalability. Techniques such as adaptive slicing, where the number and orientation of slices are dynamically adjusted based on the data characteristics, have been proposed to improve the accuracy of the distance metric. Additionally, the integration of SWD with other anomaly detection methods, such as autoencoders and generative adversarial networks (GANs), has shown promising results in various domains, including image and time-series data [15]. These hybrid approaches leverage the strengths of SWD in capturing distributional differences while benefiting from the feature extraction capabilities of deep learning models, leading to more robust and accurate anomaly detection systems.

### 4.3.2 GradStop for Unsupervised Outlier Detection
GradStop is a novel approach designed to enhance unsupervised outlier detection by integrating gradient-based stopping criteria with deep learning architectures. Unlike traditional unsupervised methods that rely solely on static thresholds or fixed hyperparameters, GradStop dynamically adjusts its decision boundaries based on the gradients of the model's loss function. This adaptive mechanism allows GradStop to better capture the intrinsic structure of the data, particularly in high-dimensional spaces where the distinction between inliers and outliers can be subtle. By leveraging the gradients, GradStop can identify regions of the feature space where the data distribution deviates significantly from the norm, thereby improving the precision and recall of outlier detection.

The core innovation of GradStop lies in its ability to incorporate gradient information during the training phase, which helps in refining the model's understanding of what constitutes an outlier. Specifically, GradStop uses a gradient-based criterion to determine when to stop updating the model parameters for a given data point. If the gradient magnitude for a particular data point is below a predefined threshold, it indicates that the model has sufficiently learned the characteristics of that point, and further updates are unnecessary. This stopping criterion not only optimizes the training process but also prevents overfitting to noisy or anomalous data points. Moreover, GradStop can be seamlessly integrated with various deep learning models, such as autoencoders and generative adversarial networks (GANs), enhancing their outlier detection capabilities without significant modifications to the underlying architecture [15].

In practice, GradStop has demonstrated superior performance in detecting outliers across a range of datasets, including those with complex and non-linear distributions. The dynamic nature of the gradient-based stopping criterion makes GradStop particularly effective in scenarios where the data distribution evolves over time, such as in streaming data applications. Additionally, GradStop's adaptability to different types of data and its compatibility with existing deep learning frameworks make it a versatile tool for unsupervised outlier detection. Future research directions include exploring the application of GradStop in semi-supervised settings and investigating its potential for real-time anomaly detection in large-scale systems.

### 4.3.3 Efficient Incremental Local Outlier Factor
The Efficient Incremental Local Outlier Factor (EILOF) algorithm is designed to address the computational inefficiencies associated with traditional Local Outlier Factor (LOF) methods in the context of streaming data [20]. Unlike the original LOF algorithm, which requires a full recalculation of reachability distances and LOF scores whenever new data points are added, EILOF updates these metrics incrementally. This incremental approach is crucial for real-time anomaly detection in high-frequency data streams, where the continuous arrival of new data points necessitates a dynamic and efficient update mechanism [20]. By focusing only on the new data points and their immediate neighborhood, EILOF minimizes the computational overhead, making it suitable for large-scale and resource-constrained environments.

EILOF achieves its efficiency through a carefully designed update procedure that leverages the existing neighborhood structures and reachability distances. When a new data point arrives, the algorithm first identifies its k-nearest neighbors and updates the reachability distances for these points. Subsequently, it recalculates the LOF scores for the new point and its neighbors, ensuring that the overall structure of the data remains consistent. This selective update strategy avoids the need for a full dataset scan, which is a significant bottleneck in traditional LOF implementations. Moreover, EILOF maintains a dynamic data structure to efficiently manage the neighborhood relationships, allowing for quick insertion and deletion of points as the data stream evolves.

The effectiveness of EILOF is further enhanced by its ability to adapt to changes in the data distribution over time. As the data stream progresses, the algorithm can dynamically adjust the neighborhood sizes and reachability distances to reflect the evolving patterns in the data. This adaptability is particularly important in scenarios where the underlying data distribution is non-stationary, such as in network traffic monitoring or financial market analysis. By maintaining an accurate and up-to-date representation of the data, EILOF ensures that the outlier detection process remains robust and reliable, even in the presence of concept drift. The combination of incremental updates and dynamic adaptation makes EILOF a powerful tool for real-time anomaly detection in streaming data environments [20].

# 5 Interpretable and Robust Anomaly Detection Techniques

## 5.1 Patch-Based and Diffusion Models

### 5.1.1 Patch-based Diffusion Model with Motion and Appearance Conditions
In this section, we introduce the Patch-based Diffusion Model with Motion and Appearance Conditions (MAPDM), a novel approach designed to address the challenges of video anomaly detection (VAD) in high-dimensional and complex video data [21]. The MAPDM decomposes video frames into distinct appearance and motion components, allowing for a more nuanced and accurate representation of the video content. The initial frame captures the static appearance attributes, such as color and texture, while subsequent frames capture the dynamic motion attributes, such as pixel displacements over time. This decomposition is crucial for isolating and analyzing the specific aspects of the video that contribute to anomalies.

The core of the MAPDM involves a patch-based approach, where both the appearance and motion frames are divided into smaller, manageable patches. Each patch is then processed independently to estimate the noise present in the video. By treating each patch separately, the model can effectively handle spatial variations and local anomalies that might be overlooked in a holistic frame-by-frame analysis. The estimated noise from each patch is subsequently combined and refined to form a comprehensive frame-level noise map. This noise map is then used in the denoising diffusion implicit model (DDIM) reverse step to reconstruct the clean, anomaly-free image. The use of patches allows the model to focus on localized features, enhancing its ability to detect subtle anomalies that may be indicative of abnormal behavior.

To further improve the robustness and accuracy of the MAPDM, we incorporate motion and appearance conditions into the diffusion process. These conditions guide the model in generating more realistic and contextually appropriate reconstructions. The motion conditions, derived from the temporal differences between consecutive frames, help the model understand the dynamics of the scene, while the appearance conditions ensure that the reconstructed images maintain the visual consistency of the original video. By integrating these conditions, the MAPDM can effectively distinguish between normal and anomalous behaviors, even in scenarios with complex backgrounds and varying lighting conditions. The combination of patch-based processing and condition-guided diffusion represents a significant advancement in the field of VAD, offering a more reliable and efficient method for detecting anomalies in video data [21].

### 5.1.2 Patch-Level Denoising for Unsupervised AD
Patch-level denoising represents a significant advancement in unsupervised anomaly detection (AD) by addressing the limitations of traditional sample-level denoising methods [22]. Unlike sample-level denoising, which treats entire data points uniformly, patch-level denoising focuses on smaller, localized regions within the data, allowing for more granular and context-aware noise reduction. This approach is particularly beneficial in high-dimensional and complex datasets, such as those encountered in video and image analysis, where anomalies can manifest in subtle, localized patterns that may be overlooked by broader, sample-level techniques.

In the proposed method, a denoising algorithm assigns an outlier factor to each patch, which is then used to construct a coreset memory bank [23]. This coreset serves as a representative subset of the data, capturing the essential characteristics while filtering out noise. By leveraging patch-level denoising, the method significantly improves the data usage rate compared to conventional sample-level denoising, as it retains more relevant information and reduces the impact of noisy samples. The use of a coreset memory bank also enhances computational efficiency, making the approach scalable for large datasets.

To further enhance robustness, the method incorporates three noise discriminators that operate in conjunction with the re-weighting of coreset examples. These discriminators help in distinguishing true anomalies from noise, thereby reducing false positives and improving the overall performance of the AD system. The integration of patch-level denoising with these discriminators sets a strong baseline for fully unsupervised industrial AD, demonstrating superior performance in both noisy and general settings [22]. This approach is particularly valuable in practical applications where data from production lines or other real-world environments are inherently noisy, and ensuring the reliability of AD systems is critical [22].

### 5.1.3 Cepstral Linear Discriminant Analysis for Robust Spectral Estimation
Cepstral Linear Discriminant Analysis (CLDA) represents a sophisticated approach to enhancing the robustness of spectral estimation in the presence of noise and outliers [24]. By integrating cepstral features, which capture the logarithmic spectrum of a signal, CLDA leverages the linear discriminant analysis (LDA) framework to maximize the separation between different classes while minimizing within-class variability [24]. This method is particularly advantageous in scenarios where traditional spectral estimation techniques, such as the Fourier transform, may fail to provide reliable estimates due to the presence of non-stationary noise or abrupt changes in the signal.

In the context of robust spectral estimation, CLDA addresses the limitations of conventional LDA by incorporating cepstral coefficients, which are known for their ability to represent the spectral envelope of a signal in a more stable and interpretable manner [24]. The cepstral domain transformation helps in reducing the impact of additive noise and preserving the essential characteristics of the signal. Furthermore, the use of cepstral features in CLDA facilitates the identification of subtle patterns and structures that might be obscured in the time or frequency domains. This is particularly useful in applications such as speech recognition, where the cepstral representation can effectively capture the formants and other phonetic features that are crucial for accurate classification.

To further enhance the robustness of CLDA, several modifications and extensions have been proposed. For instance, the Mcepstral estimator, a variant of the cepstral estimator, has been developed to provide more reliable spectral estimates in the presence of heavy-tailed noise distributions. The Mcepstral estimator uses robust statistical techniques, such as the M-estimation framework, to downweight the influence of outliers and improve the overall stability of the spectral estimates. Additionally, the integration of multitaper methods and wavelet-based approaches has been explored to combine the strengths of multiple spectral estimation techniques, thereby providing a more comprehensive and robust solution for spectral analysis in complex and noisy environments.

## 5.2 Fairness and Explainability

### 5.2.1 Disparate Impact Ratio for Anomaly Detection
The Disparate Impact Ratio (DIR) is a critical metric for evaluating the fairness of anomaly detection algorithms, particularly in applications where the outcomes can have significant social and ethical implications. DIR measures the overrepresentation of a protected group (or its complement) in the set of anomalies detected by an algorithm. This metric is essential because it helps to identify whether certain groups are disproportionately flagged as anomalies, which can lead to unfair treatment or discrimination. By quantifying the extent to which a protected group is overrepresented, DIR provides a quantitative basis for assessing the fairness of anomaly detection systems.

In our experimental setup, we compute the DIR by comparing the proportion of anomalies detected within a protected group to the proportion of anomalies detected in the overall population. A DIR value significantly greater than 1 indicates that the protected group is overrepresented in the anomaly set, suggesting potential bias in the algorithm. Conversely, a DIR value significantly less than 1 suggests that the protected group is underrepresented, which may also indicate a form of bias. We apply this metric across various datasets and algorithms to systematically evaluate the fairness of different anomaly detection methods. Our findings reveal that the interaction between the dataset and the algorithm plays a crucial role in determining the DIR, highlighting the importance of dataset selection and algorithm design in ensuring fair outcomes.

To further understand the "Why" behind the observed disparities, we investigate four main factors that contribute to group-level unfairness: incompressibility, sample size bias, feature representation, and algorithmic sensitivity. Incompressibility refers to the inherent difficulty in representing certain groups accurately within the feature space, leading to higher anomaly scores. Sample size bias occurs when the protected group is underrepresented in the training data, resulting in a model that is less robust to variations within that group. Feature representation issues arise when the features used by the algorithm are not equally informative for all groups, leading to biased anomaly detection. Lastly, algorithmic sensitivity refers to the degree to which an algorithm is influenced by small variations in the input data, which can disproportionately affect certain groups. By addressing these factors, we aim to develop more equitable and reliable anomaly detection systems.

### 5.2.2 SHAP under Differential Privacy
Differential Privacy (DP) is a framework designed to protect individual privacy in data analysis by adding controlled noise to the data or the output of algorithms. In the context of Explainable AI (XAI), particularly with SHapley Additive exPlanations (SHAP), the integration of DP introduces a layer of complexity that affects the fidelity and stability of the explanations. SHAP values, which are used to attribute the prediction of a machine learning model to its input features, are inherently sensitive to small changes in the input data. Therefore, the addition of DP noise can significantly alter the SHAP values, leading to less accurate and less stable explanations.

To investigate the impact of DP on SHAP values, we formulate two primary research questions: (1) How does increasing DP noise affect the fidelity and stability of SHAP values in anomaly detection (AD)? [25] (2) What are the implications of these changes for the interpretability and trustworthiness of the AD models? We conduct extensive experiments to quantify the degradation of SHAP values as the level of DP noise increases. Our results show that while DP noise effectively preserves privacy, it can lead to a notable reduction in the fidelity of SHAP values, making it challenging to accurately attribute model predictions to specific features.

To address these challenges, we explore various strategies to mitigate the impact of DP noise on SHAP values [25]. These strategies include adjusting the noise scale, using advanced DP mechanisms such as the Gaussian mechanism, and employing post-processing techniques to refine the SHAP values. Our findings suggest that a balanced approach, where the noise level is carefully calibrated, can maintain a reasonable level of privacy while preserving the interpretability of the AD models. Additionally, we propose a framework for evaluating the trade-offs between privacy, accuracy, and interpretability, which can guide the selection of appropriate DP parameters for different AD applications [25].

### 5.2.3 Hierarchical Robust Principal Component Analysis
Hierarchical Robust Principal Component Analysis (HrPCA) represents a significant advancement in the field of anomaly detection for high-dimensional, unlabeled movement datasets. Unlike traditional Robust Principal Component Analysis (RPCA), which focuses on decomposing a data matrix into a low-rank component and a sparse component, HrPCA extends this framework to a hierarchical setting [26]. This extension allows for the simultaneous modeling of low-rank structures at multiple levels of data aggregation, thereby providing a more nuanced and accurate representation of the underlying data. By isolating unexpected deviations as sparse anomalies at each level, HrPCA enhances the ability to detect subtle and complex anomalies that might be overlooked by conventional methods.

The hierarchical nature of HrPCA is particularly advantageous in scenarios where data is collected from multiple sources or sensors, each contributing different types of information. For instance, in movement data analysis, different sensors might capture various aspects of movement, such as acceleration, velocity, and orientation. HrPCA can effectively aggregate these diverse data streams, ensuring that the low-rank components reflect the true underlying movement patterns while the sparse components capture deviations that indicate potential anomalies. This approach is especially useful in environments where data quality varies across sensors, as it can robustly handle noisy or corrupted data without compromising the overall analysis.

Moreover, HrPCA offers a scalable and interpretable solution for detecting data quality (DQ) issues in complex data pipelines [26]. By decomposing the data at multiple levels, HrPCA can pinpoint the exact sources of anomalies, whether they originate from individual sensors, specific regions, or entire data streams. This fine-grained anomaly detection capability is crucial for maintaining the integrity of downstream systems that rely on aggregated data for decision-making. The mathematical rigor of HrPCA ensures that the detected anomalies are not only statistically significant but also meaningful in the context of the specific application domain, making it a powerful tool for enhancing the reliability and trustworthiness of data-driven systems [26].

## 5.3 Depth-Weighted and Multilevel Approaches

### 5.3.1 Depth-Weighted Loss for Anomaly Detection
In the realm of anomaly detection, the challenge of detecting anomalies that are not immediately apparent is exacerbated by the variability in the representation of normal and anomalous events, especially in scenarios involving movement data from multiple camera perspectives. To address this, a novel depth-weighted loss function has been proposed, which aims to enforce equivalent importance to events irrespective of their distance from the camera. This approach is particularly useful in scenarios where the scale and perspective of the observed events can significantly affect the anomaly detection performance. By utilizing the training outliers to determine the anomaly threshold, the depth-weighted loss function ensures that the model remains robust to variations in the input data, thereby improving the detection of subtle anomalies [18].

The depth-weighted loss function is integrated into three different existing anomaly detection methods, creating what we refer to as their depth variants. These variants are designed to leverage the structural information provided by the movement taxonomy, which aggregates variables into coherent movement behaviors [27]. This integration not only enhances the ability of the models to detect anomalies but also aligns the feature representation with the hierarchical structure of the taxonomy, leading to more interpretable and contextually relevant anomaly scores. The effectiveness of the depth-weighted loss is evaluated through a comprehensive comparison with the original methods, demonstrating significant improvements in anomaly detection accuracy, particularly in complex and diverse datasets.

To further validate the proposed approach, an ablation analysis is conducted to investigate the individual contributions of the depth-weighted loss and the impact of frame size and frame rate on the detection of behaviors of risk [28]. The results of this analysis provide insights into the optimal configuration of the anomaly detection system, highlighting the importance of considering both the temporal and spatial aspects of the input data [4]. Additionally, the integration of the depth-weighted loss into multiple anomaly detection methods showcases its versatility and potential for broader application in various anomaly detection tasks, particularly in scenarios where the data is inherently multidimensional and complex.

### 5.3.2 Multilevel Taxonomical Approach for Movement Data
In the context of analyzing high-dimensional, unlabeled movement data, the multilevel taxonomical approach provides a structured framework to systematically categorize and interpret the complex patterns inherent in such data [27]. This approach leverages a hierarchical taxonomy that decomposes movement data into multiple levels of abstraction, from basic kinematic features to higher-order behavioral patterns. By organizing the data into a taxonomy, the method facilitates the identification of meaningful substructures within the data, which can be crucial for uncovering hidden relationships and anomalies.

The multilevel taxonomical approach begins with the extraction of low-level features, such as position, velocity, and acceleration, which are then aggregated into more complex descriptors, such as trajectories and activity sequences. These descriptors are further classified into higher-order categories, such as movement styles, behaviors, and interactions. Each level of the taxonomy is designed to capture specific aspects of the movement data, allowing for a nuanced and comprehensive analysis [27]. For instance, at the trajectory level, the taxonomy might include categories for linear, circular, and erratic movements, while at the behavior level, it could encompass actions like walking, running, and jumping.

By applying this multilevel taxonomical approach, researchers can effectively reduce the dimensionality of the movement data while preserving the essential characteristics that are relevant for analysis. This reduction not only simplifies the data but also enhances the interpretability of the results, making it easier to identify and understand the underlying patterns. Furthermore, the hierarchical structure of the taxonomy enables the integration of domain-specific knowledge, which can guide the analysis and help in the development of more accurate and meaningful models for movement data. This approach is particularly useful in applications such as anomaly detection, where the ability to distinguish between normal and abnormal patterns is critical [1].

### 5.3.3 Mahalanobis Distance for Brain MRI Anomaly Detection
The Mahalanobis Distance (MHD) has emerged as a powerful tool for anomaly detection in brain MRI scans, offering a robust method to quantify the deviation of individual pixels from a learned distribution of healthy tissue. Unlike traditional Euclidean distance, which assumes equal variance across dimensions, MHD accounts for the covariance structure of the data, making it particularly suitable for high-dimensional medical imaging data. In the context of brain MRI anomaly detection, the MHD is calculated by measuring the distance of each pixel in the input image from the distribution of pixels in a set of healthy reconstructions [29]. This approach leverages the fact that generative models, such as denoising diffusion probabilistic models (DDPMs), can generate a pseudo-healthy reference distribution that closely approximates the characteristics of healthy brain tissue.

The integration of MHD with DDPMs involves training the generative model on a dataset of healthy brain MRI scans to learn the underlying distribution of healthy pixels. Once trained, the model generates multiple reconstructions of the input image, which are then used to compute the MHD for each pixel. The MHD effectively captures the degree to which each pixel deviates from the learned healthy distribution, allowing for the identification of regions in the MRI scan that exhibit anomalous behavior. This method is particularly advantageous because it can detect subtle variations that might be missed by simpler distance metrics, thereby improving the sensitivity and specificity of anomaly detection in brain MRI scans.

Moreover, the application of MHD in the pixel space, rather than at the sample level, enables a fine-grained analysis of the input image, facilitating the localization of anomalies with high precision [29]. This is crucial in clinical settings, where the accurate identification and localization of abnormalities can significantly impact diagnosis and treatment planning. The use of MHD in conjunction with DDPMs not only enhances the robustness of the anomaly detection process but also provides a principled approach to handling the inherent variability and complexity of brain MRI data. This combination represents a promising advancement in the field, offering a more reliable and interpretable method for detecting and characterizing anomalies in brain MRI scans.

# 6 Future Directions


The current landscape of anomaly detection, while rich with advancements, still faces several limitations and gaps. Despite the progress in integrating pre-trained models, vision and language integration, and deep learning techniques, there remains a significant challenge in handling the dynamic and evolving nature of real-world data. Many existing methods struggle with adapting to non-stationary data distributions, which are common in applications such as cybersecurity and industrial monitoring. Additionally, the reliance on large amounts of labeled data for training remains a bottleneck, particularly in domains where labeled anomalies are rare or costly to obtain. Another critical gap is the lack of robustness and interpretability in many advanced models, which hinders their adoption in safety-critical applications.

To address these limitations, several directions for future research are proposed. Firstly, developing more adaptive and scalable algorithms that can handle non-stationary data distributions is crucial. This could involve the integration of online learning and continual learning techniques, which allow models to update their parameters in real-time as new data arrives. Such algorithms would be particularly valuable in dynamic environments where the data characteristics change frequently. Secondly, there is a need for more effective methods to generate synthetic anomalies, which can be used to augment the training data and improve the model's ability to generalize to unseen anomalies. This could involve the use of generative models, such as GANs, to create realistic and diverse synthetic anomalies that capture the complexity of real-world scenarios.

Thirdly, enhancing the interpretability and explainability of anomaly detection models is essential for building trust and ensuring transparency. Techniques such as attention mechanisms, saliency maps, and post-hoc explanation methods can be integrated into deep learning models to provide insights into the decision-making process. Additionally, developing fairness-aware anomaly detection algorithms that minimize disparate impact on protected groups is a critical area of research. This involves not only detecting and mitigating biases in the data but also designing algorithms that are inherently fair and equitable.

The potential impact of the proposed future work is significant. More adaptive and scalable algorithms will enable real-time anomaly detection in dynamic and complex environments, enhancing the responsiveness and reliability of monitoring systems. Effective synthetic anomaly generation will reduce the dependence on labeled data, making anomaly detection more accessible and cost-effective. Enhanced interpretability and explainability will foster greater trust in the models, making them more acceptable in critical applications such as healthcare and finance. Finally, fairness-aware algorithms will ensure that anomaly detection systems are equitable and just, promoting broader societal acceptance and ethical use of these technologies. Together, these advancements will drive the field of anomaly detection towards more robust, efficient, and trustworthy solutions.

# 7 Conclusion



The survey on the latest developments in outlier and anomaly detection methods has provided a comprehensive overview of the current state-of-the-art techniques, with a focus on the integration of pre-trained models, vision and language integration, deep learning and dimensionality reduction, and efficient and adaptive algorithms. Key findings include the effectiveness of sequence contrast methods in time-series anomaly detection, the robustness of Random Forest-based approaches like RFuni in handling high-dimensional and imbalanced datasets, and the enhancement of anomaly detection through post-hoc calibration techniques. Vision and language models, such as VLMs, have shown significant improvements in precision and recall by leveraging textual prompts and abnormal pseudo-samples. Deep learning and dimensionality reduction techniques, including DeepHYDRA and CON2, offer balanced solutions for handling high-dimensional and dynamic data streams. Efficient and adaptive algorithms, such as EHBOS and GradStop, address the computational and practical challenges of real-time anomaly detection, ensuring both performance and scalability.

The significance of this survey lies in its contribution to the field of anomaly detection by synthesizing recent research and providing a structured and detailed resource for researchers, practitioners, and students. The survey highlights the advancements in integrating advanced machine learning and deep learning techniques, which have significantly improved the accuracy and robustness of anomaly detection systems. By addressing the limitations of traditional methods and exploring novel approaches, the survey offers valuable insights into the current landscape and identifies key areas for future research. The integration of fairness and explainability in anomaly detection systems, the development of more adaptive and scalable algorithms, and the application of advanced techniques to new and emerging domains are highlighted as critical areas for further investigation.

In conclusion, this survey underscores the importance of continuous innovation and interdisciplinary collaboration in advancing the field of anomaly detection. It calls for the development of more adaptive and scalable algorithms that can handle the complexity and volume of modern datasets. Additionally, the integration of fairness and explainability is essential to ensure that anomaly detection systems are not only accurate but also reliable and trustworthy. Researchers and practitioners are encouraged to explore the promising directions identified in this survey, such as the application of advanced techniques to new domains and the development of more robust and interpretable models. By addressing these challenges, the field of anomaly detection can continue to evolve and meet the growing demands of various applications, from finance and healthcare to cybersecurity and industrial monitoring.

# References
[1] Extended Histogram-based Outlier Score (EHBOS)  
[2] Anomaly Detection by Context Contrasting  
[3] DeepHYDRA  Resource-Efficient Time-Series Anomaly Detection in  Dynamically-Configured Systems  
[4] Can Tree Based Approaches Surpass Deep Learning in Anomaly Detection  A  Benchmarking Study  
[5] Deep evolving semi-supervised anomaly detection  
[6] RoCA  Robust Contrastive One-class Time Series Anomaly Detection with  Contaminated Data  
[7] Improved AutoEncoder with LSTM module and KL divergence  
[8] VL4AD  Vision-Language Models Improve Pixel-wise Anomaly Detection  
[9] Enhancing Anomaly Detection Generalization through Knowledge Exposure   The Dual Effects of Augmenta  
[10] AA-CLIP  Enhancing Zero-shot Anomaly Detection via Anomaly-Aware CLIP  
[11] Interpretable Transformation and Analysis of Timelines through Learning  via Surprisability  
[12] Class Imbalance in Anomaly Detection  Learning from an Exactly Solvable  Model  
[13] Research on Dynamic Data Flow Anomaly Detection based on Machine  Learning  
[14] MVG-CRPS  A Robust Loss Function for Multivariate Probabilistic  Forecasting  
[15] PyOD 2  A Python Library for Outlier Detection with LLM-powered Model  Selection  
[16] Unsupervised Event Outlier Detection in Continuous Time  
[17] Towards Open-World Object-based Anomaly Detection via Self-Supervised  Outlier Synthesis  
[18] GradStop  Exploring Training Dynamics in Unsupervised Outlier Detection  through Gradient Cohesion  
[19] Outlier detection by ensembling uncertainty with negative objectness  
[20] An Efficient Outlier Detection Algorithm for Data Streaming  
[21] Video Anomaly Detection with Motion and Appearance Guided Patch  Diffusion Model  
[22] SoftPatch+  Fully Unsupervised Anomaly Classification and Segmentation  
[23] SoftPatch  Unsupervised Anomaly Detection with Noisy Data  
[24] Discriminant Analysis in stationary time series based on robust cepstral  coefficients  
[25] Differential Privacy for Anomaly Detection  Analyzing the Trade-off  Between Privacy and Explainabil  
[26] Hierarchical Robust PCA for Scalable Data Quality Monitoring in  Multi-level Aggregation Pipelines  
[27] A Novel Multilevel Taxonomical Approach for Describing High-Dimensional  Unlabeled Movement Data  
[28] Depth-Weighted Detection of Behaviours of Risk in People with Dementia  using Cameras  
[29] Leveraging the Mahalanobis Distance to enhance Unsupervised Brain MRI  Anomaly Detection  