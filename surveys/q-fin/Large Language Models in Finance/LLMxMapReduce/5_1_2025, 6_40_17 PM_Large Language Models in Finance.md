# 5/1/2025, 6:40:17 PM_Large Language Models in Finance 0. Large Language Models in Finance  

# 1. Introduction  

The financial industry, characterized by its complexity, reliance on information, and rapid evolution, has historically been a fertile ground for the application of Artificial Intelligence (AI). The landscape of AI in finance has evolved significantly, moving beyond traditional statistical methods and machine learning models to more sophisticated approaches [6,8,18]. The advent of Large Language Models (LLMs) marks a transformative phase, offering unprecedented capabilities in understanding, processing, and generating human language [34]. These models, leveraging deep learning advancements, are increasingly recognized for their potential to revolutionize various facets of the financial sector, from back-office operations and customer interfaces to complex analytical tasks [1,27].  

The growing interest in applying LLMs to finance stems from their potential to address inherent challenges and enhance efficiency, reduce costs, and improve decision-making processes [3,18,29,31]. LLMs offer advantages such as improved model structure, reduced data dependency, expanded application scenarios, and enhanced interpretability compared to traditional AI methods [12]. Their ability to process vast amounts of text data and understand context makes them particularly valuable in a domain heavily reliant on textual information, such as news articles, reports, and regulations [3,12].  

<html><body><table><tr><td>Application Area</td><td>Description</td></tr><tr><td>Financial Sentiment Analysis</td><td>Quantifying market sentiment from text sources.</td></tr><tr><td>Financial Time Series Forecasting</td><td>Predicting market trends & classifying data.</td></tr><tr><td>Financial Advisory</td><td>Providing investment recommendations and guidance.</td></tr><tr><td>Regulatory Interpretation</td><td>Assisting with understanding and implementing regulations.</td></tr><tr><td>Financial Statement Analysis</td><td>Analyzing documents like earnings reports.</td></tr><tr><td>Risk Management and Prediction</td><td>ldentifying,assessing,and forecasting various risks.</td></tr><tr><td>Intelligent Agents Development</td><td>Creating autonomous systems for financial tasks.</td></tr></table></body></html>  

Potential applications span a wide range, including financial sentiment analysis [26,32], financial time series forecasting [5], financial advisory [14,28], regulatory interpretation [25], financial statement analysis [23,33], risk management and prediction [4,24], and the development of intelligent agents for diverse financial tasks [15,21]. This transformative potential is driving the adoption of generative AI in banking and corporate finance [6,22], and is supported by initiatives promoting technology integration within the financial sector [19].  

Despite their promise, the direct application of general-purpose LLMs to financial tasks faces significant challenges. Traditional methods often struggle with the nuances of financial language, numerical sensitivity, complex time dependencies, and the need for deep domain-specific knowledge [5,24]. While powerful, general LLMs may exhibit inconsistencies, unreliability, and a lack of domain-specific understanding when applied without adaptation to financial contexts [21,28]. The complexity and unique terminology of finance necessitate domain-specific models or adaptation techniques to achieve reliable and accurate performance [2,30]. Challenges also include managing data complexity and noise, handling multimodal data (like tables and time series), ensuring interpretability and explainability, addressing computational resource demands, and mitigating risks related to bias, fairness, and data security [22,24,27,30,37].  

This survey aims to provide a comprehensive overview of the current state of research on Large Language Models in finance, highlighting their progress, prospects, and challenges [3,12,29]. Specifically, the objectives are to synthesize existing knowledge on LLM applications across key financial domains, analyze the methodologies employed, identify the primary challenges hindering widespread adoption and reliable performance, explore emerging opportunities, and discuss future research directions and considerations for responsible deployment [29]. By systematically reviewing the literature, this survey provides a structured perspective for researchers and practitioners, laying a foundation for further innovation and guiding decision-making regarding the suitability and responsible adoption of LLMs for specific financial tasks [12,29]. The survey contributes by offering a holistic view of financial LLMs, covering aspects from models and data to applications and evaluation, and highlighting novel challenges and opportunities in this rapidly evolving field [3,7].​  

The remainder of this survey is organized as follows. Section  provides background on Large Language Models. Section categorizes and details the diverse applications of LLMs across key areas of finance, such as . Section  discusses various approaches for adapting and deploying LLMs in finance, including domain-specific models and finetuning techniques. Section  analyzes the challenges and limitations associated with using LLMs in financial contexts, including technical, ethical, and regulatory considerations. Finally, Section  explores future directions and opportunities for research and practical adoption.  

# 2. Overview of Large Language Models  

![](images/fa809a1abd05ec07aeb2478fa7b2cc5fd6c58105b9a659145462df5d4e891423.jpg)  

The field of artificial intelligence has witnessed a significant evolution, progressing from early rule-based systems and traditional machine learning models to the current era dominated by generative AI and large language models (LLMs) [17,27]. Historically, language models aimed to predict the probability distribution of word sequences, often using statistical methods like n-gram models [29]. The advent of deep learning brought about models based on Recurrent Neural Networks (RNNs), such as LSTMs and GRUs, which improved handling sequential data but faced challenges with long-range dependencies and parallel processing [24,29]. This evolution can be broadly categorized into stages, including an initial stage (associated with models like CNNs), an exploration stage marked by the emergence of Transformers, and an explosive stage led by models like the GPT series [12,18].​  

A pivotal paradigm shift occurred with the introduction of the Transformer architecture, described in the paper "Attention is All You Need" [9,24,36]. Unlike previous architectures that relied on recurrence or convolution, the Transformer is built entirely upon the attention mechanism [24]. The architecture typically consists of an encoder and a decoder. The encoder processes the input sequence using layers of self-attention and feed-forward networks, extracting features layer by layer to perform semantic analysis [9,24]. The decoder, also employing attention mechanisms, generates the output sequence, often predicting word probabilities [9].​  

The core innovation of the Transformer is the self-attention mechanism, which allows the model to weigh the importance of different words in the input sequence when processing a specific word, regardless of their distance [3,9,10,24]. This capability enables the model to effectively capture long-range dependencies within sequential data, which was a significant limitation for previous RNN-based models [3,9,24,36]. Multi-headed attention enhances this process by allowing the model to attend to different parts of the input simultaneously and extract contextual information from multiple perspectives [34]. This mechanism also facilitates parallel processing, significantly improving training efficiency [9].​  

The efficacy of LLMs is largely attributed to their extensive pre-training on massive and diverse text datasets, encompassing books, articles, and vast text corpora [5,10,29,34]. The objective of this pre-training is typically to learn the underlying patterns and structure of human language, often through tasks like predicting the next word in a sequence (autoregressive models like GPT) or masked language modeling (like BERT) [18,21,29,36]. This process allows LLMs to develop a sophisticated understanding of context and semantics [3,10]. Following pre-training, models may undergo fine-tuning on specific datasets or instruction-based learning, sometimes incorporating human feedback, to align their responses with desired behavior and improve task performance [5,34].​  

Key general-purpose LLMs include the GPT series (e.g., GPT-3, GPT-4, ChatGPT), BERT, PaLM, Claude 3, and T5, among others [2,3,7,10,29,34]. These models exhibit remarkable general capabilities, including advanced contextual understanding, customizable functionalities, and scalable real-time analysis [3,10]. A notable strength is their ability to perform zero-shot and few-shot learning, enabling them to tackle new tasks with minimal or no task-specific training data by leveraging knowledge acquired during pre-training [2,10,17]. They can process and interpret natural language, generate coherent and relevant text, and perform tasks such as summarization, translation, reasoning, and even code generation [11,18,21,36]. This versatility positions LLMs as powerful tools capable of understanding, generating, and reasoning with various forms of data.  

# 3. Large Language Models for Finance: Specialization and Landscape  

The application of large language models (LLMs) in the financial domain necessitates either the adaptation of generalpurpose models or the development of specialized, finance-specific LLMs. While general LLMs, such as GPT-4o and ChatGPT3.5, have demonstrated capabilities in understanding and processing text [11,26], their limitations for specialized financial tasks become apparent due to the finance industry's unique jargon, complex regulations, and domain-specific data structures [32]. General models may struggle with the nuances of financial language, detailed analysis of complex financial documents, and the high accuracy required for critical applications [1]. Consequently, customizing general LLMs or creating models trained explicitly on financial corpora is crucial to enhance performance in areas like financial sentiment analysis, forecasting, and regulatory interpretation [5,21,26]. This trend signifies a shift towards vertical development, moving from broad general models to industry-specific and domain-specific applications [18].  

![](images/acc6ad82f47688b11a7eb7eafcf1098c4e6db7f7e31df19a999f78824f2e9c1d.jpg)  

The landscape of financial LLMs includes both adapted general models and purpose-built financial models, exhibiting diverse technical designs and training methodologies [3,10]. Prominent examples of financial-specific models include BloombergGPT, FinBERT, FinGPT, FinLLaMA, FinLLaVA, BBT-FinT5, and XuanYuan 2.0 [2,3,10,30]. BloombergGPT, a 50-billionparameter model, utilizes a hybrid training approach, combining a massive financial-specific dataset (FinPile, 363 billion tokens from Bloomberg's proprietary sources) with general datasets (345 billion tokens from sources like The Pile, C4, and Wikipedia) [2]. This hybrid strategy aims to balance general language understanding with deep domain expertise. In contrast, FinBERT, a customized version of BERT, is primarily pre-trained and fine-tuned on extensive financial datasets [10,28]. Variants like FinBERT-19, FinBERT-20, and FinBERT-21 demonstrate different pre-training strategies, including continued pre-training on financial texts, focusing on financial communications, and hybrid domain pre-training leveraging both general and financial corpora [3]. BBT-FinT5, tailored for the Chinese financial sector, incorporates knowledgeenhanced pre-training methods alongside a large financial corpus [3].  

The impact of specialized training data on model performance is a critical factor. Models trained on large, domain-specific datasets demonstrate enhanced understanding and generation capabilities for financial content [10]. BloombergGPT's reliance on Bloomberg's vast proprietary data is a key aspect of its design [2,7]. Similarly, FinLLaMA is pre-trained on 52 billion tokens of financial corpus, uniquely combining text, tables, and time-series data, enabling it to outperform models like LLaMA3 and BloombergGPT in zero-shot and few-shot settings on various financial datasets [30]. The FinGPT framework adopts a data-centric approach, emphasizing the importance of accessible, cleaned, and preprocessed real-time financial data [7]. This highlights that not only the size but also the type and quality of specialized data significantly influence the model's domain proficiency.​  

Adaptation techniques play a crucial role in tailoring both general and financial-specific LLMs for downstream tasks. Finetuning, including standard fine-tuning and instruction tuning, is a common method to improve performance on specific financial applications [10,29]. Instruction tuning, as applied to FinGPT and LLaMA models, converts supervised financial sentiment data into instruction formats to enhance task-specific capabilities [5,10]. Domain adaptation, often achieved through continued pre-training on financial texts or hybrid tuning strategies as seen in XuanYuan 2.0, helps models better comprehend the domain's language and context [3]. Efficient fine-tuning techniques like Low-Rank Adaptation (LoRA) and quantization are also employed to enable adaptation with reduced computational resources [10,29], making it feasible to adapt even smaller base models to achieve performance comparable to larger ones [10,31]. Retrieval-Augmented Generation (RAG) modules can further enhance performance by providing richer context, as demonstrated with instructiontuned LLMs in financial sentiment analysis [10].  

Researchers and practitioners face a trade-off between using fine-tuned general models and pre-trained financial-specific models [3,10]. General-purpose LLMs can be accessed via APIs or open-source releases, offering flexibility and potentially lower initial development costs [29]. Examples include the use of ChatGPT/GPT-4 for summarizing financial documents, financial statement analysis, and predicting equity premiums [11,23,33]. However, fine-tuning or instruction tuning is often necessary to align these models with financial domain requirements and improve performance on specific tasks [5,10]. Financial-specific models, while requiring significant investment in data collection and training, are generally designed to inherently understand and process financial information more effectively due to their specialized training data and sometimes modified architectures [3,10]. Studies suggest that well-designed financial-specific models or even fine-tuned smaller general models can achieve superior or comparable performance to larger, general models on domain-specific tasks [10,30,31].​  

The market also features both proprietary and open-source financial LLMs, each with distinct benefits and limitations [2,7,19]. Proprietary models, such as BloombergGPT and platforms developed by major banks like ICBC and Agricultural Bank of China [2,19], often leverage exclusive or difficult-to-access financial data, potentially providing a performance edge in certain domain tasks [7,20]. However, their closed nature limits transparency, reproducibility, and customization by external researchers and developers. Open-source financial LLMs and frameworks like FinGPT, FinLLaMA, and models like DeepSeek-R1, LLaMA, BLOOM, Flan-T5, Qwen, 智鹿, and Tongyi Qianwen used by various institutions [7,20,29,30], offer greater flexibility, privacy, and foster collaborative development and innovation [20,29]. They enable researchers to inspect model architectures, experiment with training data and techniques, and build upon existing models. While some opensource models may currently exhibit a performance gap compared to top-tier proprietary models, their lower cost, adaptability, and community-driven improvements are significant advantages [20,29]. The emergence of multimodal financial models like FinLLaVA, capable of processing tables and charts, further expands the capabilities of specialized opensource models in handling complex financial data types [30].  

# 4. Applications of LLMs in Finance  

Large Language Models (LLMs) are rapidly transforming the financial sector by offering innovative solutions across a diverse range of applications [3,10,19]. These models are increasingly leveraged to process and analyze complex financial data, automate tasks, enhance decision-making, and improve customer interactions, driving significant advancements in efficiency, accuracy, and insight generation [12,18,27].  

<html><body><table><tr><td>Major Application Area</td><td>Examples of Tasks</td></tr><tr><td>Text Analysis</td><td>Sentiment Analysis, Information Extraction, Summarization</td></tr><tr><td>Prediction and Forecasting</td><td>Time Series Forecasting, Earnings Prediction</td></tr><tr><td>Risk Management& Compliance</td><td>Credit/Market Risk, Fraud Detection, Regulatory Adherence</td></tr><tr><td>Trading& Investment Analysis</td><td>Strategy Optimization, Portfolio Building, Research</td></tr><tr><td>Customer Service& Interaction</td><td>Chatbots,Virtual Assistants,Personalized Advice</td></tr><tr><td>Financial Analysis & Reporting</td><td>Statement Analysis, Report Generation</td></tr><tr><td>Intelligent Agents</td><td>Autonomous Decision-Making, Task Automation</td></tr></table></body></html>  

Key application areas span from analyzing textual information for market sentiment and extracting insights from financial documents to forecasting market trends using time series and contextual data, managing risks, detecting fraudulent activities, supporting trading and investment analysis, enhancing customer service through intelligent chatbots, automating reporting, and enabling sophisticated decision-making through LLM-based agents [1,3,4,5,6,9,10,16,19,21,23,28,32,33]. This section organizes and details the state-of-the-art applications of LLMs in finance, examining the specific tasks performed, the benefits realized, the techniques employed, the data sources utilized (including textual, numerical, and multimodal data), and the reported performance and challenges within each domain [3,10,19]. By comparing and contrasting different LLM-based approaches and evaluating common datasets and metrics, this section provides a structured overview of the current landscape and identifies potential areas for future improvement and research.  

# 4.1 Financial Sentiment Analysis  

Financial sentiment analysis constitutes a significant application area for Large Language Models (LLMs) in the finance domain, facilitating the quantification of market sentiment from diverse textual sources [3,5,10]. These sources encompass financial news, social media platforms, corporate disclosures, reports, and earnings call transcripts [3,5,8,10,26,31]. By analyzing these texts, often involving millions of headlines [11] or specific datasets like Twitter financial news and FiQA [5], LLMs provide crucial insights into market trends and support informed investment decisions [3,10]. The historical progression in sentiment analysis, from early rule-based systems to machine learning models and subsequently to deep learning methods leveraging large pre-trained models, underscores the increasing sophistication in capturing complex emotional states and achieving accurate interpretations [10].  

<html><body><table><tr><td>Technique</td><td>Description</td></tr><tr><td>General LLMs (Direct Use)</td><td>Classifying sentiment or predicting impact using models like ChatGPT.</td></tr><tr><td>Domain-Specific LLMs</td><td>Utilizing models pre-trained on financial data (e.g., BloombergGPT, FinBERT).</td></tr><tr><td>Instruction Tuning</td><td>Adapting LLMs to understand financial contexts and interpret numerical values.</td></tr><tr><td>Prompt Engineering</td><td>Designing specific prompts for classification, though challenging for complex texts.</td></tr><tr><td>Zero/Few-Shot Learning</td><td>Classifying sentiment with minimal or no task-specific examples.</td></tr><tr><td>Retrieval-Augmented LLMs (RALMs)</td><td>Enhancing context by retrieving external financial knowledge.</td></tr></table></body></html>  

A variety of LLMs and techniques are currently employed for financial sentiment analysis. General-purpose models such as ChatGPT-3.5 have been utilized to classify the sentiment of news headlines, predicting their potential impact on the stock market as "UP," "DOWN," or "UNCERTAIN" [11]. Similarly, GPT-3.5 and subsequent versions are applied to predict stock returns based on news headline sentiment [8]. Domain-specific models like BloombergGPT have demonstrated strong performance on internal sentiment analysis tasks [2], while comparisons are also made against other specialized models such as FinBERT when analyzing sources like financial news and company announcements [26]. Various techniques are applied to adapt LLMs for this domain. Instruction tuning is a notable method employed to enhance LLMs' capability to interpret numerical values and improve their understanding of specific financial contexts, thereby boosting the accuracy of sentiment prediction [3,5,32]. Prompt engineering is another critical technique, though effectively classifying sentiment in complex financial texts via prompting presents practical challenges [26]. Additionally, strategies like zero-shot and few-shot learning are leveraged, for instance, with models like GPT-4o, for effective sentiment classification [26].​  

Retrieval-augmented LLMs (RALMs) represent a significant advancement in enhancing financial sentiment analysis by integrating external knowledge [31,32]. These frameworks combine instruction-tuned language models with retrieval modules designed to enrich the context available to the LLM with relevant information retrieved from external data sources [3,32]. This approach is particularly valuable for mitigating challenges such as the frequently limited context in financial news and the inherent mismatch between the broad pre-training objectives of general LLMs and the specific, nuanced requirements of financial sentiment tasks [32]. By incorporating external information, RALMs have been shown to improve both predictive performance and the contextual understanding required for accurate financial sentiment analysis [3,32].  

Despite the capabilities demonstrated, several challenges remain specific to financial sentiment analysis using LLMs. These include the highly specialized terminology and domain-specific language, the necessity for precise interpretation of numerical data, and the intricate contextual dependencies present in financial documents [3,5,31]. Overcoming the mismatch between generic LLM pre-training and specialized financial tasks, addressing the limitations of context in certain financial texts, and effectively utilizing techniques like prompt engineering for robust classification are ongoing areas of concern [26,32]. Future research is expected to focus on developing more sophisticated domain adaptation strategies, improving the models' numerical and contextual reasoning abilities, and advancing retrieval-augmented methodologies to better handle the dynamic and complex landscape of financial information [31,32].  

# 4.2 Financial Prediction and Forecasting  

Large Language Models (LLMs) are increasingly being applied to financial prediction and forecasting tasks, particularly focusing on financial time series analysis [3,5,10]. The primary objective in this domain is to forecast market trends, detect anomalies, and classify financial data by capturing complex temporal dependencies and patterns within diverse financial datasets [3,10].​  

![](images/5491ccc630f13c2a6f2118d179e4fced83883f5b3334f644eb7e9bcf265bcbec.jpg)  

LLMs handle financial time series data by integrating historical numerical data with textual and other contextual information [5]. A common approach involves preprocessing numerical data, such as historical stock prices, by normalizing them into percentage changes to standardize the input format [5]. While specific LLM architectures are not extensively detailed across the digests, the general capability leveraged is the ability to process sequences and potentially capture long-term dependencies, which is characteristic of models like Transformers [24]. The debate on the overall effectiveness of LLMs in precisely capturing these complex financial dynamics remains ongoing [10].​  

A significant advantage of LLMs in financial forecasting is their capacity to incorporate external knowledge and unstructured data, particularly financial news and sentiment [1]. Studies demonstrate the impact of integrating financial news data on forecasting performance [5,11]. For instance, LLMs can analyze news headlines to generate sentiment scores that are subsequently used in predictive models, as shown in the prediction of risk premiums for the Shanghai Securities Composite Index (SSE) and CSI 300 Index using ChatGPT [11]. This method involves comparing the performance against baseline models like a bag-of-words approach, highlighting the superior capabilities of LLMs in extracting relevant sentiment from text [11]. LLMs can also generate concise summaries and extract keywords from news to identify factors affecting stock prices [5]. Transformer models, for example, can leverage economic indicators, news events, and social media sentiment alongside historical prices to predict stock movements [24].​  

Specific frameworks have been developed to combine multimodal data for enhanced forecasting and risk prediction. The Ploutos framework, built upon GPT-4, is designed for interpretable stock movement prediction [3]. Its component,  

PloutosGen, specifically integrates sentiment, technical, and expert analyses to address the challenge of fusing disparate data types like text and numerical information [3]. PloutosGPT employs techniques such as hindsight prompting and dynamic token weighting to improve accuracy and generate interpretable rationales for predictions [3]. Other studies also focus on integrating market time series data with contextual news data surrounding specific events, demonstrating the potential of multimodal approaches [4]. Multimodal LLMs can analyze various sources, including news reports, social media, and economic reports, utilizing both text and visual information like stock charts to predict market trends and risks [21].​  

Beyond market time series, LLMs have shown promise in forecasting specific financial indicators. GPT-4 has demonstrated the ability to forecast the direction of future earnings changes based on financial statement data, with performance comparable to or even exceeding human analysts and specialized machine learning models, including neural networks [23,33]. Investment strategies derived from GPT-4's predictions have reportedly outperformed traditional models [23]. LLMs are also being explored for nowcasting real economic activity or inflation, potentially overcoming the limitations of traditional, narrowly scoped models by providing forecasts without extensive fine-tuning [17].  

Evaluation of these models often involves metrics relevant to time series forecasting, such as out-of-sample $R ^ { 2 } ~ ( R _ { O O S } ^ { 2 } )$ and adjusted Mean Squared Prediction Error (MSPE-Adj.), often assessed using recursive window approaches to ensure robustness [11].  

Despite these advancements, common challenges persist, notably the ongoing debate about the consistent effectiveness and robustness of LLMs in capturing the complex and often non-stationary nature of financial time series data [10]. Fusing multimodal data effectively and developing methods for interpreting LLM-based financial predictions remain active areas of research [3]. Future research directions should focus on developing more robust multimodal fusion techniques, enhancing the interpretability of LLM predictions in finance, and conducting rigorous, large-scale evaluations to conclusively assess their performance relative to established financial forecasting models.​  

# 4.3 Risk Management and Fraud Detection  

Large Language Models (LLMs) are increasingly applied in finance to enhance risk management and fraud detection, demonstrating potential for improving efficiency and accuracy [1,3,10]. Their capabilities extend across various domains within these critical functions, potentially driving evolutionary or revolutionary changes in established processes [1].  

In risk management, LLMs facilitate a more comprehensive and real-time approach [18]. They can integrate and analyze diverse information sources, including market data, news, public sentiment, and regulatory documents, to identify potential risks that might be overlooked by human analysts [9]. This enables early risk identification, warning, exposure, and disposal [9]. Specific applications include credit risk assessment and prediction, where LLMs analyze multiple data points to evaluate creditworthiness, provide credit ratings and risk warnings, and predict default probabilities using historical loan data and customer information [18,21,24]. This capability helps financial institutions potentially reduce nonperforming loan rates [18]. LLMs also contribute to market risk assessment, analyzing market data and economic indicators to identify potential risks like volatility and variance [4,18]. They can suggest hedging measures or asset allocation adjustments [24]. Frameworks like RiskLabs explore multi-task financial risk prediction through multimodal fusion of textual, vocal, time series, and contextual news data [4]. Furthermore, LLMs can optimize risk management decisions by generating multiple potential solutions and simulating different scenarios [9]. They also improve operational efficiency by automating the generation of management and audit reports [9]. AI Agents powered by LLMs can evaluate customer risk levels in detail, considering macroeconomic and microeconomic factors [20]. The application of LLMs also extends to regulatory compliance (RegTech), assisting financial institutions in adhering to regulations like Basel III by processing and collecting necessary information [1,25]. Proprietary LLM platforms have been developed by major banks for intelligent risk control [19].​  

In fraud detection, LLMs serve as powerful tools for identifying complex and advanced financial crimes [6]. They automate the detection of suspicious behavior, significantly reducing the need for manual review [16,28,34]. Techniques include generating synthetic data that replicates fraudulent patterns to refine detection algorithms [16]. Multimodal LLMs can analyze financial transaction records, contracts, and communications to identify and report potentially illegal or noncompliant activities [21]. AI, including techniques that could potentially be integrated with LLMs like Graph Neural Networks, has shown superior performance over traditional rule-based methods in detecting complex patterns such as money laundering networks, particularly in cross-border transactions and when data is shared in a privacy-preserving manner [17,35]. Cybersecurity firms also leverage LLMs for broader threat detection [34].  

Despite the promising applications, deploying LLMs in financial risk management and fraud detection faces several challenges. Key concerns include ensuring data privacy, particularly when handling sensitive financial and personal information [1,3,10]. Explainability requirements are paramount in regulated financial environments, demanding models that can provide transparent and interpretable reasoning for their risk assessments or fraud alerts, which is often difficult with complex neural networks [1,3,10]. Furthermore, handling imbalanced datasets, common in fraud detection where fraudulent instances are rare compared to legitimate ones, remains a significant technical hurdle [1,3,10]. Addressing these challenges is crucial for the responsible and effective integration of LLMs into critical financial operations.​  

# 4.4 Trading and Investment Analysis  

Large Language Models (LLMs) are increasingly recognized for their potential to enhance trading and investment outcomes by processing and interpreting diverse financial data sources [23,33]. These models are capable of synthesizing vast amounts of financial information from various sources, enabling investors to process unstructured data, improve analytical tools, and enhance price discovery across asset classes [1,10]. Specific data sources processed by LLMs include historical market trends, news information, financial statements, and financial research reports [9,16,21,23,33]. Multimodal LLMs, for instance, are specifically employed for interpreting and analyzing financial research reports in the securities sector, offering in-depth insights for decision-making [21]. Furthermore, LLMs analyze financial information to identify investment clues and contribute to constructing financial knowledge graphs, supporting intelligent decision-making and identifying business opportunities [18].​  

The application of LLMs in trading and investment analysis involves several specific techniques and areas. These include automated and high-speed trading [1], strategic financial planning [3,10], and the generation of investment recommendations and advisory services [3,10]. LLMs are utilized for predicting stock prices and analyzing data [23,28], predicting stock market risk premiums, and analyzing news sentiment to inform market trend predictions [11]. They assist in building more effective investment portfolios by analyzing historical and real-time market data [21] and optimizing trading strategies [16,35]. LLMs can also automate activities within investment consulting, such as report production and analysis, thereby increasing service efficiency [9]. Personalized investment advice can be offered by establishing customer profiles based on information like transaction records and risk preferences [9]. AI-assisted investment research is recognized as a growing area of interest [19].​  

Evaluation of LLM performance in these areas indicates promising results compared to traditional methods or human analysts [3,10,23,33]. Research exploring the use of GPT-4's predictions for constructing trading strategies suggests the potential for generating excess returns and demonstrates that investment strategies built by GPT-4 can outperform traditional models [23,33]. Specifically, the Sharpe ratio of trading strategies based on GPT-4 forecasts has been evaluated [33]. Similarly, models like FinLLaMA have achieved impressive Sharpe ratios in trading simulations, underscoring their potential [30]. InvestLM, built upon LLaMA-65B and diverse investment datasets, has demonstrated the capability to provide investment advice comparable to cutting-edge commercial models [3]. The ability of LLMs to analyze financial statements has been noted as potentially comparable to human analysts in providing insights into profitability [33].​  

Despite these advancements, the use of LLMs in trading and investment analysis faces significant challenges. A primary challenge is the critical need for real-time data to inform timely decisions in fast-moving markets. Furthermore, the intrinsic difficulty of accurately predicting complex and often irrational market behavior remains a hurdle for any model, including LLMs. Ethical considerations surrounding the generation of investment advice by AI models are also paramount, requiring careful attention to issues such as potential biases, transparency, and accountability in autonomous financial recommendations.​  

# 4.5 Customer Service and Chatbots  

Intelligent customer service represents a significant priority across financial institutions, driven by the necessity to manage large user bases and address immediate demands efficiently [19]. Large Language Models (LLMs) and Generative AI (GenAI) are being actively applied in this domain [3,10,18], primarily through the deployment of LLM-powered chatbots and virtual assistants. These systems are designed to enhance customer service quality, improve customer satisfaction, and strengthen customer relationships [18].​  

The benefits of integrating LLMs into financial customer service are multifaceted. A primary advantage is the enhancement of efficiency and availability. LLM-based intelligent customer service robots can provide 24/7 automated customer consultation services, significantly reducing the rate of transfers to human agents and yielding labor cost savings for the company [9]. These models automate routine customer service tasks, contributing to reduced operational costs and the streamlining of mundane workflows [16,20]. Furthermore, GenAI can act as an in-call live "copilot," assist in handling more advanced service requests, and automate the analysis of customer calls [6].  

Beyond efficiency, LLMs elevate the customer experience through enhanced interaction and personalization. They facilitate natural language interaction and provide personalized communication underpinned by contextual awareness [16]. Their strong semantic understanding and multi-turn dialogue capabilities enable them to provide efficient service solutions [9]. A Agents, powered by LLMs, can understand and respond to customer inquiries using natural language processing, thereby providing personalized financial advice and improving the overall customer experience [21]. LLMs excel at processing nuanced language, enabling them to tailor customer support and deliver efficient, personalized service [34]. This personalization extends to providing services tailored to the customer's specific situation [9], offering personalized recommendations [20], creating tailored offers based on customer profiles [1,18], and even analyzing user emotions via multimodal capabilities to adjust response tone and content [9]. Specific implementations are observed in areas like intelligent services, financial knowledge bases, financial consulting, and customer relationship management [18], with platforms such as Chinese internet securities firms Eastmoney and Tonghuashun launching LLM-backed smart dialogue services [19].​  

While LLMs offer substantial benefits, their application in financial customer service also presents notable limitations and challenges. A dedicated analysis focusing on financial advisement compares the performance of LLM-based chatbots (like ChatGPT and Bard) with traditional rule-based systems (such as SafeFinance) [28]. This comparison highlights critical considerations regarding the efficacy and fairness of LLM-generated advice [28]. Key limitations include the ability of LLMs to accurately handle complex queries, ensure the factual accuracy of financial information and advice, and maintain fairness in their recommendations and interactions [28]. The complexity and high-stakes nature of financial decision-making necessitate rigorous attention to potential biases and factual errors that could undermine fairness and trust. Although LLMs can process vast amounts of information and provide advice [18,21,28], ensuring their knowledge base is continuously updated and comprehensive remains a challenge [9], directly impacting accuracy in a rapidly changing financial landscape. Addressing these limitations, particularly concerning the robustness of LLMs in handling intricate financial scenarios and ensuring equitable treatment across diverse customer profiles, is crucial for broader adoption and reliance in the financial customer service sector.​  

# 4.6 Financial Analysis and Reporting  

Large Language Models (LLMs) are increasingly being utilized to automate and enhance various tasks within financial analysis and reporting [23,33]. A primary benefit is their capability to process and synthesize large volumes of complex textual financial data, offering significant advantages over traditional methods which often struggle with unstructured information.​  

One key application lies in the automatic summarization of extensive financial documents. LLMs can efficiently distill complex financial narratives, such as enterprise information disclosures, into concise summaries, significantly streamlining information processing for analysts and investors [3,10,23]. This capability allows for rapid absorption of key information from lengthy reports that would otherwise require extensive manual review [23].​  

Beyond summarization, LLMs excel at extracting structured data from unstructured text. This involves identifying and extracting critical information, which is fundamental for subsequent analysis [3,10,23]. Furthermore, LLMs can be applied to distill complex regulatory texts into more structured formats, such as concise mathematical frameworks, aiding compliance and analysis [25]. They can also construct financial relationships and classify text, enhancing the utility of extracted data for decision-making [10].  

LLMs also show potential in assisting with report generation. They are capable of drafting various technical documents, including financial, environmental, social, and governance (ESG), and audit reports [6,28]. This extends to compliance testing and regulatory reporting, where generative AI can automate analyses and even generate synthetic data to streamline processes and ensure adherence to diverse regulations [16]. The ability to automate code synthesis for financial document processing further demonstrates the role of generative AI in enhancing efficiency in this domain [35].​  

Specific applications include using LLMs for detailed financial statement analysis, generating predictive insights into a company's future earnings direction [33]. For instance, models like GPT-4 and ChatGPT have been explored for financial statement analysis and summarizing complex disclosures [23]. Compared to traditional methods, LLMs offer superior capabilities in handling the scale, variety, and inherent ambiguity often present in financial textual data, enabling more efficient extraction, synthesis, and even predictive analysis based on narrative information.  

# 4.7 LLM-Based Agents for Financial Decision-Making  

Large Language Model (LLM)-based agents represent a significant advancement in applying artificial intelligence to financia decision-making, moving beyond static models to systems capable of dynamic interaction and complex task execution.  

![](images/1941b403bd31e1f4899c350c5c376b0db3afcdbf72ab86429ed87aebf82c4f59.jpg)  

The architecture of these agents typically integrates the LLM as the central reasoning engine with planning capabilities, memory, and access to external tools [9,21]. The LLM serves as the "brain," responsible for disassembling complex user instructions or goals into smaller steps, generating reasoning paths, and evaluating outcomes [21]. Prompt engineering plays a crucial role in this architecture, involving the strategic assembly of instructions and prompts based on specific strategies to guide the LLM's task execution [9,21]. Agents utilize both short-term memory, often stored within the prompt template during execution, and long-term memory for retaining information across interactions [9]. Crucially, they interact with external tools, such as web crawlers, search engines, or calculators, to supplement the LLM's limitations and gather necessary information, with the results feeding back into the prompt engineering loop to refine subsequent actions until the task is complete [9,21]. This architecture enables agents to autonomously analyze data, write and update code, and perform a sequence of actions to achieve defined objectives [27].  

The application of LLM-based agents in finance is diverse and expanding. Since around 2020, the combination of LLMs, domain-specific knowledge, and smart agents has begun to automate and enhance productivity in various financial sector functions [19]. Specific implementations are emerging across different areas, including corporate and investment banking, where "RM assistants" analyze client interactions (voice and text) to generate investment ideas, assist sales processes, and clarify product policies [6]. These assistants can also serve as training tools for junior relationship managers through simulations and personalized coaching based on call transcripts [6]. Financial institutions like 招联消费 are developing specialized agents such as 消保智能体 (consumer protection agent), 审批智能体 (approval agent), and 运营智能体 (operation agent) leveraging various LLMs like LLaMA, Qwen, and 智鹿大模型 [20]. Beyond customer-facing or internal operations, agents are being explored for high-frequency information processing and autonomous action [27]. Furthermore, agentbased modeling using LLMs extends their reasoning capabilities to simulate complex interactions between agents, environments, markets, and individuals, allowing for the simulation of market behavior and economic dynamics [3]. Potential benefits include automating repetitive tasks, providing sophisticated decision support, improving efficiency, and enabling advanced simulations and risk control strategies [9,19,27].  

Evaluating the capabilities of these sophisticated agents requires specialized benchmarks. InvestorBench is specifically designed for assessing LLM-based agents in financial decision-making scenarios [15]. This benchmark includes a comprehensive suite of tasks covering various financial products, such as stocks, cryptocurrencies, and exchange-traded funds (ETFs) [15]. It facilitates the assessment of agents' reasoning and decision-making abilities by testing them with thirteen different LLMs as backbone models across diverse market environments [15]. InvestorBench provides curated opensource, multi-modal datasets and environments to support rigorous evaluation [15].  

Despite the promising applications and architectural advancements, significant limitations and challenges exist. While agents have the potential for autonomous action and high-frequency processing, the concept of fully autonomous AI agents executing trades without human oversight remains a source of discomfort among market participants [1]. This discomfort stems from substantial regulatory hurdles, challenges in risk management, questions of liability in case of errors or losses, and underlying ethical considerations [1]. A major technical challenge is the "black box" nature of some AI strategies, which market participants generally avoid due to the lack of explainability for trading patterns and decisions [1]. This highlights the need for increased transparency and interpretability in agent decision-making processes. Future research must focus on addressing these regulatory, risk, liability, and ethical concerns, developing robust safety mechanisms, and enhancing the explainability of agent actions to build trust and enable wider adoption of autonomous or semi-autonomous LLM-based agents in critical financial functions.​  

# 4.8 Applications in Specific Financial Domains (e.g., CIB, Securities Industry)  

Large Language Models (LLMs) are increasingly being adopted across specific financial domains, including the Corporate and Investment Banking (CIB) sector and the securities industry, demonstrating significant potential to enhance productivity, improve client service, and optimize operational efficiency.​  

<html><body><table><tr><td>Domain</td><td>Examples of Applications</td></tr><tr><td>Securities Industry</td><td>Intelligent Work Assistants (Drafting, Summarization), Knowledge Bases, Code Review Assistance</td></tr><tr><td>Corporate& Investment Banking (CIB)</td><td>RM Assistants (Sales Support, Client Analysis), Operational Assistants (Document Prep, Data Extraction)</td></tr><tr><td>Regulatory Compliance (RegTech)</td><td>Interpreting Regulations (e.g., Basel Ill), Compliance Reporting Assistance</td></tr><tr><td>General Banking Operations</td><td>Contract Inspection, Valuation Reconciliation,Loan Underwriting, Mortgage Approval</td></tr></table></body></html>  

Within the securities industry, firms are rapidly integrating LLMs, often favoring localized deployment strategies [20]. A key application area is the deployment of LLMs as intelligent work assistants to support employees in a wide array of tasks [9]. These LLM-powered assistants can substantially improve writing efficiency by quickly generating document drafts, aiding text creation through outlining, optimizing expressions, and generating content [9]. Beyond drafting, they automate mundane yet time-consuming activities such as automatically generating meeting minutes, assisting with work reports, daily document sorting and review, email sending, and even code review [9]. By handling these tasks, LLMs enable employees to allocate more time to creative and strategic endeavors [9]. Furthermore, LLMs can be combined with professional domain knowledge, semantic understanding, and vector database technologies to construct specialized knowledge bases within securities companies, providing employees with rapid access to professional information and answers [9]. This localized knowledge integration is crucial for delivering domain-specific insights.​  

In Corporate and Investment Banking (CIB), generative AI, including LLMs, is being leveraged to transform various functions [6]. In sales and marketing, LLMs serve as real-time sales assistants for relationship managers (RMs), assist in generating marketing collateral and client onboarding instructions, act as public assistants for clients, prepare proposals and pitch books, identify cross-sales opportunities across complex organizational structures, and even coach RMs through simulated client calls to improve engagement and lead generation [6]. Operationally, generative AI functions as a mid-office assistant, providing expertise, preparing necessary documents, and performing data extraction and validation [6]. Broader banking applications also include using LLMs for contract quality inspection and automated valuation reconciliation [20], as well as transforming loan underwriting and mortgage approval through synthetic data, automated document verification, and risk evaluation [16].​  

A particularly impactful application across the banking sector and other regulated domains is the use of LLMs for financial regulatory interpretation [25]. For instance, LLMs are being applied to interpret and implement complex regulations like Basel III, which is highly pertinent to global banking institutions [25]. By automating or assisting with the interpretation of regulatory mandates, LLMs can streamline their implementation within financial reporting and risk management systems, thereby enhancing compliance efficiency and reducing the burden associated with regulatory adherence [25]. The exploration of LLM applications extends across the broader FinTech landscape [14], encompassing banking, insurance, financial management, and investment sectors [12].  

The specific use cases identified demonstrate clear benefits for financial institutions, including enhanced employee productivity through automation of routine tasks [9], improved client service via intelligent assistance and tailored communication [6], and increased operational efficiency through streamlined processes like data handling, document processing, and regulatory compliance [6,25]. While these applications highlight significant potential, the specific challenges associated with deploying LLMs in these specialized contexts, such as data privacy, model explainability, potential biases, and integration complexities within legacy systems, are not detailed within the scope of the provided digests.​  

# 5. Broader Impact of LLMs on the Financial Sector  

The advent of Large Language Models (LLMs) represents a significant technological shock poised to reshape the financial sector [8].  

<html><body><table><tr><td>Area of Impact</td><td>Description</td></tr><tr><td>Financial Markets</td><td>Market reaction to LLM releases, potential volatility amplification.</td></tr><tr><td>Financial Firms</td><td>Enhanced productivity, new business models, cost democratization.</td></tr><tr><td>Financial Occupations</td><td>Differential exposure, potential automation/displacement, skill shifts.</td></tr><tr><td>Financial& Economic Research</td><td>Increased efficiency, newanalytical approaches, simulation capabilities.</td></tr><tr><td>Macroeconomy</td><td></td></tr></table></body></html>  

<html><body><table><tr><td></td><td>Potential impact on aggregate demand/supply, inflation,inequality.</td></tr><tr><td>Financial Stability</td><td>Systemic risk from algorithmic concentration,herding,speed of market moves.</td></tr></table></body></html>  

This transformative impact extends across financial markets, individual firms, occupations, and even the methodologies employed in financial and economic research. Evaluating this impact necessitates developing methods to quantify the exposure of companies and occupations to these new generative AI technologies, often relying on analyses of task structures and occupational data within firms [8].​  

The financial market has demonstrated a discernible reaction to the emergence and advancement of prominent LLMs. Studies using events like the public release of ChatGPT as a natural experiment indicate a swift market re-evaluation, with firms identified as having high exposure to generative AI exhibiting significantly higher market returns immediately following such releases [8]. Subsequent model updates, such as GPT-4, have also shown a continued influence on portfolio performance, suggesting that the market perceives LLMs as catalysts impacting future enterprise value and productivity [8].  

LLMs are anticipated to enhance enterprise productivity by streamlining workflows, improving operational efficiency, and enabling new business models, for example in securities services and consumer finance [6,20]. They are simultaneously expanding financial service scenarios horizontally and deepening industrial integration vertically, thereby facilitating precise services and modernization [18]. Furthermore, the potential emergence of lower-cost LLMs could democratize AI access, potentially narrowing the technology gap between different financial institutions [20].​  

The impact of LLMs on the labor market within finance is significant and varies across occupations [8]. Financial roles, in general, exhibit a higher-than-average exposure to generative AI compared to some other sectors [8]. However, this exposure differs substantially: roles involving structured data processing and analysis, such as for accountants and insurance underwriters, face a greater potential impact on core tasks from automation compared to roles like financial managers, loan officers, and financial advisors, which often involve complex interpersonal skills and relationship building [8,34]. LLMs’ demonstrated ability to perform financial analysis tasks with accuracy comparable to that of human experts highlights the potential for automation in analytical roles [33]. Broader AI adoption, including that of LLMs, raises concerns about potential job displacement, devaluation of certain labor markets, and increased economic inequality, with possible systemic implications for financial stability and government revenues [27]. The overall effects on the labor market and the macroeconomy will depend on the balance between labor substitution, productivity gains, and the creation of new tasks [17].​  

LLMs are also fundamentally transforming financial and economic research by boosting efficiency and enabling novel analytical approaches [8]. They streamline tasks such as code generation, automated text data classification, and writing assistance [8]. Beyond improving efficiency, LLMs facilitate new research avenues, such as simulating human participants for large-scale qualitative data generation and enabling sophisticated qualitative analysis [8]. Techniques like processing textual data for market prediction further exemplify their potential as powerful research tools [11].  

Key techniques underlying LLMs’ utility in research include the use of embeddings for capturing semantic relationships [8], transformer models for tasks like text classification [8], and Retrieval-Augmented Generation (RAG) [8,9]. RAG improves model accuracy and relevance by incorporating external, domain-specific knowledge, expanding the effective knowledge boundary of the LLM, enhancing trustworthiness, and mitigating issues like hallucinations—an essential factor when leveraging vast, domain-specific financial information [9].  

The macroeconomic impact of AI is expected to expand both aggregate demand and supply, influencing output and potentially exerting complex effects on inflation depending on the relative magnitude of these impacts [17]. AI could also improve market liquidity, though it poses potential challenges for financial stability [1]. The evolving role of AI necessitates changes in how institutions, such as central banks, approach data collection and collaboration [17].​  

# 5.1 LLMs as a Technological Shock and Market Reaction  

Large Language Models (LLMs) represent a significant technological shock with profound implications for financial firms and markets. The emergence of these models has been posited to enhance information processing capabilities, for instance, by improving summary generation, which increases information content and potentially alleviates the burden on investors [23]. Evaluating the impact of this shock necessitates methodologies to quantify a firm's exposure to generative AI technologies. Research indicates that such exposure can be measured, with approaches potentially based on occupational data within firms [8].​  

The initial market reactions to the release of prominent LLMs provide evidence of their disruptive potential. Following the public release of ChatGPT, firms identified as having high exposure to generative AI technologies demonstrated significantly higher market returns. Specifically, companies with high generative AI exposure experienced a daily excess return that was 44 basis points greater than those with low exposure in the two weeks immediately after the release of ChatGPT [8]. This finding suggests a swift positive market re-evaluation of firms perceived to be well-positioned to leverage this new technology.​  

Furthermore, subsequent advancements and updates to LLMs have continued to influence enterprise valuations and market performance. The release of GPT-4 in March 2023, for instance, had a discernible impact on portfolio returns, as evidenced by the analysis of the "Artificial Minus Human" (AMH) portfolio cumulative abnormal returns [8]. This indicates that the market continues to react to the evolving capabilities and availability of advanced LLMs, treating them as catalysts that affect future earnings potential and, consequently, firm valuation. The continuous development and deployment of more powerful LLMs are likely to perpetuate this dynamic, necessitating ongoing analysis of their impact on specific industries and overall market structure.​  

# 5.2 Impact on Financial Occupations and Labor Market  

The advent of large language models (LLMs) is poised to significantly impact the financial sector labor market, marked by substantial, yet varied, exposure across different occupations. Compared to sectors such as healthcare, financial occupations exhibit a higher-than-average exposure to generative AI [8]. However, this exposure is not uniform across the sector and is highly differentiated among specific roles.  

<html><body><table><tr><td>Occupation Category</td><td>Example Roles</td><td>Typical Exposure to Core Task Impact</td><td>Primary Skillsets</td></tr><tr><td>High Structured Data Processing</td><td>Accountants, Insurance Underwriters</td><td>Higher</td><td>Data Analysis, Rule Application</td></tr><tr><td>Complex Interpersonal & Strategic</td><td>Financial Managers, Loan Officers, Financial Advisors</td><td>Lower</td><td>Relationship Negotiation, Strategic Judgment Building,</td></tr></table></body></html>  

For instance, occupations such as accountants and insurance underwriters face a greater impact on their core tasks from generative AI compared to roles such as financial managers, loan officers, and financial advisors [8]. This differentiation suggests that tasks involving structured data processing and analysis may be more susceptible to automation by current LLM capabilities.  

Specific applications of LLMs, such as their demonstrated ability to perform financial analysis tasks with accuracy comparable to human experts, further underscore the potential for automation in roles heavily reliant on such functions, notably impacting financial analysts [33]. This capability suggests a potential shift in the nature of financial analysis work, where LLMs could augment or potentially replace certain analytical tasks.​  

Beyond the direct impact on task automation within specific roles, the broader adoption of AI, including LLMs, raises significant concerns regarding potential job displacement across the financial industry [27]. Such displacement could have wider economic implications, potentially affecting consumer spending and loan repayment abilities, thereby creating systemic impacts on the financial system itself [27]. Furthermore, rapid advancements in AI technology could lead to a devaluation of labor markets, potentially resulting in reduced tax revenues for governments [27].  

The differentiated exposure levels across financial occupations also highlight potential shifts in the demand for various skill sets. Roles reported as less exposed to the core task impacts of generative AI, such as financial managers, loan officers, and financial advisors [8], often involve substantial interpersonal interaction, relationship building, negotiation, and complex decision-making that are currently less amenable to full automation compared to the more structured, data-intensive tasks prevalent in fields like accounting or underwriting [8]. While the provided literature does not explicitly quantify the direct relationship between LLM exposure and factors such as salary levels or provide a detailed analysis of how the value of interpersonal skills will precisely evolve, the disparity in exposure levels across roles strongly implies that skills complementing LLM capabilities—or those in areas less susceptible to automation, such as complex interpersonal skills and strategic judgment—may become increasingly valuable in the future financial labor market.  

# 5.3 Impact on Financial and Economic Research  

Large Language Models (LLMs) are fundamentally transforming financial and economic research by enhancing efficiency and enabling novel methodological approaches [8]. These models streamline traditional research processes, notably improving the speed and effectiveness of tasks such as code generation, automated text data classification, and writing assistance [8]. Beyond efficiency gains, LLMs facilitate entirely new avenues for research. They allow for the simulation of human participants in studies, providing a scalable method for generating large‐scale qualitative data, and enable sophisticated large‐scale qualitative data analysis that was previously challenging [8]. For instance, LLMs have been successfully applied to analyze qualitative data, such as news headlines, for tasks like predicting market behavior. This approach demonstrates significant improvements in accuracy and efficiency compared to traditional methods like bag‐ of‐words models, highlighting the potential of LLMs as powerful research instruments [11].  

The efficacy of LLMs in these research applications stems from underlying technical concepts. Leveraging embeddings, LLMs can represent complex data, including textual information, numerically in a high‐dimensional space, capturing semantic relationships and facilitating subsequent analysis [8]. Furthermore, transformer‐based models are extensively utilized for tasks like text classification, enabling researchers to systematically categorize and analyze vast amounts of financial texts based on sentiment, topic, or other relevant criteria [8].​  

Retrieval Augmented Generation (RAG) is another key technology paradigm enhancing LLMs' utility in research [8,9]. RAG systems improve the relevance and accuracy of model outputs by retrieving information from an external, domain‐specific knowledge base before generating a response [8,9]. This capability is particularly valuable in financial and economic research, where access to specific, up‐to‐date, and often proprietary knowledge is crucial [9]. By grounding the generation process in verified external data, RAG expands the effective knowledge boundary of the LLM, enhances the trustworthiness of the generated content, and can help prevent issues like model hallucinations, thereby significantly improving knowledge access and reliability for researchers [9].​  

# 6. Challenges and Risks of LLMs in Finance  

The integration of Large Language Models (LLMs) into the financial sector, while promising, introduces a complex landscape of challenges and risks that span technical, ethical, regulatory, and economic dimensions [3,7,10,12,13,17,18,19,20,29,37].  

<html><body><table><tr><td>Challenge Category</td><td>Key Issues</td></tr><tr><td>Technical Challenges</td><td>Data quality/availability, Interpretability, Reliability/Hallucinations, Computational Costs, Security</td></tr><tr><td>Ethical Considerations</td><td>Bias,Fairness,Accountability,Transparency Privacy</td></tr><tr><td>Regulatory Compliance</td><td>Evolving frameworks, Need for governance, Supervisory capacity</td></tr><tr><td>Economic& Systemic Risks</td><td>Market volatility, Herding behavior, Concentration risk,Impact on labor market, Financial stability</td></tr></table></body></html>  

Addressing these multifaceted issues is paramount for ensuring the reliable, trustworthy, and responsible deployment of LLMs in critical financial applications [3,12,29].  

Technical challenges are substantial and pervasive. A foundational issue lies in the quality, availability, and nature of financial data, which is often noisy, sparse, rapidly changing, and exists in diverse formats [2,3,7,8,9,11,16,18,20,21]. The inherent "black box" nature of many LLMs compromises interpretability and explainability, hindering the understanding of model decisions essential for trust, validation, and regulatory compliance [1,3,5,9,10,18,23,29]. Furthermore, LLMs are susceptible to generating "hallucinations"—plausible but factually incorrect content—and exhibit inconsistency and unreliability in complex reasoning tasks, posing significant risks in financial advisory or decision-making contexts [9,27,28]. High computational costs for training and deployment represent a major technical and economic barrier, particularly affecting smaller institutions and contributing to accessibility disparities [2,3,6,7,9,12,20,34]. Security concerns are elevated, with risks including cyberattacks exploiting model vulnerabilities, data poisoning, the potential misuse of LLMs for generating harmful content or facilitating market manipulation [1,3,6,10,12,13,17,29,34].​  

Ethical considerations are critically important, demanding rigorous attention to fairness, accountability, and transparency in LLM applications [3,10,13,22,29,37]. Bias embedded within training data or introduced during development poses a substantial risk of reinforcing stereotypes and inequalities, leading to potentially discriminatory outcomes in areas like credit assessment or loan applications [3,6,7,8,27,28,34]. Protecting sensitive customer data from privacy violations is another paramount ethical and technical challenge [16,18,20,21,34].  

Navigating the evolving regulatory landscape is a significant challenge, as frameworks and ethical standards for AI in finance are still under development [19]. Regulatory bodies globally are working to establish guidelines based on principles like riskbased approaches, market supervision, transparency, responsibility, privacy, security, interpretability, and robust risk control [13,18,22,27,37]. Financial institutions must adapt existing governance and supervisory frameworks to ensure compliance with emerging regulations, which may require leveraging new supervisory technologies and fostering international cooperation [1,13,27].​  

Economically, beyond the direct costs of deployment, the widespread adoption of LLMs in finance introduces potential systemic risks to financial stability. Reliance on a limited number of algorithms can amplify procyclicality and market volatility, potentially triggering collective behaviors such as herding, liquidity hoarding, or fire sales at unprecedented speed and scale [1,17,27]. Furthermore, the concentration of critical AI service providers poses interdependency risks and potential market concentration issues [1,27].​  

Mitigating these challenges requires a multi-faceted approach. Strategies discussed in the literature include implementing robust data governance and quality control measures, developing methods for bias detection and mitigation, enhancing model interpretability and explainability, establishing clear and adaptable regulatory frameworks and governance principles, exploring cost-effective deployment strategies such as utilizing smaller fine-tuned models, strengthening cybersecurity defenses, and developing tools for continuous monitoring of both model performance and potential systemic risks [1,3,7,8,10,12,13,17,18,20,22,27,29,31,37]. Ongoing research and proactive collaboration among researchers, developers, financial institutions, and regulators are essential to navigate these complexities and foster the responsible adoption of LLMs in the financial sector.​  

# 6.1 Data Quality, Availability, and Bias  

The efficacy and reliability of large language models (LLMs) in the financial domain are fundamentally contingent upon the quality, availability, and freedom from bias in the data used for their training and application. Data quality is considered critical for the successful deployment of generative AI in banking [16], and addressing related issues is essential for the performance and fairness of LLMs in finance [3,7,8].​  

<html><body><table><tr><td>Data Challenge</td><td>Description</td></tr><tr><td>Quality & Availability</td><td>Noisy,sparse,rapidly changing, diverse formats,limited data for smaller firms.</td></tr><tr><td>Bias</td><td>Embedded in training data,engineering decisions,alternative data sources.</td></tr><tr><td>Privacy</td><td>Handling sensitive financial and personal information.</td></tr><tr><td></td><td></td></tr></table></body></html>  

<html><body><table><tr><td>Complexity</td><td>Handling multimodal data (text, tables, time</td></tr><tr><td></td><td>series).</td></tr></table></body></html>  

Financial data presents unique challenges regarding quantity and availability. Smaller financial institutions, for instance, may face limitations in the volume of proprietary data available, necessitating the combination of internal and external datasets for model optimization [20]. While data quality and quantity can incrementally improve within specific datasets over time [2], the inherent nature of financial markets means data can be noisy, sparse, and subject to rapid changes. Ensuring high-quality data for LLM training requires rigorous data curation, cleaning, and preprocessing methods [7]. Specific steps include cleaning data to remove extraneous elements such as markup, special formatting, and templates [2]. For textual data, methods like Jaccard similarity can be employed to identify and remove highly similar entries, refining the dataset and mitigating potential redundancy or skewed representation [11].​  

Beyond quality and availability, bias within financial data poses a significant challenge to LLM fairness and performance [3,7,8]. Sources of bias in LLMs include imperfect training data and engineering decisions made during both development and deployment phases [6]. LLMs trained on extensive text corpora may inadvertently learn and propagate biases present within these datasets [28], potentially resulting in the reinforcement of stereotypes and inequalities [34]. Furthermore, alternative data sources, increasingly used in finance, may introduce bias due to shorter time series or smaller sample sizes, leading to recommendations or decisions that are not generalizable [27].  

The use of biased LLMs in finance carries significant ethical implications [3,13,29,37]. Outputs that reinforce stereotypes or exhibit unfairness can lead to discriminatory outcomes in critical financial services such as credit assessment, loan applications, or investment recommendations. It is therefore imperative to exercise mindfulness when deriving financial or regulatory decisions based on potentially biased data, particularly alternative data [27].​  

Detecting and mitigating bias in financial data and the resultant LLMs is a critical area of focus [3,13,29,37]. Fundamental mitigation strategies begin with robust data governance, including rigorous data curation, cleaning, and preprocessing [7]. Techniques such as removing markup and special formatting assist in standardizing data [2], while employing similarity measures like Jaccard similarity helps refine textual datasets by removing redundant or near-duplicate entries that could skew model training [11]. These data-level interventions are foundational steps in addressing potential biases before they are learned and amplified by large language models. Further research is needed on model-level bias detection and mitigation techniques specifically tailored for financial applications.  

# 6.2 Interpretability and Explainability  

The integration of large language models (LLMs) into financial applications necessitates a critical focus on interpretability and explainability.  

![](images/3f06b2d2592f6144802d2a85070a9975ef8d74fb35dadbc0ab5274e9c89d7868.jpg)  

A primary driver for this requirement stems from the need for regulatory compliance and the imperative to build trust among market participants and users [3,10,29]. Market participants are frequently wary of “black box” analyses that generate unexplainable outcomes, particularly in areas like trading patterns, highlighting a significant need for transparency in AI-driven financial processes [1]. This demand for transparency extends to specific tasks such as financial time series forecasting, where the requirement for explainability is explicitly emphasized [5].  

Meeting regulatory requirements and enhancing user trust mandates that AI models, including LLMs, possess robust interpretability and auditability [18]. This involves ensuring that the model’s decision-making processes are transparent and that its behavior can be tracked and recorded [18]. Such capabilities are fundamental to ensuring that decisions rendered by AI models are fair, equitable, and compliant with relevant regulations, thereby concurrently increasing user confidence in these systems [18].  

Despite the acknowledged need, a significant challenge in deploying LLMs in finance is their inherent “black box” nature and often poor interpretability [9]. While some observations suggest that models like GPT-4 may base predictions on analytical reasoning rather than mere memorization, hinting at a degree of interpretability, the fundamental challenge posed by their opaque operation persists [23]. A critical issue arising from poor interpretability is the propensity for large models to generate “hallucinations” – content that appears superficially plausible but is factually incorrect or inapplicable to real-world scenarios [9]. In the context of finance, such inaccuracies can have severe consequences, potentially leading to erroneous investment advice or flawed risk assessments [9]. Consequently, addressing the interpretability challenge remains paramount for the safe and reliable deployment of LLMs in the financial sector.  

# 6.3 Regulatory Compliance and Governance  

The application of Large Language Models (LLMs) in finance necessitates navigating a dynamic and evolving regulatory landscape [19]. Regulatory bodies globally are actively developing frameworks to address the unique risks and challenges posed by AI and LLMs within the financial sector [22,37]. For instance, the European Union's AI Act has significant implications for financial services, particularly in areas such as credit assessment and risk evaluation for insurance, highlighting the need for regulatory compliance and governance [13,37]. Regulatory approaches emphasize principles such as adopting a risk-based framework, implementing market supervision to identify potential non-compliance, and leveraging synergies with prudential oversight [13]. Similarly, in China, regulatory efforts include the release of draft rules aimed at  

strengthening data security management within the financial sector and guidelines specifically addressing generative AI services [22].  

Key principles for AI and LLM governance in finance are emerging to guide responsible development and deployment. These principles generally advocate for a comprehensive framework built upon transparency, responsibility, privacy protection, and security across the entire lifecycle of AI systems, from design and training to deployment and long-term management [27]. Furthermore, policies must strive to balance technological development with robust regulation, clarifying specific norms and requirements for LLMs in the financial industry. Critical areas demanding clear guidelines include data security, user privacy, model interpretability, and risk control [18,27]. Specific challenges related to data management, such as user privacy and complexities arising from cross-regional and departmental data flows, require careful consideration and regulatory clarity when training LLMs with sensitive financial data [20].​  

The implications of this evolving regulatory environment for financial institutions are significant. Existing supervisory frameworks and tools may prove insufficient across various jurisdictions to effectively oversee sophisticated AI deployments, necessitating policymakers to assess preparedness and identify areas for improvement [1]. A proactive regulatory stance involves not only establishing guidelines but also potentially enhancing supervisory capabilities through technology. Regulators may need to invest in supervisory technology (sup-tech) that can leverage AI itself, for example, to efficiently process information and detect instances of fraud [1].  

Ensuring LLM deployments comply with relevant laws and guidelines requires multifaceted strategies. Financial institutions must integrate the outlined governance principles—transparency, responsibility, privacy, security, interpretability, and robust risk control—into their AI development and deployment pipelines [18,27]. Adherence to jurisdiction-specific regulations, such as those emerging in the EU and China, is paramount [13,22]. Furthermore, LLMs themselves might offer a means to enhance compliance efforts; for instance, they can be applied to assist in the interpretation of complex financial regulations like Basel III [25]. Given the global nature of finance and AI development, international cooperation in AI governance is also highlighted as essential to ensure safe and responsible AI applications and potentially simplify regulations to avoid unnecessary complexities [13,27].​  

# 6.4 Ethical Considerations  

The deployment of Large Language Models (LLMs) within the financial sector necessitates a rigorous examination of ethical considerations, particularly focusing on the principles of fairness, accountability, and transparency [3,10,13,29,37]. While the ethical standards specifically for AI applications in finance are noted as still developing [19], discussions around the ethical implications of LLMs are gaining prominence [2,14].  

A primary ethical concern highlighted is the potential for bias. This manifests notably in financial advisement, where the use of LLMs carries the risk of generating biased advice, which could have significant financial ramifications for users [28]. Beyond specific applications, biases embedded within the LLM training data, such as cultural biases, are a broader ethical issue [34]. These biases can perpetuate or exacerbate social disparities [34].​  

In addition to bias and fairness, data privacy violations represent another critical ethical challenge associated with LLMs in finance [34]. Given the sensitive nature of financial data, ensuring robust protection mechanisms is paramount.  

Addressing these potential risks requires emphasizing fairness, accountability, and transparency in the design and application of generative AI technologies in finance [3,10,13,22,29,37]. While comprehensive guidelines and frameworks are still evolving [19], a foundational element proposed for ethical AI-based strategies is the integration of human oversight [1]. Human intervention can provide necessary checks and balances, mitigating risks associated with autonomous decisionmaking by LLMs, thereby contributing to greater accountability and potentially identifying and correcting instances of bias or error. The ongoing development of ethical standards and responsible deployment frameworks is crucial for harnessing the benefits of LLMs in finance while safeguarding against their potential harms [3,10,13,29,37].​  

# 6.5 Computational Costs and Accessibility  

![](images/8c3b9bd3485fdd17dc7df51bd93c04a671c1f46e119112f651da7e707a06e17e.jpg)  

The deployment and scaling of Large Language Models (LLMs) within the financial sector are significantly impacted by substantial computational and infrastructure costs [3,12]. At-scale utilization of generative AI technologies necessitates either investment in dedicated hardware or considerable expansion of cloud computing resources, both of which contribute to increased expenses [6]. Technical hurdles, including steep operational costs, present notable challenges to widespread adoption [34]. Specifically, the acquisition and upgrading of requisite hardware equipment, adherence to demanding computing power standards, and the modernization of existing systems represent major budgetary outlays [9]. The high initial training costs of large foundational models, exemplified by BloombergGPT which required approximately 1.3 million GPU hours using 512 NVIDIA A100 GPUs over 53 days, further underscore the significant investment required in this domain [2,7].​  

These considerable financial requirements pose a significant barrier to accessibility, particularly for small and mediumsized financial institutions, such as smaller securities companies or city commercial banks [9]. Their limited budgets make it challenging to absorb the huge costs associated with acquiring necessary infrastructure and maintaining operational capacity [9]. Consequently, the accessibility of advanced LLM technology tends to be skewed towards larger institutions with greater financial resources.  

Addressing these cost challenges is crucial for democratizing LLM access across the financial industry. Several strategies are being explored to mitigate computational expenses. One prominent approach involves leveraging smaller LLMs that are subsequently fine-tuned on domain-specific financial data and instructions [3]. Research indicates that smaller, fine-tuned models can achieve performance comparable or even superior to much larger general-purpose models while being significantly more efficient in terms of parameters and data requirements, directly alleviating computational cost concerns [3,31]. This aligns with the need for low-cost domain adaptation strategies [7]. Furthermore, the development of models designed for lower operational costs, such as DeepSeek-R1, holds promise for reducing the investment threshold for smaller entities, potentially enabling them to allocate more resources towards LLM application development rather than infrastructure [20]. Such cost efficiencies could allow small and medium city commercial banks to invest in large model research and application at a more manageable cost [20]. While utilizing cloud infrastructure offers scalability and access to high-performance computing, it also contributes to increased costs, particularly at scale [6], necessitating careful cost management. Other strategies like model compression, while not specifically detailed in the provided digests, are generally considered methods to reduce model size and computational footprint, contributing to lower inference costs.  

# 6.6 Security, Robustness, and Reliability  

The integration of Large Language Models (LLMs) into the financial sector introduces critical considerations regarding security, robustness, and reliability, which are paramount given the sensitivity of financial data and operations [3,10,12,17,29].  

<html><body><table><tr><td>Risk Type</td><td>Description</td></tr><tr><td>Cyberattacks</td><td>Exploiting model vulnerabilities, bypassing safety filters, generating malware.</td></tr><tr><td>Misuse</td><td>Facilitating market manipulation (e.g., deep fakes).</td></tr><tr><td>Data Poisoning</td><td>Introducing malicious data to compromise model integrity.</td></tr><tr><td>Hallucinations</td><td>Generating factually incorrect or unreliable information.</td></tr></table></body></html>  

<html><body><table><tr><td>Unintended Behavior</td><td>Model actions deviate from expected or safe</td></tr><tr><td></td><td>operation.</td></tr></table></body></html>  

A primary concern is the heightened risk of cyberattacks that can exploit vulnerabilities inherent in LLMs [17]. Attackers may leverage AI capabilities to enhance the sophistication and effectiveness of their malicious activities [13], potentially leading to unintended model behavior or the unauthorized disclosure of confidential information [17]. Specific attack vectors include users or malicious actors attempting to bypass safety filters designed to constrain model output [6]. Furthermore, LLMs can be misused to generate harmful content, such as malware, increasing the digital security threat landscape [34]. The potential for market manipulation is also a significant risk, with the advent of sophisticated techniques like "deep fakes" posing new challenges for identifying fraudulent activities [1].  

Robustness issues manifest in the susceptibility of AI systems, including LLMs, to data poisoning attacks, where malicious data is introduced during training or fine-tuning to compromise model integrity and performance [13]. Such attacks can undermine the reliability of LLM outputs, making them vulnerable to manipulation or causing them to generate incorrect or biased information.​  

Reliability is another critical dimension. LLMs are susceptible to generating factually incorrect or nonsensical information, commonly referred to as "hallucinations" [27]. This propensity for generating false content poses a substantial risk, particularly in customer-facing financial applications or advisory roles, where the provision of consistent and reliable financial information is imperative [27,28]. The identified critical gaps in the current performance of LLM-based chatbots highlight the need for significant improvements in ensuring the accuracy and trustworthiness of the information they provide [28].​  

While the digests primarily focus on the risks, it is acknowledged that AI can also serve as a tool to enhance IT security, for instance, through improved detection of suspicious behavior [13]. Developing strategies to enhance the security and robustness of LLM models and their deployment in finance requires a multi-faceted approach, encompassing adversarial training, robust validation processes, continuous monitoring for anomalous behavior, and the development of interpretability tools to understand model decisions and identify potential vulnerabilities.  

# 6.7 Potential Impact on Financial Stability  

The integration of artificial intelligence (AI), including advanced models, into financial markets introduces significant potential challenges to financial stability and may exacerbate existing systemic risks [1,17]. A primary concern is that reliance on a limited number of algorithms could amplify procyclicality and market volatility [17]. This concentrated algorithmic activity may lead to undesirable collective behaviors such as herding, liquidity hoarding, runs, and fire sales [17]. Furthermore, AI has the potential to intensify traditional financial stability concerns related to interconnectedness, liquidity, and leverage within the system [1]. The speed and scale of price movements driven by algorithmic trading may exceed historical precedents [1]. The selloff experienced in Japanese and US equity markets on August 5th serves as a notable example where algorithmic trading appeared to amplify market turmoil [1].  

Potential systemic risks are further compounded if AI agents exhibit highly correlated behavior, particularly when their actions are difficult to explain and adequate oversight is lacking [27]. AI agents, especially those designed to pursue narrow objectives like profit maximization, might inadvertently engage in risk-shifting activities or otherwise undermine overall financial stability [27]. These factors highlight the complex and multifaceted nature of AI-related financial stability risks, ranging from market microstructure impacts to systemic vulnerabilities arising from agent interactions and governance challenges.​  

Acknowledging these potential risks, there is also recognition that AI could serve as a tool for enhancing financial stability monitoring. Specifically, AI technologies can be utilized to develop more effective early warning indicators [17], potentially providing regulators and supervisors with improved capabilities to detect emerging vulnerabilities. Nevertheless, the inherent risks identified necessitate that regulators and supervisors must proactively adapt their frameworks and tools [1,17] to effectively monitor and mitigate these novel and potentially amplified systemic impacts introduced by the increasing adoption of AI in finance.​  

# 7. Future Directions and Opportunities  

The trajectory of large language models (LLMs) in finance presents a landscape rich with promising directions for continued research and development, poised to fundamentally reshape the sector [3,10,19,20,29,30].  

<html><body><table><tr><td>Future Research Area</td><td>Focus Areas</td></tr><tr><td>Model Architectures &Techniques</td><td>Multi-modal fusion, Knowledge Graph integration, RLHF,LoRA.</td></tr><tr><td>Explainable& Trustworthy Al</td><td>XAl techniques for LLMs, Bias reduction, Trust building.</td></tr><tr><td>Data& Computational Limitations</td><td>Robust data pipelines,Augmentation, Efficient architectures, Cost reduction.</td></tr><tr><td>Societal& Economic Impact</td><td>Labor market changes, Systemic risk, Sustainable finance, Regulation.</td></tr><tr><td>Evaluation & Benchmarks</td><td>Improving benchmarks for complex tasks and agents.</td></tr></table></body></html>  

Future advancements are anticipated across model architectures, data handling, interpretability, computational efficiency, and the broader societal and economic implications.  

Significant opportunities lie in the evolution of LLM architectures and training methodologies. Research is focusing on refining underlying deep learning algorithms to enhance performance in complex financial tasks, such as market prediction [11]. The development of more powerful foundational models is expected to provide better baselines for specialized financial applications [3]. A particularly impactful direction is the increasing emphasis on multi-modal data fusion, integrating diverse financial information beyond text, such as time series data, images, and structured reports [18]. This integration, potentially leveraging models like CLIP and combining multi-modal LLMs with knowledge graphs, promises deeper reasoning and improved decision-making accuracy [10,21,30]. Techniques like reinforcement learning from human feedback (RLHF) and low-rank adapters (LoRA) are also being explored to enhance model adaptation and personalization for financial users [7,31]. Future work will involve continued fine-tuning on specific financial tasks and exploring different tokenization and instruction tuning strategies [2,32].  

A critical area requiring continued research is the advancement of Explainable AI (XAI) and building trustworthy LLMs for finance [3,10]. Given the stringent regulatory requirements and the need for user trust in financial applications, future models must prioritize interpretability, clearly articulating the basis for their decisions [18]. Research should focus on developing XAI techniques specifically tailored to the complexity of LLMs, including advanced post-hoc and intrinsic interpretability methods for transformer-based architectures [18]. Overcoming limitations in providing trusted financial guidance is essential for wider adoption [28]. Reducing bias and toxicity in models remains a crucial aspect of building trustworthiness [2].​  

Addressing data and computational limitations is also paramount. Future research needs to develop robust data pipelines capable of handling the high-frequency, noisy, and diverse nature of financial data [17]. This includes improving data acquisition, cleaning, and developing data augmentation techniques tailored for financial time series and text [32]. Furthermore, research must tackle the substantial computational demands of LLMs by exploring more efficient model architectures and training methodologies, such as quantization, pruning, knowledge distillation, and parameter-efficient fine-tuning [34]. Optimizing inference for real-time financial applications and developing smaller, more specialized models or efficient adaptation techniques can enhance accessibility and scalability [22,34]. Strengthening underlying infrastructure, including computing clusters, networks, big data storage, and vector databases, is vital to support the training and application of financial LLMs [18].​  

Beyond technical considerations, future research must delve into the broader societal and economic impacts of LLMs in finance [8]. This includes analyzing transformations in labor markets, shifts in investment patterns, and the potential for automating tasks to free human professionals for strategic work [8,22]. Critical investigation is needed into the relationship between AI capabilities, human talent, and systemic risk within financial institutions, particularly concerning enterpriselevel risk management frameworks [1,8]. Integrating sustainable finance and social responsibility into model design and application, exploring the use of LLMs for identifying socially responsible investments and ensuring models do not inadvertently lead to discriminatory outcomes or market manipulation, represents a vital future direction [18]. Research on regulating AI in finance, including the development of supervisory technology (sup-tech), is also crucial [1]. The development of large models is expected to promote disruptive innovation in financial services, particularly in areas like risk control and operations [20].  

Key research questions for the future revolve around developing robust methods for integrating multi-modal financial data, creating truly interpretable and trustworthy LLMs for high-stakes financial decisions, devising efficient training and deployment strategies that overcome current computational barriers, and comprehensively understanding and mitigating the societal and economic consequences of widespread LLM adoption. The potential for LLMs to participate deeply in the R&D of innovative, personalized financial products is also a promising avenue [12]. Furthermore, fostering interdisciplinary collaboration between AI researchers, financial experts, data scientists, cybersecurity experts, and policymakers is essential to navigate these complex challenges and opportunities effectively [13,19]. Continuous maintenance and improvement of models and benchmarks will be crucial to support ongoing innovation in both academia and industry [30]. Adopting a cautious yet proactive approach, focusing on safety, reliability, and compliance while embracing new technologies, will maximize the potential of LLMs in the financial industry [9].​  

# 7.1 Emerging LLM Architectures and Techniques  

<html><body><table><tr><td>Technique</td><td>Description</td></tr><tr><td>Multi-modal Data Fusion</td><td>Integrating text, time series,images (e.g., charts),and structured data.</td></tr><tr><td>Integration with Knowledge Graphs</td><td>Using LLMs with KGs for deeper reasoning and information retrieval.</td></tr><tr><td>Reinforcement Learning from Human Feedback (RLHF)</td><td>Aligning model outputs with human preferences for financial tasks.</td></tr><tr><td>Parameter-Eficient Fine-tuning (e.g., LoRA)</td><td>Adapting models with reduced computational resources.</td></tr><tr><td>Advanced Tokenization/Instruction Tuning</td><td>Refining how models process and respond to financial instructions.</td></tr></table></body></html>  

Future advancements in large language model architectures and training techniques are poised to significantly impact financial applications, offering pathways to enhanced performance and novel capabilities. Beyond current model iterations, ongoing research emphasizes the refinement and optimization of underlying algorithms, particularly those rooted in deep learning, as a crucial avenue for improving market prediction accuracy and other complex financial tasks [11].​  

Furthermore, the continuous development of foundational models, such as the launch of Llama 3 by Meta in April 2024, indicates a trend towards more powerful and versatile base architectures from which specialized financial LLMs are expected to emerge, promising improved baseline performance and broader applicability [3].  

A particularly significant trend in emerging LLM techniques is the increasing focus on multi-modal data fusion. This approach integrates diverse data types beyond traditional text, such as financial reports (text), stock price charts (images/time series), and market sentiment indicators, enhancing the expressive power of financial large models and leading to improvements in task accuracy [18]. Multi-modal LLMs present substantial opportunities for processing and integrating varied financial information sources. For instance, research explores the integration of multimodal LLMs with knowledge graphs (KG). This involves using prompt engineering techniques to generate relevant relation paths from multimodal inputs. These paths can then facilitate the construction or retrieval of knowledge graph elements, enabling deeper reasoning and consequently improving the accuracy and efficiency of financial decision-making processes [21].​  

Models like CLIP (Contrastive Language-Image Pre-training), a multimodal pre-training neural network model, exemplify the foundational technologies that can underpin such advanced multimodal financial applications [21]. The fusion of diverse data modalities via sophisticated architectural designs and training methods represents a critical direction for future  

financial LLM development, potentially unlocking more comprehensive and nuanced analyses of complex financial scenarios.  

# 7.2 Advancements in Explainable and Trustworthy AI for Finance  

The increasing integration of large language models (LLMs) into financial applications necessitates a robust focus on explainable AI (XAI) and trustworthiness [3,10]. Building trust among users and stakeholders, alongside meeting stringent regulatory requirements inherent to the financial sector, hinges on the ability of these complex models to provide transparent and comprehensible decision-making processes [3,10]. Future financial large models must prioritize interpretability, enabling a clear articulation of the basis for their decisions to deliver trustworthy outcomes [18]. This clarity in explaining model behavior is crucial for users to grasp how the models function, thereby fostering greater trust and accelerating the wider adoption of LLMs in critical financial decision-making contexts [3,18]. Approaches to enhance interpretability include employing inherently interpretable model structures or designing dedicated explanatory modules to facilitate a deeper understanding of the model's internal workings [18]. Given the sophisticated and often black-box nature of current LLM architectures, future research in XAI for finance must concentrate on developing techniques specifically tailored to these complex models. This involves exploring advanced post-hoc explanation methods capable of interpreting decisions derived from high-dimensional inputs and intricate attention mechanisms, as well as investigating novel intrinsic interpretability methods applicable to transformer-based models, ultimately aiming to provide actionable and reliable explanations for financial predictions and recommendations.  

# 7.3 Addressing Data and Computational Limitations  

Future research in applying large language models (LLMs) to finance must critically address existing data and computational constraints to enhance robustness, accessibility, and efficiency. A primary area for development lies in improving data pipelines. Financial data is characterized by its high frequency, noise, sparsity, and susceptibility to biases and regulatory changes. Developing more robust data acquisition techniques is crucial, potentially involving exploration of alternative data sources beyond traditional market feeds and news while ensuring data quality and compliance. Furthermore, advanced methods for data cleaning—specifically tailored to the nuances of financial time series and text data (e.g., handling financial jargon, entity resolution, noise filtering from diverse sources)—are necessary. Data augmentation techniques also represent a promising avenue, allowing researchers to generate synthetic but realistic financial data samples to enrich datasets, mitigate overfitting, and improve model generalization, particularly in scenarios with limited historical data or when modeling rare events.​  

Concurrently, the substantial computational resources required for training and deploying large-scale LLMs pose a significant barrier to entry and scalability. Future research should focus on developing more efficient model architectures and training methodologies. This includes exploring techniques such as model quantization, pruning, knowledge distillation, and parameter-efficient fine-tuning methods specifically adapted for financial tasks and datasets. Investigating distributed training strategies optimized for the unique characteristics of financial data and the associated infrastructure constraints is also essential. On the deployment side, research into optimizing LLM inference for real-time financial applications—potentially leveraging specialized hardware or edge computing—could significantly reduce operational costs and latency. Increasing accessibility further requires developing models that are either smaller and more specialized for financial tasks or techniques that allow efficient adaptation of large foundation models to specific financial use cases without requiring massive retraining, thereby democratizing the use of advanced LLMs across financial institutions regardless of their computational capacities.​  

# 7.4 Future Research on Societal and Economic Impact  

Future research is essential to thoroughly explore the longer-term societal and economic impacts stemming from the widespread adoption of large language models (LLMs) within the financial sector [8]. This includes analyzing anticipated changes in organizational structures, transformations in labor markets, and shifts in investment patterns [8]. As LLM-related technologies advance, they are expected to automate tedious tasks, potentially enabling human professionals in finance to allocate more time to creative and strategic thinking [22], which necessitates a deeper understanding of the evolving workforce dynamics.  

Beyond direct industry changes, future investigations should address the broader economic and social implications [1]. A critical area for ongoing analysis is the intricate relationship between AI capabilities, the necessary human talent pool, and the potential for systemic risk within financial institutions [8]. Research should specifically explore the potential impact of AI on enterprise-level risk management frameworks [1].  

Furthermore, future research must place significant emphasis on integrating sustainable finance and social responsibility considerations into the design and application of financial LLMs [18]. This involves exploring how models can be developed to explicitly account for environmental protection factors or be utilized to identify opportunities for socially responsible investments [18]. Equally important is research into ensuring that the deployment of these models does not inadvertently trigger discriminatory outcomes, compromise customer privacy, or facilitate market manipulation [18]. Understanding and mitigating these potential negative externalities are crucial for the responsible and beneficial integration of LLMs into the financial ecosystem.​  

# 8. Conclusion  

The integration of Large Language Models (LLMs) into the financial sector represents a significant technological advancement with profound implications [1,3,10,12,19,29].  

<html><body><table><tr><td>Aspect</td><td>Summary Points</td></tr><tr><td>Progress</td><td>Demonstrable potential& advancements across applications (Sentiment, Risk, Agents, etc.), Specialized models emerging.</td></tr><tr><td>Challenges</td><td>Technical (Data, Interpretability, Reliability, Costs,Security), Ethical (Bias, Privacy), Regulatory, Systemic Risks.</td></tr><tr><td>Future Directions</td><td>Multi-modal fusion, XAl, Efficiency improvements, Broader impact analysis, Responsible development, Collaboration.</td></tr></table></body></html>  

As synthesized from the preceding sections, the current state of LLMs in finance is characterized by demonstrable progress in various applications, coupled with a clear recognition of inherent challenges that necessitate careful management. LLMs have shown significant potential to enhance efficiency and decision-making across numerous financial domains [16,23,34]. Key application areas explored include sentiment analysis, risk management, financial statement analysis, regulatory interpretation, and customer service [3,18,21]. Specific advancements, such as the development of domain-specific models like BloombergGPT [2], FinGPT [7], and Open-FinLLM [30], alongside frameworks like RiskLabs for risk prediction [4] and InvestorBench for evaluating agent capabilities [15], highlight the growing maturity and specialization of LLM applications in finance. Research demonstrates LLMs' capabilities in tasks such as predicting financial risk premiums [11], performing financial statement analysis on par with human analysts [33], and assisting in regulatory interpretation [25]. Techniques like instruction tuning and retrieval augmentation have proven effective in improving performance in financial tasks like sentiment analysis [5,31,32].​  

Despite the transformative potential to improve efficiency, enhance decision-making, and create new opportunities, significant challenges and limitations must be addressed for responsible adoption [3,10,12,18]. Technical challenges include addressing issues such as look-ahead bias, the mismatch between pre-training objectives and financial tasks, the need for robust contextual understanding, numerical sensitivity, data quality limitations, and potential issues like "redundant disclosure" in analysis [3,5,16,23,32]. The reliability and consistency of LLMs in critical functions like financial advisement also require further development [28]. Beyond technical hurdles, the deployment of LLMs introduces significant ethical and regulatory considerations, including privacy concerns, potential biases leading to impaired fairness, security threats, and the broader impact on financial stability [1,3,6,9,13,18,19,21,22]. The need for establishing comprehensive industry standards and regulations is paramount [12,17,18,37].​  

Looking forward, the trajectory of LLMs in finance points towards continued innovation driven by advancements in model architectures, training techniques, and data integration. Promising areas for future research include optimizing retrieval augmentation and improving evaluation benchmarks [32], expanding multimodal fusion techniques to integrate diverse data types [4,21,30], and exploring the fusion of LLMs with knowledge graphs [21]. The development of open-source  

frameworks and benchmarks is expected to democratize access and accelerate progress [7,15]. Achieving competitive advantages will increasingly depend on the effective integration of AI with business operations, necessitating the cultivation of new AI-specific skills within the workforce [20,34].  

Ultimately, harnessing the full potential of LLMs in the financial industry requires a balanced approach that couples proactive innovation with rigorous risk management and regulatory foresight [9,27]. It is imperative that researchers, practitioners, and policymakers engage in collaborative efforts to ensure the responsible development and deployment of LLMs, safeguarding against potential risks while maximizing the beneficial and ethical application of this transformative technology within the financial sector [1,13,17,19,37].​  

# References  

[1] AI's Impact on Financial Markets and Financial Sta http://www.imf.org/en/News/Articles/2024/09/06/sp090624-artificialintelligence-and-its-impact-on-financial-markets-and-financial-stability  

[2] BloombergGPT：面向金融领域的大语言模型 https://blog.csdn.net/Together_CZ/article/details/144880005 [3] 大语言模型在金融领域的应用：进展、前景与挑战 https://blog.csdn.net/m0_59164304/article/details/140217427 ] RiskLabs: LLM-Based Financial Risk Prediction via  http://www.paperreading.club/page?id $\ c =$ 221299  

5] LLM在金融时序数据预测与情感分析中的应用研究 https://blog.csdn.net/weixin_49020292/article/details/134408866 [6] Gen AI in Corporate and Investment Banks: Adoption https://www.mckinsey.com/industries/financial-services/ourinsights/been-there-doing-that-how-corporate-and-investment-banks-are-tackling-gen-ai  

[7] FinGPT：开源金融大型语言模型框架 https://blog.csdn.net/cdxxsq/article/details/137358849 [8] 生成式人工智能对金融的冲击：企业价值、研究与未来展望 https://cec.blog.caixin.com/archives/278704 [9] 大语言模型在证券行业应用：思考、探索与挑战 http://finance.china.com.cn/roll/20241125/6189518.shtml [10] 金融应用大语言模型综述：进展、前景与挑战 https://blog.csdn.net/yorkhunter/article/details/141290006  

[11] ChatGPT解码金融：AI预测中国股市风险溢价 https://mp.weixin.qq.com/s? _biz=MzA3NzIxNDQ3MQ $\scriptstyle = =$ &mid=2650331214&idx $\underline { { \underline { { \mathbf { \Pi } } } } } = \underline { { \underline { { \mathbf { \Pi } } } } }$ 3&sn=09117d39bbb61ceaddaeaff5175a7d4a&chksm $\mid =$ 868cc367eab0632   
061f57bcd0b105f1175abdc453d7d65d67c993f7212aec71af247d3aec25e&scene=27  

[12] Large Language Models in Finance: Opportunities, C https://jtp.cnki.net/bilingual/detail/html/JNXB202408009 [13] 金融人工智能：风险、挑战与监管应对 https://baijiahao.baidu.com/s?id $\ c =$ 1820959865650330115&wfr=spider&for=pc [14] LLMs for Business Research: Applications in FinTec https://sme.cuhk.edu.cn/node/2558 [15] InvestorBench: A Benchmark for LLM-Based Agents in https://paperswithcode.com/paper/investorbench-a-benchmarkfor-financial  

[16] Generative AI in Finance and Banking: Use Cases, E https://www.netguru.com/blog/generative-ai-use-cases-finance  

[17] 人工智能对中央银行的影响：机遇与挑战 https://mp.weixin.qq.com/s?  
__biz $: =$ MjM5MDMwMjUyNA $\scriptstyle =$ &mid=2652318248&idx=1&sn=40f3180858d0c128d42cff4c79e7e1c2&chksm=bccffaf1a5b9625c3  
e9247d6e1144f9c7333b1e3c8d19847b41f0108a23348a43a0793768636&scene=27  

[18] 积极稳妥推进金融大模型发展与应用 http://www.rmlt.com.cn/2024/0716/707542.shtml [19] LLMs Reshape China's Fintech Sector: Opportunities http://www.chinadaily.com.cn/a/202407/03/WS6684b457a31095c51c50c16e.html [20] DeepSeek搅局：金融大模型走向何方？成本降低能否缩小技术鸿沟 https://baijiahao.baidu.com/s? id=1823736203327719949&wfr=spider&for=pc  

[21] 大语言模型在金融领域的应用场景探析 https://mp.weixin.qq.com/s?   
_biz=MjM5NDI3ODI4OQ $\scriptstyle = =$ &mid=2650928181&idx $\mathbf { \bar { \rho } } = \mathbf { \rho }$ 4&sn=a5ec37945d27313a3a719ebea5ab856c&chksm=bc6a652c7a63ca7a   
62cadcdc68fee4467a1d5bb9c15ff3aae76fa7ea786a82d9d31e028b190c&scene=27  

[22] Generative AI Set to Expand in Banking, Emphasizinhttp://www.chinadaily.com.cn/a/202308/10/WS64d43183a31035260b81b446.html[23] 生成式AI在会计与财务分析中的前沿应用研究 https://www.swufe.edu.cn/info/1067/36171.htm  

[24] Transformer模型在金融领域的应用：风险管理与预测分析 https://wenku.csdn.net/column/5shsuiyc3u   
[25] LLMs for Financial Regulatory Interpretation: Base http://www.paperreading.club/page?id=226614   
[26] LLMs and FinBERT for Financial Sentiment Analysis: http://www.paperreading.club/page?id=256498   
[27] 金融智能革命：人工智能如何重塑金融业？ https://mp.weixin.qq.com/s?   
_biz=MjM5MDMwMjUyNA $\scriptstyle { \underline { { = } } } =$ &mid=2652318135&idx=1&sn=19e465196b0becfb0976ee2bff302d84&chksm=bc46736740bc53e   
d68de8078a2e20376d89de15850e1c46338a04b37b6ce48f64304be711368&scene=27   
[28] LLMs in Financial Advisement: Fairness and Efficac https://dl.acm.org/doi/fullHtml/10.1145/3604237.3626867   
[29] 金融领域大型语言模型：综述、解决方案与应用指南 https://juejin.cn/post/7350941300734361635​   
[30] Open-FinLLM：开放式多模态金融大语言模型介绍 https://blog.csdn.net/c_cpp_csharp/article/details/142431959   
[31] 金融情绪分析：大型语言模型的自适应研究 https://blog.csdn.net/c_cpp_csharp/article/details/136352674​   
[32] 检索增强LLM提升金融情绪分析 https://blog.csdn.net/c_cpp_csharp/article/details/134281468   
[33] LLM财务报表分析：媲美分析师，洞察盈利方向 https://weibo.com/1402400261/OfSbKmqRf   
[34] Large Language Models (LLMs): Understanding, Appli https://www.dataquest.io/blog/what-are-large-language-models  
llms/   
[35] NYU Data Science Master's Capstone Projects https://cds.nyu.edu/masters-in-data-science-capstone/   
[36] LLM在量化金融中的应用展望 https://max.book118.com/html/2024/0607/7021050126006116.shtm   
[37] AI/ML 治理：金融服务风险与监管 https://caia.org/videos/governance-ai-ml-financial-services  