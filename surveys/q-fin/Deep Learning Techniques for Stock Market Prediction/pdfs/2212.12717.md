# Stock Market Prediction via Deep Learning Techniques: A Survey  

JINAN ZOU∗ and QINGYING ZHAO∗, University of Adelaide, Australia   
YANG JIAO, University of Adelaide, Australia   
HAIYAO CAO, University of Adelaide, Australia   
YANXI LIU, University of Adelaide, Australia   
QINGSEN YAN, Northwestern Polytechnical University, China   
EHSAN ABBASNEJAD, University of Adelaide, Australia   
LINGQIAO LIU, University of Adelaide, Australia   
JAVEN QINFENG SHI, University of Adelaide, Australia  

Existing surveys on stock market prediction often focus on traditional machine learning methods instead of deep learning methods. This motivates us to provide a structured and comprehensive overview of the research on stock market prediction. We present four elaborated subtasks of stock market prediction and propose a novel taxonomy to summarize the state-of-the-art models based on deep neural networks. In addition, we also provide detailed statistics on the datasets and evaluation metrics commonly used in the stock market. Finally, we point out several future directions by sharing some new perspectives on stock market prediction.  

# CCS Concepts: $\cdot$ Applied computing $$ Economics; $\cdot$ Computing methodologies $$ Artificial intelligence; Machine learning.  

Additional Key Words and Phrases: Deep learning, Machine learning, Finance, AI in finance, Stock market prediction  

# ACM Reference Format:  

Jinan Zou, Qingying Zhao, Yang Jiao, Haiyao Cao, Yanxi Liu, Qingsen Yan, Ehsan Abbasnejad, Lingqiao Liu, and Javen Qinfeng Shi. 2023. Stock Market Prediction via Deep Learning Techniques: A Survey. 1, 1 (February 2023), 34 pages. https://doi.org/XXXXXXX.XXXXXXX  

# 1 INTRODUCTION  

The financial market plays a crucial role in shaping the development of global economies. As the stock market gains more prominence in the economic sphere, it has garnered increasing attention from the general public. One theory that explains the pricing of financial assets and the reasoning behind stock market volatility is the efficient market hypothesis [88]. The efficient market hypothesis posits that in a legally sound, well-functioning, transparent, and competitive stock market, rational investors can quickly and rationally react to all market information. As a result, stock prices will accurately, sufficiently, and promptly reflect all important facts, including a company’s present and future value. However, the fluctuation of stock prices is influenced by a complex array of factors, including company  

∗Both authors contributed equally to this research.  

earnings reports, national policies, influential shareholders, and expert speculations on current events. Therefore, there is a need to utilize machine learning techniques for stock market prediction tasks, such as stock movement prediction, stock price prediction, portfolio management, and trading strategies.  

The stock market is characterized by both uncertainty and variability, making it challenging to accurately predict market trends. Machine learning techniques have been employed in stock price prediction to improve the accuracy of predictions and alleviate these difficulties. Historically, conventional models such as decision tree-based models [56, 97, 124] and Support Vector Machines (SVM) [138] have been utilized in stock market forecasting.  

As deep learning models have evolved, the methods used for predicting the stock market have shifted from traditional techniques to advanced deep learning techniques such as Recurrent Neural Networks (RNNs), Long Short-Term Memory (LSTM), Gated Recurrent Units (GRUs), Graph Neural Networks (GNNs), and Convolutional Neural Networks (CNNs). Recently, researchers have also begun to explore the use of Transformer-based models and Reinforcement learning (RL) models in stock market forecasting. Despite the abundance of surveys on stock market forecasting, existing surveys [4, 5, 73, 122] had limitations. For instance, some surveys have focused on traditional technologies without critically examining the latest advancements, such as Transformer models. Additionally, some surveys have been vague in their classification of models and have not used an authoritative criterion. Furthermore, many of the challenges and open issues identified in previous studies have already been addressed. This survey aims to fill these gaps by providing a comprehensive and insightful overview of the latest techniques and trends in stock market forecasting. By reviewing high-quality papers from top conferences, this survey summarizes the most recent advancements in techniques such as Transformer and RL and provides in-depth analysis and discussion. It is intended to provide researchers, practitioners, and educators with a systematic overview and a comprehensive understanding of relevant deep learning techniques and the most promising directions for future research.  

This survey aims to gain insight into the advancements in stock market forecasting by categorizing the models and analyzing their publication year. Additionally, the survey aims to provide a detailed understanding of the structure and application of each model in stock market forecasting.  

The three key contributions of this survey are as follows:  

• In this survey, we thoroughly examine stock market prediction, which encompasses four distinct tasks: stock movement prediction, stock price prediction, portfolio management, and trading strategies. To conduct this study, we have compiled a collection of 94 papers that focus on these highly relevant topics.   
• This survey introduces a new deep-learning classification system for predicting stock market performance. The reviewed literature, which is organized according to this taxonomy, explores various deep learning models such as RNN, CNN, GNN, Transformer, and RL. Furthermore, the survey compiles a summary of the datasets, evaluation techniques, and model inputs used in these studies.   
• In this study, we delve into the unresolved challenges faced by deep learning-based stock market prediction and offer thorough insights into potential future research in this area.  

Organization of the Survey. This survey is organized into eight sections. The hierarchical structure of the survey is illustrated in Figure 1. The first section provides an overview of the background, research motivation, and objectives of stock market forecasting. In Section 2, previous surveys on the topic are reviewed, and their limitations and areas for improvement are identified. Section 3 details the methodology used for reviewing papers, including the criteria for categorization, such as conference, model, and year of publication. In Section 4, various deep learning models used in the stock market prediction are discussed, and the papers are analyzed based on model types. The datasets and model Manuscript submitted to ACM  

![](images/c30a8e295bbaa31b05c0b1ab5c0f69566653a511b142a330393ec11c8a3427fb.jpg)  
Fig. 1. The hierarchical structure of this survey with eight sections.  

input features used in the reviewed methods are discussed in Section 5. Evaluation metrics commonly used in the stock market prediction are introduced in Section 6. Section 7 focuses on open issues and potential future developments in the field. The survey concludes with a summary in Section 8.  

# 2 RELATED WORK  

In past studies on stock prediction, traditional methods such as SVM, regression, and KNN have been widely used. However, with the advancement of neural networks, there has been a shift towards utilizing these networks in stock prediction research. Atsalakis and Valavanis [4] conducted a survey of 100 papers on stock market prediction, focusing on neural and neuro-fuzzy techniques. They classified and analyzed papers published from 1990 to 2006 by comparing different stock markets, input variables, prediction approaches, and evaluation metrics. Li and Ma [73] published a survey on using artificial neural networks in financial market applications, including stock price prediction and option pricing. Ballings et al. [5] focused on classifier models for ensemble methods in stock price prediction and single classifier models. The ensemble methods included Random Forest, Adaboost, and Kernel Factory, while the single classifier models included Neural Networks, Linear Regression, SVM, and K-Nearest Neighbors. This was the first study to make an extensive benchmark. Tkac and Verner [122] provided a systematic overview of 412 papers published between 1994 and 2015 on the commercial application of artificial neural networks in the financial industry. The main applications of this survey included financial distress, bankruptcy problems, and decision support for stock price forecasting, with a focus on classification tasks. Cavalcante et al. [12] reviewed influential papers using various machine learning algorithms from 2009 to 2015 in financial applications, and discussed challenges and unsolved problems in this field. The main machine learning methods covered included artificial neural networks, SVMs, hybrid methods, optimization methods, and ensemble methods. The applications included preprocessing and clustering financial data, forecasting future market trends, and mining financial text information. Li et al. [66] surveyed 229 papers from 2007 to 2016 investigating the relationship between web media and stock markets, and proposed directions for further research. They proposed a taxonomy that divided machine learning techniques into statistical models, regression models, and machine learning-based models. The neural network models included Bayesian classifiers and SVMs. Xing, Cambria, and Welsch [139] investigated papers on applying natural language processing methods to financial forecasting tasks, mainly focusing on three aspects: different types of text sources, algorithms, and results based on different evaluation metrics. The text sources included news, social media, financial reports, and message boards. The model types included regressions, SVM, ensemble learning, and CNN. Nti, Adekoya, and Weyori [96] reviewed papers from 2007 to 2018, focusing on three categories of analysis: technical, fundamental, and combined analysis. The models were limited, and only three techniques were well discussed: decision tree, SVM and ANN. Ersan, Nishioka, and Scherp [37] also focused on three prediction models: KNN, ANN, and SVM. This survey aims to make comparisons among various machine learning approaches on DAX 30 and the S&P 500 datasets at daily and hourly levels.  

![](images/d38fa2ad1b733c05b398d7376cebdd702bb70099c2e7c40e0e1057cb966fae56.jpg)  
Fig. 2. Three Figures show the statistics of the papers according to different criteria.  

Recent surveys on stock market prediction have primarily focused on deep learning techniques such as CNN, RNN, and GNN. Jiang [54] stood out among others as it took into consideration the implementation and reproducibility of the research. Specifically, the paper highlighted the main tools used for implementation, including Keras, TensorFlow, PyTorch, Theano, and scikit-learn. The data and code availability of several papers were also investigated to demonstrate reproducibility. This study placed emphasis on the recent advancements in deep learning methods applied to stock market prediction. Thakkar and Chaudhari [120] examined various deep learning-based neural network approaches for stock market prediction. The study summarizes and analyzes the need, challenges, and future directions based on papers from 2017 to 2020. Kumbure et al. [60] conducted a literature review of 138 journal articles on stock market forecasting published between 2000 and 2019. The survey places particular attention on the features and unique variables in the datasets. The survey categorizes the deep learning methods into two groups, supervised and unsupervised machine learning methods. However, some of the surveys still lack the inclusion of the latest techniques such as Transformer and pre-trained BERT models, which are also reviewed in this survey.  

Previous surveys have extensively covered traditional methods and older neural network techniques, leaving a gap in understanding current research trends. Recent surveys have not been fully updated to include the latest techniques. Additionally, some existing surveys [50, 54, 59, 60, 66, 120] have not adequately classified papers by targets or have only focused on stock market forecasting tasks. Given this need for an updated survey that incorporates the latest techniques for stock market prediction, this survey proposes a new deep learning model classification method and aims to provide a more comprehensive and up-to-date analysis. The focus will be on newer papers and the most current technology.  

Manuscript submitted to ACM  

# 3 REVIEW METHODOLOGY AND CRITERIA  

# 3.1 Review Methodology  

In this study, we focus on literature pertaining to stock market prediction. To gather a comprehensive collection of papers, we implemented a strategy as follows. Initially, we limited the timeframe to the last decade. Next, we identified the leading Natural Language Processing (NLP) and Artificial Intelligence (AI) conferences, including ACL, EMNLP, AAAI, IJCAI, ICAIF, NeurIPS, and KDD. Within these conferences, we utilized the search engine Google Scholar with specific keywords such as stock prediction, market, finance and portfolio. We also included the names of deep learning models as keywords, such as RNN, LSTM, and GNN, Transformer, and RL. By using these keywords, we were able to find papers related to stock market prediction, finance, trading, and portfolio. We then used machine learning to filter papers that predicted the stock market. After filtering, we selected 42 high-quality papers related to stock prediction. After excluding papers with less than two pages of content, 39 papers were screened. By reading the cited papers in these 39 papers, we also included the top-ranked papers from journals and conferences in our research paper list. In total, this survey includes 94 high-quality papers that cover a diverse range of deep learning methods.  

# 3.2 Selected Paper Statistics  

This section presents statistics from the stock market forecast papers included in the survey through various charts. First, the papers are grouped by top conference. Figure 2(a) displays the number of papers from top conferences, such as $\mathrm { \ A C L ^ { 1 } }$ , NAACL2, EMNLP3, AAAI4, IJCAI5, $\mathrm { I C A I F } ^ { 6 }$ , NeurIPS7, ICML8, $\mathrm { I C L R } ^ { 9 }$ , and $\mathrm { K D D ^ { 1 0 } }$ . As seen in Figure 2(a), a total of 39 high-quality papers were included in this survey. The conferences of ACL and AAAI had the most papers on stock market prediction. Figure 2(b) illustrates the proportion of papers utilizing five different models. This survey covers all the types of models mentioned, with each model having more than 15 papers. The survey includes advanced models, such as Transformer-based and RL models, which make up $1 8 . 9 \%$ and $2 4 . 2 \%$ respectively. Figure 2(c) shows the number of papers by publication year. The largest proportion of papers in this survey were published in 2021, with a total of 24 papers. During the five-year period from 2012 to 2016, there were 11 papers.  

# 4 STOCK MARKET PREDICTION IN MACHINE LEARNING  

# 4.1 Stock Prediction Related Tasks  

Before delving into the specifics of the deep learning model, we will first define four key stock market prediction tasks and provide an overview of the concepts associated with each task. These tasks include stock price prediction, stock movement prediction, portfolio management, and trading strategies. These categories encapsulate the majority of existing stock market prediction tasks.  

Stock Price Prediction. The objective of Stock Price Prediction utilizing time-series data is to anticipate future values for stocks and financial assets traded on an exchange by researchers. The ultimate goal of this prediction is to achieve substantial profits. Additionally, various factors also influence the prediction process, including psychological factors as well as rational and irrational behavior. All of these factors work together to make share prices dynamic and volatile.  

• Stock Movement Prediction. The task of Stock Movement Prediction typically categorizes stock trends into three categories: uptrend, downtrend and sideways. This task is formalized by analyzing the difference between the adjusted closing prices of a stock over a certain period of trading days.   
• Portfolio Management. Portfolio management involves the strategic selection and oversight of a collection of investments with the aim of achieving financial objectives. The goal of portfolio management is to allocate resources in a way that maximizes returns while minimizing risks.   
• Trading Strategies. A trading strategy is a pre-established set of guidelines and criteria that are used to make trading decisions, and it is a methodical approach to buying and selling stocks. Trading strategies can range from simple to complex, and factors such as investment style (e.g., value vs. growth), market cap, technical indicators, fundamental analysis, level of portfolio diversification, risk tolerance, and leverage are taken into consideration. In stock market prediction tasks that utilize deep learning, common trading strategies include event-driven, data-driven, and policy optimization.  

The above tasks center around the process of stock market prediction. To provide a comprehensive understanding of deep learning-based approaches, Figure 3 illustrates the prediction process. The first step involves processing input data, including stock data, graphs, and texts. After that, relevant stock features are selected and collected. The next step is to input the extracted features into a deep learning model for training. Lastly, the model’s experimental results will be obtained and analyzed.  

![](images/67fc2b946a675191ce1108ab7942c40f63698d4785af5ee08b5d2e783f2a372c.jpg)  
Fig. 3. The Processing Framework.  

# 4.2 Deep Learning Based Models  

We categorized the papers based on the models and presented the different models in Figure 4. Figure 5 provides a general overview of the mainstream deep learning models used in stock market prediction. These models include: RNN-based models (Figure 5(a)), CNN-based models (Figure 5(b)), GNN-based models (Figure 5(c)), RL models (Figure 5(d)), Transformer-based models (Figure 5(e)), as well as other unique methods. The input for these models can be stock price-related data, text data, and relationships between companies, and the models generate outputs based on the goals outlined in the papers.   
Manuscript submitted to ACM  

![](images/4f3f3be97fe92913441e2c6008e8efa1a0a7f32fc096e5221fc9254eac7f7466.jpg)  
Fig. 4. The classification method of stock market prediction papers according to the models.  

![](images/236c87e95935b753580fa6fbf063ca85aeadcb646dbd4fe63ca1c20a05f14a8a.jpg)  
Fig. 5. The general view of mainstream deep learning models for stock market prediction.  

# 4.3 Recurrent Neural Network Based Models  

The RNN, as described in [107], is a deep learning model that can efficiently process sequential data. Stock market data is commonly represented as time series, making RNN an ideal choice for making predictions by modeling historical data. However, RNNs have the drawback of gradient vanishing when processing data over a long-term period. To address this issue, several variants of RNN have been developed, including LSTM [46], GRU [20], and Bidirectional LSTM (Bi-LSTM) [43]. RNNs can be thought of as a recurrent combination of multiple identical network cells, where the output of each Manuscript submitted to ACM cell is provided as input to the next cell [62]. Each cell contains a set of input, hidden, and output units. The LSTM unit has three gates, the update gate, the forget gate, and the output gate, which help to control short-term and long-term memory. The GRU model is an improvement over the LSTM model, which combines the input gate and the forget gate into an update gate, and adds a reset gate to control the information to be forgotten [20]. These models have improved RNNs and made significant progress in stock market prediction.  

Recurrent Neural Network (RNN). RNN is a well-established deep learning model that has been applied in stock prediction. However, in recent years, researchers have sought to enhance the performance of RNN by exploring its hybrid application with other machine learning techniques. Agarwal and Sastry [106] proposed a novel and robust hybrid prediction model (HPM) that combines three prediction models: RNN, Exponential smooth (ES) and Autoregressive moving average model (ARMA). They also used genetic algorithms to optimize the model by providing optimal weights which significantly improves the prediction accuracy. Another approach, proposed by Zhang, Aggarwal and Qi [152], is the State Frequency Memory (SFM) based on RNN, which is able to capture multi-frequency trading patterns from the stock market underlying the fluctuation of stock prices.  

Long Short-Term Memory (LSTM). The LSTM model boasts the ability to effectively handle text and time-series data, making it ideal for stock market forecasting. LSTM addresses the problem of preserving information over longer time intervals through the use of the gradient method, which is an improvement over RNN models. For example, Akita et al. [1] proposed a Paragraph Vector method to represent textual information and utilized LSTM for the prediction model. In this experiment, ten companies were represented as ten articles, where the vector of articles is represented as $P _ { t }$ . The prices of these companies were represented as $\{ c 1 , c 2 \mathrm { f i } , c 1 0 \}$ at a single timestep $t$ and concatenated as a stock prices vector $N _ { t }$ . The input of LSTM is the combination of $P _ { t }$ and $N _ { t }$ . LSTM significantly outperforms the baselines, Multi-Layer Perceptron (MLP), Support Vector Regression (SVR), and Simple-RNN, for the opening prices prediction. Another example, Ma et al. [87] proposed the News2vec model, in which dense vectors represent news features. They used LSTM with the self-attention mechanism as the predictive model. This text embedding model News2vec helps to uncover the potential relationship between news and its event elements. Nelson, Pereira and Oliveira [94] used LSTM for stock movement prediction, but the model inputs were numerical information, including stock prices and volume.  

In stock prediction research, it is common to process stock prices as a time series analysis, but few researchers take into account the potential time dependency of the data. Zhao et al. [156] proposed a time-weighted LSTM model with trend retracement, which assigns weights to data based on its temporal proximity to the data to be predicted. Hybrid models, which are a combination of LSTM with other models, have been proposed to improve prediction performance. Polamuri et al. [98] proposed the Generative Adversarial Network-based Hybrid Prediction Algorithm (GAN-HPA) to implement the Stock-GAN developed from a GAN-based framework. The framework takes various inputs, such as stock datasets and hyperparameters. Linear and non-linear models are used to extract features from the dataset, and the hyperparameters and pre-processing results are used as inputs to the LSTM. The output of the generator and raw data are provided to the discriminator, and Bayesian approximation is used to adjust the parameters and update the prediction results. Wang et al. [130] made a significant contribution by proposing a method for dynamically extracting potential representations of financial market trends from transaction data. They proposed a hybrid Convolutional LSTM-based Variational Sequence-to-Sequence model with Attention (CLVSA). The model consists of convolutional LSTM units and a sequence-to-sequence framework with self-attention and inter-attention mechanisms.  

Nguyen and Yoon [95] developed a framework called deep transfer with related stock information (DTRSI) that takes into account stock relationships to predict stock price movements. To achieve this, the authors employed LSTM cells during pre-training on large-scale data to optimize parameters and then fine-tuned the base model using a small Manuscript submitted to ACM  

amount of target data to obtain the final model. This approach addresses the problem of overfitting due to the small sample size and accounts for the relationship between stocks.  

Adversarial training can simulate stock price fluctuations by introducing perturbations, which can enhance the accuracy of stock movement prediction. In 2019, Feng et al. [40] proposed a method that combines attentive LSTM and adversarial training to predict stock market movements. Another approach to predicting multiple stock prices simultaneously is the associated network model proposed by Ding and Qin [27], which consists of three branches that predict the opening price, the lowest price, and the highest price respectively.  

Chen et al. [14] used Bi-LSTM to encode stock data and financial news representations in their models, namely the Structured Stock Prediction Model (SSPM) and multi-task Structured Stock Prediction Model (MSSPM). They also incorporated representations of trading events consisting of event roles embeddings, which are the subject and object extracted using the 𝑆𝑡𝑎𝑛𝑑 𝑓 𝑜𝑟𝑑 𝐶𝑜𝑟𝑒𝑁 𝐿𝑃2 tool [106]. The MSSPM model was uniquely trained on both stock prediction and event extraction tasks, as the authors believed these tasks have an intrinsic relationship, and accurate extraction results would benefit stock prediction results. To make time-aware predictions, Sawhney et al. [110] proposed a hierarchical learning method named FAST for ranking stocks based on expected profit. This model used a time-aware LSTM to model temporal irregularities in news and tweets. The FAST model demonstrates the positive effects of factoring in-text fine-grained temporal irregularities in simulations on the S&P 500 and China A-shares indexes.  

Li and Pan [74] proposed that stock prices are impacted by a variety of factors and put forth an ensemble deep learning model that combines LSTM and GRU. They also determined the window size for textual information by consulting psychological and economic theories to account for the lasting or fleeting impact of news.  

Gated Recurrent Unit (GRU). GRUs are a variation of LSTMs that have been found to perform well in stock market prediction. They address the issue of vanishing gradients and improve training speed by reducing the number of cells [20]. Inspired by the work of Qin et al. [103], who proposed a dual-stage attention-based RNN for time series prediction, Yang et al. [146] proposed a dual-level attention mechanism for stock price prediction using a GRU network. This mechanism allocates different weights to different financial news titles based on their impact on the stock price, with a focus on explaining the reasons for the prediction and avoiding errors from natural language processing tools. Similarly, Li, Shen, and Zhu [63] proposed a novel multi-input LSTM (MI-LSTM) model that uses attention to differentiate between main and auxiliary factors and assign different weights to these inputs to prevent the influence of irrelevant factors on the final result.  

To address the challenge of chaotic news, Hu et al. [49] developed a Hybrid Attention Network (HAN) that incorporates a self-paced learning mechanism. This approach takes into account both the credibility and comprehensiveness of financial news. The HAN consists of two attention layers, one at the news level and the other at the temporal level. Bi-directional GRU layers are also utilized to encode the temporal sequence of corpus vectors. After back-testing, the annualized rate of return in simulated transactions was significantly improved. Similarly, Wang et al. [129] proposed a framework for the stock prediction that incorporates expert opinions. The multi-view fusion network stance detection model (MFN) framework uses text features from multiple views and relevant financial domain knowledge to determine texts’ upside and downside investment opinions. A stance aggregation module is then used to identify and aggregate high-quality opinions based on a dynamic expert mining procedure. Finally, a stock prediction module is used to predict the future trend of individual stocks using the input expert opinion indicators from the first two sections. The prediction component utilizes a GRU to encode a time-ordered sequence of features and a time-aware attention mechanism to dynamically incorporate hidden states in the stocks. The model was validated using real-world datasets, demonstrating its effectiveness in making investment recommendations and individual stock predictions.  

In an effort to tackle the difficulties of stock trend forecasting caused by non-smooth dynamics and complex market dependencies, Wang et al. [127] introduced a new Hierarchical Adaptive Temporal-Relational Network (HATR) for describing and predicting the evolution of stocks in 2021. The HATR model captures both short-term and long-term transition characteristics from multi-scale local combinations of stock trading series through the use of expanding causal convolutions and gating paths. This model builds upon their previous work, in which they utilized a dual attention mechanism with a Hawkes process and target-specific queries to detect key time points and scales based on individual stock characteristics. Additionally, to uncover hidden interdependencies among stocks, the authors incorporated a multi-graph interaction module that combines prior domain knowledge with data-driven adaptive learning.  

# 4.4 Convolutional Neural Network Based Models  

CNNs have been widely studied for their effectiveness in both computer vision (CV) and natural language processing (NLP) tasks [52]. A CNN model is composed of several convolutional and pooling layers that are used for feature extraction. The traditional convolutional layers use two-dimensional filters (kernels) and activation functions to process image features. However, in the stock prediction domain, CNNs are used to process time series data, which are onedimensional features. To accommodate for this difference in data shape, CNNs for time series utilize a one-dimensional filter that slides over the time series with a stride determined by the data granularity.  

It is commonly believed that CNNs excel at capturing important features through the use of convolution layers, making them effective at predicting stock fluctuations. Selvin et al. [115] supported this view. Additionally, Ding et al. [30] improved upon the event embedding method [29] by incorporating a CNN for training on input history event embeddings, with the pooling layer effectively extracting representative event history features. The Universal CNN-based predictor (U-CNN pred) [47] was trained using a layer-wise approach, where the subCNNs layers were pre-trained sequentially until the proposed model structure was completed. This model showed reasonable results and was proven effective due to its shallow structure, which reduced the risk of overfitting as there were less weights to be learned.  

To fully utilize the information contained within industrial relations, some models have integrated knowledge graphs with CNNs in order to enhance their performance. One such model is the Knowledge-Driven Temporal Convolutional Network (KDTCN) proposed by Deng et al. [25]. This model utilizes the Open IE [38] to extract events related to the knowledge graph and make interpretable stock predictions. A common issue with traditional one-dimensional convolutional layers is data leakage, where information from time $t - 1$ and $t + 1$ could influence the data at time 𝑡. To address this issue, the KDTCN model employs causal convolution, which only used information from the current and previous time steps in the previous layer. The KDTCN model has been shown to be effective in explaining abrupt price changes by extracting significant features in the price time series [25].  

The integration of CNN and LSTM can enhance time series prediction even further. Lu et al. [83] introduced a CNN-LSTM model for forecasting daily stock closing prices, where the CNN component extracts features from a 10-day historical data time series, and the LSTM component makes the price prediction. In a subsequent study, Lu et al. [84] proposed a CNN-BiLSTM-AM model which incorporates the attention mechanism to capture historical influential stock fluctuations on price time series and improve the performance of the CNN-based model. Wang et al. [128] also presented a CNN-BiLSTM model for stock closing price prediction and improved the model’s performance by adding a tanh function to the output gate of the Bi-LSTM. Mehtab and Sen [91] proposed a univariable convolutional LSTM model for predicting the opening price of Indian stocks and improved the model’s performance by partitioning a 10-day time series into two 5-day data sequences to allow the convolutional layer to extract more historical data features. Manuscript submitted to ACM  

Additionally, the use of GRU has also been recently demonstrated as efficient in processing tasks. Zhou, Zhou, and Wang [157] proposed an ensemble stock market prediction model consisting of CNN and Bidirectional GRU, which is feature-selection-based. The CNN is responsible for feature extraction, while the GRU is responsible for processing the time series data. They used the closing price of the stock market as the model output and all other data as inputs and obtained results with less error than other basic models.  

Some recent studies have explored the integration of knowledge graphs, LSTM, and CNN for stock prediction. Wu et al. [137] developed a CNN-based framework that utilized historical stock prices and future data, such as leading financial indicators. In their subsequent work [136], they proposed a graph-based CNN-LSTM model that uses a combination image composed of an option image, a future image, and a historical image. This image contains 30-day information, including stock price and financial indices of one specific stock. The rows of the combination image represent the time series changes, while the columns represent the features that are fed into the CNN-LSTM model. To address the issues of overfitting and slow convergence in fuzzy systems, Chandar [13] developed a robust stock trading model. This model extracted ten technical indicators from historical stock data and used them as feature vectors. By setting the data range, the convergence rate was improved. These feature vectors were then transformed into images and used as input for a CNN model to obtain labelled sell points, buy points, and hold points. The dropout layer added in the CNN models helped to prevent overfitting. The effectiveness of this model was measured by accuracy and F1-score.  

# 4.5 Graph Neural Network Based Models  

GNN is a type of artificial neural network that process data in the form of graphs, as outlined in [112]. They play a crucial role in stock market prediction, as they are able to operate on irregularly structured data, unlike CNNs which are designed for Euclidean structured data. The structure of a GNN is made up of nodes and edges, which allows it to model the relationships between entities. In the context of stock market prediction, nodes typically represent companies or stocks and edges represent the relationships between them. For example, the share prices of linked companies often fluctuate simultaneously, such as when a piece of good news is released and corresponding stocks see an immediate surge. This highlights the importance of taking relationships into account when making predictions. This chapter will explore four main graph-based models: GNN, Graph Convolutional Networks (GCN) [58], and Graph Attention Networks (GAT).  

Graph Neural Network (GNN). Matsunaga, Suzumura and Takahashi [90] employed a knowledge graph to integrate information on companies and GNN models as a means of predicting individual stock performance. The use of knowledge graphs allows for the representation of relationships between entities that represent companies in the context of stock market predictions. One of the key contributions of the paper is the utilization of a backtesting approach through rolling window analysis. Similarly, Ding et al. [31] built upon their previous event-driven works [29, 30] by introducing a Knowledge Graph Neural Tensor Network (NTN) model. This model encodes the entity vectors that represent the relationship between entities of extracted events and feeds them into the event-embedding learning process, addressing the limitation of event embedding in revealing syntactic or semantic relationships between events.  

Xu et al. [141] tackled the challenge of stock price limit prediction by introducing the Hierarchical Graph Neural Network (HGNN). This model takes into account the various properties of the market state by constructing a stock market relationship graph and extracting information from multiple perspectives, such as the node view, relation view, and graph view in a hierarchical manner. The HGNN achieved excellent results in classifying the type of pricelimit-hitting stocks and resulted in an improvement in the investment return ratio. Similarly, Li et al. [70] proposed a GNN-based model for predicting the stock market by fusing multi-source heterogeneous subgraphs. The datasets used in this research included three types of subgraphs representing the relationships between the stock market index, stock market news, and graphical indicators. The fusion of these subgraphs was then converted into a fully connected classification layer to make predictions. Ang and Lim [141] utilized a graph encoding module to propagate multimodal information across companies’ relationships. Additionally, they introduced an attention module for capturing global and local information among inter-company relations and different modalities. The model performed robustly on three forecasting tasks and two applications on real-world datasets.  

Graph Convolutional Network (GCN). GCN is a type of deep learning model that are specifically designed to handle graph data, which uses graph convolutional layers to extract features from the graph and make predictions based on the relationships between nodes in the graph. GCN is often combined with other deep learning models. For example, Chen and Wei [18] proposed a pipeline prediction model that integrates the relationships between corporations by using a GCN model. In this model, each corporation is represented as a node in the graph, with edges representing the relationships between corporations and the weights of those edges representing the shareholding ratios. Additionally, the LSTM-based encoder layer is used to encode historical features of corporations, resulting in improved performance. Similarly, Li et al. [69] proposed an LSTM Relational Graph Convolutional Network (LSTM-RGCN) model that handles both positive and negative correlations among stocks. The correlation matrix between companies is calculated based on historical market data, and the LSTM mechanism added to the RGCN layers helps to alleviate the over-smoothing problem when predicting overnight stock price movements. A novel Gated temporal convolution is also introduced to learn the temporal evolution of stock features.  

Several existing models aimed to capture the temporal dependence between stock prices and news information. However, they did not fully utilize information from other highly correlated stocks. To address this gap, Yin et al. [149] introduced a graph convolutional network model that integrates GCN and GRU. GCN extracts features from stocks that have a high degree of similarity, which are then fed into the GRU model to capture the time dependence. Another approach to consider the relationship between stocks is the Relational Stock Ranking (RSR) framework proposed by Feng et al. [41]. The RSR framework consists of three layers: a sequential embedding layer using LSTM, a relational embedding layer, and a prediction layer. Additionally, they proposed a temporal graph convolution model to solve the ranking problem. Sawhney et al. proposed the Spatio-Temporal Hypergraph Convolution Network (STHGCN) [109], a notable approach that used a hypergraph structure to model relationships among stocks and applies spatial hypergraph convolutions. This was the first hypergraph learning approach.  

Predicting the price movements of individual stocks can be a difficult task due to various factors such as company operations and public opinion. However, stock market indices provide a more reliable means of understanding the overall trend of a specific industry or company in the stock market as they are less affected by the variables of a single company. In a recent study, Wang et al. [125] employed the use of a GCN to analyze the correlation of indicators in stock trend prediction. They introduced the MG-Conv model, which is based on a multi-Graph Convolutional neural network and utilizes static graphs between indices that are constructed using constituent stock data. Additionally, they created dynamic graphs based on trend correlations between indices with different portfolio strategies and defined multi-graph convolution operations based on both graphs.  

Graph Attention Networks (GAT). The Graph Attention Network (GAT) combines the strengths of GNN and attention layers to improve performance in large-scale graphs. Attention mechanisms help to focus on the most critical nodes, reducing the impact of complex background noise and improving the signal-to-noise ratio. Additionally, attention allows for exploiting interconnectedness and hierarchical connections among nodes to enhance the relevant information for the task at hand. Kim et al. [57] proposed using a hierarchical attention network (HATs) to predict individual stock Manuscript submitted to ACM  

prices and market index movements using relational data. HATs employ LSTM and GRU as feature extraction modules for these respective tasks and achieve better results than previous methods by aggregating different types of data and adding this information to each representation. Similarly, Sawhney et al. [108] proposed a multipronged attention network for stock forecasting (MAN-SF) that fuses information from financial data, social media, and inter-stock relationships using hierarchical attention to train a GAT.  

One approach for forecasting a specific firm’s trend is using GCNs based on pre-established relationships among firms. However, momentum spillovers can occur through various firm connections, the significance of which can change over time. Cheng and Li [19] introduced an attribute-driven graph attention network (AD-GAT) to capture these attribute-driven momentum spillovers. This network utilizes an unmasked attention mechanism to infer the dynamic firm relationships within the market signal, utilizing a feature extraction module based on tensors. The proposed model was found to be more accurate and have a higher AUC than GCN, eLSTM [67], and TGC [41] in experiments using three years of data from the S&P 500.  

# 4.6 Transformer Based Models  

CNNs excel in handling spatial data by creating an internal representation of two-dimensional information. In addition, RNNs are better suited for tasks involving temporal or sequential data, such as financial news, tweets, and stock price time series. However, RNNs may struggle with processing long sequences as the model can forget the contents of distant locations or mix up the contents of nearby positions. The Transformer addresses this issue by utilizing a self-attention mechanism and positional embedding to process sentences. As a result, the Transformer model has shown promising results in various stock market prediction tasks.  

Transformer Based Models. In an effort to enhance stock volatility models, Ramos-PÃľrez et al. [104] implemented machine learning and deep learning techniques. They proposed the Multi-Transformer model, a variation of the existing Transformer model, which utilizes a strategy of randomly selecting various training data subsets and incorporating multiattention methods to increase the stability and accuracy of attention processes. Similarly, Ding et al. [28] introduced the hierarchical multi-Scale Gaussian Transformer for predicting stock movements. They improved upon the traditional Transformer by incorporating multi-scale Gaussian prior and optimizing locality, as well as implementing Orthogonal Regularization to prevent redundant learning heads under multiple attention. Additionally, they developed the Trading Gap Splitter for the Transformer to aid in learning the structural hierarchy of high-frequency financial data.  

Transformer models have been shown to effectively capture long-term dependencies, making them well-suited for tackling problems related to temporal dependence. Li et al. [72] proposed a novel Transformer encoder attention (TEA) framework that utilizes attention mechanisms to address issues of time dependency in financial data and reveal hidden information in stock prices related to social media texts. The TEA model utilizes a feature extractor and cascade processor architecture, consisting of a Transformer encoder, attention mechanism, and normalization technique. The feature extractor effectively gathers information from past text and stock prices for five calendar days in order to extract crucial information. Similarly, Zhang et al. [153] introduced the Transformer-based attention network (TEANet) architecture to handle time-dependent problems utilizing five calendar-day data. The TEANet framework includes a deep textual feature extractor that utilizes the Transformer and a concatenation processor to effectively incorporate and balance the influence of various elements, such as tweets and market prices. Yoo et al. [150] improved predictive accuracy by leveraging connections between multiple equities. To achieve this, they introduced the Data-axis Transformer with Multi-Level Contexts (DTML). The DTML model builds asymmetric and dynamic correlations in an end-to-end approach to learn the correlations between stocks and provide final predictions for all individual stocks.  

Many studies utilizing Transformer-based models employed textual information as input to understand the sentiment in stock-related news media. The goal of financial news sentiment analysis is to predict market reactions to the underlying information in texts [148]. According to Li et al. [68], social sentiment plays a crucial role in reflecting public views on stock trends. To gather this information, a collection of social sentiments and professional opinions was collected from both social platforms and financial news articles. This data was then fed into a tensor Transformer for model training, which helped to eliminate noise and capture more intrinsic relationships. The trained model could then be used to explore the impact and function of social emotions using data from various sources. Liu et al. [78] argued that existing social media-based stock prediction algorithms only considered individual stock semantics and correlations, but failed to account for the contradicting information present on vast social media platforms. They proposed a Capsule network based on Transformer Encoder (CapTE) as a solution, which includes a Transformer Encoder to capture deep semantic features and structured relationships among tweets. Yang et al. [145] proposed a Hierarchical, Transformer-based, multi-task (HTML) model for predicting short-term and long-term asset volatility. Additionally, they used audio data in addition to common news and reports about finance to make predictions.  

Chen et al. [15] introduced the Gated Three-Tower Transformer (GT3) as a solution for extracting and integrating multivariate stock time series. To address the challenge of limited receptive fields, they implemented the Shifted Window Tower Encoder (CWTE) for capturing channel-wise features from data embedding. In order to extract and aggregate multi-scale temporal information, the team developed the Shifted Window Tower Encoder (SWTE) with multi-temporal aggregation. For sophisticated text feature extraction, the team employed a vanilla Transformer encoder as the Text Tower Encoder (TTE). Additionally, the Cross-Tower Attention method was implemented to aid the model in understanding market tendencies and the meanings conveyed by social media content. The features from CWTE, SWTE, and TTE are then fused through an adaptive gate layer for efficient and accurate results.  

Pre-trained Language Model. BERT, a language model based on the Transformer architecture, has become a popular choice for pre-training in natural language processing tasks [26]. The model utilized two unique training methods, namely masked-language modeling (MLM) and next sentence prediction (NSP) [26], to gain an understanding of relationships between words and long-term dependencies between sentences. Additionally, BERT’s pre-trained model could be fine-tuned to suit specific use cases.  

Financial news is considered a key source of information for stock market analysis and its impact on stock returns has been well-documented [71]. Dong et al. [32] proposed a BERT-LSTM model that uses the BERT to extract the direction of stock prices based on social media news, while the autoregressive LSTM integrates information features as covariates. The model also utilizes historical price trends to predict future stock price movements. Sonkiya et al. [118] employed the BERT model for sentiment analysis on news and headlines about Apple Incorporation. The sentiment scores obtained from the analysis were used as input vectors for a GAN, which consisted of a GRU and a CNN as the generator and discriminator. The GAN was able to generate data continuously and discriminate between true and generated samples of stock prices, thus achieving the desired prediction effect. The model’s early convergence was optimized by using sentiment scores as input. Colasanto et al. [21] improved stock forecasting by utilizing AlBERTo [99], a Transformer-based model, for sentiment analysis of Italian social media. This model calculates the sentiment values of various event news in the market that may affect stocks.  

Instead of relying solely on the sentiment found in texts for stock market prediction, some researchers propose that news comments can influence investors’ sentiment and ultimately affect their estimation of market trends and investment decisions. Li et al. [65] used the BERT pre-training model to evaluate and classify investor comments found on news websites. They applied a cross-sectional regression analysis approach to validate the relationship between Manuscript submitted to ACM  

![](images/cab31006eff5516ea1ad81ef64fd6ba426598b4a1967e3ee848674d5a480cb17.jpg)  
Fig. 6. In the field of financial trading, the interaction between the agent (trader) and the environment (financial market) is crucial. RL algorithms utilize this interaction by considering the financial market and trader as the environment and agent, respectively. Within the agent, different RL algorithms may incorporate the use of policy networks and Q networks. The financial data and returns in finance can be viewed as the state $s$ and reward $R$ in RL, while the trading transaction can be considered as the action $A$ in RL.  

investor emotions and stock returns, utilizing a two-step cross-sectional regression validation [39] to eliminate any potential issues with heteroskedasticity and consistency in the data. Zhao et al. [155] also acknowledged the importance of expert stock commentary for accurate stock prediction and thus chose to utilize BERT for more comprehensive and accurate translations of comments from field experts. They noted that the fixed-length text input of BERT can lead to poor performance in exploring long text information. To overcome this limitation, they employed a sliding window technique to segment the original text, increasing the sample size and reducing over-fitting, to capture all information from the lengthy text. Furthermore, they extracted the output features from each layer of the BERT model and applied an ablation strategy to extract useful information from these features.  

The utilization of BERT in the stock market is not limited to just predicting prices or movements. Zhou et al. [158] proposed a bi-level BERT-based model for detecting predefined trading events, which is further enhanced by incorporating a wide range of financial texts. The low-level model is a multi-label token classifier that identifies events for each token in each phrase. The high-level model combines the output of the low-level model with the entire article to determine the likelihood of each event occurring. The final trading strategy is based on the recognized time and ticker, utilizing string matching to detect events. Hsu et al. [48] adopted a selective perturbed masking (SPM) approach for aspect-based sentiment analysis. SPM analyzes the value of each word in a sentence and replaces insignificant words using two replacement strategies without compromising aspect-level polarity to tackle readability and semantic consistency issues. The authors tested SPM for stock price and risk change prediction as a real-world scenario for sentiment analysis and further evaluated it in sub-tasks such as aspect term sentiment classification (ATSC) and aspect term extraction (ATE).  

# 4.7 Reinforcement Learning Models  

In the stock market, RL is utilized to design trading strategies and manage portfolios. RL is a framework that allows for learning through interactions with the environment, as depicted in Figure 6. Key concepts in RL include the Markov Decision Process (MDP) [102], agent, environment, and reward signal. The RL problem can be formulated as follows:  

the agent optimizes its policy through interactions with the environment. Specifically, the agent consists of a state and a policy represented by $S _ { t }$ and $\pi$ at time $\mathrm {  ~ t ~ } .$ . When the agent interacts with the environment, a reward $r$ is received and the agent’s state is updated to $S _ { t + 1 }$ . A decision process is considered Markov if the next state is solely dependent on the current state.  

MDP also can be defined in the form of a tuple: $\boldsymbol { \mathcal { M } } = \{ \boldsymbol { S } , \boldsymbol { \mathcal { A } } , \boldsymbol { \mathcal { R } } , \boldsymbol { \mathcal { T } } , \boldsymbol { \gamma } \}$ , where the states and actions are represented by $\boldsymbol { s } \in \mathbb { R } ^ { n }$ and $\mathcal { A } \in \mathbb { R } ^ { m }$ , respectively. The function $\mathcal { R } : S \times \mathcal { A }  \mathbb { R }$ represents the reward, and the function $\mathcal { T } : \mathcal { S } \times \mathcal { A }  \mathcal { S }$ represents the next state. The discount factor $\gamma$ is used to decrease the impact of future rewards. The objective of RL is to optimize the policy, in order to maximize the expected return.  

The general trading process, which includes both high-frequency trading and portfolio management, can be visualized in Figure 6. This process can be formalized as a decision-making process, represented by the MDP $\boldsymbol { \mathcal { M } } = \boldsymbol { S } , \boldsymbol { \mathcal { A } } , \boldsymbol { \mathcal { R } } , \boldsymbol { \mathcal { T } } , \boldsymbol { \gamma }$ . In this MDP, the state $s$ contains fundamental information and market data for companies, as well as the position held by the agent. The action $a _ { t }$ is a continuous or discrete vector indicating the number of stocks being traded at a given time step. The reward $r$ for each time step is the profit gained at that step. The state transition $\mathcal { T }$ is determined by both the state and action. The goal of RL algorithms is to find a policy that maximizes the expected return $\begin{array} { r } { R = \underset { \tau } { E } [ \sum _ { i = 1 } ^ { \infty } \gamma ^ { t - 1 } r _ { t } ] } \end{array}$ over a trajectory $\tau$ .  

4.7.1 Model-free Reinforcement Learning. Model-free RL algorithms are a well-established branch developed in recent decades where the agent interacts directly with the environment. In model-free settings, policy gradient, Q-learning, and hybrid algorithms are widely used in the financial market.  

Policy Gradient. The RL aims to maximize the expected return. One direct way is to maximize the objective function $J ( \pi _ { \theta } ) = E _ { \tau \sim \pi _ { \theta } } [ R ( \tau ) ]$ . The gradient of this function, known as $\nabla J ( \pi _ { \boldsymbol { \theta } } )$ , is called the policy gradient. By using the Log-Derivative Trick, the gradient can be transformed into:  

$$
\nabla _ { \theta } J \left( \pi _ { \theta } \right) = \underset { \tau \sim \pi _ { \theta } } { \mathrm { E } } \left[ \sum _ { t = 0 } ^ { T } \nabla _ { \theta } \log \pi _ { \theta } \left( a _ { t } \mid s _ { t } \right) R ( \tau ) \right] .
$$  

The REINFORCE algorithm [135] is the basic policy gradient algorithm. The Advantage Actor-Critic (A2C) [92] algorithm improves REINFORCE by adding a baseline to reduce the variance and a critic to estimate the state values, which can evaluate the action token. To improve the efficiency of A2C, the Asynchronous Advantage Actor-Critic (A3C) [92] algorithm was proposed, which uses multiple agents to train the actor-critic network asynchronously. The Trust Region Policy Optimization (TRPO) [113] and Proximal Policy Optimization Algorithms (PPO) [114] set constraints on the KL-Divergence and clip, respectively, on how much difference there is between the old policy and the new policy and take the biggest improvement step under these constraints.  

The REINFORCE algorithm has gained attention in the field of financial trading due to its ability to be optimized through gradient ascent. For instance, Liang et al. [76] evaluated the effectiveness of three different RL algorithms, including DDPG, PPO, and REINFORCE, in an adversarial training setting and found that REINFORCE performed the best. These experiments were conducted on the China stock market and the authors suggested that the policy gradientbased method is particularly well-suited for financial scenarios. Additionally, incorporating historical information into the state by using a policy gradient with a recurrent network has also been a promising approach. Jiang, Xu, and Liang [55] developed a model-free financial RL framework for portfolio management that incorporates CNN, RNN, and LSTM, and was built on the deterministic policy gradient (DPG). The framework was tested in the cryptocurrency market and was shown to outperform other methods.  

Manuscript submitted to ACM  

The actor-critic-based method has been shown to be effective in reducing policy variance by incorporating state value. Li, Rao, and Shi [64] and Ponomarev, Oseledetsa, and Cichocki [100] both employed actor-critic methods (A2C and A3C respectively) in combination with CNNs to analyze the China stock market and RTS index future respectively. In their study, Li, Rao, and Shi [64] found that their proposed Deep Actor-Critic Trading (DACT) strategy outperformed other methods such as buying and holding, DQN, and REINFORCE. Meanwhile, Ponomarev, Oseledetsa, and Cichocki [100] achieved promising results, achieving $6 6 \%$ profitability per year even when accounting for commission fees.  

Several studies have sought to improve performance in quantitative trading by utilizing information on the relationships between different stocks, rather than solely focusing on improving RL algorithms. For instance, Wang et al. [131] developed the AlphaStock method, which utilizes a sharp ratio-oriented policy gradient approach to address challenges in portfolio management such as balancing profit and risk and avoiding extreme losses. The method fuses information on the relationships between assets and is the first to implement an interpretable trading strategy using Deep Reinforcement Learning (DRL). The algorithm was tested in both the US and China stock markets, and the results showed its effectiveness, robustness, and generalization ability. It tends to select stocks that have increasing tendencies and low volatility. Building on AlphaStock, Wang et al. [133] proposed a new policy gradient trading algorithm called DeepTrader for portfolio management. It includes an Asset Scoring Unit (ASU) and a Market Scoring Unit (MSU). The ASU extracts temporal and spatial features crossing assets using dilated CNN and attention mechanisms, respectively, and also introduces GCNs to represent interrelationships and causal relationships between assets. The MSU controls overall positions for long and short, and its main network is an LSTM that extracts historical market representation. DeepTrader was tested in different stock markets and achieved the most profitable performance with less risk compared to baselines.  

Q-learning method. Q-learning is a method for obtaining the optimal policy by updating the action-state value, represented by $\boldsymbol { Q }$ . The Bellman update is used to update $\boldsymbol { Q }$ until it converges to the optimal value. The optimal policy can then be found by searching the $\boldsymbol { Q }$ values greedily. The emergence of the Deep Q-learning Network (DQN) brought Q-learning to a new level by using a deep neural network to approximate the Q value. Prior to DQN, many studies in finance trading utilized tabular Q-learning algorithms [8, 17, 24, 36, 53, 61]. DQN-based models have shown promising results in this field. Carapucco Neves and Horta [10] used a DQN-based RL agent for forex trading, resulting in stable learning and environmental construction. Lucarelli and Borrotti [85] proposed a Double Dueling DQN for cryptocurrency trading and evaluated the performance of different reward functions, such as the profit reward function and sharp ratio reward function. Theatre and Ernst [121] developed a DQN-based trading algorithm using a limited stock market dataset and introduced new assessment indicators, including the Sharp ratio, Sortino Ratio, and profit or loss ratio.  

Researchers have been increasingly drawn to variants of DQN with recurrent networks due to their ability to handle time-series data. Huang [51] proposed an MDP model for stock trading that combines time, market, and position features, and leveraged a recurrent DQN with small replay memory and action augmentation to solve the model. Chen and Gao [16] also used a variant of DQN, the Deep Recurrent Q-network (DRQN), for automated trading on S&P 500 ETF data and achieved superior performance compared to other methods. Additionally, Tsantekidis et al. [123] applied recurrent DQN in the forex market with the use of a novel reward function that incorporates price trailing, profit, Sharpe ratio, and maximum drawdown to enhance the algorithm’s simplicity and effectiveness.  

Recurrent algorithms, such as RNN, LSTM and GRU, that predict market behaviour often rely solely on price information. However, as Carta et al. [11] have noted, using only price information and a supervised method to predict future market behaviour is highly challenging. To address this issue, the authors proposed a multi-layer and ensemble-based trading agent utilizing the DQN. This algorithm utilizes different meta-learners to maximize rewards and generate trading signals in various iterations. Additionally, all the learners are fused to make the final decision for trading. The proposed algorithm was tested in both future and stock markets and was found to outperform considered baselines.  

Hybrid methods. Hybrid RL algorithms simultaneously learn both the policy and Q function. One such example is the Deterministic Policy Gradient method, which includes variations such as Deep Deterministic Policy Gradient (DDPG) [77], Twin Delay DDPG (TD3) [42], and Soft Actor-Critic (SAC) [44]. In particular, DDPG utilizes an off-policy approach to learn both the Q value and policy from the Q function. TD3 incorporates techniques such as Clipped Double-Q Learning, Delay Policy Updates, and Target Policy Smoothing to prevent the overestimation of Q values. SAC, on the other hand, combines entropy regularization with Clipped Double-Q Learning and updates the Q-network using Polyak averaging.  

The use of DDPG in the financial market has been widely studied by researchers due to its ability to combine the strengths of policy gradient and Q-learning in continuous action spaces. Xiong et al. [140] applied DDPG algorithms to a custom environment consisting of 30 Dow Jones Industrial Average component stocks in order to develop a stock strategy. The agent’s performance was evaluated by comparing it to the Dow Jones Industrial Average index and a traditional min-variance portfolio allocation strategy. The results revealed that the proposed agent demonstrated exceptional profitability.  

In a similar vein, Bao and Liu [6] employed DDPG with multiple agents to tackle the Liquidation problem. This approach allows agents to both compete and cooperate with one another, resulting in a significant improvement over single-agent algorithms. Additionally, Sawhney et al. [111] introduced the PROFIT model, a deep RL-based approach that utilizes time-aware text analysis to model market information and optimize trading actions. This model was found to surpass competing methods in terms of profitability and risk management on the S&P 500 and China A-shares indexes.  

RL algorithms have the potential to be used in stock trading, however, creating and training a practical RL algorithm can be challenging and prone to errors. To address this issue, Liu et al. developed the FinRL library [80], which focuses on model-free RL algorithms and simplifies the implementation process for users. The library includes tutorials and various financial environments such as NASDAQ-100, DJIA, S&P 500, HSI, SSE 50, and CSI 300, as well as popular DRL algorithms like DQN, DDPG, PPO, SAC, A2C, and TD3. Additionally, FinRL includes backtesting metrics for fair and objective evaluation. The authors has continued to improve the platform with updates such as [75, 79, 81].  

Researchers have continued to investigate alternative approaches to RL despite its advancements in the field. Liu et al. [82] identified two major challenges in the application of RL to quantitative trading: handling noisy high-frequency financial data and balancing exploration and exploitation. To address these challenges, they proposed the adaptive trading method iRDPG, which combines imitation learning with the Recurrent Deterministic Policy Gradient. This approach treated the trading process as a partially observable MDP and was trained using minute-level data, highlighting its robustness and adaptability in different markets. Similarly, Wang et al. [132] recognized that existing methods were impractical due to their disregard for price slippage. To address this issue, they proposed a hierarchical model that incorporated a Reinforcement Learning algorithm for maximum return at the lower level and a policy gradient algorithm for portfolio weight generation at the higher level. The low-level RL also utilizes one-step temporal-difference learning to minimize trading costs and make quick trades.  

4.7.2 Model-based Reinforcement Learning. In recent years, model-based algorithms have gained increased attention in the field of RL. These algorithms utilize a parameterized approximator, denoted as $\hat { p } _ { \eta }$ , to simulate the dynamics of a MDP defined by the set of states and actions $s , \mathcal { A }$ . The model allows for the approximation of both the reward and the next state, given a specific state and action. Compared to model-free RL algorithms, model-based methods offer several advantages. Firstly, they can improve data efficiency by addressing challenges related to real-world data sampling, such as time-consuming or hardware-sensitive processes. Secondly, the parameterized model allows for interesting exploration strategies. Additionally, model-based methods can improve performance by combining local planning and global learning. Furthermore, dynamic models can be deployed in new tasks, making them useful in transfer learning scenarios. Additionally, the model’s ability to capture causality can aid in solving both the intervention problem, which addresses the impact of a specific action and the counterfactual problem, which addresses the potential outcome of different actions in a specific situation.  

Model-based RL has been used in the development of several trading algorithms due to its potential to improve the performance of dynamics transition models. Researchers, such as Yang, Yu, and Almahdi [147], have noted that investor sentiment plays a significant role in the market and have therefore sought to design trading systems that incorporate this sentiment using the Gaussian inverse RL method. This method aimed to uncover the intrinsic mapping of investors’ sentiment to market conditions and predict future market trends. While not a model-based method, the research by Yang et al. [147] provided insight into the potential for using such methods in trading. Wei et al. [134] took a different approach by training a world model using Limit Order Book data with a frequency of once per 0.17s. By using a dynamics transition model, the RL agent can interact with a simulated world for optimization instead of the real environment. The authors also claimed that the trading policy trained using this model can be transferred directly to the real environment with stable profitability. Model-based RL has also been applied to portfolio management tasks. Yu et al. [151] proposed an architecture that includes a prediction model, a generative adversarial data augmentation model, and a policy cloning model. When combined with the DDPG algorithm and trained on hourly price data, the model demonstrated both profitability and robustness. Briola et al. [9] also employed a model-based approach by building an end-to-end DRL agent using the PPO algorithm. The agent learns the transition dynamics and implements planning to achieve long-term returns. The algorithm uses limited order book data and selects training samples with significant price changes. The results showed that the proposed agent could produce stable profits in non-stationary markets.  

# 4.8 Other Deep Learning Methods  

In the field of event-driven stock forecasting, there are two key issues related to the use of indicator data sources: (1) the low reliability of individual sources and (2) the lack of understanding of the interactions and correlations among multiple sources. To address these challenges, Zhang et al. [154] developed a coupled matrix and tensor factorization approach. This approach involves the creation of a quantitative feature matrix, the construction of a matrix, the extraction of events and sentiments, and the application of coupled matrix and tensor factorization. The resulting model is able to effectively fill in missing values in sparse tensors, allowing for accurate forecasting of market movements through the use of factorized low-rank matrices.  

Stock movement prediction is challenging in highly stochastic stock markets. To solve this problem, Xu and Cohen [143] have proposed a solution through their novel deep generative model, Stocknet. This model utilizes both text and price signals from Twitter data and the previous five days’ price data to predict the stock movement on the sixth day. The Stocknet model is composed of three parts: the Market Information Encoder (MIE), which encodes tweets and prices; the Variational Movement Decoder (VMD), which decodes stock movements; and the Attentive Temporal Auxiliary (ATA), which integrates temporal losses through an attention mechanism.  

To address the issue of inadequate generalization caused by uncertainty in data and models, Wang et al. [126] introduced a copula-based contrastive predictive coding (Co-CPC) method. Co-CPC considers the dependencies between a stock class, sector, and related macroeconomic variables, and learns stock representations from a micro perspective in a self-supervised manner. This allows for the mapping of stock characteristics to a generalized embedding space. The system combines microstock context with diverse macroeconomic factors and captures the coupling through a self-supervised objective of minimizing uncertainty in data and the model. Similarly, Duan et al. [33] proposed a novel target-specific abstract-guided news document representation model for extracting the most informative content. The model uses a target-sensitive representation of the news abstract to weigh sentences in the news content, allowing for the selection and combination of the most informative sentences for market modelling.  

The factor model is a commonly employed asset pricing model in quantitative investment strategies. One of the major obstacles in constructing efficient factor models is the low signal-to-noise ratio present in financial data. To address this issue, Duan et al. [34] introduced the FactorVAE, which combines a dynamic factor model with the use of a variational autoencoder for noise modeling. By approximating the factor posterior factor model with future information, the FactorVAE can effectively guide the learning process.  

# 5 DATASET AND MODEL INPUT  

In the field of stock prediction, the datasets utilized by machine learning models vary depending on the perspective being taken in different stock markets. Two tasks that draw the most attention are predicting stock prices and price movements. Additionally, much of the research utilizing reinforcement learning (RL) centers around developing trading policies. When it comes to the input features used in the models, datasets can be broadly classified into two groups: intrinsic and extrinsic data. Intrinsic data primarily includes information extracted from the stock data itself, such as historical stock prices, financial indexes, and other technical analysis data. As stock data is inherently time-series in nature, intrinsic data is typically composed of time-series data. Moreover, extrinsic data can be quite varied and may include information such as text, fundamental data, industrial knowledge graphs, and more [54]. Furthermore, the datasets used in this area of research can cover a wide range of time periods, from a few months to a decade or more. Another notable characteristic of the datasets is that they often come from different regions, with the majority being based on the US market, but also including markets from China, Japan, and India. A list of commonly used stock market abbreviations with country information can be found in Table 1. Table 2 provides an overview of the datasets and model details used in the reviewed papers.  

(1) Stock Price. The stock price is considered the most direct reflection of the stock market’s performance and is commonly used as both an input feature and a predicted target in various models. In the papers reviewed in this survey, the use of stock price was prevalent, but it was utilized in various forms such as open, high, low, and closed data, depending on the model design.   
(2) Technical analysis tools. Technical analysis tools, commonly employed in traditional stock analysis, have a strong correlation with stock market performance. These tools take into account factors such as exchange rate, book-market ratio, trading volume, and other relevant financial indicators.   
(3) Macroeconomic data. Macroeconomic data reflects the economic status of a specific region. Two commonly used indicators that are linked to the stock market are the Consumer Price Index (CPI) and Gross Domestic Product  

Table 1. Introduced Stock Market Abbreviations.   


<html><body><table><tr><td>Abbreviation</td><td>Country</td><td>Full Name</td></tr><tr><td>CSI-300</td><td>China</td><td>Index of top 3oo stocks in Shanghai and Shenzhen stock exchanges</td></tr><tr><td>SSE</td><td>China</td><td>Shanghai Stock Exchange</td></tr><tr><td>SZI</td><td>China</td><td>Shenzhen Component Index</td></tr><tr><td>SZSW</td><td>China</td><td>Shenzhen Stock Exchange</td></tr><tr><td>HKEX</td><td>China</td><td>Honkong Stock Exchange</td></tr><tr><td>NSE</td><td>India</td><td>National stock exchange of India</td></tr><tr><td>Nifty 50</td><td>India</td><td>The benchmark index of the NSE (National Stock Exchange) of India</td></tr><tr><td>BSE</td><td>India</td><td>Bombay stock exchange</td></tr><tr><td>Nikkei 225</td><td>Japan</td><td>225 companies in Tokyo Stock Exchange</td></tr><tr><td>TOPIX</td><td>Japan</td><td>Tokyo Stock Price Index</td></tr><tr><td>KOSPI</td><td>Korea</td><td>The Korea Composite Stock Price Index</td></tr><tr><td>S&P 500</td><td>US</td><td>Standard and Poor 5oo Index</td></tr><tr><td>SPX</td><td>US</td><td>S&P 500 index</td></tr><tr><td>DJIA</td><td>US</td><td>Dow Jones Industrial Average</td></tr><tr><td>NASDAQ</td><td>US</td><td>National Association of Securities Dealers Automated Quotations Stock Market</td></tr><tr><td>NYSE</td><td>US</td><td>New York Stock Exchange</td></tr><tr><td>IWD</td><td>US</td><td>iShares Russell 100o Value</td></tr><tr><td>IWC</td><td>US</td><td>iShares Micro-Cap</td></tr><tr><td>SPY</td><td>US</td><td>SPDR S&P 500 ETF</td></tr><tr><td>DEM</td><td>US</td><td>WisdomTree Emerging Markets High Dividend</td></tr><tr><td>VTI</td><td>US</td><td>Vanguard Total Stock Market ETF</td></tr></table></body></html>  

(GDP). These indexes provide insight into the current market conditions and indicate whether the stock market is experiencing growth or decline [54].  

(4) Fundamental data. Fundamental data refers to comprehensive information about an economic entity, including financial conditions, corporate structure, and any other information shared with shareholders. However, when it comes to utilizing this data in deep learning models, only a small portion is utilized due to limitations such as low reporting frequency and unstructured textual information.   
(5) Knowledge graph. Different industries may have intrinsic connections, such as corporations in a single supply chain being affected by the same news. Recent experiments have shown that incorporating knowledge graphs from open sources with traditional stock data can improve the performance of models.   
(6) Textual information. Textual information encompasses a wide range of sources, including but not limited to news articles, reports, social media posts, and user comments. Given that a majority of this information is unstructured, sentiment analysis is a widely employed technique for extracting insights through deep machine learning. The data can be categorized into various classes, such as positive, neutral, or negative, for further analysis and utilization.  

# 5.1 Input Features  

The input features are extracted and organized based on the prediction target and dataset constitution, which can be roughly divided into four groups: time series, texts, knowledge graphs, and others.  

(1) Time series. Time series data is a prevalent input in stock prediction due to the fact that many models rely on modeling stock price over time. The specific time frame of the prediction, such as intraday or interday, can determine the granularity of the data used, ranging from minute-level to day-level. Additionally, in the context of reinforcement learning, the time series data can be transformed into an environment where features can be utilized for creating states and rewards. This allows agents to interact with the environment and continually improve their decision-making policies.  

(2) Text. Textual information encompasses a broad range of information sources such as news and articles. This type of information is thought to have a ripple effect on investor emotions. However, before being utilized in models, the textual information must undergo preprocessing and structuring, as it may originate from various languages and sources.   
(3) Graph. The industrial knowledge graph is widely utilized, not only for displaying direct connections between corporations but also for uncovering internal relationships such as upstream and downstream supply chains.   
(4) Others. Different data sources have been utilized in the stock prediction task, each offering unique perspectives. These include image data and audio data [145]. These data are employed as supplementary information, for instance, vocal features, such as voice tones, which can indicate the sentiment of speakers.  

Table 2. Datasets and models in reviewed papers. The column ’Input’ refers to the model input features, while ’Target’ refers to the model prediction target.   


<html><body><table><tr><td>Author</td><td>Methods</td><td>Input</td><td>Target</td><td>Dataset</td><td>Time Span</td></tr><tr><td>Rather [106]</td><td>RNN</td><td>Price</td><td>Stock Return</td><td>NSE</td><td>2007 - 2010</td></tr><tr><td>Akita [106]</td><td>LSTM</td><td>Price, Text</td><td>Stock Price</td><td>Nikkei 225</td><td>2001 - 2008</td></tr><tr><td>Nelson [1]</td><td>LSTM</td><td>Price</td><td>Price Movement</td><td>Brazilian stock exchange</td><td>2014</td></tr><tr><td>Zhao [156]</td><td>LSTM</td><td>Price</td><td>Price Movement</td><td>Yahoo! Finance.</td><td>2002 - 2007</td></tr><tr><td>Zhang [152]</td><td>RNN</td><td>Price</td><td>Price Movement</td><td>Yahoo! Finance</td><td>2007 - 2016</td></tr><tr><td>Yang [146]</td><td>GRU</td><td>Text, S&P 500</td><td>Price Movement</td><td>Reuters, Bloomberg</td><td>2006 - 2013</td></tr><tr><td>Li[63]</td><td>LSTM</td><td>Price</td><td>Stock Price</td><td>CSI-300 index</td><td>2013 - 2017</td></tr><tr><td>Hu [49]</td><td>GRU</td><td>Price, News</td><td>Price Movement</td><td>Chinese stock data, Economic news</td><td>2014 - 2017</td></tr><tr><td>Nguyen [95]</td><td>LSTM</td><td>Stock pice</td><td>Price Movement</td><td>KOSPI 200 and the S&P 500</td><td>2012 - 2018</td></tr><tr><td>Wang [130]</td><td>LSTM</td><td>Price, Indicators</td><td>Price Movement</td><td>Oil, Gold,Gas,Soybeans,S&P 5o and Nasdaq 100</td><td>2010 - 2017</td></tr><tr><td>Feng [40]</td><td>LSTM</td><td>Price</td><td>Price Movement</td><td>NASDAQ, NYSE</td><td>2007 - 2017</td></tr><tr><td>Ma [87]</td><td>LSTM</td><td>Price, News</td><td>Price Movement</td><td>Sohu, SSE</td><td>2009 - 2016</td></tr><tr><td>Chen [14]</td><td>Bi-LSTM</td><td>Event, Price, News</td><td>Price Movement</td><td>finance news related to TOPIX top 1000 stocks</td><td>2011 - 2017</td></tr><tr><td>Ding [27]</td><td>LSTM</td><td>Price</td><td>Stock Price</td><td>SSE,PetroChina on SSE, ZTE on SZI.</td><td></td></tr><tr><td>Shen [117]</td><td>Hypergraph</td><td>Price, Indicator</td><td>Price Movement</td><td>SSE</td><td>2008</td></tr><tr><td>Luo [86]</td><td>Hypergraph</td><td>Price</td><td>Price Movement</td><td>SSE</td><td>2008</td></tr><tr><td>Chen [18]</td><td>GCN</td><td>Stock data, Graph</td><td>Stock Price</td><td>CSI 300</td><td>2017 - 2017</td></tr><tr><td>Kim [57]</td><td>GAT</td><td>Stock data, Graph</td><td>Price Movement</td><td>U.S. stock market, related Wikidata</td><td>2013 - 2019</td></tr><tr><td>Feng [41]</td><td>GCN</td><td>Stock data, Graph</td><td>Return Ratio</td><td>NASDAQ, NYSE</td><td>2013 - 2017</td></tr><tr><td>Matsunaga [90]</td><td>GNN</td><td>Stock data, Graph</td><td>Stock Price</td><td>Nikkei 225</td><td>2009 - 2019</td></tr><tr><td>Sawhney [109]</td><td>GCN</td><td>Price, Graph</td><td>Price Movement</td><td>S&P 500, Yahoo finance</td><td>2013 - 2019</td></tr><tr><td>Sawhney [108]</td><td>GAT</td><td>Price, Graph, Text</td><td>Price Movement</td><td>S&P 500,NYSEiijNNASDAQ, Yahoo Finance.</td><td>2014 - 2016</td></tr><tr><td>Li [69]</td><td>GCN</td><td>Price, Graph, Text</td><td>Price Movement</td><td>TPX500,TPX100 index,Reuters Financial News</td><td>2018 - 2018</td></tr><tr><td>Wang [129]</td><td>MFN</td><td>Price, Text</td><td>Stock Price</td><td>Guba</td><td>2017 - 2018</td></tr><tr><td>Wang [127]</td><td>Conv., Gating</td><td>Price, Text</td><td>Price Movement</td><td>CSI-300,S&P 500,TOPIX-100</td><td>2015-2020</td></tr><tr><td>Xu [141]</td><td>HGNN</td><td>Stock data, Graph</td><td>Price-limit-hitting Stocks</td><td>SSE, SZSE</td><td>2018 - 2019</td></tr><tr><td>Li [70]</td><td>GNN</td><td>Stock, Text, Graphi- cal Indicators</td><td>Price Movement</td><td>SSE,CSI,SZI</td><td>2013 - 2019</td></tr><tr><td>Xu [142]</td><td>HIST</td><td>Stock Data</td><td>Price Movement</td><td>CSI 100,CSI 300</td><td>2007 - 2020</td></tr><tr><td>Ding [30]</td><td>NTN</td><td>Price, Text</td><td>Price, Index</td><td>S&P 500,related news</td><td>1999</td></tr><tr><td>Deng [25]</td><td>KDTCN</td><td>DJIA, Text</td><td>Price Movement</td><td>DJIA, Reddit news,Freebase,Wikidata</td><td>2008 - 2016</td></tr><tr><td>Rasheed [105]</td><td>CNN</td><td>Price</td><td>Stock Price</td><td>Amerisource Bergen Corporation, Cardinal Health</td><td></td></tr><tr><td>Eapen [35]</td><td>CNN</td><td>Price</td><td>Stock Price</td><td>S&P 500 grand challenge dataset on Yahoo</td><td>2008 - 2018</td></tr><tr><td>Wu [137]</td><td>CNN</td><td>Price, Indicators</td><td>Price Movement</td><td>TSM, NYSE,NASDAQ</td><td></td></tr></table></body></html>  

Continued   


<html><body><table><tr><td>Author</td><td>Methods</td><td>Input</td><td>Target</td><td>Dataset</td><td>Time Span</td></tr><tr><td>Lu [84]</td><td>CNN-BiLSTM-</td><td>Price</td><td>Stock Price</td><td>SCI</td><td>1991 - 2020</td></tr><tr><td>Lu [83]</td><td>AM CNN-LSTM</td><td>Price</td><td>Stock Price</td><td>SCI</td><td>1991 - 2020</td></tr><tr><td>Wu [136]</td><td>SACLSTM</td><td>Price</td><td>Stock Price</td><td>Stock price of USA and Taiwan</td><td></td></tr><tr><td>Wang [128]</td><td>CNN-BiSLSTM</td><td>Price</td><td>Stock Price</td><td>SZCI</td><td>1991 - 2020</td></tr><tr><td>Mehtab [91]</td><td>CNN-LSTM</td><td>Stock index, Price</td><td>Stock Price</td><td>NIFTY 50</td><td>2009 - 2020</td></tr><tr><td>Hoseinzade [47]</td><td>U-CNNpred</td><td>Stock index, Price</td><td>Price Movement</td><td>S&P 500</td><td>2010 - 2017</td></tr><tr><td>Zhou [158]</td><td>BERT</td><td>Price, Text</td><td>Stock Events</td><td>EDT dataset,Financial articles,S&P 50o index,ETF</td><td>2020 - 2021</td></tr><tr><td>Ding [28]</td><td>Transformer</td><td>Price, Indicator</td><td>Price Movement</td><td>NASDAQ, CSI-500</td><td>2010 - 2019</td></tr><tr><td>Dong [32]</td><td>BERT+LSTM</td><td>Stock data, Text</td><td>Stock Price</td><td>Tweet news,DJIA stocks</td><td>2019- 2020</td></tr><tr><td>Yang [145]</td><td>Transformer</td><td>Price，Text,Audio,</td><td>Volatility</td><td>S&P 500 Earning Conference Calls dataset</td><td>2017</td></tr><tr><td>Man [89]</td><td>BERT</td><td>Video Stock data, Text</td><td>Trading Strategy</td><td>CSI 300 index,Related news</td><td>2018 - 2019</td></tr><tr><td>Hsu [48]</td><td>BERT,seq2seq</td><td>Text</td><td>Price Movement</td><td>Lap14,Rest14, Rest15, Rest16,SST-2,MR</td><td>2014 - 2016</td></tr><tr><td>Yoo [150]</td><td>Transformer</td><td>Price</td><td>Price Movement</td><td>ACL181,KDD171,NDX100,CSI300,NI225,FTSE100</td><td>2007- 2019</td></tr><tr><td>Ramos-PAIrez</td><td>MultiaASTransformeiPrice</td><td></td><td>Volatilty</td><td>S&P 500</td><td>2016- 2020</td></tr><tr><td>[104] Sonkiya [118]</td><td>FinBERT, GAN</td><td>Stock data,Text</td><td>Stock Price</td><td>NYSE,NASDAQ,S&P 500,NIffty 50,SSE,HKI HKEX,</td><td>2010- 2020</td></tr><tr><td>Li [65]</td><td>BERT</td><td></td><td></td><td>News</td><td></td></tr><tr><td>Li [68]</td><td>Tensor Trans-</td><td>Price, Text Price, Text</td><td>Stock sentiment Stock movement</td><td>Oriental Fortune online review, Monthly yield CSI 100 companies,news,social reviews</td><td>2018 - 2020 2010 - 2011</td></tr><tr><td></td><td>former</td><td></td><td></td><td></td><td></td></tr><tr><td>Liu [78] Zhang [153]</td><td>Transformer Transformer</td><td>Price, Text Price, Text</td><td>Price Movement Price Movement</td><td>S&P 500</td><td>2017</td></tr><tr><td>Colasanto [21]</td><td>AIBERTINO,</td><td>Price, Text</td><td>Stock Price</td><td>Stocks,Twitter, CHRNN, Stocknet-dataset FinancialPhrasebank,EssilorLuxottica, Intesa San-</td><td>2008-2019 2012 - 2022</td></tr><tr><td></td><td>Transformer Transformer</td><td></td><td></td><td>Paolo, UnipolSai</td><td></td></tr><tr><td>Chen [15] Li [72]</td><td>Transformer,</td><td>Price, Text Price, Text</td><td>Stock movement Stock movement</td><td>S&P 500,Tweets,Stock consequential data 88 highest-ranked stocks</td><td>2014 - 2019</td></tr><tr><td>Jiang [55]</td><td>LSTM Deterministic</td><td>Cryptocurrency</td><td>Portfolio</td><td>Tradable cryptocurrency pair, cryptocurrencies</td><td>2014 - 2017</td></tr><tr><td>Liang [76]</td><td>Policy Gradient Adversarial PG</td><td>price Price</td><td>Portfolio</td><td>China stock market and US stock market</td><td></td></tr><tr><td>Li [64]</td><td>A2C</td><td>Price</td><td>Policy</td><td>CSI 300 stocks</td><td>2005- 2018</td></tr><tr><td>Huang [51]</td><td>DQN</td><td>Tick-by-tick forex</td><td>Policy</td><td>12 currency pairs from TrueFX.com</td><td>2012 - 2017</td></tr><tr><td>Xiong [140]</td><td>DDPG</td><td>Price, Assets</td><td>Policy</td><td>30 DJIA stocks</td><td>2016 - 2018</td></tr><tr><td>Yang [147]</td><td>IRL</td><td> Stock return rate</td><td>Policy, Stock Movement</td><td>SPX, IWD,IWC,SPY, DE, VI</td><td>2008 - 2015</td></tr><tr><td>Chen [16]</td><td>DQN</td><td>Price</td><td>Policy</td><td>S&P 500 stocks</td><td>2000- 2018</td></tr><tr><td>Ponomarev [100]</td><td>A3C</td><td>Future Price</td><td>Policy</td><td>RTS Index futures (MOEX:RTSI) asks and bids</td><td>2015 - 2016</td></tr><tr><td>Wang [131]</td><td>Policy Gradient</td><td>Trading features</td><td>Portfolio</td><td>U.S. stock markers</td><td>1970 - 2016</td></tr><tr><td>Bao [6]</td><td>DDPG</td><td>Stock data</td><td>Policy</td><td>Simulation Environment</td><td></td></tr><tr><td>Tsantekidis [123]</td><td>PPO, DQN</td><td>forex price</td><td>Policy</td><td>Instrument combinations with currencies</td><td>2009 - 2018</td></tr><tr><td>Liu [80]</td><td>DQN, PPO, TD3,</td><td>Balance Shares own</td><td>Policy</td><td>NASDAQ-100,DJIA,S&P 500,SSE 50,CSI 300,HSI,</td><td></td></tr><tr><td></td><td>DDPG,SAC,A2C</td><td>price</td><td></td><td></td><td></td></tr><tr><td>Liu [82]</td><td>iRDPG</td><td> Indicators</td><td>Policy</td><td>300 stocks on SSI and SZI</td><td>2016 - 2019</td></tr><tr><td>Wang [133]</td><td>Policy Gradient</td><td>Indicators</td><td>Portfolio</td><td>DJIA 30,HSI 49,CSI100</td><td>1971 - 2019</td></tr><tr><td>Carta [11] Wang [132]</td><td>DQN REINFORCE,</td><td>Price Stock, States.</td><td>Policy Portfolio</td><td>S&P 500 future market,J.P.Morgan, Microsoft 23 DJIA stocks,23 SSE 50 Index stocks</td><td>2012 - 2019 2000 - 2018</td></tr><tr><td></td><td>DDQN</td><td></td><td></td><td></td><td></td></tr><tr><td>Briola [9] Liu [81]</td><td>PPO, DQN DQN, PPO, TD3,</td><td>Volumns, Position States，Price, Senti-</td><td>Policy Policy</td><td>scale market activities description Dow-30,NASDAQ-100, S&P-500,Cryptocurrencies,</td><td>2019</td></tr><tr><td></td><td>DDPG, SAC,A2C</td><td>ment</td><td></td><td>Currency, Futures</td><td></td></tr><tr><td>Li[75]</td><td>Ensemble Strat- egy</td><td>States,Price,Senti- ment</td><td>RL policy Acceleration.</td><td>NASDAQ stocks</td><td>2019 - 2021</td></tr></table></body></html>  

Continued   


<html><body><table><tr><td>Author</td><td>Methods</td><td>Input</td><td>Target</td><td>Dataset</td><td>Time Span</td></tr><tr><td>Liu [79]</td><td>DRL-based strat-</td><td>States,Price, Senti- ment</td><td>RL environments</td><td>30 DJIA stocks,10 market cap cryptocurrencies</td><td></td></tr><tr><td>Zhang [154]</td><td>egy CMT</td><td>Stock data, Text</td><td>Stock Price</td><td>CSI 100,HKEX,Wind data and news,Guba posts</td><td>2015</td></tr><tr><td>Duan [33]</td><td>Bi-LSTM</td><td>Stock Return</td><td>Stock Return</td><td>NYSE, Amex, NASDAQ news</td><td>2006 - 2015</td></tr><tr><td>Xu [143]</td><td>Deep Generative</td><td>Text, Price</td><td>Stock Movement</td><td>Conglomerates sector stocks</td><td>2014 - 2016</td></tr><tr><td>Sawhney [111]</td><td>RL</td><td>Tweets,News,Price</td><td>Stock Price</td><td>StockNet, China, Hong Kong</td><td>2014-2016</td></tr><tr><td>Ang [3]</td><td>GNN</td><td>News, Price</td><td>Stock return</td><td>IN-NY,IN-NA,BE-NY,BE-NA</td><td>2015-2019</td></tr><tr><td>Sawhney [110]</td><td>LSTM</td><td>Tweets,News,Price</td><td>Stock Price</td><td>StockNet,China,Hong Kong</td><td>2014-2016</td></tr><tr><td>Zhou [157]</td><td>GRU, CNN</td><td>Stock data</td><td>Stock Price</td><td>China</td><td>1991-2020</td></tr><tr><td>Chandar [13]</td><td>CNN</td><td>Stock data</td><td>Stock Trading</td><td>NASDAQ and NYSE</td><td>2009-2018</td></tr><tr><td>Li [74]</td><td>LSTM+GRU</td><td>Stock data + news</td><td>Stock Movement</td><td>S&P 500 Index</td><td>2017-2018</td></tr><tr><td>Wang [125]</td><td>GCN</td><td>Stock data</td><td> Stock Trading</td><td>42 commonly used indices</td><td>2009-2021</td></tr><tr><td>Duan [34]</td><td>VAE</td><td>Price</td><td>stock return</td><td>China A share</td><td>2017-2020</td></tr><tr><td>Wei [134]</td><td>Model-Based RL</td><td>LOB, Trade prints</td><td>Trading strategy</td><td>Hong Kong Stock Exchange.</td><td>2018</td></tr><tr><td>Yu [151]</td><td>Model-Based RL</td><td>Stock Price</td><td>Portfolio</td><td>U.S. equities</td><td>2005-2018</td></tr><tr><td>Yin [149]</td><td>GCN+GRU</td><td>Price, trade volume</td><td>Price,Price direction</td><td>DJIA,exchange-traded funds (ETFs)</td><td>2010-2020</td></tr><tr><td>Zhao [155]</td><td>BERT</td><td>stock price,text</td><td>Stock Movement</td><td>East Money</td><td>2020</td></tr></table></body></html>  

# 6 EVALUATION  

Evaluation measures play a crucial role in assessing the performance of stock market forecasting models. They are used to compare the forecasts made by different models to actual values. Commonly used evaluation metrics for classification models include accuracy-based metrics, while error-based metrics such as MAE and RMSE are commonly used for regression models. In this article, we classify the existing evaluation metrics into three categories: accuracy-based, error-based, and return-based. The accuracy-based and return-based metrics are considered to be better when their values are larger, while the error-based metrics are considered to be better when their values are smaller. Table 3 provides a summary of the papers that use these three types of evaluation metrics.  

# 6.1 Accuracy-based Evaluation Metrics  

In this section, we will clarify a few key terms used throughout. The acronym TP stands for "True Positive," indicating a scenario where both the actual class and the model’s prediction are positive. TN, or "True Negative," represents a situation where both the actual class and the model’s prediction are negative. FP, or "False Positive," refers to when the model predicts a positive class, but the actual class is negative. Lastly, FN, or "False Negative," denotes when the actual class is positive, but the model’s prediction is negative.  

Accuracy. Accuracy, which evaluates the proportion of correctly classified predictions to the total number of predictions, is the most commonly used metric in classification tasks. It can be represented by the equation: 𝐴𝑐𝑐𝑢𝑟𝑎𝑐𝑦 $\mathbf { \tau } = \mathbf { \tau }$ $\begin{array} { r } { \frac { T P + T N } { T P + T N + F P + F N } } \end{array}$  

In a multi-classification confusion matrix, the correctly classified samples are represented on the diagonal line from top left to bottom right. This metric, known as Accuracy, evaluates the overall performance of a model in identifying samples. For instance, in the study conducted by Hu et al. [49], Accuracy was used to measure the annualized rate of return, and in the research by Chen et al. [18], it was employed to evaluate the outcomes of stock price prediction. However, it is important to note that Accuracy may not be an appropriate metric for datasets with imbalanced class Manuscript submitted to ACM  

Table 3. The typical papers are in three evaluation methods, Accuracy-based, Error-based, and Return-based evaluation metrics.   


<html><body><table><tr><td>Evaluation methods</td><td>Author</td><td>Year</td><td>Conference/Journal name</td><td>Methods</td><td>Evaluation methods</td></tr><tr><td rowspan="5">Accuracy-based</td><td>Nelson et al. [94]</td><td>2017</td><td>IJCNN</td><td>LSTM</td><td>Accuracy，Precision，Recall，F1- score</td></tr><tr><td>Zhao et al. [156]</td><td>2017</td><td>ICTAI</td><td>LSTM</td><td>Accuracy</td></tr><tr><td>Hu et al. [49]</td><td>2018</td><td>WSDM</td><td>GRU</td><td>Accuracy</td></tr><tr><td>Chen et al. [18]</td><td>2018</td><td>CIKM</td><td>GCN</td><td>Accuracy</td></tr><tr><td>Deng et al. [25]</td><td>2019</td><td>WorldWide Web Conference</td><td>KDTCN</td><td>Accuracy,F1-score</td></tr><tr><td rowspan="6"></td><td>Li et al. [72]</td><td>2022</td><td>Complexity</td><td>Transformer, LSTM</td><td>Accuracy, MCC</td></tr><tr><td>Rather,Agarwal and Sastry [106]</td><td>2015</td><td>ESA</td><td>RNN</td><td>MSE, MAE</td></tr><tr><td>Zhang et al. [152]</td><td>2017</td><td>KDD</td><td>RNN</td><td>MSE</td></tr><tr><td>Li et al. [68]</td><td>2017</td><td>MTA</td><td>Tensor Trans-</td><td>RMSE</td></tr><tr><td></td><td></td><td></td><td>former</td><td></td></tr><tr><td>Li et al. [63]</td><td>2018</td><td>PMLR</td><td>LSTM</td><td>MSE</td></tr><tr><td rowspan="7"></td><td>Feng et al. [41]</td><td>2019 2020</td><td>TOIS</td><td>GCN</td><td>MSE</td></tr><tr><td>Rasheed et al. [105] Eapen et al. [35]</td><td>2019</td><td>IEEE</td><td>CNN</td><td>MAE, RMSE</td></tr><tr><td>Dong et al. [32]</td><td>2020</td><td>IEEE</td><td>CNN</td><td>MSE</td></tr><tr><td>Li Rao and Shi [64]</td><td>2018</td><td>IEEE</td><td>BERT,LSTM</td><td>RMSE</td></tr><tr><td>Xiong et al. [140]</td><td></td><td>ISCID</td><td>A2C</td><td>SR</td></tr><tr><td>Feng et al. [41]</td><td>2018</td><td>NeurIPS</td><td>DDPG</td><td>SR</td></tr><tr><td></td><td>2019</td><td>TOIS</td><td>GCN</td><td>MSE,IRR</td></tr><tr><td rowspan="6">Return-based</td><td>Sawhney et al. [109]</td><td>2020</td><td>ICDM</td><td>GCN</td><td>SR</td></tr><tr><td>Li et al. [70]</td><td>2022</td><td>MTA</td><td>GNN</td><td>SR,IR, MD</td></tr><tr><td>Zhou et al [158] Wang et al. [131]</td><td>2021 2019</td><td>IJCNLP</td><td>BERT</td><td>Average Return</td></tr><tr><td>Wang et al. [132]</td><td>2021</td><td>AAAI AAAI</td><td>PG</td><td>SR</td></tr><tr><td></td><td></td><td></td><td>REINFORCE,</td><td>AAR, SR</td></tr><tr><td></td><td></td><td></td><td>DDQN</td><td></td></tr></table></body></html>  

distribution, and additional indicators should be employed to provide a more accurate representation of the model’s performance.  

Precision, Recall, F-measure. The precision, recall and F1-score can be represented as equation 𝑃𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛 = 𝑇𝑃𝑇𝑃𝐹𝑃 , 𝑅𝑒𝑐𝑎 $\begin{array} { r } { l l = \frac { T P } { T P + F N } } \end{array}$ , and $\begin{array} { r } { F 1 = { \frac { 2 \times P r e c i s i o n \times R e c a l l } { P r e c i s i o n + R e c a l l } } = { \frac { 2 \times T P } { 2 \times T P + F P + F N } } } \end{array}$ .  

In a multi-classification task, the performance for each class can be evaluated using precision, recall, and F1-score. Precision refers to the number of true positive cases that are predicted by the binary classifier. This metric reflects the reliability of the model in correctly identifying positive samples. Recall, on the other hand, measures the number of true positive cases in the test set that are predicted by the binary classifier. It indicates the model’s ability to detect positive samples. The F1-score is a combination of both precision and recall, and it has been widely used in recent works such as [21, 25, 94, 117, 150] to evaluate the performance of neural networks. The F1-score aims to strike a balance between precision and recall for a fair evaluation of the model. However, it should be noted that when the model’s performance is evaluated using precision, recall, and F1-score, it may lead to an imbalance and ignore the true negative cases. Therefore, the Matthews Correlation Coefficient (MCC) can also be introduced as a possible evaluation strategy. Matthews Correlation Coefficient (MCC). The MCC (Matthews Correlation Coefficient) is a useful tool for evaluating the performance of a single-value classification model. It provides a summary of the information contained in a confusion matrix, which is a matrix used to represent the results of a classification model. The confusion matrix is typically represented in the following format: $M C C = { \frac { T P \times T N - F P \times F N } { \sqrt { \left( T P + F P \right) \left( T P + F N \right) \left( T N + F P \right) \left( T N + F N \right) } } }$ - The MCC is a measure of the correlation between predicted and actual samples, with a range of values from -1 to 1. A value of 1 indicates a perfect positive correlation, while a value of $^ { - 1 }$ indicates a perfect negative correlation, which occurs when the classifier misclassifies. The MCC is more robust to imbalanced categories compared to accuracy-based metrics. Several studies, such as [72, 126, 143, 154], have used MCC to evaluate their prediction results.  

# 6.2 Error-based Metrics  

Evaluating the performance of a prediction model can be done by comparing the predicted values to the actual values. One of the most widely used methods for this is measuring the error between the two. A lower error value indicates a better performance. In the context of stock market prediction, various error-based evaluation metrics are commonly utilized. These include the mean absolute error, mean square error, root-mean-square deviation, and mean absolute percentage error. In these metrics, a higher value indicates a better prediction.  

Mean Absolute Error (MAE). The metric of MAE, which stands for Mean Absolute Error, calculates the average number of absolute differences between the predicted and actual values. Several studies, such as [105, 106], have employed MAE as a means of evaluating the discrepancy between the actual and predicted values. The formula for MAE is as follows: $M A E = \frac { 1 } { n } \sum i = 1 ^ { n } | y i - \hat { y _ { i } } |$ .  

Mean Square Error (MSE). The MSE, or Mean Squared Error, is a metric used to determine the average squared distance between the actual value and the predicted value. Unlike the MAE, or Mean Absolute Error, which calculates absolute errors, the MSE amplifies errors to their maximum by using the sum of squares of errors. Several studies, such as [35, 41, 68, 106, 152], have employed the MSE method to evaluate the discrepancy between actual and predicted values. The formula for MSE is represented as $M S E = \frac { 1 } { n } \sum i = 1 ^ { n } ( y i - \hat { y _ { i } } ) ^ { 2 }$  

Root-Mean-Square Deviation (RMSE). The Root Mean Squared Error (RMSE) is a commonly used metric for evaluating the accuracy of predictions by measuring the square root of the second sample moment of the differences between predicted and actual values. It is similar to Mean Squared Error (MSE), with the only difference being the inclusion of the square root. It is therefore challenging to determine which evaluation metric is superior. In the works of [68, 105], the authors employed RMSE to assess the discrepancy between predicted and actual values. The equation for RMSE is represented as: 𝑅𝑀𝑆𝐸 = √︃ Í𝑖𝑛=1 (𝑦𝑛𝑖 −𝑦ˆ𝑖 )2 .  

Mean Absolute Percentage Error (MAPE). The Mean Absolute Percentage Error (MAPE) is a metric used to evaluate the accuracy of forecasting models. It calculates the average of the absolute percentage difference between the predicted and actual values. This method has been widely used in the literature, as seen in studies such as [3, 157]. The formula for MAPE can be represented as: $\begin{array} { r } { M A P E = \frac { 1 0 0 \% } { n } \sum _ { i = 1 } ^ { n } { \left| \frac { y _ { i } - \hat { y } _ { i } } { y _ { i } } \right| } , } \end{array}$ where $n$ is the number of observations, $y _ { i }$ is the actual value, and $\hat { y _ { i } }$ is the predicted value.  

# 6.3 Return-based Evaluation Metrics  

Evaluating the accuracy of stock market predictions can be done effectively using return-based evaluation metrics. Two commonly used metrics in finance for assessing earnings are the return ratio and the Sharpe ratio. The higher the value of these metrics, the better the prediction.  

Investment Return Ratio (IRR). IRR, or internal rate of return, is a metric used to measure the performance of an investment. It is calculated by determining the percentage difference between the value of an asset at the current time $\left( \boldsymbol { p } _ { t } \right)$ and the value of the same asset at the previous time $( p _ { t - 1 } )$ , divided by the previous value $( p _ { t - 1 } )$ . Studies such as [41, 110] have used IRR as an evaluation metric to assess the return ratio of investments. The equation for calculating IRR is 𝑅𝑒𝑡𝑢𝑟𝑛𝑟𝑎𝑡𝑖𝑜 $\begin{array} { r } { = \frac { p _ { t } - p _ { t - 1 } } { p _ { t - 1 } } \times 1 0 0 \% } \end{array}$ .  

Average Annual Return (AAR). The Average Annual Return (AAR) is a metric that measures the historical average return of a mutual fund as a percentage. Unlike the Internal Rate of Return (IRR), AAR calculates returns on an annual basis. It is particularly useful for assessing the performance of investments over a prolonged period. In their study, Wang et al. [130] utilized a dataset spanning seven years from 2010 to 2017 and employed AAR as one of the evaluation Manuscript submitted to ACM  

methods to determine the average annual rate of return.  

Sharpe Ratio (SR). The Sharpe Ratio (SR) takes into account both return and risk and calculates the average return per unit of volatility in relation to the risk-free rate [116]. This is represented by the equation: $S R = \frac { R _ { t } - R _ { f } } { \sigma } { \times } 1 0 0 \%$ , where $R _ { t }$ represents the return, $R _ { f }$ represents the risk-free rate, and $\sigma$ represents the standard deviation of the returns [90]. Several studies [64, 109, 132, 140] have utilized the SR as an evaluation metric to assess the performance of return ratios.  

# 7 FUTURE DIRECTIONS AND OPEN ISSUES  

The stock market prediction task has greatly contributed to the advancement of machine learning, particularly in the areas of natural language processing (NLP) and reinforcement learning (RL). However, there are still several potential research directions and open questions that need to be addressed in order to further improve and develop this field. Improving Generalization Ability For Stock Market Prediction. The ability of a machine learning model to accurately classify or predict unseen data is known as generalization. In the context of stock market prediction, a deep learning model must possess both high timelessness and strong generalization capabilities in order to be effective. However, some previous methods have struggled to generalize well to real-world trading scenarios or perform poorly on certain subsets of unseen data. Recent studies have suggested that incorporating self-supervised learning tasks into classification tasks can improve generalization, as demonstrated in works such as [45, 93, 159]. Further research in this area, both in terms of exploring existing methods and developing new ones, may be a promising direction for stock market prediction tasks. A self-supervised approach to enhancing generalization may be worth investigating in the future.  

Integrating Deep Learning Techniques with Online Learning Approaches Online learning is a training approach that utilizes the results of online training as feedback in order to optimize models. This method is particularly useful in mitigating the effects of volatility, uncertainty, and high noise factors in the stock market. Its application in stock market investment strategies is valuable as investors must constantly adjust their investment plans based on changes in stock prices. Online learning enables the simultaneous updating of the model and automatic control of the difference between predicted results and desired values. Other areas of application for online learning methods include dealing with abruptly changing time series. For example, Habibi [101] proposed using a Bayesian setting for online change point detection, taking into account sudden variations in the Dow Jones Industrial Average’s daily results. While this work contributes to detecting change points in time, it does not provide feedback for changing trading policies. We believe that integrating online learning and machine learning holds great potential for stock market prediction.  

Improving Evaluation and Datasets for Stock Market Prediction. Currently, many stock market prediction models only evaluate intermediate performance metrics such as stock movement prediction accuracy. However, it is unclear how well these models can support a practical trading system and there is a lack of uniform evaluation criteria for profitability. Each paper often uses different evaluation metrics on different datasets. Therefore, new stock market prediction models should be able to evaluate financial-relevant metrics, which can be grouped into three categories: profit criterion, including Annualized Rate of Return (ARR); risk criterion, including Maximum DrawDown (MDD) and Annualized Volatility (AVol); and risk-profit criterion, including Calmar Ratio (CR), Sortino ratio (SoR), and Annualized Sharpe Ratio (ASR). Furthermore, the stock market prediction task is currently fragmented with a lack of unified benchmark datasets and clear task descriptions, which greatly hinders the progress of this field.  

Improving Time Series Anomaly Detection for Stock Market Prediction. It is a practical proposition to quickly and effectively identify out-of-performance stocks from among thousands of stocks across the market. Instability in financial markets poses significant risks to investors; examples of instability include market crashes due to systemic risk and abnormal stock price movements caused by artificially large publicity. The most common stock market prediction models failed to capture the best trading points without considering the existence of anomaly outliers. Time-serious anomaly detection will facilitate stock market prediction for capturing outliers in stock market trading prices, which can help investors adjust their strategies and reduce investment risk. In addition, the model can be used to model multiple financial time series datasets and capture anomalies in the companies of interest. To this end, a promising and essential anomaly detection would be to design a better mechanism based on time series anomaly detection tasks to capture the best trading points for prediction tasks when trading in the real world.  

Tasks All In One On Continual Learning For Stock Market Prediction. Continual learning is a technique for training a model on multiple tasks consecutively while retaining information learned from previous tasks, even when the data from those tasks is no longer available. This enables neural networks to continuously accumulate knowledge and mitigate "catastrophic forgetting" in tasks such as stock prediction. However, current deep learning models for stock prediction are typically trained on static, homogeneously distributed data that cannot adapt or extend over time. To the best of our knowledge, there are no continual learning models specifically designed for stock market prediction, as the fluctuation of the stock market environment requires models to autonomously acquire new skills and adapt to new situations. Existing stock market prediction methods evaluate a single task on a single dataset, which can lead to overfitting of recent input data. Continual learning methods, such as those based on parameter isolation, can overcome this issue by freezing a portion of parameters after learning each task, allowing for more accurate and effective updating of the model for new tasks.  

Leveraging Distributional RL For Stock Trading. Quantitative trading algorithms still struggle with balancing profit and risk due to the volatility and noise in the financial market [2, 119]. One potential solution is the use of distributional ${ \mathrm { R L } } ,$ first proposed by Bellemare et al. in their paper C51 [7]. Distributional RL goes beyond traditional values by utilizing a defined random variable, whose expectation represents the state-action value, to form the distributional Bellman equation [7]. This equation is proven to be contracted under the measure of $p$ -Wassertain distance. Many state-of-the-art Q-learning algorithms in RL are distributional, such as C51 [7], Quantile Regression DQN (QR-DQN) [23], Implicit Quantile Network (IQN) [22], and Fully Parameterized Quantile Function (FQF) [144]. Distributional RL can provide more information about the distribution of returns, which can help algorithms reduce risk or improve robustness. Previous research has demonstrated the effectiveness of Distributional RL in Atari games, where algorithms achieved scores higher than human players. However, there has been limited exploration of the application of Distributional RL in financial trading. Therefore, it is worth investigating the potential of distributional RL in this field.  

Treating Stock Trading As Partially Observable Markov Decision Process. RL algorithms have been widely used in financial trading, as discussed in section . These include model-free methods such as policy gradient, Q-learning, and hybrid methods. However, these methods assume a fully observed MDP which does not accurately reflect the open and ever-changing nature of the financial market. To address this issue, there are two potential solutions for future research. The first solution is to collect all the transactions to make the dynamics fully observed, which may require significant storage and computational resources. For example, Briola et al. [9] have used transaction data on a small scale, which serves as a potential direction for future research. Another solution is to approximate the dynamics using a model-based RL approach. Researchers such as Wei et al. [134], Yu et al. [151], and Liu et al. [82] have demonstrated the effectiveness of transition dynamics models. Thus, the application of model-based methods in financial trading has Manuscript submitted to ACM  

a considerable potential and is worth exploring. By using a transition dynamics model, the policy could be capable of planning for a longer horizon.  

# 8 CONCLUSION  

In this paper, we present a comprehensive examination of the most prominent studies on utilizing deep learning for stock market prediction. To aid in understanding and organizing previous research in this area, we propose a classification system for categorizing and grouping similar works. Additionally, we provide an overview of current primary methods, evaluation metrics, and datasets used in stock market prediction. We also explore open questions and highlight promising future directions for machine learning research in stock market prediction. Through this survey, we aim to provide readers with a thorough understanding of the use of deep learning in stock market prediction.  

# REFERENCES  

[1] Ryo Akita, Akira Yoshihara, Takashi Matsubara, and Kuniaki Uehara. 2016. Deep learning for stock prediction using numerical and textual information. In 2016 IEEE/ACIS 15th International Conference on Computer and Information Science (ICIS). IEEE, 1–6.   
[2] Bo An, Shuo Sun, and Rundong Wang. 2022. Deep Reinforcement Learning for Quantitative Trading: Challenges and Opportunities. IEEE Intelligent Systems 37, 2 (2022), 23–26.   
[3] Gary Ang and Ee-Peng Lim. 2022. Guided Attention Multimodal Multitask Financial Forecasting with Inter-Company Relationships and Global and Local News. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 6313–6326.   
[4] George S Atsalakis and Kimon P Valavanis. 2009. Surveying stock market forecasting techniques–Part II: Soft computing methods. Expert systems with applications 36, 3 (2009), 5932–5941.   
[5] Michel Ballings, Dirk Van den Poel, Nathalie Hespeels, and Ruben Gryp. 2015. Evaluating multiple classifiers for stock price direction prediction. Expert systems with Applications 42, 20 (2015), 7046–7056.   
[6] Wenhang Bao and Xiao-yang Liu. 2019. Multi-agent deep reinforcement learning for liquidation strategy analysis. arXiv preprint arXiv:1906.11046 (2019).   
[7] Marc G Bellemare, Will Dabney, and Rémi Munos. 2017. A distributional perspective on reinforcement learning. In International Conference on Machine Learning. PMLR, 449–458.   
[8] Francesco Bertoluzzo and Marco Corazza. 2012. Testing different reinforcement learning configurations for financial trading: Introduction and applications. Procedia Economics and Finance 3 (2012), 68–77.   
[9] Antonio Briola, Jeremy Turiel, Riccardo Marcaccioli, and Tomaso Aste. 2021. Deep reinforcement learning for active high frequency trading. arXiv preprint arXiv:2101.07107 (2021).   
[10] João Carapuço, Rui Neves, and Nuno Horta. 2018. Reinforcement learning applied to Forex trading. Applied Soft Computing 73 (2018), 783–794.   
[11] Salvatore Carta, Andrea Corriga, Anselmo Ferreira, Alessandro Sebastian Podda, and Diego Reforgiato Recupero. 2021. A multi-layer and multi-ensemble stock trader using deep learning and deep reinforcement learning. Applied Intelligence 51, 2 (2021), 889–905.   
[12] Rodolfo C Cavalcante, Rodrigo C Brasileiro, Victor LF Souza, Jarley P Nobrega, and Adriano LI Oliveira. 2016. Computational intelligence and financial markets: A survey and future directions. Expert Systems with Applications 55 (2016), 194–211.   
[13] S Kumar Chandar. 2022. Convolutional neural network for stock trading using technical indicators. Automated Software Engineering 29, 1 (2022), 1–14.   
[14] Deli Chen, Yanyan Zou, Keiko Harimoto, Ruihan Bao, Xuancheng Ren, and Xu Sun. 2019. Incorporating fine-grained events in stock movement prediction. arXiv preprint arXiv:1910.05078 (2019).   
[15] Jia Chen, Tao Chen, Mengqi Shen, Yunhai Shi, Dongjing Wang, and Xin Zhang. 2022. Gated three-tower transformer for text-driven stock market prediction. Multimedia Tools and Applications (2022). https://doi.org/10.1007/s11042-022-11908-1   
[16] Lin Chen and Qiang Gao. 2019. Application of deep reinforcement learning on automated stock trading. (2019), 29–33.   
[17] Yan Chen, Shingo Mabu, Kotaro Hirasawa, and Jinglu Hu. 2007. Genetic network programming with sarsa learning and its application to creating stock trading rules. In 2007 IEEE Congress on Evolutionary Computation. IEEE, 220–227.   
[18] Yingmei Chen, Zhongyu Wei, and Xuanjing Huang. 2018. Incorporating corporation relationship via graph convolutional neural networks for stock price prediction. In Proceedings of the 27th ACM International Conference on Information and Knowledge Management. 1655–1658.   
[19] Rui Cheng and Qing Li. 2021. Modeling the Momentum Spillover Effect for Stock Prediction via Attribute-Driven Graph Attention Networks. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 35. 55–62.   
[20] Kyunghyun Cho, Bart Van Merriënboer, Dzmitry Bahdanau, and Yoshua Bengio. 2014. On the properties of neural machine translation: Encoderdecoder approaches. arXiv preprint arXiv:1409.1259 (2014).   
[21] Francesco Colasanto, Luca Grilli, Domenico Santoro, and Giovanni Villani. 2022. AlBERTino for stock price prediction: a Gibbs sampling approach. Information Sciences 597 (2022), 341–357. https://doi.org/10.1016/j.ins.2022.03.051   
[22] Will Dabney, Georg Ostrovski, David Silver, and Rémi Munos. 2018. Implicit quantile networks for distributional reinforcement learning. In International conference on machine learning. PMLR, 1096–1105.   
[23] Will Dabney, Mark Rowland, Marc Bellemare, and Rémi Munos. 2018. Distributional reinforcement learning with quantile regression. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 32.   
[24] Michael AH Dempster, Tom W Payne, Yazann Romahi, and Giles WP Thompson. 2001. Computational learning techniques for intraday FX trading using popular technical indicators. IEEE Transactions on neural networks 12, 4 (2001), 744–754.   
[25] Shumin Deng, Ningyu Zhang, Wen Zhang, Jiaoyan Chen, Jeff Z Pan, and Huajun Chen. 2019. Knowledge-driven stock trend prediction and explanation via temporal convolutional network. In Companion Proceedings of The 2019 World Wide Web Conference. 678–685.   
[26] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers). Association for Computational Linguistics, Minneapolis, Minnesota, 4171–4186. https: //doi.org/10.18653/v1/N19-1423   
[27] Guangyu Ding and Liangxi Qin. 2020. Study on the prediction of stock price based on the associated network model of LSTM. International Journal of Machine Learning and Cybernetics 11, 6 (2020), 1307–1317.   
[28] Qianggang Ding, Sifan Wu, Hao Sun, Jiadong Guo, and Jian Guo. 2020. Hierarchical Multi-Scale Gaussian Transformer for Stock Movement Prediction.. In IJCAI. 4640–4646.   
[29] Xiao Ding, Yue Zhang, Ting Liu, and Junwen Duan. 2014. Using structured events to predict stock price movement: An empirical investigation. In Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP). 1415–1425.   
[30] Xiao Ding, Yue Zhang, Ting Liu, and Junwen Duan. 2015. Deep learning for event-driven stock prediction. In Twenty-fourth international joint conference on artificial intelligence.   
[31] Xiao Ding, Yue Zhang, Ting Liu, and Junwen Duan. 2016. Knowledge-driven event embedding for stock prediction. In Proceedings of coling 2016, the 26th international conference on computational linguistics: Technical papers. 2133–2142.   
[32] Yingzhe Dong, Da Yan, Abdullateef Ibrahim Almudaifer, Sibo Yan, Zhe Jiang, and Yang Zhou. 2020. BELT: A Pipeline for Stock Price Prediction Using News. In 2020 IEEE International Conference on Big Data (Big Data). 1137–1146. https://doi.org/10.1109/BigData50022.2020.9378345   
[33] Junwen Duan, Yue Zhang, Xiao Ding, Ching Yun Chang, and Ting Liu. 2018. Learning target-specific representations of financial news documents for cumulative abnormal return prediction. In Proceedings of the 27th international conference on computational linguistics. 2823–2833.   
[34] Yitong Duan, Lei Wang, Qizhong Zhang, and Jian Li. 2022. FactorVAE: A Probabilistic Dynamic Factor Model Based on Variational Autoencoder for Predicting Cross-sectional Stock Returns. (2022).   
[35] Jithin Eapen, Doina Bein, and Abhishek Verma. 2019. Novel deep learning model with CNN and bi-directional LSTM for improved stock market index prediction. In 2019 IEEE 9th annual computing and communication workshop and conference (CCWC). IEEE, 0264–0270.   
[36] Dennis Eilers, Christian L Dunis, Hans-Jörg von Mettenheim, and Michael H Breitner. 2014. Intelligent trading of seasonal effects: A decision support algorithm based on reinforcement learning. Decision support systems 64 (2014), 100–108.   
[37] Deniz Ersan, Chifumi Nishioka, and Ansgar Scherp. 2020. Comparison of machine learning methods for financial time series forecasting at the examples of over 10 years of daily and hourly data of DAX 30 and S&P 500. Journal of Computational Social Science 3, 1 (2020), 103–133.   
[38] Oren Etzioni, Michele Banko, Stephen Soderland, and Daniel S Weld. 2008. Open information extraction from the web. Commun. ACM 51, 12 (2008), 68–74.   
[39] Eugene Fama and James D MacBeth. 1973. Risk, Return, and Equilibrium: Empirical Tests. Journal of Political Economy 81, 3 (1973), 607–36. https://EconPapers.repec.org/RePEc:ucp:jpolec:v:81:y:1973:i:3:p:607-36   
[40] Fuli Feng, Huimin Chen, Xiangnan He, Ji Ding, Maosong Sun, and Tat-Seng Chua. 2018. Enhancing stock movement prediction with adversarial training. arXiv preprint arXiv:1810.09936 (2018).   
[41] Fuli Feng, Xiangnan He, Xiang Wang, Cheng Luo, Yiqun Liu, and Tat-Seng Chua. 2019. Temporal relational ranking for stock prediction. ACM Transactions on Information Systems (TOIS) 37, 2 (2019), 1–30.   
[42] Scott Fujimoto, Herke Hoof, and David Meger. 2018. Addressing function approximation error in actor-critic methods. In International conference on machine learning. PMLR, 1587–1596.   
[43] Alex Graves and Jürgen Schmidhuber. 2005. Framewise phoneme classification with bidirectional LSTM networks. In Proceedings. 2005 IEEE International Joint Conference on Neural Networks, 2005., Vol. 4. IEEE, 2047–2052.   
[44] Tuomas Haarnoja, Aurick Zhou, Pieter Abbeel, and Sergey Levine. 2018. Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor. In International conference on machine learning. PMLR, 1861–1870.   
[45] Dan Hendrycks, Mantas Mazeika, Saurav Kadavath, and Dawn Song. 2019. Using Self-Supervised Learning Can Improve Model Robustness and Uncertainty. Advances in Neural Information Processing Systems (NeurIPS) (2019).   
[46] Sepp Hochreiter and Jürgen Schmidhuber. 1997. Long short-term memory. Neural computation 9, 8 (1997), 1735–1780.   
[47] Ehsan Hoseinzade, Saman Haratizadeh, and Arash Khoeini. 2019. U-cnnpred: A universal cnn-based predictor for stock markets. arXiv preprint arXiv:1911.12540 (2019).   
[48] Ting-Wei Hsu, Chung-Chi Chen, Hen-Hsen Huang, and Hsin-Hsi Chen. 2021. Semantics-Preserved Data Augmentation for Aspect-Based Sentiment Analysis. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, Online and Punta Cana, Dominican Republic, 4417–4422. https://doi.org/10.18653/v1/2021.emnlp-main.362   
[49] Ziniu Hu, Weiqing Liu, Jiang Bian, Xuanzhe Liu, and Tie-Yan Liu. 2018. Listening to chaotic whispers: A deep learning framework for news-oriented stock trend prediction. In Proceedings of the eleventh ACM international conference on web search and data mining. 261–269.   
[50] Zexin Hu, Yiqi Zhao, and Matloob Khushi. 2021. A survey of forex and stock price prediction using deep learning. Applied System Innovation 4, 1 (2021), 9.   
[51] Chien Yi Huang. 2018. Financial trading as a game: A deep reinforcement learning approach. arXiv preprint arXiv:1807.02787 (2018).   
[52] Hassan Ismail Fawaz, Germain Forestier, Jonathan Weber, Lhassane Idoumghar, and Pierre-Alain Muller. 2019. Deep learning for time series classification: a review. Data mining and knowledge discovery 33, 4 (2019), 917–963.   
[53] O Jangmin, Jongwoo Lee, Jae Won Lee, and Byoung-Tak Zhang. 2006. Adaptive stock trading with dynamic asset allocation using reinforcement learning. Information Sciences 176, 15 (2006), 2121–2147.   
[54] Weiwei Jiang. 2021. Applications of deep learning in stock market prediction: recent progress. Expert Systems with Applications 184 (2021), 115537.   
[55] Zhengyao Jiang, Dixing Xu, and Jinjun Liang. 2017. A deep reinforcement learning framework for the financial portfolio management problem. arXiv preprint arXiv:1706.10059 (2017).   
[56] Rupesh A Kamble. 2017. Short and long term stock trend prediction using decision tree. In 2017 International Conference on Intelligent Computing and Control Systems (ICICCS). IEEE, 1371–1375.   
[57] Raehyun Kim, Chan Ho So, Minbyul Jeong, Sanghoon Lee, Jinkyu Kim, and Jaewoo Kang. 2019. Hats: A hierarchical graph attention network for stock movement prediction. arXiv preprint arXiv:1908.07999 (2019).   
[58] Thomas N Kipf and Max Welling. 2016. Semi-supervised classification with graph convolutional networks. arXiv preprint arXiv:1609.02907 (2016).   
[59] Deepak Kumar, Pradeepta Kumar Sarangi, and Rajit Verma. 2021. A systematic review of stock market prediction using machine learning and statistical techniques. Materials Today: Proceedings (2021).   
[60] Mahinda Mailagaha Kumbure, Christoph Lohrmann, Pasi Luukka, and Jari Porras. 2022. Machine learning techniques and data for stock market forecasting: a literature review. Expert Systems with Applications (2022), 116659.   
[61] Jae Won Lee, Jonghun Park, O Jangmin, Jongwoo Lee, and Euyseok Hong. 2007. A multiagent approach to $q$ -learning for daily stock trading. IEEE Transactions on Systems, Man, and Cybernetics-Part A: Systems and Humans 37, 6 (2007), 864–877.   
[62] Chen Lei. 2021. RNN. In Deep Learning and Practice with MindSpore. Springer, 83–93.   
[63] Hao Li, Yanyan Shen, and Yanmin Zhu. 2018. Stock price prediction using attention-based multi-input LSTM. In Asian conference on machine learning. PMLR, 454–469.   
[64] Jinke Li, Ruonan Rao, and Jun Shi. 2018. Learning to trade with deep actor critic methods. In 2018 11th International Symposium on Computational Intelligence and Design (ISCID), Vol. 2. IEEE, 66–71.   
[65] Menggang Li, Wenrui Li, Fang Wang, Xiaojun Jia, and Guangwei Rui. 2020. Applying BERT to analyze investor sentiment in stock market. Neural Computing and Applications 33, 10 (2020), 4663–4676. https://doi.org/10.1007/s00521-020-05411-7   
[66] Qing Li, Yan Chen, Jun Wang, Yuanzhu Chen, and Hsinchun Chen. 2017. Web media and stock markets: A survey and future directions from a big data perspective. IEEE Transactions on Knowledge and Data Engineering 30, 2 (2017), 381–399.   
[67] Qing Li, Jinghua Tan, Jun Wang, and Hsinchun Chen. 2021. A Multimodal Event-Driven LSTM Model for Stock Prediction Using Online News. IEEE Transactions on Knowledge and Data Engineering 33, 10 (2021), 3323–3337. https://doi.org/10.1109/TKDE.2020.2968894   
[68] Qing Li, Jun Wang, Feng Wang, Ping Li, Ling Liu, and Yuanzhu Chen. 2017. The role of social sentiment in stock markets: a view from joint effects of multiple information sources. Multimedia Tools and Applications 76, 10 (2017), 12315–12345.   
[69] Wei Li, Ruihan Bao, Keiko Harimoto, Deli Chen, Jingjing Xu, and Qi Su. 2021. Modeling the stock relation with graph network for overnight stock movement prediction. In Proceedings of the Twenty-Ninth International Conference on International Joint Conferences on Artificial Intelligence. 4541–4547.   
[70] Xiaohan Li, Jun Wang, Jinghua Tan, Shiyu Ji, and Huading Jia. 2022. A graph neural network-based stock forecasting method utilizing multi-source heterogeneous data fusion. Multimedia Tools and Applications (2022), 1–23.   
[71] Xiaodong Li, Haoran Xie, Li Chen, Jianping Wang, and Xiaotie Deng. 2014. News impact on stock price return via sentiment analysis. KnowledgeBased Systems 69 (2014), 14–23. https://doi.org/10.1016/j.knosys.2014.04.022   
[72] Yawei Li, Shuqi Lv, Xinghua Liu, and Qiuyue Zhang. 2022. Incorporating Transformers and Attention Networks for Stock Movement Prediction. Complexity 2022 (2022).   
[73] Yuhong Li and Weihua Ma. 2010. Applications of artificial neural networks in financial economics: a survey. In 2010 International symposium on computational intelligence and design, Vol. 1. IEEE, 211–214.   
[74] Yang Li and Yi Pan. 2022. A novel ensemble deep learning model for stock prediction based on stock prices and news. International Journal of Data Science and Analytics 13, 2 (2022), 139–149.   
[75] Zechu Li, Xiao-Yang Liu, Jiahao Zheng, Zhaoran Wang, Anwar Walid, and Jian Guo. 2021. FinRL-Podracer: High performance and scalable deep reinforcement learning for quantitative finance. In Proceedings of the Second ACM International Conference on AI in Finance. 1–9.   
[76] Zhipeng Liang, Hao Chen, Junhao Zhu, Kangkang Jiang, and Yanran Li. 2018. Adversarial deep reinforcement learning in portfolio management. arXiv preprint arXiv:1808.09940 (2018).   
[77] Timothy P Lillicrap, Jonathan J Hunt, Alexander Pritzel, Nicolas Heess, Tom Erez, Yuval Tassa, David Silver, and Daan Wierstra. 2015. Continuous control with deep reinforcement learning. arXiv preprint arXiv:1509.02971 (2015).   
[78] Jintao Liu, Hongfei Lin, Xikai Liu, Bo Xu, Yuqi Ren, Yufeng Diao, and Liang Yang. 2019. Transformer-Based Capsule Network For Stock Movement Prediction. In Proceedings of the First Workshop on Financial Technology and Natural Language Processing. Macao, China, 66–73. https://aclanthology.org/W19-5511   
[79] Xiao-Yang Liu, Jingyang Rui, Jiechao Gao, Liuqing Yang, Hongyang Yang, Zhaoran Wang, Christina Dan Wang, and Jian Guo. 2021. FinRL-Meta: A Universe of Near-Real Market Environments for Data-Driven Deep Reinforcement Learning in Quantitative Finance. arXiv preprint arXiv:2112.06753 (2021).   
[80] Xiao-Yang Liu, Hongyang Yang, Qian Chen, Runjia Zhang, Liuqing Yang, Bowen Xiao, and Christina Dan Wang. 2020. FinRL: A deep reinforcement learning library for automated stock trading in quantitative finance. arXiv preprint arXiv:2011.09607 (2020).   
[81] Xiao-Yang Liu, Hongyang Yang, Jiechao Gao, and Christina Dan Wang. 2021. FinRL: Deep reinforcement learning framework to automate trading in quantitative finance. (2021), 1–9.   
[82] Yang Liu, Qi Liu, Hongke Zhao, Zhen Pan, and Chuanren Liu. 2020. Adaptive quantitative trading: An imitative deep reinforcement learning approach. In Proceedings of the AAAI conference on artificial intelligence, Vol. 34. 2128–2135.   
[83] Wenjie Lu, Jiazheng Li, Yifan Li, Aijun Sun, and Jingyang Wang. 2020. A CNN-LSTM-based model to forecast stock prices. Complexity 2020 (2020).   
[84] Wenjie Lu, Jiazheng Li, Jingyang Wang, and Lele Qin. 2021. A CNN-BiLSTM-AM method for stock price prediction. Neural Computing and Applications 33, 10 (2021), 4741–4753.   
[85] Giorgio Lucarelli and Matteo Borrotti. 2019. A deep reinforcement learning approach for automated cryptocurrency trading. In IFIP International Conference on Artificial Intelligence Applications and Innovations. Springer, 247–258.   
[86] Yongen Luo, Jicheng Hu, Xiaofeng Wei, Dongjian Fang, and Heng Shao. 2014. Stock trends prediction based on hypergraph modeling clustering algorithm. In 2014 IEEE International Conference on Progress in Informatics and Computing. IEEE, 27–31.   
[87] Ye Ma, Lu Zong, Yikang Yang, and Jionglong Su. 2019. News2vec: News network embedding with subnode information. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). 4843–4852.   
[88] Burton G Malkiel. 2003. The efficient market hypothesis and its critics. Journal of economic perspectives 17, 1 (2003), 59–82.   
[89] Xiliu Man, Jianwu Lin, and Yujiu Yang. 2020. Stock-UniBERT: A News-based Cost-sensitive Ensemble BERT Model for Stock Trading. In 2020 IEEE 18th International Conference on Industrial Informatics (INDIN), Vol. 1. 440–445. https://doi.org/10.1109/INDIN45582.2020.9442147   
[90] Daiki Matsunaga, Toyotaro Suzumura, and Toshihiro Takahashi. 2019. Exploring graph neural networks for stock market predictions with rolling window analysis. arXiv preprint arXiv:1909.10660 (2019).   
[91] Sidra Mehtab and Jaydip Sen. 2020. Stock price prediction using CNN and LSTM-based deep learning models. In 2020 International Conference on Decision Aid Sciences and Application (DASA). IEEE, 447–453.   
[92] Volodymyr Mnih, Adria Puigdomenech Badia, Mehdi Mirza, Alex Graves, Timothy Lillicrap, Tim Harley, David Silver, and Koray Kavukcuoglu. 2016. Asynchronous methods for deep reinforcement learning. In International conference on machine learning. PMLR, 1928–1937.   
[93] Sina Mohseni, Mandar Pitale, JBS Yadawa, and Zhangyang Wang. 2020. Self-supervised learning for generalizable out-of-distribution detection. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 34. 5216–5223.   
[94] David MQ Nelson, Adriano CM Pereira, and Renato A De Oliveira. 2017. Stock market’s price movement prediction with LSTM neural networks. In 2017 International joint conference on neural networks (IJCNN). IEEE, 1419–1426.   
[95] Thi-Thu Nguyen and Seokhoon Yoon. 2019. A novel approach to short-term stock price movement prediction using transfer learning. Applied Sciences 9, 22 (2019), 4745.   
[96] Isaac Kofi Nti, Adebayo Felix Adekoya, and Benjamin Asubam Weyori. 2020. A systematic review of fundamental and technical analysis of stock market predictions. Artificial Intelligence Review 53, 4 (2020), 3007–3057.   
[97] FX Satriyo D Nugroho, Teguh Bharata Adji, and Silmi Fauziati. 2014. Decision support system for stock trading using multiple indicators decision tree. In 2014 The 1st International Conference on Information Technology, Computer, and Electrical Engineering. IEEE, 291–296.   
[98] Subba Rao Polamuri, Kudipudi Srinivas, and A Krishna Mohan. 2021. Multi-model generative adversarial network hybrid prediction algorithm (MMGAN-HPA) for stock market prices prediction. Journal of King Saud University-Computer and Information Sciences (2021).   
[99] Marco Polignano, Pierpaolo Basile, Marco Degemmis, Giovanni Semeraro, and Valerio Basile. 2019. AlBERTo: Italian BERT Language Understanding Model for NLP Challenging Tasks Based on Tweets. In CLiC-it.   
[100] ES Ponomarev, Ivan V Oseledets, and AS Cichocki. 2019. Using reinforcement learning in the algorithmic trading problem. Journal of Communications Technology and Electronics 64, 12 (2019), 1450–1457.   
[101] Ryan Prescott Adams and David JC MacKay. 2007. Bayesian online changepoint detection. ArXiv e-prints (2007), arXiv–0710.   
[102] Martin L Puterman. 2014. Markov decision processes: discrete stochastic dynamic programming. John Wiley & Sons.   
[103] Yao Qin, Dongjin Song, Haifeng Chen, Wei Cheng, Guofei Jiang, and Garrison Cottrell. 2017. A dual-stage attention-based recurrent neural network for time series prediction. arXiv preprint arXiv:1704.02971 (2017).   
[104] Eduardo Ramos-Pérez, Pablo J Alonso-González, and José Javier Núñez-Velázquez. 2021. Multi-transformer: A new neural network-based architecture for forecasting S&P volatility. Mathematics 9, 15 (2021), 1794.   
[105] Jawad Rasheed, Akhtar Jamil, Alaa Ali Hameed, Muhammad Ilyas, Adem Özyavaş, and Naim Ajlouni. 2020. Improving stock prediction accuracy using cnn and lstm. In 2020 International Conference on Data Analytics for Business and Industry: Way Towards a Sustainable Economy (ICDABI). IEEE, 1–5.   
[106] Akhter Mohiuddin Rather, Arun Agarwal, and VN Sastry. 2015. Recurrent neural network and a hybrid model for prediction of stock returns. Expert Systems with Applications 42, 6 (2015), 3234–3241.   
[107] David E Rumelhart, Geoffrey E Hinton, and Ronald J Williams. 1986. Learning representations by back-propagating errors. nature 323, 6088 (1986), 533–536.   
[108] Ramit Sawhney, Shivam Agarwal, Arnav Wadhwa, and Rajiv Shah. 2020. Deep attentive learning for stock movement prediction from social media text and company correlations. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). 8415–8426.   
[109] Ramit Sawhney, Shivam Agarwal, Arnav Wadhwa, and Rajiv Ratn Shah. 2020. Spatiotemporal hypergraph convolution network for stock movement forecasting. In 2020 IEEE International Conference on Data Mining (ICDM). IEEE, 482–491.   
[110] Ramit Sawhney, Arnav Wadhwa, Shivam Agarwal, and Rajiv Shah. 2021. FAST: Financial news and tweet based time aware network for stock trading. In Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume. 2164–2175.   
[111] Ramit Sawhney, Arnav Wadhwa, Shivam Agarwal, and Rajiv Shah. 2021. Quantitative day trading from natural language using reinforcement learning. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 4018–4030.   
[112] Franco Scarselli, Marco Gori, Ah Chung Tsoi, Markus Hagenbuchner, and Gabriele Monfardini. 2008. The graph neural network model. IEEE transactions on neural networks 20, 1 (2008), 61–80.   
[113] John Schulman, Sergey Levine, Pieter Abbeel, Michael Jordan, and Philipp Moritz. 2015. Trust region policy optimization. In International conference on machine learning. PMLR, 1889–1897.   
[114] John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov. 2017. Proximal policy optimization algorithms. arXiv preprint arXiv:1707.06347 (2017).   
[115] Sreelekshmy Selvin, R Vinayakumar, EA Gopalakrishnan, Vijay Krishna Menon, and KP Soman. 2017. Stock price prediction using LSTM, RNN and CNN-sliding window model. In 2017 international conference on advances in computing, communications and informatics (icacci). IEEE, 1643–1647.   
[116] William F. Sharpe. 1994. The Sharpe Ratio. The Journal of Portfolio Management 21, 1 (1994), 49–58. https://doi.org/10.3905/jpm.1994.409501 arXiv:https://jpm.pm-research.com/content/21/1/49.full.pdf   
[117] Yang Shen, Jicheng Hu, Yanan Lu, and Xiaofeng Wang. 2012. Stock trends prediction by hypergraph modeling. In 2012 IEEE International Conference on Computer Science and Automation Engineering. IEEE, 104–107.   
[118] Priyank Sonkiya, Vikas Bajpai, and Anukriti Bansal. 2021. Stock price prediction using BERT and GAN. arXiv preprint arXiv:2107.09055 (2021).   
[119] Shuo Sun, Rundong Wang, and Bo An. 2021. Reinforcement learning for quantitative trading. arXiv preprint arXiv:2109.13851 (2021).   
[120] Ankit Thakkar and Kinjal Chaudhari. 2021. A comprehensive survey on deep neural networks for stock market: the need, challenges, and future directions. Expert Systems with Applications 177 (2021), 114800.   
[121] Thibaut Théate and Damien Ernst. 2021. An application of deep reinforcement learning to algorithmic trading. Expert Systems with Applications 173 (2021), 114632.   
[122] Michal Tkáč and Robert Verner. 2016. Artificial neural networks in business: Two decades of research. Applied Soft Computing 38 (2016), 788–804.   
[123] Avraam Tsantekidis, Nikolaos Passalis, Anastasia-Sotiria Toufa, Konstantinos Saitas-Zarkias, Stergios Chairistanidis, and Anastasios Tefas. 2020. Price trailing for financial trading using deep reinforcement learning. IEEE Transactions on Neural Networks and Learning Systems 32, 7 (2020), 2837–2846.   
[124] Tien Thanh Vu, Shu Chang, Quang Thuy Ha, and Nigel Collier. 2012. An experiment in integrating sentiment features for tech stock prediction in twitter. In Proceedings of the workshop on information extraction and entity analytics on social media data. 23–38.   
[125] Changhai Wang, Hui Liang, Bo Wang, Xiaoxu Cui, and Yuwei Xu. 2022. MG-Conv: A spatiotemporal multi-graph convolutional neural network for stock market index trend prediction. Computers and Electrical Engineering 103 (2022), 108285. https://doi.org/10.1016/j.compeleceng.2022.108285   
[126] Guifeng Wang, Longbing Cao, Hongke Zhao, Qi Liu, and Enhong Chen. 2021. Coupling macro-sector-micro financial indicators for learning stock representations with less uncertainty. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 35. 4418–4426.   
[127] Heyuan Wang, Shun Li, Tengjiao Wang, and Jiayi Zheng. 2021. Hierarchical Adaptive Temporal-Relational Modeling for Stock Trend Prediction.. In IJCAI. 3691–3698.   
[128] Haiyao Wang, Jianxuan Wang, Lihui Cao, Yifan Li, Qiuhong Sun, and Jingyang Wang. 2021. A stock closing price prediction model based on cnn-bislstm. Complexity 2021 (2021).   
[129] Heyuan Wang, Tengjiao Wang, and Yi Li. 2020. Incorporating expert-based investment opinion signals in stock prediction: A deep learning framework. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 34. 971–978.   
[130] Jia Wang, Tong Sun, Benyuan Liu, Yu Cao, and Hongwei Zhu. 2021. CLVSA: A convolutional LSTM based variational sequence-to-sequence model with attention for predicting trends of financial markets. arXiv preprint arXiv:2104.04041 (2021).   
[131] Jingyuan Wang, Yang Zhang, Ke Tang, Junjie Wu, and Zhang Xiong. 2019. Alphastock: A buying-winners-and-selling-losers investment strategy using interpretable deep reinforcement attention networks. In Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery & data mining. 1900–1908.   
[132] Rundong Wang, Hongxin Wei, Bo An, Zhouyan Feng, and Jun Yao. 2021. Commission fee is not enough: A hierarchical reinforced framework for portfolio management. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 35. 626–633.   
[133] Zhicheng Wang, Biwei Huang, Shikui Tu, Kun Zhang, and Lei Xu. 2021. DeepTrader: A Deep Reinforcement Learning Approach for Risk-Return Balanced Portfolio Management with Market Conditions Embedding. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 35. 643–650.   
[134] Haoran Wei, Yuanbo Wang, Lidia Mangu, and Keith Decker. 2019. Model-based reinforcement learning for predictions and control for limit order books. arXiv preprint arXiv:1910.03743 (2019).   
[135] Ronald J Williams. 1992. Simple statistical gradient-following algorithms for connectionist reinforcement learning. Machine learning 8, 3 (1992), 229–256.   
[136] Jimmy Ming-Tai Wu, Zhongcui Li, Norbert Herencsar, Bay Vo, and Jerry Chun-Wei Lin. 2021. A graph-based CNN-LSTM stock price prediction algorithm with leading indicators. Multimedia Systems (2021), 1–20.   
[137] Jimmy Ming-Tai Wu, Zhongcui Li, Gautam Srivastava, Jaroslav Frnda, Vicente Garcia Diaz, and Jerry Chun-Wei Lin. 2020. A CNN-based stock price trend prediction with futures and historical price. In 2020 International Conference on Pervasive Artificial Intelligence (ICPAI). IEEE, 134–139.   
[138] Boyi Xie, Rebecca Passonneau, Leon Wu, and Germán G Creamer. 2013. Semantic frames to predict stock price movement. In Proceedings of the 51st annual meeting of the association for computational linguistics. 873–883.   
[139] Frank Z Xing, Erik Cambria, and Roy E Welsch. 2018. Natural language based financial forecasting: a survey. Artificial Intelligence Review 50, 1 (2018), 49–73.   
[140] Zhuoran Xiong, Xiao-Yang Liu, Shan Zhong, Hongyang Yang, and Anwar Walid. 2018. Practical deep reinforcement learning approach for stock trading. arXiv preprint arXiv:1811.07522 (2018).   
[141] Cong Xu, Huiling Huang, Xiaoting Ying, Jianliang Gao, Zhao Li, Peng Zhang, Jie Xiao, Jiarun Zhang, and Jiangjian Luo. 2022. HGNN: Hierarchical Graph Neural Network for Predicting the Classification of Price-Limit-Hitting Stocks. Information Sciences (2022).   
[142] Wentao Xu, Weiqing Liu, Lewen Wang, Yingce Xia, Jiang Bian, Jian Yin, and Tie-Yan Liu. 2021. HIST: A Graph-based Framework for Stock Trend Forecasting via Mining Concept-Oriented Shared Information. arXiv preprint arXiv:2110.13716 (2021).   
[143] Yumo Xu and Shay B Cohen. 2018. Stock movement prediction from tweets and historical prices. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 1970–1979.   
[144] Derek Yang, Li Zhao, Zichuan Lin, Tao Qin, Jiang Bian, and Tie-Yan Liu. 2019. Fully parameterized quantile function for distributional reinforcement learning. Advances in neural information processing systems 32 (2019).   
[145] Linyi Yang, Tin Lok James Ng, Barry Smyth, and Riuhai Dong. 2020. HTML: Hierarchical Transformer-Based Multi-Task Learning for Volatility Prediction. Association for Computing Machinery, New York, NY, USA, 441âĂŞ451. https://doi.org/10.1145/3366423.3380128   
[146] Linyi Yang, Zheng Zhang, Su Xiong, Lirui Wei, James Ng, Lina Xu, and Ruihai Dong. 2018. Explainable text-driven neural network for stock prediction. In 2018 5th IEEE International Conference on Cloud Computing and Intelligence Systems (CCIS). IEEE, 441–445.   
[147] Steve Y Yang, Yangyang Yu, and Saud Almahdi. 2018. An investor sentiment reward-based trading system using Gaussian inverse reinforcement learning algorithm. Expert Systems with Applications 114 (2018), 388–401.   
[148] Yi Yang, Mark Christopher Siy UY, and Allen Huang. 2020. FinBERT: A Pretrained Language Model for Financial Communications. arXiv:2006.08097   
[149] Xingkun Yin, Da Yan, Abdullateef Almudaifer, Sibo Yan, and Yang Zhou. 2021. Forecasting Stock Prices Using Stock Correlation Graph: A Graph Convolutional Network Approach. In 2021 International Joint Conference on Neural Networks (IJCNN). 1–8. https://doi.org/10.1109/IJCNN52387. 2021.9533510   
[150] Jaemin Yoo, Yejun Soun, Yong-chan Park, and U Kang. 2021. Accurate Multivariate Stock Movement Prediction via Data-Axis Transformer with Multi-Level Contexts. In Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining (Virtual Event, Singapore) (KDD ’21). Association for Computing Machinery, New York, NY, USA, 2037âĂŞ2045. https://doi.org/10.1145/3447548.3467297   
[151] Pengqian Yu, Joon Sern Lee, Ilya Kulyatin, Zekun Shi, and Sakyasingha Dasgupta. 2019. Model-based deep reinforcement learning for dynamic portfolio optimization. arXiv preprint arXiv:1901.08740 (2019).   
[152] Liheng Zhang, Charu Aggar , and Guo-Jun Qi. 2017. Stock price prediction via discovering multi-frequency trading patterns. In Proceedings of the 23rd ACM n knowledge discovery and data mining. 2141–2149.   
[153] Qiuyue Zhan n Bao, Caiming Zhang, and Peide Liu. 2022. Transformer-based attention network for stock ns 202 (2022), 117239. https://doi.org/10.1016/j.eswa.2022.117239   
[154] Xi Zhang ng Fang, and S Yu Philip. 2018. Improving stock market prediction via heterogeneous informa   
[155] Feng Zh , and Caiming Zhang. 2022. Multi-layer features ablation of BERT model and its pplicati Applications 207 (2022), 117958. https://doi.org/10.1016/j.eswa.2022.117958   
[156] Zhiyong Zhao, Ruo i. 201 . Time-weighted LSTM model with redefined labeling for stock trend prediction. In 2017 IEEE 29th interna artificial intelligence (ICTAI). IEEE, 1210–1217.   
[157] Qihang Zhou, Changjun Zhou, d Xiao Wa g. 2022. Stock prediction based on bidirectional gated recurrent unit with convolutional neural network and feature selection. Plos one 17, 2 (2022), e0262501.   
[158] Zhihan Zhou, Liqian Ma, and Han Liu. 2021. Trade the event: Corporate events detection for news-based event-driven trading. arXiv preprint arXiv:2105.12825 (2021).  