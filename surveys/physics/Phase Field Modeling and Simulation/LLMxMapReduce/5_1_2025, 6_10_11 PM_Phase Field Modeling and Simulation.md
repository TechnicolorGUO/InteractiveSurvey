# 5/1/2025, 6:10:11 PM_Phase Field Modeling and Simulation  

0. Phase Field Modeling and Simulation  

1. Introduction  

![](images/47c99793953ecff0cc44fd85bf3052cedf36a51a44424f4f74093a115e57c325.jpg)  

Phase-field modeling (PFM) is a sophisticated numerical simulation method widely applied in materials science and engineering for simulating the evolution of morphology and physical properties during phase transformation processes and microstructure evolution [9,13,18]. A core principle of PFM is its diffuse interface approach, which utilizes continuous variables, often referred to as order parameters, to simulate phenomena that are discontinuous in reality, such as phase boundaries [2,6,12,13,24,27]. This method eliminates the necessity of explicitly tracking the geometric morphology of interfaces, which is a significant challenge in traditional methods [6,12,13,27]. By introducing a continuous phase field function, the position and shape of the phase interface are represented as isolines of this function [9].  

The historical evolution of phase-field modeling traces back to foundational theories in statistical physics and thermodynamics. Early concepts for describing diffuse interfaces were proposed by van der Waals, who used density fields to model fluid interfaces in liquid-gas systems [11]. The phase-field models commonly used today are fundamentally based on the Ginzburg-Landau theory developed in the 1950s for describing superconductivity using complex order parameters [11,17,27]. Building upon this, Cahn and Hilliard made a seminal contribution by constructing a model for the evolution of instantaneous microstructures based on thermodynamic principles, specifically addressing diffusion interfaces in nonuniform systems [11]. They introduced both non-conservative (structural order parameters) and conservative (concentration field) variables to characterize the system's evolution through changes in these field variables [11,18]. The introduction of micro-fields by Kha-chatuyran, describing atomic occupation probability as field variables, further contributed to describing microstructural changes [27].​  

In contrast to sharp interface methods like the Stefan problem, which require explicitly tracking phase boundaries and applying connection conditions at these moving interfaces, PFM treats the system as a whole, applying the same form of governing equations across different phase regions [4,6,13]. This diffuse interface approach offers a significant advantage, particularly in handling complex interface morphologies and evolution, such as dendritic growth [2,4,12,13]. The introduction of phase-field variables that vary rapidly but continuously across the interface, coupled with other field variables like concentration or temperature, allows the direct simulation of phase transformation processes without cumbersome interface tracking, greatly reducing computational complexity for intricate geometries [4,6,12,13,27]. Furthermore, PFM simplifies the incorporation of external fields (e.g., thermal, mechanical, electromagnetic) by including their contributions to the system's free energy functional [4].  

With the rapid advancement of computer technology and computational power, simulation research has become increasingly favored in materials science [4,20]. This increase in computational capability has directly contributed to the growing popularity and feasibility of PFM, which often involves solving complex, nonlinear partial differential equations for coupled field variables [4,5,11,16]. PFM has emerged as a mainstream computational method for predicting the evolution of nano- and mesoscopic microstructures and properties [18].​  

Phase-field modeling is positioned within the broader landscape of multiscale modeling techniques used in computational materials science, bridging the gap between atomic-scale methods (such as Density Functional Theory, Molecular Dynamics, Monte Carlo) and macroscale methods (like Finite Element Analysis) [1,4,18,20]. PFM is considered a mesoscale approach, capable of capturing microstructure evolution influenced by non-equilibrium factors, which in turn affects macroscale kinetics [20]. This mesoscale capability is crucial for understanding phenomena such as grain growth, solidification, precipitation, dislocation dynamics, and fracture, as well as applications in ferroelectric materials, electrochemical energy storage, nuclear fuels, and additive manufacturing [1,4,7,8,9,13,14,17,18,19].  

Despite its significant advantages and wide applicability, PFM faces several challenges and limitations that represent knowledge gaps and areas for future research. One notable challenge is the computational expense associated with solving the stiff phase-field equations, particularly when high spatial resolution is required to capture fine microstructure features like grain boundaries [6,16]. While efforts are ongoing to leverage high-performance computing, advanced numerical schemes like adaptive mesh refinement, and integrating machine learning to accelerate simulations [6,16,28], achieving high computing speed, large simulation scale, and high accuracy simultaneously remains a crucial area of development. Another challenge lies in the accurate representation of complex material properties and the rigorous mathematical and physical consistency when extending models from two-phase to multi-phase systems [4,6]. Early models also showed a dependence on the chosen interface width, which needed to be addressed [12]. Furthermore, incorporating realistic processing and operating conditions, such as stress and fission rate in nuclear fuels, into comprehensive phase-field models is an ongoing research need [17]. The development of readily accessible open-source software packages is helping to lower technical barriers and promote wider adoption and debugging of PFM [1,10,18,24]. This review aims to provide a comprehensive overview of phase-field modeling and simulation, highlighting its theoretical foundations, computational aspects, diverse applications across various material systems, and current challenges and future directions in the field.  

# 2. Theoretical Foundations and Core Concepts  

Phase field modeling (PFM) provides a powerful framework for simulating microstructural evolution and phase transformations in materials, rooted fundamentally in statistical physics and the Ginzburg–Landau theory of phase transitions [6,11,13]. This approach utilizes continuous field variables, known as order parameters or phase field variables, to represent the state of a material and its microstructure across spatial domains [1,4,27]. These variables vary smoothly between different phases or microstructural features, naturally describing the diffuse interfaces that exist between them [12,27]. From a physical perspective, the order parameter can signify properties such as the degree of crystallinity or the concentration of a species, directly reflecting the local material structure [1,6].​  

![](images/2fc1db5477756e2ea9a4d94b8021910f290f8679a305702357939461bd65a6ca.jpg)  

Order parameters are primarily distinguished by whether they obey local conservation laws, leading to the classification of conserved and non-conserved variables [1,27]. Conserved variables, such as chemical concentration (c), gaseous atom concentration (c₍gas₎), or vacancy concentration (c₍vac₎), satisfy local mass or species conservation and are typically governed by equations of the Cahn–Hilliard type [1,4,17,27]. Their evolution equation takes the general form:​  

$$
\frac { \partial c _ { i } } { \partial t } = \boldsymbol { \nabla } \cdot \left( \sum _ { j } M _ { i j } \boldsymbol { \nabla } \frac { \delta F } { \delta c _ { j } } \right) ,
$$  

where $\mathsf { c } \boxtimes$ is the conserved variable, $\mathsf { M } \boxtimes \boxtimes$ is the mobility matrix, and  

$$
\frac { \delta F } { \delta c _ { j } }
$$  

is the variational derivative of the total free energy functional F with respect to $\mathsf { c } \boxtimes$ [4]. Conversely, non-conserved variables, such as phase fraction $( \Phi )$ or crystallographic orientation parameters (ηᵢ), do not adhere to local conservation principles and evolve via equations of the Allen–Cahn type [1,4,27]. Their dynamic behavior is described by:​  

$$
\frac { \partial \phi _ { \alpha } } { \partial t } = - \sum _ { \beta } L _ { \alpha \beta } \frac { \delta F } { \delta \phi _ { \beta } } ,
$$  

where $\Phi _ { 1 } \mathfrak { a } ,$ is the non-conserved variable, $\mathsf { L } _ { \mathsf { \Lambda } } \mathsf { a } \mathsf { \beta } ,$ is the interface mobility matrix, and  

$$
\frac { \delta F } { \delta \phi _ { \beta } }
$$  

is the variational derivative of the free energy functional with respect to $\Phi _ { \imath } \beta _ { \jmath }$ [4]. The specific choice of order parameters is paramount, as it dictates the particular physical phenomena and microstructural features captured by the model [1].  

The evolution of these order parameters is thermodynamically driven by minimizing the total free energy functional of the system [6]. The free energy functional, F, is a central component of PFM, representing the total energy integrated over the system volume, typically expressed as an integral of the free energy density, f, which depends on the field variables and their spatial gradients [4,27]. This functional is generally composed of several contributions, including the bulk free energy density, gradient energy density associated with interfaces, and strain energy density resulting from elastic fields [7,14,17,27]. For example, a common form includes terms for chemical energy f, gradient energies $\frac { \kappa } { 2 } | \boldsymbol { \nabla } c | ^ { 2 } ,$ ​  

and elastic energy F₍elastic₎ [17]:  

$$
\boldsymbol { F } = \int _ { V } \left( f ( \{ u _ { i } \} ) + \sum _ { j } \frac { \kappa _ { j } } { 2 } | \nabla u _ { j } | ^ { 2 } + F _ { s t r a i n } + \ldots \right) d \boldsymbol { V } ,
$$  

where $\{ \mathfrak { u } \boxtimes \}$ represents the set of field variables and $\boldsymbol { \kappa } \bigotimes$ are gradient coefficients.  

Different types of bulk free energy potentials, such as polynomial, double-well, and multi-well functions, are employed to describe the thermodynamic states and energy minima of the various phases involved in a transformation [11]. These potentials define the thermodynamic driving force that propels the system towards a lower free energy state [11,27]. Thermodynamic properties crucial to the simulation, such as interfacial energy and diffusion coefficients, are inherently incorporated within the parameters of the free energy functional and the kinetic equations derived from it [11]. The equilibrium state of the system corresponds to a minimum of the free energy functional, and the dynamic equations describe how the system evolves to approach this minimum over time [27]. The ability of PFM to capture complex phenomena like supercooling during solidification arises from this fundamental representation of the system's state and its evolution based on the free energy landscape and continuous field variables [25]. For accurate simulations, careful parameterization of the free energy density functional based on experimental data or higher-level theoretical calculations is essential [14].​  

# 2.1 Order Parameters and Phase Field Variables  

Phase field modeling (PFM) quantifies material systems and their evolution during phase transformations through the use of continuous field variables, often referred to as order parameters or phase field variables [1,4,27]. These variables are continuous in space and represent the state of the material at each point, effectively defining its microstructure [12,13,24,27]. From a condensed matter physics perspective, the order parameter can be conceptually understood as the degree of crystallinity or order within a phase, providing a fundamental description, for example, of the atomic diffusion interface [6].  

Order parameters are fundamentally categorized into two types based on whether they satisfy local conservation laws: conserved and non-conserved variables [1,27]. Conserved field variables adhere to local conservation conditions throughout the system [27]. A prototypical example is concentration, such as the concentration of a chemical species c, the concentration of gaseous atoms ${ \mathsf { C } } _ { 1 } { \mathsf { g a s } } ,$ , or vacancy concentration c₍vac₎ [1,4,17,27]. Other conserved variables include atom occupation probability P used in microscopic diffuse phase-field models (MPFM) for processes like phase separation in binary alloys, and average atom density ρ utilized in phase-field-crystal (PFC) models applicable to materials including graphene [18]. The evolution of conserved variables is typically governed by the Cahn–Hilliard equation [4]:​  

$$
\frac { \partial c _ { i } } { \partial t } = \nabla \cdot \left( \sum _ { j } M _ { i j } \nabla \frac { \delta f } { \delta c _ { j } } \right) ,
$$  

where $\mathsf { c } \boxtimes$ represents the conserved variable, ${ \mathsf { M } } _ { ( } { \mathsf { i j } } ,$ is the component mobility matrix, f is the free energy density, and $\frac { \delta f } { \delta c _ { j } }$  

is the variational derivative [4].  

Conversely, non-conserved field variables, such as phase fraction or long-range order parameters, do not satisfy local conservation conditions [1,27]. The basic phase field variable $\Phi _ { \iota } \mathfrak { a } ,$ , describing the phase state α, is generally treated as a nonconserved variable because phases can be generated or disappear locally [4]. For instance, in solid–liquid phase transitions, the phase field variable can be defined such that it is 1 in the solid phase and 0 in the liquid phase, with a diffuse interface region where it varies continuously between these values [27]. In modeling polycrystalline materials and grain growth, a series of continuous field variables $\boldsymbol { \mathsf { n } } \bigotimes ( \bigotimes )$ are used to represent the microstructure, where i denotes different grain orientations and p is the total number of orientations [12,13,24]. These orientation field variables ηᵢ are non-conserved. The evolution of non-conserved variables is typically described by the Allen–Cahn equation [4]:​  

$$
\frac { \partial \phi _ { \alpha } } { \partial t } = - \sum _ { \beta } L _ { \alpha \beta } \frac { \delta f } { \delta \phi _ { \beta } } ,
$$  

where $\Phi _ { 1 } \mathtt { a } ,$ is the non-conserved variable, $\mathsf { L } _ { \mathsf { \Lambda } } \mathsf { a } \mathsf { \beta } ,$ is the interface mobility matrix, f is the free energy density, and $\frac { \delta f } { \delta \phi _ { \beta } }$  

is the variational derivative [4]. Variational derivatives  

$$
\frac { \delta f } { \delta \phi _ { \beta } } \quad \mathrm { a n d } \quad \frac { \delta f } { \delta c _ { j } }
$$  

incorporate contributions from the gradients of the field variables, distinguishing them from ordinary partial derivatives [4].  

The choice of order parameters is central to defining the specific phase transformation or microstructural evolution being modeled, as different choices capture distinct physical phenomena and thus influence the behavior of the phase-field model [1]. Examples of various order parameters used in PFM include the phase variable $\Phi$ or $\Phi _ { 1 } \mathtt { a } ,$ for general phase transitions like solidification [4,18], concentration c for compositional changes or spinodal decomposition [1,18,27], orientation fields $\boldsymbol { \mathsf { n } } \boldsymbol { \boxtimes }$ for polycrystalline microstructures and grain growth [12,13,24], and polarization as the primary order parameter to describe ferroelectric domain structures, potentially coupled with strain [7,14]. The evolution of the system's organization is dynamically characterized by changes in these chosen order parameters and concentration fields over time [11]. The ability of PFM to account for phenomena like supercooling or superheating during solid–liquid phase change, which traditional methods like the enthalpy method may overlook, stems directly from its representation of the interface and phase state through continuous field variables and their associated dynamics [25].  

# 2.2 Free Energy Functionals and Thermodynamic Considerations  

Phase field models are fundamentally rooted in thermodynamics, with the free energy functional serving as the central element that governs material behavior and phase transformations [6]. The free energy functional of a system, typically denoted as F, represents the total free energy integrated over the system volume V. It is generally expressed as an integral of the free energy density, f, which depends on the local field variables {u_i} and their gradients $\{ \nabla \mathfrak { u } _ { - } \mathfrak { i } \}$ [4]:​  

$$
F = \int _ { V } f ( \{ u _ { i } , \nabla u _ { i } \} ) d V
$$  

This functional formulation allows for the incorporation of spatial variations in the order parameters and other relevant fields, enabling the description of diffuse interfaces between phases.  

The free energy density, f, encapsulates the local thermodynamic state and is typically composed of several contributing energy terms. These components include the bulk free energy density, interfacial energy density, strain energy density (including elastic strain energy density), and potentially other interaction energy densities such as electro-magnetic contributions, depending on the physical system being modeled [27]. The specific formulation of the free energy density is crucial as it defines the thermodynamic driving force for phase transformations and dictates the equilibrium states and transformation kinetics [11,27].  

Different types of bulk free energy potentials are employed to describe the thermodynamic states of various phases [11]. Common forms include polynomial potentials, such as double-well or multi-well functions, which are chosen to represent the distinct energy minima corresponding to different stable or metastable phases [11]. For instance, near a phase transition point, the thermodynamic energy can be approximated by a Landau polynomial expansion as a function of the order parameter:​  

$$
F = \alpha \phi + \beta \phi ^ { 2 } + \gamma \phi ^ { 3 } + . . .
$$  

[1]. Specific chemical energy formulations can involve polynomial terms for certain species, such as a fourth-order polynomial for vacancy concentration $\mathsf { ( c \_ f v a c ) ) }$ and quadratic terms for gas concentration (c_{gas}), often including binding energy terms between different species [17]:​  

​f ${ \begin{array} { l } { { \frac { * } { c } } _ { h e m } ( { c } _ { g a s } , { c } _ { v a c } ) = f _ { v a c } \left( { c } _ { v a c } ^ { 4 } + b _ { 3 } { c } _ { v a c } ^ { 3 } + b _ { 2 } { c } _ { v a c } ^ { 2 } + b _ { 1 } { c } _ { v a c } + b _ { 0 } \right) + f _ { g a s } ( { c } _ { g a s } - { c } _ { g a s 0 } ) ^ { 2 } + f _ { b i n d } ( { c } _ { g a s } - { c } _ { g a s 0 } ) } \end{array} }$ cgas0 ​)(cvac ​ − cvac0 ​) where constants f_{vac}, f_{gas}, f_{bind}, b_0, b_1, b_2, b_3 and solubilities c_{gas0}, c_{vac0} define the potential landscape [17].​  

Beyond the bulk energy, the free energy functional includes terms accounting for spatial gradients of the field variables, which represent the energy associated with interfaces between phases. Strain energy is another critical component, particularly in systems involving lattice mismatch or external stresses. The elastic energy, for example, can be formulated based on the elastic strain ε_{ij}^{el} and the elastic stiffness tensor λ_{ijkl} [17]:​  

$$
F _ { e l a s t i c } = \frac { 1 } { 2 } \lambda _ { i j k l } \epsilon _ { i j } ^ { e l } \epsilon _ { k l } ^ { e l }
$$  

In materials like ferroelectrics, the functional also incorporates energies related to polarization, strain, and electric fields [14]. Models for ferroelectric domain behavior, for instance, often utilize Landau-Ginzburg-Devonshire (LGD) theory within the free energy functional framework, explicitly including electrostatic and elastic energy contributions [7].​  

The variation of the total free energy functional with respect to the field variables provides the thermodynamic driving force for the evolution of the system towards equilibrium. Thermodynamic properties, such as interfacial energy and diffusion coefficients, are inherently incorporated within the structure and parameters of the free energy functional and the kinetic equations derived from it [11]. The free energy functional is thus instrumental in predicting the equilibrium state, which corresponds to a minimum of the functional, and the kinetics of phase transformations, governed by how the system evolves to minimize this functional over time [27]. This approach allows for the simulation of complex phenomena, including nucleation, growth, coarsening, and domain evolution. Accurate parameter identification for the free energy density functional is paramount for reliable simulation results [14]. During first-order phase transformations, the system transitions between free energy minima. At equilibrium, the chemical potential of the coexisting phases is equal, although changes in volume  

$$
\Delta V = \left( { \frac { \partial \mu } { \partial P } } \right) _ { T }
$$  

phase transition entropy  

$$
\Delta S = - \Big ( \frac { \partial \mu } { \partial T } \Big ) _ { P }
$$  

and latent heat  

$$
Q = T \Delta S
$$  

are characteristic features [24].  

# 3. Governing Equations and Numerical Implementation  

Phase-field models describe the evolution of system microstructure through one or multiple order parameter fields and concentration fields, which can be either conservative or non-conservative. These models are rooted in thermodynamic principles aiming to minimize free energy dissipation [6,13]. The dynamics of these fields are governed by partial differential equations derived from the functional derivatives of the total free energy with respect to the field variables [6].  

Two fundamental types of kinetic equations are widely employed in phase-field simulations, distinguished by the nature of the order parameter they evolve: the Time-Dependent Ginzburg-Landau (TDGL) or Allen-Cahn equation for non-conserved order parameters, and the Cahn-Hilliard equation for conserved order parameters [1,4,11].  

For a non-conserved order parameter $\Phi$ , often representing structural or compositional degrees of freedom whose total amount in the system is not conserved, the evolution follows linear kinetics described by the TDGL or Allen-Cahn equation [1]:​  

$$
\frac { \partial \phi } { \partial t } = - L \frac { \delta F } { \delta \phi }
$$  

Here, t is time, L is a positive kinetic coefficient related to the mobility of the order parameter, F is the total free energy functional of the system, and  

$$
\frac { \delta F } { \delta \phi }
$$  

represents the thermodynamic driving force derived from the functional derivative of the free energy with respect to $\boldsymbol { \Phi }$ . This equation dictates that the order parameter evolves towards minimizing the system's free energy. The TDGL equation is fundamental for modeling phenomena where the order parameter is not conserved, such as the evolution of ferroelectric domain structures where the order parameter signifies polarization [7,14]. Key parameters include the kinetic coefficient L.  

For a conserved order parameter c, typically representing concentration or mass density, the evolution is governed by a diffusion-type equation known as the Cahn-Hilliard equation [1,13]:  

$$
\frac { \partial c } { \partial t } = \boldsymbol { \nabla } \cdot \left( M \boldsymbol { \nabla } \frac { \delta \boldsymbol { F } } { \delta c } \right)
$$  

In this equation, c is the conserved parameter, M is the diffusion mobility coefficient, and  

$$
\frac { \delta F } { \delta c }
$$  

is the functional derivative representing the chemical potential. The equation describes the flux of the conserved quantity driven by gradients in chemical potential, ensuring conservation within a closed system. This model was initially developed to describe diffusion interfaces [13] and is applied to simulate phenomena like phase separation and the evolution of coherent microstructures in alloys [21]. The mobility coefficient M is a critical parameter influencing the kinetics of mass transport. Variations of the Cahn-Hilliard equation may include source or sink terms to account for generation or annihilation of the conserved quantity. For example, models describing vacancy and gas atom dynamics incorporate generation rates ( $\bigtriangledown$ )̇into the equations [17]:​  

$$
\begin{array} { r l } & { \cfrac { \partial c _ { g a s } } { \partial t } = \nabla \cdot \bigg ( M _ { g a s } \nabla \frac { \delta F } { \delta c _ { g a s } } \bigg ) + \dot { g } _ { g a s } } \\ & { \cfrac { \partial c _ { v a c } } { \partial t } = \nabla \cdot \bigg ( M _ { v a c } \nabla \frac { \delta F } { \delta c _ { v a c } } \bigg ) + \dot { g } _ { v a c } } \end{array}
$$  

These terms, like 𝑔̇₍gas₎ and 𝑔̇₍vac₎, can depend on external factors such as fission rate [17]. The flexibility in defining the specific forms and terms of these equations, including parameters such as mobility matrices, is central to applying the phase-field framework to diverse material systems [4,6]. Some model formulations, like the Chen model, offer advantages such as automatically constraining phase field variables within physical bounds [4]. Beyond standard applications, the framework extends to time-fractional phase-field equations [15] and coupled physics problems like solid-liquid phase change with convection [25].​  

Solving these complex partial differential equations necessitates robust numerical methods [1,15]. The most common approaches employed are finite difference, finite element, and spectral methods [11,27]. Each method presents distinct advantages and disadvantages regarding accuracy, computational cost, and ease of implementation [11].  

Finite difference and spectral methods are often relatively simpler to program, especially on uniform grids with straightforward time-stepping schemes like the Euler method [6]. Spectral methods, utilizing techniques like Fourier transforms, can achieve high accuracy for problems with smooth solutions and simple geometries, sometimes requiring specialized libraries such as FFTW for implementations like OpenPhase [12,17]. These methods rely on grid-based discretization, and convergence studies are essential to ensure results are independent of grid spacing [24].  

The Finite Element Method (FEM), in contrast, offers greater flexibility for handling complex geometries and boundary conditions [27]. Implementing phase-field models using FEM involves transforming the governing PDEs into their weak forms and discretizing them over a mesh [14]. Proper treatment of various boundary conditions, including periodic ones, is crucial for accurate FEM simulations [14]. Software environments like COMSOL Multiphysics are frequently used for FEMbased phase field modeling [21], while general numerical computation platforms like MATLAB can also be used for custom implementations [9].​  

A critical aspect of numerical implementation is balancing accuracy and efficiency [27]. Simple methods may be easy to implement but can demand very fine grids or small time steps for stability and accuracy, increasing computational cost. More advanced techniques, such as Adaptive Mesh Refinement (AMR), improve efficiency and accuracy by dynamically adjusting mesh resolution but add complexity [6]. The analytical difficulty of certain terms, like the gradient energy, underscores the ongoing need for faster numerical algorithms [1].  

Ensuring the stability and accuracy of numerical solutions requires careful consideration of parameter selection, the choice of initial conditions, and the application of appropriate boundary conditions [10,14]. Parameter values, including those representing physical fluctuations, must be chosen appropriately [17]. Convergence studies based on mesh or time-step refinement are standard practice to validate the numerical scheme and demonstrate solution robustness [24]. Ongoing theoretical work on areas like time-fractional equations highlights challenges and avenues for further research in numerical methods for phase field modeling [15].​  

In summary, the selection of the appropriate governing equations, derived from the free energy functional based on the physics of conserved and non-conserved order parameters, coupled with the judicious choice and implementation of numerical methods—whether finite difference, finite element, or spectral approaches—forms the foundation for accurate and efficient phase-field simulations. Challenges persist in developing highly efficient and stable algorithms, particularly for complex or time-fractional systems, and require careful consideration of discretization, boundary conditions, and parameter calibration [1,6,15].  

# 3.1 Governing Equations  

Phase-field models are fundamentally based on thermodynamic principles, particularly the concept of minimizing free energy dissipation [6]. The evolution of the system microstructure is described by one or multiple order parameter fields and concentration fields, which can be either conservative or non-conservative [6,13]. The governing equations are typically partial differential equations derived from functional derivatives of the total free energy with respect to these field variables.  

Two fundamental types of kinetic equations underpin phase-field simulations, corresponding to the nature of the order parameter they govern: the Time-Dependent Ginzburg-Landau (TDGL) or Allen-Cahn equation for non-conserved order parameters, and the Cahn-Hilliard equation for conserved order parameters [1,4,11].  

For a non-conserved order parameter, often denoted by $\phi$ , the dynamic evolution follows linear kinetics, commonly described by the TDGL or Allen-Cahn equation [1]:​  

$$
\frac { \partial \phi } { \partial t } = - L \frac { \delta F } { \delta \phi }
$$  

Here, $t$ represents time, $L$ is a kinetic coefficient representing the mobility of the non-conserved order parameter, $F$ is the total free energy of the system, and $\frac { \delta F } { \delta \phi }$ is the functional derivative of the free energy with respect to the order parameter $\phi$ . This equation dictates that the rate of change of the order parameter is proportional to the thermodynamic driving force, $- \frac { \delta F } { \delta \phi }$ , which seeks to reduce the system's free energy. The TDGL equation is implicitly utilized in modeling the evolution of ferroelectric domain structures, where the order parameter represents polarization, influenced by factors such as electric fields and mechanical stresses [7,14].  

For a conserved order parameter, such as concentration (often denoted by $c$ ), the evolution is governed by a diffusion-type equation, known as the Cahn-Hilliard equation [1,13]:  

$$
\frac { \partial c } { \partial t } = \boldsymbol { \nabla } \cdot \left( M \boldsymbol { \nabla } \frac { \delta \boldsymbol { F } } { \delta c } \right)
$$  

In this equation, $c$ is the conserved order parameter (e.g., concentration), $M$ is the diffusion mobility coefficient, and δF $\frac { \delta F } { \delta c }$ is the functional derivative of the free energy with respect to the conserved parameter, representing the chemical potential. The equation describes the diffusion flux, proportional to the gradient of the chemical potential, leading to microstructural evolution while conserving the total amount of the parameter within a closed system. Cahn and Hilliard originally developed this model to describe diffusion interfaces in non-homogeneous systems [13]. Specific applications include simulating coherent microstructures in alloys [21] and modeling phase separation.  

In some applications, source or sink terms representing generation or annihilation of the conserved quantity may be included in the Cahn-Hilliard equation. For instance, the movement of vacancy and gas atoms can be described by modified Cahn-Hilliard equations that include generation rates [17]:  

$$
\begin{array} { r l } & { \cfrac { \partial c _ { g a s } } { \partial t } = \nabla \cdot \bigg ( M _ { g a s } \nabla \frac { \delta F } { \delta c _ { g a s } } \bigg ) + \dot { g } _ { g a s } } \\ & { \cfrac { \partial c _ { v a c } } { \partial t } = \nabla \cdot \bigg ( M _ { v a c } \nabla \frac { \delta F } { \delta c _ { v a c } } \bigg ) + \dot { g } _ { v a c } } \end{array}
$$  

Here, $c _ { g a s }$ ​ and $c _ { v a c }$ ​ are the concentrations of gas atoms and vacancies, respectively, and $M _ { g a s }$ ​ and $M _ { v a c }$ ​ are their respective mobilities [17]. The terms $\dot { g } _ { g a s }$ ​ and $\dot { g } _ { v a c }$ represent the generation rates, which can depend on external factors like fission rate $\dot { f }$ ​ and fission yield $Y _ { X e }$ ​ for gas production, potentially incorporating switching functions $h _ { m }$ to define generation zones [17]. These specific forms illustrate how parameters like mobility $( M , M _ { g a s } , M _ { v a c } )$ ) and generation rates ( ​g˙ ​gas ​ , $\dot { g } _ { v a c }$ ) are incorporated into the governing equations. The general framework of phase-field equations, derived from the free energy minimization principle, allows for flexibility in defining the specific forms and terms based on the material system and phenomena being studied [4,6]. Some models, such as the Chen model, offer advantageous properties like automatically constraining phase field variables within physical bounds without numerical truncation [4].  

Solving these complex partial differential equations typically requires numerical methods [1]. Variations such as timefractional phase-field equations are also explored in theoretical advancements [15]. Beyond basic phase separation, these equations are adapted to model diverse phenomena like solid-liquid phase change, incorporating effects like supercooling and superheating, often coupled with other physics like convection [25]. The core structure involving order parameters and free energy functional derivatives, however, remains central to deriving these governing equations [6]. Key parameters in these equations can include terms analogous to the interface mobility matrix and the diffusion mobility matrix, which influence the kinetics of phase evolution and mass transport [4].​  

# 3.2 Numerical Methods  

Solving the complex partial differential equations inherent in phase field models necessitates the deployment of robust numerical methods [1,15]. Common approaches in the literature include finite difference, finite element, and spectral methods [11,27]. Each method presents distinct advantages and disadvantages concerning accuracy, computational cost, and ease of implementation [11].  

The finite difference and spectral methods, particularly when coupled with simple time-stepping schemes like the Euler method on a uniform grid, are often considered relatively straightforward to program [6]. Spectral methods, utilizing techniques such as Fourier transformation, can offer high accuracy for smooth solutions and simple geometries. For instance, simulations have been implemented using an implicit Fourier transformation method with specific mesh parameters, such as a grid of 128 points and a spatial resolution $\Delta l = 0 . 2 \mathrm { n m }$ , at temperatures around 1200K [17]. Implementations of spectral methods often require specialized libraries, such as the FFTW library for performing fast Fourie transforms, as seen in projects like OpenPhase [12]. Grid-based discretization is fundamental to finite difference and spectral methods, and convergence studies based on grid spacing, such as using $\Delta x = 1 \mu \mathrm { m }$ in AlCu benchmark tests with specified system sizes, are crucial for assessing the discretization's impact on results [24].  

The finite element method (FEM) provides flexibility for complex geometries and boundary conditions. The FEM approach involves transforming the phase-field partial differential equations (PDEs) into their weak forms, which are then discretized over a mesh [14]. A detailed understanding of the PDE and weak forms is essential for accurate FEM implementation,  

including the proper treatment of various boundary conditions, such as periodic ones [14]. Software packages like COMSOL Multiphysics are frequently utilized for establishing and solving phase field models based on the finite element method, as demonstrated in studies of metallic microstructures [21]. Furthermore, general numerical computation environments like MATLAB can be used to implement phase field simulations by developing custom programs to study material phase transformations [9].​  

Critically assessing accuracy and efficiency is paramount [27]. While simple methods like Euler time-stepping on uniform grids are easy to implement [6], they may have limitations regarding accuracy or stability for complex problems, potentially requiring very small time steps or fine grids, thereby increasing computational cost. More advanced techniques, such as Adaptive Mesh Refinement (AMR), are available to enhance efficiency and accuracy by dynamically adjusting the mesh resolution based on the solution gradient, though they add complexity to the implementation [6]. The necessity for developing fast numerical algorithms is underscored by the analytical difficulty posed by terms like the gradient energy in phase field equations [1]. Strategies to improve simulation efficiency and effect can also involve introducing parameters representing physical fluctuations, such as thermal fluctuations of gas atoms ( $\xi _ { g } = 0 . 0 0 2 5$ ) and vacancies ( $\xi _ { v } = 0 . 0 0 2 5$ ), as implemented in certain simulations [17]. Parameter selection, the choice of initial conditions (not detailed in digests), and boundary conditions [14] are critical for ensuring the stability and accuracy of numerical solutions [10]. Convergence studies, like the one based on domain discretization in the AlCu benchmark, are standard practice for validating the numerical settings and demonstrating solution independence from the chosen grid resolution [24].  

# 4. Computational Efficiency and Advanced Techniques  

Phase field modeling (PFM) is a sophisticated computational tool widely employed for simulating complex material phenomena, such as microstructure evolution and phase transformations. However, the inherent complexity and computational cost of PFM simulations, particularly for large-scale or long-time problems, necessitate the development and application of advanced techniques to enhance efficiency and expand capabilities [11]. Research efforts in this domain focus on improving computational performance through optimized algorithms and hardware utilization, extending the PFM framework to incorporate diverse physical interactions, bridging disparate length and time scales, and leveraging modern data-driven approaches like machine learning [2,11]. Furthermore, the accessibility and reproducibility of these advancements are significantly influenced by the availability and features of simulation software. This section provides an overview of key computational efficiency techniques, advanced modeling extensions including multi-physics and multiscale approaches, the integration of machine learning, and a review of relevant open-source software packages.  

![](images/d90b8730a7c7fc75cb0bc0cf5bd793ed9d719516a647232799bb98fd675b1ea3.jpg)  

Improving the computational efficiency of PFM simulations is a foundational requirement for tackling realistic engineering and materials science problems [11]. Effective code development that ensures a clear correspondence between mathematical models and numerical implementation is crucial [10]. Standard techniques for performance enhancement include adaptive mesh refinement, which dynamically adjusts spatial discretization based on local field gradients; parallel computing, which distributes computational workloads across multiple processing units; and GPU acceleration, utilizing the parallel architecture of graphics processing units for speedup [11]. Parallel execution can be implemented through libraries such as OpenMP [24]. While these methods significantly reduce computation time, the considerable expense for extensive simulations motivates the exploration of further acceleration strategies [5].  

Beyond enhancing numerical solvers, the PFM framework can be significantly extended to incorporate the influence of multiple interacting physical phenomena [11,27]. This multi-physics capability is achieved by coupling the phase field variables with other relevant physical fields, including temperature, solute concentration, electrical potential, mechanical stress/strain, and fluid flow [14,24,27,28]. Coupling strategies typically involve integrating energy contributions from  

additional fields into the total free energy functional or explicitly linking the evolution equations governing the phase field and the coupled fields [14]. Examples include coupling PFM with diffusion or elasticity modules [24]. A detailed illustration of mechanical coupling involves incorporating elasticity by accounting for applied stress and dislocation stress fields within the elastic energy term. This often requires considering an inhomogeneous elastic stiffness tensor, potentially represented as a statistical average, and decomposing the intrinsic strain field,   
\​  

into contributions from various sources like vacancies, gas atoms, and dislocations [17]. Here, \(\epsilon_{ij}^{vac}\), \ (\epsilon_{ij}^{gas}\), and \(\epsilon_{ij}^{dis}\) represent the eigenstrains associated with vacancies, gas atoms, and dislocations, respectively. Such multi-physics coupling is essential for applications such as fluid-structure interaction, heat and mass transfer, ion transport, and flow-solid coupling in porous media [28].  

Multi-scale modeling represents another crucial direction, where PFM, combined with fields like temperature and solute, facilitates establishing connections between micro-scale phenomena and their macro-scale impact [27]. This coupling aids in bridging disparate length and time scales relevant to material behavior [2]. Hybrid approaches, integrating PFM with other simulation methodologies, such as coupling with elasticity or diffusion solvers, can enhance simulation accuracy and efficiency by leveraging the strengths of different techniques [2,24]. However, challenges remain in developing seamless multi-scale frameworks and ensuring accurate information transfer between different simulation methods and scales.​  

An increasingly prominent advanced technique is the integration of machine learning (ML) with PFM [11]. This interdisciplinary approach offers significant potential for parameter estimation, model calibration, microstructure prediction, and crucially, simulation acceleration [11]. The primary benefits expected from this integration include improved accuracy, reduced computational cost, and an enhanced ability to model complex material systems [11]. ML is particularly valuable for accelerating computationally demanding PFM simulations [5,16]. A key strategy involves developing ML-based surrogate models to mimic PFM behavior at lower computational cost [16]. This includes history-dependent ML approaches, such as utilizing Long Short-Term Memory (LSTM) networks, to learn and predict the time evolution based on a lowdimensional statistical representation of the microstructure [16]. Another innovative method involves reformulating the PFM problem as an unsupervised learning task on a graph structure, employing physics-embedded graph networks (PEGN) that minimize a physics-based loss function to efficiently solve for key fields [5]. This approach has demonstrated substantial speedups over traditional methods while maintaining accuracy [5]. The integration of ML with PFM resonates with the broader application of neural networks like CNNs, RNNs, and Physics-Informed Neural Networks (PINNs) in computational mechanics for tasks involving field prediction and solving partial differential equations [28]. Despite the significant opportunities, challenges such as data scarcity for training robust models and ensuring model generalization outside the training domain need to be addressed [16].  

The practical application and advancement of PFM are also heavily reliant on available software tools [18].  

<html><body><table><tr><td>Software Package</td><td>Primary Language</td><td>Base Library Type</td><td>Focus Areas (Mentioned)</td><td>Notes (Mentioned)</td></tr><tr><td>MOOSE</td><td>C++, Python</td><td>Finite Element</td><td>Various, built on FE libs like Libmesh</td><td>Developed by labs</td></tr><tr><td>PRISMS</td><td>Not specified</td><td>Not specified</td><td>Not specified</td><td>Mentioned in list</td></tr><tr><td>FEniCS</td><td>C++, Python</td><td>Custom FE (DOLFIN)</td><td>Various PDE problems, PFM</td><td>Own FE tools</td></tr><tr><td>MMSP</td><td>Not specified</td><td>Not specified</td><td>Microstructure science</td><td>Mentioned in list</td></tr><tr><td>Fipy</td><td>Python</td><td>Finite Volume</td><td>PDE solutions</td><td>Mentioned in list</td></tr><tr><td>Sfepy</td><td>Python</td><td>Finite Element</td><td>Various PDE problems</td><td>Mentioned in list</td></tr></table></body></html>  

<html><body><table><tr><td>OpenPhase</td><td>C++</td><td>Spectral (FFTW)</td><td>First-order</td><td>Modular,</td></tr><tr><td rowspan="3"></td><td></td><td></td><td>phase</td><td>examples,</td></tr><tr><td></td><td></td><td>transitions,</td><td>testing stages</td></tr><tr><td></td><td></td><td>coupling</td><td></td></tr></table></body></html>  

While commercial and in-house codes have been used, open-source software platforms offer distinct advantages, including enhanced transparency, improved reproducibility, facilitated collaboration, and greater accessibility, thereby addressing some limitations of proprietary solutions [1]. Several major open-source packages incorporate PFM capabilities, including MOOSE, PRISMS, FEniCS, MMSP, Fipy, and Sfepy [1]. These platforms are frequently built upon existing open-source finite element libraries and primarily developed in $\mathsf { C } { + } { + }$ or Python [1]. OpenPhase, an object-oriented $\mathsf { C } { + } { + }$ open-source project, is dedicated to simulating microstructure formation during first-order phase transitions, offering a modular architecture for extensibility and providing examples for various simulations, including those involving coupled diffusion or elasticity [12,24]. The availability of detailed examples within packages like OpenPhase is particularly beneficial for new users [12,24]. The development of these tools by research institutions underscores a focus on scientific accuracy and community support, which are critical for advancing the field [1]. Overall, open-source software plays a vital role in democratizing access to PFM capabilities and promoting collaborative research.​  

# 4.1 Computational Efficiency and Acceleration Techniques  

Improving the computational efficiency of phase field modeling (PFM) simulations is crucial for addressing the complex, large-scale problems often encountered in materials science and engineering [11]. Efficient code development, facilitating a clear connection between mathematical formulations and numerical implementation, is emphasized as a foundational aspect [10]. Beyond fundamental implementation considerations, several advanced computational techniques are commonly employed to accelerate PFM simulations. These include adaptive mesh refinement, which dynamically adjusts grid resolution based on local field gradients; parallel computing, which distributes the computational workload across multiple processors; and GPU acceleration, which leverages the highly parallel architecture of graphics processing units [11]. While these techniques enhance performance, the inherent complexity and computational cost of PFM, particularly for longtime simulations or large domains, motivate the exploration of alternative acceleration strategies [5].​  

Machine learning (ML) has emerged as a promising tool to address the computational expense of PFM [5]. A key approach involves the use of ML surrogate models to approximate the behavior of the phase-field system, thereby bypassing the need for computationally intensive numerical integration of the full PFM equations [16]. One such application focuses on predicting microstructure evolution, for example, during spinodal decomposition [16]. This involves generating large datasets from traditional phase-field simulations across a range of material parameters, such as phase fraction $\left( c _ { A } \right)$ and phase mobilities $( M _ { A } , M _ { B } )$ [16]. The microstructure evolution, represented by spatially dependent fields like $c ( \mathbf { x } , t _ { i } )$ , can be characterized by spatial statistics such as autocorrelations, ${ S _ { 2 } ^ { ( \mathrm { A } , \mathrm { A } ) } \left( \mathbf { r } , t _ { i } \right) }$ [16]. Principal component analysis (PCA) can then be applied to construct a low-dimensional representation of the time evolution of these statistics [16]. A Long ShortTerm Memory (LSTM) neural network can be trained on this data, using input parameters and a history of previous principal scores to predict future microstructure states [16]. This surrogate model demonstrated significant speedup, predicting a sequence of 10 frames (equivalent to 5,000,000 time steps in the original simulation) in 0.01 seconds, with an additional 0.05 seconds for microstructure reconstruction from the autocorrelation, compared to the original PFM simulation time [16].​  

Another innovative ML-based surrogate modeling approach utilizes physics-embedded graph networks (PEGN), specifically tailored for accelerating phase-field simulations in complex processes like additive manufacturing [5]. The PEGN algorithm is designed to efficiently solve for critical fields such as temperature, liquid/solid phase fraction, and grain orientation by minimizing a loss function that incorporates physical principles [5]. This method has been reported to achieve substantial performance gains, being at least 50 times faster than traditional direct numerical simulation (DNS) methods on both CPU and GPU platforms [5]. Crucially, the PEGN method is claimed to maintain high accuracy in capturing the essential physical features of the simulation, suggesting that ML surrogate models can offer significant computational advantages while preserving predictive capabilities [5]. While the LSTM approach focuses on learning the time evolution of reduced-order statistics, the PEGN approach aims to solve the physical fields directly on a graph representation, highlighting different strategies within ML acceleration for PFM. Comparing the predictive accuracy and computational cost, these studies demonstrate that ML surrogate models can provide considerable speedups over traditional PFM, albeit with accuracy dependent on the training data and model architecture [5,16].​  

# 4.2 Multi-Physics and Multi-Scale Modeling  

Phase field modeling (PFM) offers a robust framework that can be effectively extended to incorporate a variety of physical phenomena, thereby enabling the simulation of complex material behaviors driven by coupled processes [11,27]. This multiphysics capability is achieved by coupling the phase field variables with other relevant physical fields, such as temperature, solute concentration, electrical potential, mechanical stress/strain, and fluid flow [14,24,27,28].​  

Coupling strategies typically involve incorporating the energy contributions from the additional physical fields into the total free energy functional of the system, or by explicitly linking the evolution equations of the phase field and the coupled fields. For instance, interactions between electrical and mechanical fields can be coupled within the PFM framework [14]. PFM can also be coupled with diffusion and elasticity modules, as demonstrated by examples like DendrDiff and EshelbyTest [24]. The versatility extends to various essential applications including fluid-structure interaction, heat transfer, mass transfer, ion transfer, and flow-solid coupling in porous materials [28].  

A detailed example of mechanical coupling involves integrating elasticity into the PFM framework by considering applied stress and dislocation stress fields within the elastic energy term of the free energy functional [17]. In such models, the elastic stiffness tensor may be treated as inhomogeneous, often represented as a statistical average based on the composition or phases present, such as matrix and gas inclusions [17]:​  

$$
\lambda _ { i j k l } = \lambda _ { i j k l } ^ { 0 } ( 1 - c _ { v a c } ) + \lambda _ { i j k l } ^ { \prime } c _ { g a s }
$$  

Furthermore, the intrinsic strain field, \(\epsilon_{ij}^\*\), which drives elastic deformation in response to local structural changes or defects, can be decomposed into contributions from various sources, such as vacancies, gas atoms, and dislocations [17]:​  

$$
\epsilon _ { i j } ^ { * } = \epsilon _ { i j } ^ { v a c } + \epsilon _ { i j } ^ { g a s } + \epsilon _ { i j } ^ { d i s }
$$  

Here, \(\epsilon_{ij} $ { \Lambda } \{  { \mathsf { v a c } } \}  { \backslash }$ represents the eigenstrain associated with vacancies, \(\epsilon_{ij}^{gas}\) relates to gas atoms, and \(\epsilon_{ij}^{dis}\) accounts for the eigenstrain field induced by the spatial distribution of dislocations [17]. This explicit treatment of different strain sources exemplifies the power of PFM in incorporating complex mechanical interactions.  

Multi-scale modeling is another critical aspect where PFM plays a significant role. By combining PFM with temperature, solute, and other external fields, researchers can establish links between micro-scale phenomena and their macro-scale manifestations [27]. This coupling facilitates bridging different length and time scales relevant to materials science and engineering. Hybrid approaches, which combine PFM with other simulation methods (e.g., coupling PFM with elasticity or diffusion modules as seen in [24]), enhance simulation accuracy and efficiency by leveraging the strengths of different techniques. Developing effective multi-scale PFM frameworks presents challenges, particularly concerning the seamless coupling of disparate simulation methods and the accurate transfer of information across different scales and models. However, these challenges also represent opportunities for advancing computational materials science.  

# 4.3 Integration with Machine Learning  

An emerging trend in materials science and computational mechanics is the integration of machine learning (ML) techniques with the phase‐field method (PFM) [11]. This interdisciplinary approach offers promising avenues for enhancing various aspects of PFM simulations [11]. Machine learning can be effectively utilized for tasks such as parameter estimation and model calibration, which are often critical yet challenging steps in setting up accurate phase‐field models [11]. Furthermore, ML methods show significant potential in predicting complex microstructure evolution—a core application of PFM [11].  

The integration of ML with PFM is expected to yield several key benefits, including improved simulation accuracy, a substantial reduction in computational cost, and an enhanced capability to handle complex materials systems that might be intractable with traditional PFM approaches alone [11]. A major area of application lies in accelerating high‐fidelity phase‐ field simulations, which are typically computationally expensive, particularly for large domains or long simulation times [5,16]. Machine learning can serve as a powerful tool to address this computational burden [5].​  

One prominent strategy for acceleration is the development of ML‐based surrogate models [16]. These models aim to emulate the behavior of phase‐field simulations but at a significantly lower computational expense. For instance, a history‐dependent ML approach utilizing Long Short-Term Memory (LSTM) neural networks has been employed to learn and predict the time-dependent evolution embedded within a low-dimensional representation of the microstructure [16].  

This reframes the complex phase‐field dynamics as a multivariate time-series forecasting problem, predicting future time steps based on inputs such as phase fraction $\left( c _ { A } \right)$ and phase mobilities ( $M _ { A }$ ​ , $M _ { B }$ ​ ) [16].  

Another innovative approach involves reformulating the classical phase‐field problem as an unsupervised machine learning task [5]. Specifically, graph networks have been integrated with PFM, where the simulation is cast as a problem on a graph structure [5]. By minimizing a physics-based loss or energy function, the graph network can efficiently solve for key phase‐field variables, showcasing the potential of physics-embedded graph networks (PEGN) to speed up simulations [5]. This resonates with the broader application of various neural network architectures, including Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), and Physics-Informed Neural Networks (PINNs), in computational mechanics for tasks like flow field prediction, feature extraction, time-series forecasting, and reconstruction [28].  

Despite the significant opportunities, integrating ML with phase‐field simulations presents certain challenges. Data scarcity for training robust ML models, especially for complex or novel materials systems, can be a limiting factor [16]. Ensuring the generalization capability of trained models to conditions or material parameters outside the training set also remains a key challenge [16]. Nevertheless, the potential for improved efficiency and the ability to tackle previously intractable problems continue to drive research in this promising interdisciplinary field.​  

# 4.4 Open-Source Software  

The widespread application of Phase Field Modeling (PFM) has been significantly promoted by the development of various software packages, including both commercial and open-source options [18]. Historically, much PFM research relied on inhouse codes or commercial software, a practice that can impede broader adoption and introduce challenges related to data reproducibility [1]. In contrast, the utilization of open-source software offers substantial advantages, notably enhanced transparency, improved reproducibility, facilitated collaboration, and increased accessibility, directly addressing some of the limitations associated with proprietary or custom solutions [1].  

Several major open-source software packages have integrated PFM capabilities, including MOOSE, PRISMS, FEniCS, MMSP, Fipy, and Sfepy [1]. These platforms are predominantly developed by academic institutions or research bodies, such as national laboratories [1]. A significant portion of these packages are built upon existing open-source finite element libraries like Deal II, Libmesh, and Gmsh, while others, such as FEniCS which uses DOLFIN, rely on their own custom-developed opensource finite element tools [1]. The core programming languages for these packages are typically ${ \mathsf { C } } { + } { + }$ or Python, with FEniCS and MOOSE offering versions in both languages [1].​  

OpenPhase stands out as a specific open-source project implemented in object-oriented $\mathsf { C } { + } { + }$ , designed for phase field simulations focusing on microstructure formation during first-order phase transitions [12,24]. Its modular architecture supports extensibility, allowing for the incorporation of new physics and models [12]. The OpenPhase library provides a collection of examples that serve as valuable resources for new users and facilitate understanding of its capabilities [12,24]. These examples cover fundamental simulations like single grain evolution and normal grain growth, as well as more complex scenarios such as directional solidification coupled with diffusion (DendrDiff) or elasticity (EshelbyTest) [12]. Compiling OpenPhase notably requires the FFTW library for performing Fourier transforms [12,24].​  

Evaluating the ease of use and availability of resources for open-source PFM software, the provision of detailed examples, as seen in OpenPhase, is a key factor in assisting new users [12,24]. The development by research institutions also implies a focus on scientific accuracy and potentially community support, although ease of use can vary depending on documentation and user interface design, aspects not detailed in the digests [1].​  

The primary challenges discussed in the context of PFM software, according to the provided digests, revolve around the limitations of in-house and commercial solutions, particularly concerning data reproducibility and hindering widespread adoption [1]. Open-source software is presented as a means to overcome these specific challenges through its inherent transparency and collaborative nature [1]. While the digests highlight the benefits of open-source in mitigating these issues, they do not explicitly detail specific challenges associated with the useor developmentof open-source PFM software itself, such as potential complexities in installation, reliance on user community for support, or variability in documentation quality across different packages.​  

# 5. Applications of Phase Field Modeling  

<html><body><table><tr><td>Application Category</td><td>Key Phenomena/Processes</td><td>Material Examples</td></tr></table></body></html>  

<html><body><table><tr><td>General Microstructure Evolution</td><td>Grain Growth,Precipitation, Spinodal Decomposition, Crystal Growth, Recrystallization, Solid-state transformations</td><td>Metals, Alloys, High-Entropy Alloys</td></tr><tr><td>Solidification & Additive Mfg.</td><td>Alloy Solidification, Dendritic Growth, Melt Pool Dynamics</td><td>Metals, Alloys (e.g., 316L SS)</td></tr><tr><td>Phase Transformations</td><td>Liquid-Solid, Solid-Solid, Martensitic, Pearlite, Spinodal</td><td>Various materials,PCM (Al- Si)</td></tr><tr><td>Ferroelectric Materials</td><td>Domain Structures, Polarization Response, Size Effects</td><td>Ferroelectric crystals/films (KNN)</td></tr><tr><td>Nuclear Materials</td><td>Iradiation Effects,Fission Gas Bubbles, Pore Evolution</td><td>Nuclear Fuels (U3Si2)</td></tr><tr><td>Biological Systems</td><td>Liquid-Liquid Phase Separation (LLPS), Condensate Dynamics</td><td>Biological molecules/systems</td></tr><tr><td>Electrochemical Systems</td><td>Electrodeposition, Dendrite Growth, Intercalation, Cracks</td><td>Lithium-ion Batteries (Li- metal)</td></tr><tr><td>Alloy Design</td><td>Phase Transformations, Microstructure Evolution, Property Prediction</td><td>Alloys, High-Entropy Alloys</td></tr></table></body></html>  

Phase Field Modeling (PFM) has become an indispensable computational tool across numerous domains within materials science and engineering, enabling the simulation and understanding of complex microstructural evolution and material behavior under diverse conditions [6,9,11]. The versatility of PFM stems from its ability to capture interface dynamics without explicit tracking, making it suitable for modeling a wide range of phenomena and processes [11]. Applications can be broadly categorized by the material phenomena being modeled, the specific material processes, or the class of materials investigated.​  

A primary application area involves the simulation of general microstructure evolution in metals and alloys, encompassing processes such as grain growth, precipitation, spinodal decomposition, crystal growth, dynamic recrystallization, recovery, and various solid‐state phase transformations like austenite, ferrite, pearlite, bainite, and martensite [1,18,21]. PFM effectively represents these microstructures using continuous field variables, handling complexities like solute accumulation at grain boundaries and incorporating anisotropy in properties such as grain boundary energy and mobility [21,27]. For instance, simulations of normal grain growth demonstrate curvature-driven boundary migration [24]. In highentropy alloys, PFM has successfully simulated coherent nanoprecipitation (spherical/cuboidal) and spinodal decomposition, revealing the impact of lattice misfit and Young's modulus anisotropy on precipitate morphology and understanding coarsening behavior [21]. The consistency of these simulations with experimental observations underscores PFM's predictive capability in such complex systems [21].​  

Phase transformations, both liquid-solid and solid-solid, constitute a significant focus for PFM applications [13]. Liquid-solid transformations like alloy solidification and melting are frequently studied, with PFM enabling detailed simulation of nonequilibrium processes that result in intricate microstructures like dendrites [6]. PFM allows for the detailed simulation of dendrite morphology and solute segregation [13], including the analysis of dendrite arm spacing as a function of process parameters like solidification speed and cooling rate [18]. Applications extend to phase change materials for thermal energy storage, where PFM models incorporate heat transfer and material properties [25]. Solid-solid transformations modeled via PFM include first-order transitions like martensitic transformations, which are diffusionless and displacive, and PFM effectively captures their characteristic complex microstructures such as needle-like features [1,2]. Pearlite formation,  

resulting in lamellar ferrite-cementite structures, is another example where PFM simulations provide insight into microstructure evolution influencing mechanical properties [12]. Spinodal decomposition simulations detail the rapid initial formation of interconnected subdomains and subsequent coarsening [16]. These models are often rooted in microscopic theories, using order parameters to describe the system state and microstructure evolution [13].  

In the realm of materials processing, PFM is extensively applied to solidification processes and increasingly in additive manufacturing (AM) [9,18]. For solidification, PFM simulates dendritic growth in directional solidification, accounting for temperature gradients and interface heat flow [9,12,24]. For AM, PFM is suitable for simulating complex phenomena such as material deposition, melt pool dynamics (formation and solidification), and dendrite growth within the pool [9]. Examples include simulating powder bed fusion of 316L stainless steel to predict microstructure evolution [5]. By modeling morphology and melt pool behavior, PFM simulations offer valuable insights for optimizing AM processing parameters and improving manufacturing quality [5,9,18].  

PFM is also a critical tool for investigating specific material classes and phenomena. For ferroelectric materials, PFM models complex domain structures and their response to external fields [1,7]. The approach is based on a total free energy functional incorporating bulk, gradient, elastic, and electrostatic energy terms, with polarization as the order parameter evolving via the time-dependent Ginzburg-Landau equation [7,14]. PFM allows for quantitative analysis of domain patterns, interpretation of experimental observations, and guidance for experiments to discover new mesoscale domain states or enhance properties [7]. It is particularly valuable for studying size effects in thin films, revealing how domain structures influence dielectric and piezoelectric responses (e.g., in KNN thin films) and distinguishing intrinsic vs. extrinsic contributions to material properties [8,14].  

In nuclear materials research, PFM is applied to study irradiation effects, such as the evolution of fission gas bubbles and pores [17,19]. Simulations investigate phenomena like Xe bubble nucleation, growth, and coarsening in U3Si2 fuel under varying fission rates, applied stress, and dislocation fields, showing how these factors influence bubble morphology, size, and distribution [17]. Studies on pore evolution similarly link pore characteristics (radius, size distribution, number, concentration, porosity, swelling rate) to fission density [19]. For example, pore concentration initially increases rapidly with fission density before stabilizing, while porosity and swelling rate are positively correlated [19]. These studies highlight PFM's capability to capture irradiation-induced microstructural changes, though further development is needed to fully capture the complexities across different materials and conditions [17].​  

PFM also plays a role in electrochemical systems, notably in lithium-ion battery research [4,20]. It is crucial for modeling processes like electrodeposition, which is essential for understanding dendrite growth in Li-metal batteries [1]. PFM models incorporate factors such as diffusion kinetics, interfacial anisotropy, electric fields, stress fields, and lattice mismatch to simulate different dendrite patterns (needle-like, tooth-like, tree-like) observed experimentally [18]. Insights from PFM simulations inform the optimization of processing parameters, such as those in molten salt electroplating, to control dendrite morphology and mitigate failure risks [18]. PFM's applicability extends to other battery phenomena including intercalation and crack propagation [1], and it is often integrated within multi-scale computational frameworks [20].​  

Beyond traditional materials science, PFM finds application in biological systems, particularly for studying liquid-liquid phase separation (LLPS) [3]. As a field-based theory, PFM is advantageous for examining biological systems over larger time and length scales and can incorporate non-equilibrium factors like chemical reactions [3]. Coarse-grained PFM simulations for LLPS involve model development based on key molecular interactions that drive phase separation, leading to insights into density profiles, dynamic properties, condensate formation kinetics, and stability [3]. These simulations contribute to generating phase diagrams that predict LLPS conditions [3].  

Finally, PFM is a powerful tool for alloy design, enabling researchers to explore composition spaces and processing routes computationally [18]. By combining PFM with other computational techniques, it is used to predict and control material properties through optimization of alloy composition and processing parameters [18]. This includes predicting phase transformations, understanding microstructural evolution during heat treatments, and evaluating the influence of alloying elements [9]. PFM assists in designing coherent microstructures in complex systems like high-entropy alloys and guiding compositional design [21]. Its application to processing techniques like directional solidification and AM further highlights its role in alloy fabrication design [9,18]. Principles derived from PFM, such as understanding the effects of doping or strain, can also guide the design of materials near critical phase boundaries to enhance properties, illustrating its broader applicability in material design beyond metallic alloys [8]. The integrated use of PFM offers significant potential for discovering novel phenomena and developing new high-performance alloys [18].​  

In summary, PFM has demonstrated remarkable success in modeling and simulating a vast array of phenomena and processes across diverse material systems. Its ability to capture complex microstructural features, predict material behavior under various conditions, and provide insights that complement experimental observations makes it an invaluable tool for fundamental research and practical material design and optimization [6,18]. While challenges remain, particularly in coupling multiple complex physics and computational efficiency for large-scale or long-time simulations, ongoing developments continue to expand the scope and impact of PFM in materials science.​  

# 5.1 General Microstructure Evolution  

Phase Field Modeling (PFM) is a powerful computational technique widely applied to simulate the complex microstructural evolution in materials, particularly metals and alloys [18,21]. PFM is capable of handling a diverse range of phenomena including grain growth, precipitation, spinodal decomposition, crystal growth, dynamic recrystallization and recovery, as well as various phase transformations such as austenite, ferrite, pearlite, bainite, and martensite [1,18]. The method allows for the simulation of intricate features like the needle-like structures characteristic of martensitic transformations [2].  

Modeling these phenomena within the PFM framework involves representing the microstructure using continuous field variables that distinguish different phases, grains, or other microstructural features [21]. PFM effectively handles complexities such as solute accumulation and the precipitation of second phases, particularly at grain boundaries [27]. A key advantage is its capacity to conveniently incorporate anisotropy, such as that of grain boundary energy and mobility, while largely avoiding complications related to lattice anisotropy [27]. For processes like normal grain growth, PFM simulations capture the curvature-driven migration of grain boundaries, demonstrating how larger grains expand at the expense of smaller ones, often at multi-grain junctions [24].  

Applications of PFM in simulating microstructure evolution span numerous areas. In high entropy alloys, PFM has been employed to simulate coherent microstructural evolutions, including spherical/cuboidal nanoprecipitation and weave-like spinodal decomposition [21]. These simulations provide valuable insights into how factors such as lattice misfit and the anisotropy difference in Young's moduli between the precipitated phase and matrix affect precipitate morphology, noting the particular susceptibility of cuboidal nanoprecipitation to modulus anisotropy [21]. Furthermore, PFM simulations aid in understanding the coarsening behavior of precipitates [21]. The consistency observed between simulations of precipitation and spinodal decomposition in HEAs and experimental results highlights the predictive capability of PFM in these contexts [21].​  

Beyond traditional metallic microstructures, PFM is applied to study phenomena like the evolution of intragranular bubbles and pores in nuclear fuels under irradiation [17,19]. Simulations investigating the evolution of Xe bubbles in U3Si2 fuel explore the impact of fission rates, applied stress, and dislocation stress fields on bubble morphology, size, number, and volume fraction [17]. Studies on pore evolution in U3Si2 fuel similarly link fission density $\left( F _ { D } \right)$ to pore characteristics, revealing relationships such as the average pore radius $\langle R \rangle$ following a power law with fission density, specifically $\langle R \rangle \propto F _ { D } ^ { z }$ ​ with $z = 0 . 4 5$ [19]. PFM is also used to explore microstructure-property relationships, such as examining the evolution of superdomain structures in ferroelectric thin films and how different domain configurations influence dielectric and piezoelectric responses [8].​  

Overall, PFM plays a crucial role in understanding the underlying mechanisms driving microstructure formation and evolution across a wide range of materials and conditions [18]. By providing a framework to model complex interfacial dynamics and bulk thermodynamics, PFM simulations offer insights that complement experimental observations and contribute to designing materials with tailored microstructures and properties [18].  

# 5.2 Solidification and Additive Manufacturing  

The phase-field method (PFM) serves as a powerful computational tool for investigating complex phase transformations inherent in materials science and engineering, particularly in the context of solidification processes and grain growth [6,25]. Solidification represents a non-equilibrium transformation resulting in intricate microstructures, such as those observed in casting [6]. PFM enables the study of solidification in various geometries, including semi-infinite regions and twodimensional cavities, accounting for factors like natural convection or the influence of pore morphology in phase change materials [25]. The model effectively simulates the growth and arrangement behavior of grains during alloy directional solidification [9].​  

A significant application of PFM in solidification is the simulation of dendritic growth and solute microsegregation, phenomena crucial for understanding processes like metal casting [12,13,24]. During solidification, solid crystals often exhibit "tree-like" dendritic structures, especially under typical alloy solidification conditions [12,24]. PFM, building on models like Langer's [13], allows for the detailed simulation of dendrite morphology and the distribution of solute elements [13]. Studies have utilized PFM to analyze dendrite arm spacing in as-cast alloys and establish its relationship with critical process parameters including solidification speed, cooling rate, temperature gradient, and local solidification time [18]. Examples of PFM application include the simulation of directional solidification of single crystals using platforms like OpenPhase, employing coupled phase-field and diffusion modules (e.g., DendrDiff) to study phase-field evolution and diffusion processes, with simulation convergence validated against benchmarks like the AlCu system [12,24]. Karma's quantitative model is also noted for its use in studying alloy solidification [9].  

Beyond traditional casting, PFM is increasingly applied to additive manufacturing (AM) processes [9]. The method is suitable for simulating complex phenomena in AM, such as material deposition, molten pool formation and solidification, and dendrite growth within the melt pool [9]. For instance, PFM has been used to simulate powder melting, rapid solidification, and grain structure evolution in metal AM, focusing on processes like powder bed fusion of materials such as 316L stainless steel, sometimes employing accelerated methods like PEGN [5]. By simulating the morphological evolution of materials and the behavior of molten pools during printing, PFM provides valuable insights for optimizing AM processes [9]. Specifically, phase-field models can be used to predict microstructure evolution under different processing conditions, thereby aiding in the optimization of printing parameters to improve manufacturing quality [5,9]. Furthermore, PFM can be integrated with macro-scale casting or AM software to facilitate the integrated design of materials from microstructure to final performance [18].​  

# 5.3 Phase Transformations  

Phase field modeling (PFM) is a powerful computational tool widely applied to simulate various phase transformations in materials science. These transformations can be broadly categorized into liquid–solid and solid–solid transitions [13]. PFM provides a framework to simulate the dynamics of these transitions and the evolution of complex microstructures.​  

A significant focus within PFM is the simulation of first-order phase transformations [24]. These transformations involve a discontinuous change in properties (such as density, structure, or energy) and are often characterized by the nucleation and growth of new phases. In the context of phase field simulation, understanding concepts like chemical potential is crucial for modeling the driving forces and equilibrium conditions of these transformations.  

Liquid–solid phase transformations are frequently studied using PFM, including phenomena such as alloy solidification. PFM is also applied to simulate phase transformations in materials for thermal energy storage (TES) applications [25]. For instance, the melting and solidification behavior of high-temperature phase change materials like aluminum–silicon alloys have been investigated [25]. In these simulations, PFM models incorporate heat transfer and material thermal properties, and results are often compared with experimental observations to validate the models [25].  

Solid–solid phase transformations represent another major area of PFM application [13]. This category includes diverse phenomena such as martensitic transformations, pearlite formation, and spinodal decomposition. Martensitic transformations, a type of diffusionless and displacive solid-state transformation, are first-order in nature [2]. PFM is particularly effective in capturing the complex microstructures that emerge during martensitic transformations [1,2]. PFM models for martensitic transformations aim to represent their characteristic diffusionless, displacive, and first-order behaviors [2].​  

Pearlite formation, involving the transformation of austenite into a lamellar structure of ferrite and cementite, can also be modeled using PFM [12]. The simulation focuses on the formation and evolution of this layered microstructure, where finer lamellar spacing is known to influence mechanical properties such as hardness [12].  

Spinodal decomposition is another specific type of phase transformation where PFM has been applied [16]. Simulations of spinodal decomposition reveal the rapid initial formation of interconnected subdomains, followed by a slower process of coarsening through coalescence and evolution of the microstructure [16].  

Phase field models for solid–state transitions were notably established based on microscopic theories, utilizing phase field variables such as local composition fields and long-range order parameters to describe the state of the system and the evolution of the microstructure [13]. This approach allows for a detailed investigation of the dynamics driving phase transformations and the resulting material microstructures.​  

# 5.4 Ferroelectric Materials  

Phase field modeling (PFM) has emerged as a powerful computational tool for investigating the complex domain structures characteristic of ferroelectric materials and their response to external stimuli. The application of PFM is crucial for understanding the behavior of these materials, ranging from bulk crystals to thin films [1,7].​  

A fundamental aspect of this approach involves the thermodynamics of ferroelectric crystals containing intricate domain structures. PFM provides a framework to analyze these inhomogeneous systems by considering the total free energy functional of the system, which typically includes bulk free energy, gradient energy, elastic energy, and electrostatic energy terms [7,14]. The evolution of the polarization field, which acts as the order parameter, is governed by the time-dependent Ginzburg-Landau equation, derived from minimizing this free energy functional. The theoretical framework for PFM of ferroelectrics involves defining this free energy density functional and identifying its material-specific parameters. This parameter identification can be approached using various methods, often involving fitting to experimental data or ab initio calculations [14]. Numerical implementation, frequently employing the finite element method, is essential for solving the resulting partial differential equations, requiring careful treatment of electrical and mechanical boundary conditions which significantly influence domain configurations [14].​  

A core application of PFM is the detailed study of ferroelectric domain structures and their dynamic responses to applied mechanical and electric fields [1,7]. Beyond merely visualizing domain configurations, PFM enables quantitative analysis of these structures. This capability is vital for interpreting experimental observations of domain patterns and dynamics, as well as for guiding future experimental work by predicting material behavior under specific conditions [7].​  

PFM allows for the differentiation between intrinsic and extrinsic contributions to the small signal properties of ferroelectric materials [14]. Intrinsic contributions arise from the material's lattice response, while extrinsic contributions stem from domain wall motion. Understanding these separate effects is critical for optimizing material performance in devices.  

Furthermore, PFM is particularly valuable for investigating size effects in ferroelectric thin films, where domain structure can significantly impact macroscopic properties [8]. For instance, studies on KNN thin films have employed PFM to analyze the relationship between domain size and both dielectric and piezoelectric responses [8]. Simulations reveal that local piezoelectric and dielectric responses within such films are often non-uniform and depend considerably on the film thickness [8]. Specifically, analysis of superdomains indicates that the domain size effect is primarily determined by changes in the out-of-plane polarization component of certain domain variants [8]. Such detailed insights into the localized behavior and its dependence on nanoscale features are challenging to obtain solely through experimental methods and highlight the predictive power of PFM in materials design and characterization.​  

# 5.5 Nuclear Materials and Irradiation Effects  

The phase‐field method has been extensively applied to study the effects of irradiation on the evolution of microstructures in nuclear materials, with a particular focus on phenomena such as fission gas bubble evolution, swelling, and radiation damage [17]. These models provide a mesoscale approach to understanding the complex interplay between irradiation‐ induced defects and microstructural changes.​  

Phase‐field models have been utilized to investigate the nucleation and growth of irradiation‐induced intragranular Xenon (Xe) bubbles in $U _ { 3 } S i _ { 2 }$ fuel under varying conditions, including different fission rates, applied stress, and dislocation stress fields [17]. Simulations conducted at a temperature of $1 2 0 0 \mathsf { K }$ using fission rates ranging from  

$1 . 2 6 \times 1 0 ^ { 1 3 }$ to $7 . 2 6 \times 1 0 ^ { 1 3 } \mathrm { c m } ^ { - 3 } \mathrm { s } ^ { - 1 }$  

demonstrated that increasing the fission rate advances the bubble incubation period and leads to an increase in both the final number and average radius of the bubbles [17]. Applied stress was found to induce bubble nucleation, accelerate bubble growth and coarsening processes, and promote directional bubble growth along the load direction, resulting in the formation of elongated bubble arrangements [17]. Furthermore, the presence of dislocation stress fields was shown to cause bubbles to nucleate preferentially at sites of stress concentration, with subsequent coarsening influenced by the overlapped stress fields of dislocation pairs [17].​  

Beyond fission gas bubble–specific studies, phase‐field modeling has also been applied to analyze pore evolution in $U _ { 3 } S i _ { 2 }$ nuclear fuel under irradiation, investigating the impact of fission density [19]. This research established specific relationships between fission density and key pore characteristics, including average radius, size distribution, number, concentration, porosity, and swelling rate [19]. It was observed that the number of vacancies, porosity, and swelling rate are positively correlated with the fission density [19]. The pore concentration initially increased rapidly with increasing fission density, subsequently decreasing slowly towards a stable value. For instance, at a fission density of  

$$
1 4 \times 1 0 ^ { 2 0 } \mathrm { c m } ^ { - 3 } ,
$$  

the pore concentration reached approximately  

$1 . 6 \times 1 0 ^ { 1 6 } \mathrm { c m } ^ { - 3 }$ [19].​  

Collectively, these phase‐field studies highlight the method’s capability to capture the microstructural evolution in nuclear fuels under irradiation, revealing the intricate dependencies of bubble and pore behavior on factors such as fission rate, applied stress, dislocation fields, and fission density [17,19]. While these models provide valuable insights into phenomena like fission gas bubble evolution, swelling, and overall radiation damage [17], further development is needed to fully capture the complexities of irradiation effects across different materials and conditions.  

# 5.6 Biological Systems (LLPS)  

The study of liquid-liquid phase separation (LLPS), particularly in biological contexts, frequently employs computational approaches, including both particle‐based and field‐based simulations [3]. Phase field modeling (PFM), as a prominent field‐based theory, offers valuable insights into the complex mechanisms governing LLPS phenomena [3]. These field‐ based approaches are particularly advantageous when examining systems across larger time and length scales, and they can effectively incorporate non‐equilibrium factors, such as chemical reactions, which are pertinent in biological environments [3].​  

Applying PFM to biological LLPS involves coarse‐grained simulation procedures. This process necessitates careful model development to represent the system’s components and their interactions at a relevant level of detail [3]. Identifying key interactions, which dictate the thermodynamic driving forces for phase separation, is a crucial step in constructing these models [3]. Parameters within these models, while not explicitly listed in detail in the source material, are fundamentally related to these identified interactions and the concentrations of the participating species, ultimately influencing the system’s phase behavior and captured within outputs like phase diagrams [3].​  

Through the application of these field‐based theories, researchers can gain significant insights into the system’s density profile and dynamic properties [3]. Understanding the evolution of density profiles is critical for characterizing the structure and composition of the formed condensates, while analyzing dynamic properties provides information on the kinetics of phase separation and the internal dynamics within condensates [3]. These insights contribute directly to elucidating the fundamental mechanisms driving LLPS, including the processes of condensate formation and their subsequent stability [3]. The generation of phase diagrams through these simulation procedures further aids in predicting the conditions under which LLPS occurs, providing a thermodynamic map of the system’s behavior as a function of relevant parameters [3].  

# 5.7 Electrochemical Systems (Lithium-ion Batteries)  

Multi-scale computational methods play a crucial role in supplementing experimental efforts in lithium-ion battery research and development [20]. These techniques are applied to address challenges spanning material design, performance prediction, and issues pertinent to various battery components [20]. Integrating computational techniques across disparate scales is essential for gaining a comprehensive understanding of complex battery phenomena [20]. For instance, the computational design of advanced batteries featuring Li-metal or Si anodes necessitates a unified perspective derived from methods covering multiple scales, such as Density Functional Theory (DFT) and Molecular Dynamics (MD) for solidelectrolyte interphase (SEI) formation mechanisms, MD and Monte Carlo (MC) for solvation and transport phenomena, and Phase Field Simulations (PFS) for processes like electrodeposition, intercalation, and crack propagation [1].  

The Phase Field Method (PFM) holds significant importance in the realm of electrochemical energy storage applications [4]. PFS, in particular, is critical for modeling electrodeposition processes, which is vital for comprehending dendrite growth in lithium metal batteries [1]. Researchers have leveraged PFM by incorporating factors such as diffusion kinetics, interfacial anisotropy, electric field, stress field, and lattice mismatch between the deposit and substrate [18]. This comprehensive approach facilitates the revelation of solidification mechanisms that dictate the formation of different dendrite patterns observed experimentally, including needle-like, tooth-like, and tree-like structures [18]. Furthermore, insights derived from PFM simulations can directly inform the design of processing parameters, such as those used in molten salt electroplating, to tailor dendrite patterns and minimize failures caused by uncontrolled dendrite growth [18]. This demonstrates how PFM serves not only as an analytical tool but also as a predictive platform guiding experimental design and optimization in  

electrochemical systems. Beyond dendrite formation, PFM is also applicable to other critical phenomena in batteries, including intercalation and crack propagation [1].  

# 5.8 Alloy Design  

Phase field modeling (PFM) has emerged as a powerful computational tool for the design and optimization of alloys, enabling researchers to explore composition spaces and processing routes more efficiently than solely experimental methods [18]. A key strategy involves combining PFM with other computational techniques to predict and control material properties by optimizing alloy composition and processing parameters [18]. PFM applications in alloy design span various aspects of material behavior and processing. Specifically, the method is utilized to predict critical phenomena such as phase transformations, understand the evolution of microstructures during thermal processes like heat treatment, and evaluate the influence of different alloying elements on these behaviors [9]. For instance, PFM simulations can assist in understanding and designing coherent microstructures in complex systems like high-entropy alloys, providing a technique to predict their microstructural evolution and guide compositional design [21]. Furthermore, PFM is applied to model and optimize specific processing techniques critical for alloy fabrication. Directional solidification, an important material preparation technique, relies on controlling temperature gradients and interface heat flow to achieve desired ordered grain structures—processes that can be effectively simulated and understood through PFM [9]. PFM is also relevant for understanding microstructural evolution in additive manufacturing [18]. Beyond traditional metallic systems, PFM principles —such as assessing the effects of chemical doping and strain engineering—can be extended to guide the design of materials near critical phase boundaries to enhance specific properties like the domain size effect relevant for dielectric and piezoelectric responses, illustrating the method's broader applicability in material design [8]. The effectiveness of PFMguided alloy design is evidenced by its potential to contribute to the achievement of high-performance alloys across various processing routes, including solidification, precipitation, deformation, and additive manufacturing [18]. Ultimately, the integrated use of PFM holds significant potential for the discovery of novel phenomena and the development of new highperformance alloys [18].​  

# 6. Challenges and Future Directions  

![](images/0411fcb088087b016096bdeb8afef9ba46b673e27e862f4331bae159c78828cb.jpg)  

Despite significant advancements, Phase Field Modeling (PFM) continues to face considerable challenges and limitations that hinder its broader application and quantitative predictive power. A primary challenge resides in the accurate parameterization of PFM models, which fundamentally relies on reliable thermodynamic and kinetic data [4,6,11]. Obtaining precise data, especially for complex multi-component systems or under extreme conditions, remains difficult and introduces significant uncertainty [11]. While methods such as leveraging thermodynamic databases, experimental measurements, and ab initio calculations are employed for parameter determination, each presents limitations, including data uncertainty, experimental errors, and the high computational cost of ab initio methods for large systems [11]. The process of validating simulations against experimental data is crucial [6,11,18], but achieving quantitative agreement can be challenging due to inherent model approximations and numerical issues [6].​  

Computational cost represents another significant barrier, particularly for high-resolution and large-scale simulations, often restricting the simulation domain size to tens of micrometers and limiting the ability to simulate processes over real-time scales [4,6,27]. The stiffness of phase-field equations, especially near mesoscopic interfaces, necessitates very small time steps, contributing to this computational expense [6].  

Furthermore, addressing inherent model limitations is critical. This includes tackling mathematical and physical inconsistencies that arise when extending models from simpler two-phase systems to more complex multi-phase scenarios [4,6]. Accurately representing complex physical phenomena, such as intricate microstructural evolution, defect dynamics, or domain size effects in specific materials, remains challenging, and generalized models often struggle to capture the full complexity [8,16,17]. Theoretical challenges, such as those associated with time-fractional phase-field equations, also require further development [15]. The reliance on manually writing code for simulations, coupled with the interdisciplinary requirement for researchers to possess backgrounds in materials science, mathematics, and computer programming, significantly hinders the accessibility and widespread application of PFM [11,13]. The lack of mature, user-friendly commercial software further exacerbates this accessibility issue [4,11,13].  

Looking ahead, several promising avenues are being explored to overcome these challenges and expand the capabilities of PFM. One significant direction involves the integration of machine learning (ML) techniques [18,28]. ML can potentially address limitations in computational cost and model complexity, for instance, by aiding in dimensionality reduction, accelerating simulations, or assisting in parameter determination [16]. Developing more robust and efficient numerical algorithms is crucial for tackling the computational expense and stiffness of the equations, enabling simulations of larger scales and longer times [4,6]. Future research is also directed towards establishing multi-scale simulation frameworks that integrate PFM with other simulation methods to capture phenomena across different length and time scales [1,6,18]. Expanding the application of PFM to new materials and phenomena, such as complex phase transformations, additive manufacturing processes, or energy materials, represents another vital area of growth [1,6,18]. Furthermore, the development of user-friendly software, both commercial and open-source, is essential to lower the barrier to entry and promote the wider adoption and collaborative advancement of PFM [1,4,11,13]. Building sustainable open-source communities is recognized as key for the long-term prosperity of the field [1].  

# 6.1 Parameterization and Validation  

Accurate parameterization is fundamental to obtaining reliable results from phase‐field modeling (PFM), as the parameters govern the free energy density and transport properties that dictate microstructure evolution and material behavior [14]. The determination of these parameters often relies on a combination of approaches, including leveraging thermodynamic databases, conducting experimental measurements, and employing ab initio calculations [11]. Thermodynamic databases, such as CALPHAD, provide equilibrium phase diagrams and thermodynamic properties that can be directly incorporated or used to derive model parameters. Experimental measurements offer crucial data on material properties, kinetics, and microstructures under specific conditions, which can be used to fit or inform parameter values. Ab initio calculations, derived from first principles quantum mechanics, can provide parameters that are difficult to obtain experimentally, such as interfacial energies or elastic constants for hypothetical or complex phases [11].  

A typical set of parameters used in PFM can encompass a wide range of physical quantities, including free energy coefficients $( f _ { g a s } ^ { * } , f _ { v a c } ^ { * } , f _ { b i n d } ^ { * } )$ , gradient energy coefficients $( \kappa _ { g a s } ^ { * } \mathrm { ~ , ~ } \kappa _ { v a c } ^ { * } \mathrm { ~ ) ~ }$ , mobilities ( $\boldsymbol { M } _ { g a s } ^ { * }$ ​ , $M _ { v a c } ^ { * }$ ), length scales $( a _ { 0 } \mathrm { ~ , ~ } b$ , ​ $d , \xi _ { g } , \xi _ { v } )$ , elastic constants $( C _ { 4 4 } , \nu )$ , and other process‐dependent rates $( \dot { f } ^ { * } )$ [17].  

Despite the availability of these methods, parameterization presents significant challenges. A primary difficulty is the inherent uncertainty in thermodynamic data, particularly for complex multi‐component systems or for conditions at the limits of current understanding [11]. Experimental data can also be influenced by measurement errors and variations in sample preparation. Furthermore, while ab initio calculations provide fundamental insights, they can be computationally expensive—especially for large systems or complex material compositions—limiting their direct application for all required parameters [11]. These challenges necessitate careful consideration and often require iterative refinement of the parameters.  

Validation is a critical step to ensure that PFM simulations accurately reflect real-world phenomena. This is typically achieved by comparing simulation results against experimental data [11,18]. Cross-validation involves comparing predicted microstructures, kinetics, or properties with those observed experimentally [18]. For instance, topological phase inversion observed in Ni-based superalloys after aging experiments was validated through corresponding PF simulations, which attributed the inversion to lattice misfit driven by precipitate evolution [18]. Another example is the simulation of typical BCC/B2 coherent microstructures in Al–Ni–Co–Fe–Cr high-entropy alloys, where simulated spherical, cubic, and woven nanoprecipitate morphologies were compared against experimental observations. Such comparisons allowed the derivation and validation of a specific criterion for cubic precipitate formation based on elastic mismatch, namely,  

[18]. Validation can also involve quantitative comparisons using metrics such as absolute relative error (ARE) and normalized distance (D) when comparing simulation outputs—for example, between high-fidelity PFM and surrogate models [16]. Through rigorous validation, researchers can assess the predictive capability of the PFM model and refine its parameters and underlying physical descriptions.​  

# 6.2 Addressing Model Limitations  

Despite its widespread success in simulating material evolution across various fields, phase‐field modeling still encounters significant challenges and limitations [4,6]. A primary challenge lies in extending phase‐field models from simpler two‐ phase systems to more complex multi‐phase scenarios, where current formulations can suffer from mathematical inconsistencies or physically unrealistic descriptions [4].​  

Furthermore, accurately representing complex physical phenomena remains a considerable hurdle. While the phase‐field method provides a powerful framework, capturing the full complexity of systems often requires models tailored to specific materials or configurations [8]. Limitations exist in developing generalized models that can universally describe complex microstructural evolution, defect dynamics, or specific material behaviors—such as those relevant to directional solidification or additive manufacturing [8,17]. For instance, existing models may struggle with low‐dimensional representations that fail to fully capture the intricate nonlinearities and non‐convexities present in the free energy landscapes governing microstructure evolution [16]. Similarly, simplifying assumptions regarding defect interactions or reducing dimensionality (e.g., using 2D models for inherently 3D processes like bubble evolution) can limit the quantitative accuracy and predictive power of the simulations [17].​  

A related critical limitation is the difficulty in achieving quantitative agreement between phase‐field simulations and experimental results using traditional methods [6]. This discrepancy can stem from various factors, including the inherent stiffness of the phase‐field equations—particularly near mesoscopic interfaces—which often necessitates extremely small numerical time steps [6]. Such computational constraints severely hinder the ability to perform real‐time scale simulations [6]. Achieving quantitative accuracy is also contingent upon the availability and incorporation of accurate material properties and thermodynamic data, which are crucial inputs for phase‐field models. Challenges are additionally recognized in specific mathematical formulations, such as those involving time‐fractional derivatives, where further theoretical and numerical development is needed [15]. Addressing these limitations—potentially through the integration of advanced techniques like deep learning with traditional methods—is seen as a pathway toward more accurate and efficient simulations [28].​  

# 6.3 Software Development and Accessibility  

The development of accessible and user-friendly software is pivotal for promoting the widespread adoption of Phase Field Modeling (PFM) in research and industrial applications. While the potential for commercial software to increase accessibility exists [4,13], the focus is increasingly shifting towards open-source initiatives to foster collaborative development and broader user bases. Open-sourcing PFM simulation tools is recognized as a crucial step towards establishing comprehensive open-source multiscale simulation frameworks [1].  

Open-source PFM projects offer significant advantages, particularly in enabling scientists to rapidly develop simulation programs tailored for diverse problems, such as those involving first-order phase transitions and structural transformations [24]. This rapid development capability is a key benefit for researchers, allowing for flexible adaptation and extension of existing codes.​  

However, open-source initiatives also face considerable challenges. As an example, the OpenPhase project, while promising for enabling rapid development [24], is noted to be in its early testing stages [12,24]. Currently, only thoroughly tested modules are available for download [12]. This limited availability and developmental phase represent typical challenges for open-source projects, including potential issues with code maturity, comprehensive documentation, user support, and the breadth of implemented physical models or numerical methods compared to mature commercial alternatives. Addressing these challenges, such as through community building, rigorous testing, continuous documentation efforts, and structured development roadmaps, is essential for the broader adoption and sustainability of open-source PFM tools [1].  

# 7. Conclusion  

Phase-field modeling (PFM) has rapidly emerged as a prominent and successful numerical tool for simulating microstructure evolution in materials science and engineering [12,27]. A primary strength of PFM lies in its capability to simulate complex microstructures during various phase transformations, such as solidification, precipitation [6], and martensitic transformations [2]. It excels in quantitatively describing the evolution of phase interfaces [9], including detailed features like 3D dendritic growth even with limited computational resources [12]. PFM has proven valuable in revealing the microscopic mechanisms of material phase transformation, thereby facilitating the optimization of preparation processes and improvement of material properties [9]. Its application spans diverse material systems, including high-entropy alloys for composition design [21], U3Si2 nuclear fuel for studying stress and fission rate effects on pore evolution [17,19], and ferroelectric materials for understanding domain structures and properties [7,8,14]. Despite its successes, PFM faces inherent limitations, notably the challenge of stiff equations and restrictions on accessible time scales [6]. Early models also exhibited a dependence on interface width [12], and theoretical challenges persist, particularly concerning complex formulations like time-fractional phase-field equations [15].  

Significant advancements have been made to mitigate these limitations and broaden the applicability of PFM [6]. Ongoing research focuses on developing alternative numerical methods like front-end tracking and adaptive finite elements to improve accuracy and convergence [12], alongside theoretical progress [15]. A critical area of advancement concerns computational efficiency and acceleration techniques, which are vital for tackling the computational cost associated with complex, large-scale simulations [16]. The integration of machine learning (ML) with PFM has emerged as a powerful strategy to address this challenge [20,28]. For instance, ML-accelerated frameworks can integrate low-dimensional microstructure descriptions with history-dependent ML models to predict evolution robustly and quickly [16]. Machinelearned surrogate models can accelerate high-fidelity PFM simulations by enabling "time jumping" with minimal accuracy loss [16]. Specific applications like the PEGN framework for metal additive manufacturing (AM) simulations demonstrate significant speed improvements while maintaining accuracy by leveraging graph representations and ML integration [5].  

The continued success and impact of PFM hinge on rigorous validation with experimental data and seamless integration with other modeling approaches [16]. Integrating PFM with advanced atomic-scale experimental observations and various computational and intelligent approaches is crucial for designing materials and processes more accurately and widely [18]. A multi-scale computation strategy, integrating techniques from atomic to mesoscale and continuum scales into predictive tools, is necessary for solving complex problems across different material hierarchies, such as those in lithium-ion batteries [20]. Coupling mesoscale PFM simulations with macro casting software, for example, can enable integrated design approaches from microstructure to overall material performance [18]. Open-source PFM software packages, such as OpenPhase, provide modular platforms and examples that benefit researchers, although their overall usage still lags behind the rapid development in the field [1,24]. Encouraging reproducible research by sharing simulation files and code, ideally through repositories, is essential for advancing the field [1].​  

In conclusion, PFM is a mature yet continuously evolving simulation method that has played a significant role in the study o material microstructure evolution, despite inherent imperfections in some multiphase models [4]. Its potential for future applications in materials science and engineering remains vast, particularly in areas requiring quantitative descriptions of phase transformations and microstructure-property relationships [9,11]. Key areas of impact include optimizing material preparation processes, assisting in the design of new materials and alloys, and understanding complex phenomena in functional materials like ferroelectrics and nuclear fuels [7,9,17,21]. Realizing this potential fully necessitates continued research and development to address remaining challenges, including computational efficiency, model accuracy, theoretical foundations, and seamless integration with experimental data and other computational methods [1,16,18]. Continued efforts in PFM are crucial for accelerating materials design and optimization to meet future technological demands [1,18].​  

# References  

[5] 基于图网络的增材制造相场模拟加速研究 https://baijiahao.baidu.com/s?id $=$ 1793572341220563055&wfr=spider&for=pc​   
[6] 相场法在材料科学与工程中的应用：理论、模拟及挑战 https://www.bilibili.com/read/cv18430483/   
[7] 铁电晶体畴的热力学与相场法 https://www.mse.tsinghua.edu.cn/info/1063/3325.htm​   
[8] 铁电薄膜畴尺寸效应对介电和压电响应的相场模拟研究 https://mp.weixin.qq.com/s? _biz=MzkyMTM4ODE5Mg==&mid=2247520598&idx $: =$ 1&sn=fd52c3246dab78d13b78d5f295f734a4&chksm=c1868499f6f10d8f   
cf3b01b6ede0a1276dc729a1a22b8509bc290ba9b8c21921f8cf23118c4d&scene=27   
[9] Matlab相场法模拟合金定向凝固及增材制造应用 https://blog.csdn.net/qKEcsrqMPW/article/details/139641912​   
[10] Programming Phase-Field Modeling: A Practical Guid https://www.mathworks.com/academia/books/programming  
phase-field-modeling-biner.html​   
[11] 相场法：交叉学科的材料模拟方法 https://baike.baidu.com/item/%E7%9B%B8%E5%9C%BA%E6%B3%95/12706200   
[12] OpenPhase相场模拟学习及温度场数值模拟课题设计 https://blog.csdn.net/weixin_30260399/article/details/95161540   
[13] 相场模拟：原理、类型与应用 https://baike.baidu.com/item/相场模拟/22174310​   
[14] Phase-Field Modeling of Ferroelectric Materials http://cn.comsol.com/paper/phasefield-modeling-of-ferroelectric  
materials-7242​   
[15] 汤涛院士：相场方法模型、数值与理论 https://rcm.uic.edu.cn/info/1017/1054.htm   
[16] ML-Accelerated Phase-Field Microstructure Evolutio https://www.nature.com/articles/s41524-020-00471-8   
[17] Phase-Field Study of Stress and Fission Rate Effec https://www.frontiersin.org/articles/10.3389/fenrg.2023.1092433/full   
[18] Phase-Field Simulations for Understanding and Desi https://www.nature.com/articles/s41524-023-01038-z​   
[19] U3Si2燃料孔隙演化三维相场模拟研究 https://d.wanfangdata.com.cn/periodical/yznkxjs2023z1018​   
[20] Multi-Scale Computation for Lithium-Ion Battery R& https://cpb.iphy.ac.cn/article/2016/1806/cpb_25_1_018212.html​   
[21] Acta Mater. 2020 Vol.197金属材料顶刊双语导读 http://www.gs-metals.com/News/desc/id/81/sid/169.html?   
xx/wap/thread/view-thread/tid/eq8Fg=.pptx93921   
[22] 金属凝固过程微观组织演化相场模型研究进展 http://ijmmm.ustb.edu.cn/cn/article/doi/10.1007/s12613-023-2710-x   
[23] 力学相关科研成果（专著及论文列表） https://aml.cic.tsinghua.edu.cn/column/lwlz​   
[24] OpenPhase：相场模拟开源项目及示例解析 https://blog.csdn.net/weixin_34242658/article/details/86358430​   
[25] 相变储热与卡诺电池研究进展综述 https://m.elecfans.com/article/2083264.html​   
[26] 材料科学与工程中的相图与相场方法 https://www.las.ac.cn/front/book/detail?id=ba193b2ee41a2f16a7715f767023ad0f   
[27] 相场法数值模拟简介 https://www.renrendoc.com/paper/159268163.html​   
[28] Nature级仿真技术：深度学习助力流体力学、固体力学及岩土工程 https://mp.weixin.qq.com/s? _biz=MzA4NzI1NjE0Nw $\scriptstyle 1 = =$ &mid=2649813552&idx=1&sn $\mid =$ d97ef116ed2c4c245b294e054b3f0f90&chksm $\mid =$ 89e5a9cbff8216ed7e   
5006e7beaca510a776034083fbba012856d57f3b5d4e10b8314fac0f34&scene=27   
[29] 相场法简介 (2023-12-06) https://wenku.baidu.com/view/e431be450f22590102020740be1e650e52eacfe6.html​  